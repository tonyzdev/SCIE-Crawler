[
  {
    "title": "LIBSVM",
    "doi": "https://doi.org/10.1145/1961189.1961199",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Chih-Chung Chang; Chih‐Jen Lin",
    "corresponding_authors": "",
    "abstract": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",
    "cited_by_count": 41201,
    "openalex_id": "https://openalex.org/W2153635508",
    "type": "article"
  },
  {
    "title": "Federated Machine Learning",
    "doi": "https://doi.org/10.1145/3298981",
    "publication_date": "2019-01-28",
    "publication_year": 2019,
    "authors": "Qiang Yang; Yang Liu; Tianjian Chen; Yongxin Tong",
    "corresponding_authors": "",
    "abstract": "Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.",
    "cited_by_count": 4511,
    "openalex_id": "https://openalex.org/W2912213068",
    "type": "article"
  },
  {
    "title": "Trajectory Data Mining",
    "doi": "https://doi.org/10.1145/2743025",
    "publication_date": "2015-05-12",
    "publication_year": 2015,
    "authors": "Yu Zheng",
    "corresponding_authors": "Yu Zheng",
    "abstract": "The advances in location-acquisition and mobile computing techniques have generated massive spatial trajectory data, which represent the mobility of a diversity of moving objects, such as people, vehicles, and animals. Many techniques have been proposed for processing, managing, and mining trajectory data in the past decade, fostering a broad range of applications. In this article, we conduct a systematic survey on the major research into trajectory data mining , providing a panorama of the field as well as the scope of its research topics. Following a road map from the derivation of trajectory data, to trajectory data preprocessing, to trajectory data management, and to a variety of mining tasks (such as trajectory pattern mining, outlier detection, and trajectory classification), the survey explores the connections, correlations, and differences among these existing techniques. This survey also introduces the methods that transform trajectories into other data formats, such as graphs, matrices, and tensors, to which more data mining and machine learning techniques can be applied. Finally, some public trajectory datasets are presented. This survey can help shape the field of trajectory data mining , providing a quick understanding of this field to the community.",
    "cited_by_count": 1501,
    "openalex_id": "https://openalex.org/W2126194848",
    "type": "article"
  },
  {
    "title": "Factorization Machines with libFM",
    "doi": "https://doi.org/10.1145/2168752.2168771",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Steffen Rendle",
    "corresponding_authors": "Steffen Rendle",
    "abstract": "Factorization approaches provide high accuracy in several important prediction problems, for example, recommender systems. However, applying factorization approaches to a new prediction problem is a nontrivial task and requires a lot of expert knowledge. Typically, a new model is developed, a learning algorithm is derived, and the approach has to be implemented. Factorization machines (FM) are a generic approach since they can mimic most factorization models just by feature engineering. This way, factorization machines combine the generality of feature engineering with the superiority of factorization models in estimating interactions between categorical variables of large domain. libFM is a software implementation for factorization machines that features stochastic gradient descent (SGD) and alternating least-squares (ALS) optimization, as well as Bayesian inference using Markov Chain Monto Carlo (MCMC). This article summarizes the recent research on factorization machines both in terms of modeling and learning, provides extensions for the ALS and MCMC algorithms, and describes the software tool libFM .",
    "cited_by_count": 1354,
    "openalex_id": "https://openalex.org/W2094286023",
    "type": "article"
  },
  {
    "title": "Urban Computing",
    "doi": "https://doi.org/10.1145/2629592",
    "publication_date": "2014-09-18",
    "publication_year": 2014,
    "authors": "Yu Zheng; Licia Capra; Ouri Wolfson; Hai Yang",
    "corresponding_authors": "",
    "abstract": "Urbanization's rapid progress has modernized many people's lives but also engendered big issues, such as traffic congestion, energy consumption, and pollution. Urban computing aims to tackle these issues by using the data that has been generated in cities (e.g., traffic flow, human mobility, and geographical data). Urban computing connects urban sensing, data management, data analytics, and service providing into a recurrent process for an unobtrusive and continuous improvement of people's lives, city operation systems, and the environment. Urban computing is an interdisciplinary field where computer sciences meet conventional city-related fields, like transportation, civil engineering, environment, economy, ecology, and sociology in the context of urban spaces. This article first introduces the concept of urban computing, discussing its general framework and key challenges from the perspective of computer sciences. Second, we classify the applications of urban computing into seven categories, consisting of urban planning, transportation, the environment, energy, social, economy, and public safety and security, presenting representative scenarios in each category. Third, we summarize the typical technologies that are needed in urban computing into four folds, which are about urban sensing, urban data management, knowledge fusion across heterogeneous data, and urban data visualization. Finally, we give an outlook on the future of urban computing, suggesting a few research topics that are somehow missing in the community.",
    "cited_by_count": 1237,
    "openalex_id": "https://openalex.org/W2112738128",
    "type": "article"
  },
  {
    "title": "A Survey on Evaluation of Large Language Models",
    "doi": "https://doi.org/10.1145/3641289",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "Yupeng Chang; Xu Wang; Jindong Wang; Yuan Wu; Linyi Yang; Kaijie Zhu; Hao Chen; Xiaoyuan Yi; Cunxiang Wang; Yidong Wang; Wei Ye; Yue Zhang; Yi Chang; Philip S. Yu; Qiang Yang; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate , where to evaluate , and how to evaluate . Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey",
    "cited_by_count": 1198,
    "openalex_id": "https://openalex.org/W4391136507",
    "type": "article"
  },
  {
    "title": "SNAP",
    "doi": "https://doi.org/10.1145/2898361",
    "publication_date": "2016-07-15",
    "publication_year": 2016,
    "authors": "Jure Leskovec; Rok Sosič",
    "corresponding_authors": "",
    "abstract": "Large networks are becoming a widely used abstraction for studying complex systems in a broad set of disciplines, ranging from social network analysis to molecular biology and neuroscience. Despite an increasing need to analyze and manipulate large networks, only a limited number of tools are available for this task. Here, we describe Stanford Network Analysis Platform (SNAP), a general-purpose, high-performance system that provides easy to use, high-level operations for analysis and manipulation of large networks. We present SNAP functionality, describe its implementational details, and give performance benchmarks. SNAP has been developed for single big-memory machines and it balances the trade-off between maximum performance, compact in-memory graph representation, and the ability to handle dynamic graphs where nodes and edges are being added or removed over time. SNAP can process massive networks with hundreds of millions of nodes and billions of edges. SNAP offers over 140 different graph algorithms that can efficiently manipulate large graphs, calculate structural properties, generate regular and random graphs, and handle attributes and meta-data on nodes and edges. Besides being able to handle large graphs, an additional strength of SNAP is that networks and their attributes are fully dynamic, they can be modified during the computation at low cost. SNAP is provided as an open source library in C++ as well as a module in Python. We also describe the Stanford Large Network Dataset, a set of social and information real-world networks and datasets, which we make publicly available. The collection is a complementary resource to our SNAP software and is widely used for development and benchmarking of graph analytics algorithms.",
    "cited_by_count": 781,
    "openalex_id": "https://openalex.org/W2469279958",
    "type": "article"
  },
  {
    "title": "A Survey of Unsupervised Deep Domain Adaptation",
    "doi": "https://doi.org/10.1145/3400066",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Garrett Wilson; Diane J. Cook",
    "corresponding_authors": "",
    "abstract": "Deep learning has produced state-of-the-art results for a variety of tasks. While such approaches for supervised learning have performed well, they assume that training and testing data are drawn from the same distribution, which may not always be the case. As a complement to this challenge, single-source unsupervised domain adaptation can handle situations where a network is trained on labeled data from a source domain and unlabeled data from a related but different target domain with the goal of performing well at test-time on the target domain. Many single-source and typically homogeneous unsupervised deep domain adaptation approaches have thus been developed, combining the powerful, hierarchical representations from deep learning with domain adaptation to reduce reliance on potentially costly target data labels. This survey will compare these approaches by examining alternative methods, the unique and common elements, results, and theoretical insights. We follow this with a look at application areas and open research directions.",
    "cited_by_count": 729,
    "openalex_id": "https://openalex.org/W3039883906",
    "type": "article"
  },
  {
    "title": "A survey of appearance models in visual object tracking",
    "doi": "https://doi.org/10.1145/2508037.2508039",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Xi Li; Weiming Hu; Chunhua Shen; Zhongfei Zhang; Anthony Dick; Anton van den Hengel",
    "corresponding_authors": "",
    "abstract": "Visual object tracking is a significant computer vision task which can be applied to many domains, such as visual surveillance, human computer interaction, and video compression. Despite extensive research on this topic, it still suffers from difficulties in handling complex object appearance changes caused by factors such as illumination variation, partial occlusion, shape deformation, and camera motion. Therefore, effective modeling of the 2D appearance of tracked objects is a key issue for the success of a visual tracker. In the literature, researchers have proposed a variety of 2D appearance models. To help readers swiftly learn the recent advances in 2D appearance models for visual object tracking, we contribute this survey, which provides a detailed review of the existing 2D appearance models. In particular, this survey takes a module-based architecture that enables readers to easily grasp the key points of visual object tracking. In this survey, we first decompose the problem of appearance modeling into two different processing stages: visual representation and statistical modeling. Then, different 2D appearance models are categorized and discussed with respect to their composition modules. Finally, we address several issues of interest as well as the remaining challenges for future research on this topic. The contributions of this survey are fourfold. First, we review the literature of visual representations according to their feature-construction mechanisms (i.e., local and global). Second, the existing statistical modeling schemes for tracking-by-detection are reviewed according to their model-construction mechanisms: generative, discriminative, and hybrid generative-discriminative. Third, each type of visual representations or statistical modeling techniques is analyzed and discussed from a theoretical or practical viewpoint. Fourth, the existing benchmark resources (e.g., source codes and video datasets) are examined in this survey.",
    "cited_by_count": 725,
    "openalex_id": "https://openalex.org/W1984914017",
    "type": "article"
  },
  {
    "title": "Comparison and Modelling of Country-level Microblog User and Activity in Cyber-physical-social Systems Using Weibo and Twitter Data",
    "doi": "https://doi.org/10.1145/3339474",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Po Yang; Jing Liu; Jun Qi; Yun Yang; Xulong Wang; Zhihan Lv",
    "corresponding_authors": "",
    "abstract": "As the rapid growth of social media technologies continues, Cyber-Physical-Social System (CPSS) has been a hot topic in many industrial applications. The use of “microblogging” services, such as Twitter, has rapidly become an influential way to share information. While recent studies have revealed that understanding and modelling microblog user behaviour with massive users’ data in social media are keen to success of many practical applications in CPSS, a key challenge in literatures is that diversity of geography and cultures in social media technologies strongly affect user behaviour and activity. The motivation of this article is to understand differences and similarities between microblogging users from different countries using social media technologies, and to attempt to design a Country-Level Micro-Blog User (CLMB) behaviour and activity model for supporting CPSS applications. We proposed a CLMB model for analysing microblogging user behaviour and their activity across different countries in the CPSS applications. The model has considered three important characteristics of user behaviour in microblogging data, including content of microblogging messages, user emotion index, and user relationship network. We evaluated CLBM model under the collected microblog dataset from 16 countries with the largest number of representative and active users in the world. Experimental results show that (1) for some countries with small population and strong cohesiveness, users pay more attention to social functionalities of microblogging service; (2) for some countries containing mostly large loose social groups, users use microblogging services as a news dissemination platform; (3) users in countries whose social network structure exhibits reciprocity rather than hierarchy will use more linguistic elements to express happiness in microblogging services.",
    "cited_by_count": 547,
    "openalex_id": "https://openalex.org/W2995191368",
    "type": "article"
  },
  {
    "title": "Learning <i>k</i> for kNN Classification",
    "doi": "https://doi.org/10.1145/2990508",
    "publication_date": "2017-01-12",
    "publication_year": 2017,
    "authors": "Shichao Zhang; Xuelong Li; Ming Zong; Xiaofeng Zhu; Debo Cheng",
    "corresponding_authors": "",
    "abstract": "The K Nearest Neighbor (kNN) method has widely been used in the applications of data mining and machine learning due to its simple implementation and distinguished performance. However, setting all test data with the same k value in the previous kNN methods has been proven to make these methods impractical in real applications. This article proposes to learn a correlation matrix to reconstruct test data points by training data to assign different k values to different test data points, referred to as the Correlation Matrix kNN (CM-kNN for short) classification. Specifically, the least-squares loss function is employed to minimize the reconstruction error to reconstruct each test data point by all training data points. Then, a graph Laplacian regularizer is advocated to preserve the local structure of the data in the reconstruction process. Moreover, an ℓ 1 -norm regularizer and an ℓ 2, 1 -norm regularizer are applied to learn different k values for different test data and to result in low sparsity to remove the redundant/noisy feature from the reconstruction process, respectively. Besides for classification tasks, the kNN methods (including our proposed CM-kNN method) are further utilized to regression and missing data imputation. We conducted sets of experiments for illustrating the efficiency, and experimental results showed that the proposed method was more accurate and efficient than existing kNN methods in data-mining applications, such as classification, regression, and missing data imputation.",
    "cited_by_count": 483,
    "openalex_id": "https://openalex.org/W2574388714",
    "type": "article"
  },
  {
    "title": "An Attentive Survey of Attention Models",
    "doi": "https://doi.org/10.1145/3465055",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Sneha Chaudhari; Varun Mithal; Gungor Polatkan; Rohan Ramanath",
    "corresponding_authors": "",
    "abstract": "Attention Model has now become an important concept in neural networks that has been researched within diverse application domains. This survey provides a structured and comprehensive overview of the developments in modeling attention. In particular, we propose a taxonomy that groups existing techniques into coherent categories. We review salient neural architectures in which attention has been incorporated and discuss applications in which modeling attention has shown a significant impact. We also describe how attention has been used to improve the interpretability of neural networks. Finally, we discuss some future research directions in attention. We hope this survey will provide a succinct introduction to attention models and guide practitioners while developing approaches for their applications.",
    "cited_by_count": 477,
    "openalex_id": "https://openalex.org/W3208624098",
    "type": "article"
  },
  {
    "title": "Combating Fake News",
    "doi": "https://doi.org/10.1145/3305260",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Karishma Sharma; Feng Qian; He Jiang; Natali Ruchansky; Ming Zhang; Yan Liu",
    "corresponding_authors": "",
    "abstract": "The proliferation of fake news on social media has opened up new directions of research for timely identification and containment of fake news and mitigation of its widespread impact on public opinion. While much of the earlier research was focused on identification of fake news based on its contents or by exploiting users’ engagements with the news on social media, there has been a rising interest in proactive intervention strategies to counter the spread of misinformation and its impact on society. In this survey, we describe the modern-day problem of fake news and, in particular, highlight the technical challenges associated with it. We discuss existing methods and techniques applicable to both identification and mitigation, with a focus on the significant advances in each method and their advantages and limitations. In addition, research has often been limited by the quality of existing datasets and their specific application contexts. To alleviate this problem, we comprehensively compile and summarize characteristic features of available datasets. Furthermore, we outline new directions of research to facilitate future development of effective and interdisciplinary solutions.",
    "cited_by_count": 447,
    "openalex_id": "https://openalex.org/W2911715381",
    "type": "article"
  },
  {
    "title": "A Survey of Zero-Shot Learning",
    "doi": "https://doi.org/10.1145/3293318",
    "publication_date": "2019-01-16",
    "publication_year": 2019,
    "authors": "Wei Wang; Vincent W. Zheng; Han Yu; Chunyan Miao",
    "corresponding_authors": "",
    "abstract": "Most machine-learning methods focus on classifying instances whose classes have already been seen in training. In practice, many applications require classifying instances whose classes have not been seen previously. Zero-shot learning is a powerful and promising learning paradigm, in which the classes covered by training instances and the classes we aim to classify are disjoint. In this paper, we provide a comprehensive survey of zero-shot learning. First of all, we provide an overview of zero-shot learning. According to the data utilized in model optimization, we classify zero-shot learning into three learning settings. Second, we describe different semantic spaces adopted in existing zero-shot learning works. Third, we categorize existing zero-shot learning methods and introduce representative methods under each category. Fourth, we discuss different applications of zero-shot learning. Finally, we highlight promising future research directions of zero-shot learning.",
    "cited_by_count": 436,
    "openalex_id": "https://openalex.org/W2910453440",
    "type": "article"
  },
  {
    "title": "Learning travel recommendations from user-generated GPS traces",
    "doi": "https://doi.org/10.1145/1889681.1889683",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Yu Zheng; Xing Xie",
    "corresponding_authors": "",
    "abstract": "The advance of GPS-enabled devices allows people to record their location histories with GPS traces, which imply human behaviors and preferences related to travel. In this article, we perform two types of travel recommendations by mining multiple users' GPS traces. The first is a generic one that recommends a user with top interesting locations and travel sequences in a given geospatial region. The second is a personalized recommendation that provides an individual with locations matching her travel preferences. To achieve the first recommendation, we model multiple users' location histories with a tree-based hierarchical graph ( TBHG ). Based on the TBHG , we propose a HITS (Hypertext Induced Topic Search)-based model to infer the interest level of a location and a user's travel experience (knowledge). In the personalized recommendation, we first understand the correlation between locations, and then incorporate this correlation into a collaborative filtering (CF)-based model, which predicts a user's interests in an unvisited location based on her locations histories and that of others. We evaluated our system based on a real-world GPS trace dataset collected by 107 users over a period of one year. As a result, our HITS-based inference model outperformed baseline approaches like rank-by-count and rank-by-frequency . Meanwhile, we achieved a better performance in recommending travel sequences beyond baselines like rank-by-count . Regarding the personalized recommendation, our approach is more effective than the weighted Slope One algorithm with a slightly additional computation, and is more efficient than the Pearson correlation-based CF model with the similar effectiveness.",
    "cited_by_count": 395,
    "openalex_id": "https://openalex.org/W1995103535",
    "type": "article"
  },
  {
    "title": "Adversarial Attacks on Deep-learning Models in Natural Language Processing",
    "doi": "https://doi.org/10.1145/3374217",
    "publication_date": "2020-04-03",
    "publication_year": 2020,
    "authors": "Wei Emma Zhang; Quan Z. Sheng; Ahoud Alhazmi; Chenliang Li",
    "corresponding_authors": "",
    "abstract": "With the development of high computational devices, deep neural networks (DNNs), in recent years, have gained significant popularity in many Artificial Intelligence (AI) applications. However, previous efforts have shown that DNNs are vulnerable to strategically modified samples, named adversarial examples . These samples are generated with some imperceptible perturbations, but can fool the DNNs to give false predictions. Inspired by the popularity of generating adversarial examples against DNNs in Computer Vision (CV), research efforts on attacking DNNs for Natural Language Processing (NLP) applications have emerged in recent years. However, the intrinsic difference between image (CV) and text (NLP) renders challenges to directly apply attacking methods in CV to NLP. Various methods are proposed addressing this difference and attack a wide range of NLP applications. In this article, we present a systematic survey on these works. We collect all related academic works since the first appearance in 2017. We then select, summarize, discuss, and analyze 40 representative works in a comprehensive way. To make the article self-contained, we cover preliminary knowledge of NLP and discuss related seminal works in computer vision. We conclude our survey with a discussion on open issues to bridge the gap between the existing progress and more robust adversarial attacks on NLP DNNs.",
    "cited_by_count": 382,
    "openalex_id": "https://openalex.org/W3015001695",
    "type": "article"
  },
  {
    "title": "Machine Recognition of Music Emotion",
    "doi": "https://doi.org/10.1145/2168752.2168754",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Yi‐Hsuan Yang; Homer H. Chen",
    "corresponding_authors": "",
    "abstract": "The proliferation of MP3 players and the exploding amount of digital music content call for novel ways of music organization and retrieval to meet the ever-increasing demand for easy and effective information access. As almost every music piece is created to convey emotion, music organization and retrieval by emotion is a reasonable way of accessing music information. A good deal of effort has been made in the music information retrieval community to train a machine to automatically recognize the emotion of a music signal. A central issue of machine recognition of music emotion is the conceptualization of emotion and the associated emotion taxonomy. Different viewpoints on this issue have led to the proposal of different ways of emotion annotation, model training, and result visualization. This article provides a comprehensive review of the methods that have been proposed for music emotion recognition. Moreover, as music emotion recognition is still in its infancy, there are many open issues. We review the solutions that have been proposed to address these issues and conclude with suggestions for further research.",
    "cited_by_count": 357,
    "openalex_id": "https://openalex.org/W1983507146",
    "type": "article"
  },
  {
    "title": "Federated Learning for Healthcare: Systematic Review and Architecture Proposal",
    "doi": "https://doi.org/10.1145/3501813",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Rodolfo Stoffel Antunes; Cristiano André da Costa; Arne Küderle; Imrana Abdullahi Yari; Bjoern M. Eskofier",
    "corresponding_authors": "",
    "abstract": "The use of machine learning (ML) with electronic health records (EHR) is growing in popularity as a means to extract knowledge that can improve the decision-making process in healthcare. Such methods require training of high-quality learning models based on diverse and comprehensive datasets, which are hard to obtain due to the sensitive nature of medical data from patients. In this context, federated learning (FL) is a methodology that enables the distributed training of machine learning models with remotely hosted datasets without the need to accumulate data and, therefore, compromise it. FL is a promising solution to improve ML-based systems, better aligning them to regulatory requirements, improving trustworthiness and data sovereignty. However, many open questions must be addressed before the use of FL becomes widespread. This article aims at presenting a systematic literature review on current research about FL in the context of EHR data for healthcare applications. Our analysis highlights the main research topics, proposed solutions, case studies, and respective ML methods. Furthermore, the article discusses a general architecture for FL applied to healthcare data based on the main insights obtained from the literature review. The collected literature corpus indicates that there is extensive research on the privacy and confidentiality aspects of training data and model sharing, which is expected given the sensitive nature of medical data. Studies also explore improvements to the aggregation mechanisms required to generate the learning model from distributed contributions and case studies with different types of medical data.",
    "cited_by_count": 357,
    "openalex_id": "https://openalex.org/W4214758645",
    "type": "article"
  },
  {
    "title": "Social Network Analysis and Mining for Business Applications",
    "doi": "https://doi.org/10.1145/1961189.1961194",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Francesco Bonchi; Carlos Castillo; Aristides Gionis; Alejandro Jaimes",
    "corresponding_authors": "",
    "abstract": "Social network analysis has gained significant attention in recent years, largely due to the success of online social networking and media-sharing sites, and the consequent availability of a wealth of social network data. In spite of the growing interest, however, there is little understanding of the potential business applications of mining social networks. While there is a large body of research on different problems and methods for social network mining, there is a gap between the techniques developed by the research community and their deployment in real-world applications. Therefore the potential business impact of these techniques is still largely unexplored. In this article we use a business process classification framework to put the research topics in a business context and provide an overview of what we consider key problems and techniques in social network analysis and mining from the perspective of business applications. In particular, we discuss data acquisition and preparation, trust, expertise, community structure, network dynamics, and information propagation. In each case we present a brief overview of the problem, describe state-of-the art approaches, discuss business application examples, and map each of the topics to a business process classification framework. In addition, we provide insights on prospective business applications, challenges, and future research directions. The main contribution of this article is to provide a state-of-the-art overview of current techniques while providing a critical perspective on business applications of social network analysis and mining.",
    "cited_by_count": 349,
    "openalex_id": "https://openalex.org/W2047624089",
    "type": "article"
  },
  {
    "title": "Tensors for Data Mining and Data Fusion",
    "doi": "https://doi.org/10.1145/2915921",
    "publication_date": "2016-10-03",
    "publication_year": 2016,
    "authors": "Evangelos E. Papalexakis; Christos Faloutsos; Nicholas D. Sidiropoulos",
    "corresponding_authors": "",
    "abstract": "Tensors and tensor decompositions are very powerful and versatile tools that can model a wide variety of heterogeneous, multiaspect data. As a result, tensor decompositions, which extract useful latent information out of multiaspect data tensors, have witnessed increasing popularity and adoption by the data mining community. In this survey, we present some of the most widely used tensor decompositions, providing the key insights behind them, and summarizing them from a practitioner’s point of view. We then provide an overview of a very broad spectrum of applications where tensors have been instrumental in achieving state-of-the-art performance, ranging from social network analysis to brain data analysis, and from web mining to healthcare. Subsequently, we present recent algorithmic advances in scaling tensor decompositions up to today’s big data, outlining the existing systems and summarizing the key ideas behind them. Finally, we conclude with a list of challenges and open problems that outline exciting future research directions.",
    "cited_by_count": 333,
    "openalex_id": "https://openalex.org/W2528907418",
    "type": "article"
  },
  {
    "title": "Simple and Scalable Response Prediction for Display Advertising",
    "doi": "https://doi.org/10.1145/2532128",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Olivier Chapelle; Eren Manavoglu; Rómer Rosales",
    "corresponding_authors": "",
    "abstract": "Clickthrough and conversation rates estimation are two core predictions tasks in display advertising. We present in this article a machine learning framework based on logistic regression that is specifically designed to tackle the specifics of display advertising. The resulting system has the following characteristics: It is easy to implement and deploy, it is highly scalable (we have trained it on terabytes of data), and it provides models with state-of-the-art accuracy.",
    "cited_by_count": 322,
    "openalex_id": "https://openalex.org/W1985759455",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Pose-Invariant Face Recognition",
    "doi": "https://doi.org/10.1145/2845089",
    "publication_date": "2016-02-11",
    "publication_year": 2016,
    "authors": "Changxing Ding; Dacheng Tao",
    "corresponding_authors": "",
    "abstract": "The capacity to recognize faces under varied poses is a fundamental human ability that presents a unique challenge for computer vision systems. Compared to frontal face recognition, which has been intensively studied and has gradually matured in the past few decades, Pose-Invariant Face Recognition (PIFR) remains a largely unsolved problem. However, PIFR is crucial to realizing the full potential of face recognition for real-world applications, since face recognition is intrinsically a passive biometric technology for recognizing uncooperative subjects. In this article, we discuss the inherent difficulties in PIFR and present a comprehensive review of established techniques. Existing PIFR methods can be grouped into four categories, that is, pose-robust feature extraction approaches, multiview subspace learning approaches, face synthesis approaches, and hybrid approaches. The motivations, strategies, pros/cons, and performance of representative approaches are described and compared. Moreover, promising directions for future research are discussed.",
    "cited_by_count": 320,
    "openalex_id": "https://openalex.org/W9976222",
    "type": "article"
  },
  {
    "title": "A Survey on Text Classification: From Traditional to Deep Learning",
    "doi": "https://doi.org/10.1145/3495162",
    "publication_date": "2022-04-08",
    "publication_year": 2022,
    "authors": "Qian Li; Hao Peng; Jianxin Li; Congying Xia; Renyu Yang; Lichao Sun; Philip S. Yu; Lifang He",
    "corresponding_authors": "",
    "abstract": "Text classification is the most fundamental and essential task in natural language processing. The last decade has seen a surge of research in this area due to the unprecedented success of deep learning. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. This paper fills the gap by reviewing the state-of-the-art approaches from 1961 to 2021, focusing on models from traditional models to deep learning. We create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. We then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions. A comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey. Finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area.",
    "cited_by_count": 315,
    "openalex_id": "https://openalex.org/W4226418765",
    "type": "article"
  },
  {
    "title": "Participatory Cultural Mapping Based on Collective Behavior Data in Location-Based Social Networks",
    "doi": "https://doi.org/10.1145/2814575",
    "publication_date": "2016-01-22",
    "publication_year": 2016,
    "authors": "Dingqi Yang; Daqing Zhang; Bingqing Qu",
    "corresponding_authors": "",
    "abstract": "Culture has been recognized as a driving impetus for human development. It co-evolves with both human belief and behavior. When studying culture, Cultural Mapping is a crucial tool to visualize different aspects of culture (e.g., religions and languages) from the perspectives of indigenous and local people. Existing cultural mapping approaches usually rely on large-scale survey data with respect to human beliefs, such as moral values. However, such a data collection method not only incurs a significant cost of both human resources and time, but also fails to capture human behavior, which massively reflects cultural information. In addition, it is practically difficult to collect large-scale human behavior data. Fortunately, with the recent boom in Location-Based Social Networks (LBSNs), a considerable number of users report their activities in LBSNs in a participatory manner, which provides us with an unprecedented opportunity to study large-scale user behavioral data. In this article, we propose a participatory cultural mapping approach based on collective behavior in LBSNs. First, we collect the participatory sensed user behavioral data from LBSNs. Second, since only local users are eligible for cultural mapping, we propose a progressive “home” location identification method to filter out ineligible users. Third, by extracting three key cultural features from daily activity, mobility, and linguistic perspectives, respectively, we propose a cultural clustering method to discover cultural clusters. Finally, we visualize the cultural clusters on the world map. Based on a real-world LBSN dataset, we experimentally validate our approach by conducting both qualitative and quantitative analysis on the generated cultural maps. The results show that our approach can subtly capture cultural features and generate representative cultural maps that correspond well with traditional cultural maps based on survey data.",
    "cited_by_count": 285,
    "openalex_id": "https://openalex.org/W2329660289",
    "type": "article"
  },
  {
    "title": "Deep Learning for Environmentally Robust Speech Recognition",
    "doi": "https://doi.org/10.1145/3178115",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Zixing Zhang; Jürgen T. Geiger; Jouni Pohjalainen; Amr El-Desoky Mousa; Wenyu Jin; Björn W. Schuller",
    "corresponding_authors": "",
    "abstract": "Eliminating the negative effect of non-stationary environmental noise is a long-standing research topic for automatic speech recognition but still remains an important challenge. Data-driven supervised approaches, especially the ones based on deep neural networks, have recently emerged as potential alternatives to traditional unsupervised approaches and with sufficient training, can alleviate the shortcomings of the unsupervised methods in various real-life acoustic environments. In this light, we review recently developed, representative deep learning approaches for tackling non-stationary additive and convolutional degradation of speech with the aim of providing guidelines for those involved in the development of environmentally robust speech recognition systems. We separately discuss single- and multi-channel techniques developed for the front-end and back-end of speech recognition systems, as well as joint front-end and back-end training frameworks. In the meanwhile, we discuss the pros and cons of these approaches and provide their experimental results on benchmark databases. We expect that this overview can facilitate the development of the robustness of speech recognition systems in acoustic noisy environments.",
    "cited_by_count": 279,
    "openalex_id": "https://openalex.org/W2618099328",
    "type": "article"
  },
  {
    "title": "Explainability for Large Language Models: A Survey",
    "doi": "https://doi.org/10.1145/3639372",
    "publication_date": "2024-01-02",
    "publication_year": 2024,
    "authors": "Haiyan Zhao; Hanjie Chen; Fan Yang; Ninghao Liu; Huiqi Deng; Hengyi Cai; Shuaiqiang Wang; Dawei Yin; Mengnan Du",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.",
    "cited_by_count": 274,
    "openalex_id": "https://openalex.org/W4390490761",
    "type": "article"
  },
  {
    "title": "Deep Reinforcement Learning for Vehicular Edge Computing",
    "doi": "https://doi.org/10.1145/3317572",
    "publication_date": "2019-10-18",
    "publication_year": 2019,
    "authors": "Zhaolong Ning; Peiran Dong; Xiaojie Wang; Joel J. P. C. Rodrigues; Feng Xia",
    "corresponding_authors": "",
    "abstract": "The development of smart vehicles brings drivers and passengers a comfortable and safe environment. Various emerging applications are promising to enrich users’ traveling experiences and daily life. However, how to execute computing-intensive applications on resource-constrained vehicles still faces huge challenges. In this article, we construct an intelligent offloading system for vehicular edge computing by leveraging deep reinforcement learning. First, both the communication and computation states are modelled by finite Markov chains. Moreover, the task scheduling and resource allocation strategy is formulated as a joint optimization problem to maximize users’ Quality of Experience (QoE). Due to its complexity, the original problem is further divided into two sub-optimization problems. A two-sided matching scheme and a deep reinforcement learning approach are developed to schedule offloading requests and allocate network resources, respectively. Performance evaluations illustrate the effectiveness and superiority of our constructed system.",
    "cited_by_count": 265,
    "openalex_id": "https://openalex.org/W2980360843",
    "type": "article"
  },
  {
    "title": "Discovering routines from large-scale human locations using probabilistic topic models",
    "doi": "https://doi.org/10.1145/1889681.1889684",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Katayoun Farrahi; Daniel Gática-Pérez",
    "corresponding_authors": "",
    "abstract": "In this work, we discover the daily location-driven routines that are contained in a massive real-life human dataset collected by mobile phones. Our goal is the discovery and analysis of human routines that characterize both individual and group behaviors in terms of location patterns. We develop an unsupervised methodology based on two differing probabilistic topic models and apply them to the daily life of 97 mobile phone users over a 16-month period to achieve these goals. Topic models are probabilistic generative models for documents that identify the latent structure that underlies a set of words. Routines dominating the entire group's activities, identified with a methodology based on the Latent Dirichlet Allocation topic model, include “going to work late”, “going home early”, “working nonstop” and “having no reception (phone off)” at different times over varying time-intervals. We also detect routines which are characteristic of users, with a methodology based on the Author-Topic model. With the routines discovered, and the two methods of characterizing days and users, we can then perform various tasks. We use the routines discovered to determine behavioral patterns of users and groups of users. For example, we can find individuals that display specific daily routines, such as “going to work early” or “turning off the mobile (or having no reception) in the evenings”. We are also able to characterize daily patterns by determining the topic structure of days in addition to determining whether certain routines occur dominantly on weekends or weekdays. Furthermore, the routines discovered can be used to rank users or find subgroups of users who display certain routines. We can also characterize users based on their entropy. We compare our method to one based on clustering using K-means. Finally, we analyze an individual's routines over time to determine regions with high variations, which may correspond to specific events.",
    "cited_by_count": 243,
    "openalex_id": "https://openalex.org/W1988545169",
    "type": "article"
  },
  {
    "title": "Image annotation by <i>k</i> NN-sparse graph-based label propagation over noisily tagged web images",
    "doi": "https://doi.org/10.1145/1899412.1899418",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Jinhui Tang; Richang Hong; Shuicheng Yan; Tat‐Seng Chua; Guo-Jun Qi; Ramesh Jain",
    "corresponding_authors": "",
    "abstract": "In this article, we exploit the problem of annotating a large-scale image corpus by label propagation over noisily tagged web images. To annotate the images more accurately, we propose a novel k NN-sparse graph-based semi-supervised learning approach for harnessing the labeled and unlabeled data simultaneously. The sparse graph constructed by datum-wise one-vs- k NN sparse reconstructions of all samples can remove most of the semantically unrelated links among the data, and thus it is more robust and discriminative than the conventional graphs. Meanwhile, we apply the approximate k nearest neighbors to accelerate the sparse graph construction without loosing its effectiveness. More importantly, we propose an effective training label refinement strategy within this graph-based learning framework to handle the noise in the training labels, by bringing in a dual regularization for both the quantity and sparsity of the noise. We conduct extensive experiments on a real-world image database consisting of 55,615 Flickr images and noisily tagged training labels. The results demonstrate both the effectiveness and efficiency of the proposed approach and its capability to deal with the noise in the training labels.",
    "cited_by_count": 238,
    "openalex_id": "https://openalex.org/W1968555645",
    "type": "article"
  },
  {
    "title": "Transfer Learning with Dynamic Distribution Adaptation",
    "doi": "https://doi.org/10.1145/3360309",
    "publication_date": "2020-02-06",
    "publication_year": 2020,
    "authors": "Jindong Wang; Yiqiang Chen; Wenjie Feng; Han Yu; Meiyu Huang; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Transfer learning aims to learn robust classifiers for the target domain by leveraging knowledge from a source domain. Since the source and the target domains are usually from different distributions, existing methods mainly focus on adapting the cross-domain marginal or conditional distributions. However, in real applications, the marginal and conditional distributions usually have different contributions to the domain discrepancy. Existing methods fail to quantitatively evaluate the different importance of these two distributions, which will result in unsatisfactory transfer performance. In this paper, we propose a novel concept called Dynamic Distribution Adaptation (DDA), which is capable of quantitatively evaluating the relative importance of each distribution. DDA can be easily incorporated into the framework of structural risk minimization to solve transfer learning problems. On the basis of DDA, we propose two novel learning algorithms: (1) Manifold Dynamic Distribution Adaptation (MDDA) for traditional transfer learning, and (2) Dynamic Distribution Adaptation Network (DDAN) for deep transfer learning. Extensive experiments demonstrate that MDDA and DDAN significantly improve the transfer learning performance and setup a strong baseline over the latest deep and adversarial methods on digits recognition, sentiment analysis, and image classification. More importantly, it is shown that marginal and conditional distributions have different contributions to the domain divergence, and our DDA is able to provide good quantitative evaluation of their relative importance which leads to better performance. We believe this observation can be helpful for future research in transfer learning.",
    "cited_by_count": 235,
    "openalex_id": "https://openalex.org/W3124219615",
    "type": "article"
  },
  {
    "title": "On Unexpectedness in Recommender Systems",
    "doi": "https://doi.org/10.1145/2559952",
    "publication_date": "2014-12-18",
    "publication_year": 2014,
    "authors": "Panagiotis Adamopoulos; Alexander Tuzhilin",
    "corresponding_authors": "",
    "abstract": "Although the broad social and business success of recommender systems has been achieved across several domains, there is still a long way to go in terms of user satisfaction. One of the key dimensions for significant improvement is the concept of unexpectedness . In this article, we propose a method to improve user satisfaction by generating unexpected recommendations based on the utility theory of economics. In particular, we propose a new concept of unexpectedness as recommending to users those items that depart from what they would expect from the system - the consideration set of each user. We define and formalize the concept of unexpectedness and discuss how it differs from the related notions of novelty, serendipity, and diversity. In addition, we suggest several mechanisms for specifying the users’ expectations and propose specific performance metrics to measure the unexpectedness of recommendation lists. We also take into consideration the quality of recommendations using certain utility functions and present an algorithm for providing users with unexpected recommendations of high quality that are hard to discover but fairly match their interests. Finally, we conduct several experiments on “real-world” datasets and compare our recommendation results with other methods. The proposed approach outperforms these baseline methods in terms of unexpectedness and other important metrics, such as coverage, aggregate diversity and dispersion, while avoiding any accuracy loss.",
    "cited_by_count": 228,
    "openalex_id": "https://openalex.org/W2009718036",
    "type": "article"
  },
  {
    "title": "Mining Travel Patterns from Geotagged Photos",
    "doi": "https://doi.org/10.1145/2168752.2168770",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Yan-Tao Zheng; Zheng-Jun Zha; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Recently, the phenomenal advent of photo-sharing services, such as Flickr and Panoramio, have led to volumous community-contributed photos with text tags, timestamps, and geographic references on the Internet. The photos, together with their time- and geo-references, become the digital footprints of photo takers and implicitly document their spatiotemporal movements. This study aims to leverage the wealth of these enriched online photos to analyze people’s travel patterns at the local level of a tour destination. Specifically, we focus our analysis on two aspects: (1) tourist movement patterns in relation to the regions of attractions (RoA), and (2) topological characteristics of travel routes by different tourists. To do so, we first build a statistically reliable database of travel paths from a noisy pool of community-contributed geotagged photos on the Internet. We then investigate the tourist traffic flow among different RoAs by exploiting the Markov chain model. Finally, the topological characteristics of travel routes are analyzed by performing a sequence clustering on tour routes. Testings on four major cities demonstrate promising results of the proposed system.",
    "cited_by_count": 227,
    "openalex_id": "https://openalex.org/W2068160960",
    "type": "article"
  },
  {
    "title": "Semantic trajectories",
    "doi": "https://doi.org/10.1145/2483669.2483682",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Zhixian Yan; Dipanjan Chakraborty; Christine Parent; Stefano Spaccapietra; Karl Aberer",
    "corresponding_authors": "",
    "abstract": "With the large-scale adoption of GPS equipped mobile sensing devices, positional data generated by moving objects (e.g., vehicles, people, animals) are being easily collected. Such data are typically modeled as streams of spatio-temporal (x,y,t) points, called trajectories . In recent years trajectory management research has progressed significantly towards efficient storage and indexing techniques, as well as suitable knowledge discovery. These works focused on the geometric aspect of the raw mobility data. We are now witnessing a growing demand in several application sectors (e.g., from shipment tracking to geo-social networks) on understanding the semantic behavior of moving objects. Semantic behavior refers to the use of semantic abstractions of the raw mobility data, including not only geometric patterns but also knowledge extracted jointly from the mobility data and the underlying geographic and application domains information. The core contribution of this article lies in a semantic model and a computation and annotation platform for developing a semantic approach that progressively transforms the raw mobility data into semantic trajectories enriched with segmentations and annotations. We also analyze a number of experiments we did with semantic trajectories in different domains.",
    "cited_by_count": 217,
    "openalex_id": "https://openalex.org/W2012084072",
    "type": "article"
  },
  {
    "title": "Introduction to special section on intelligent mobile knowledge discovery and management systems",
    "doi": "https://doi.org/10.1145/2542182.2542183",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Hui Xiong; Shashi Shekhar; Alexander Tuzhilin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 212,
    "openalex_id": "https://openalex.org/W2132504805",
    "type": "article"
  },
  {
    "title": "Joint Link Prediction and Attribute Inference Using a Social-Attribute Network",
    "doi": "https://doi.org/10.1145/2594455",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Neil Zhenqiang Gong; Ameet Talwalkar; Lester Mackey; Ling Huang; Eui Chul Richard Shin; Emil Stefanov; Elaine Shi; Dawn Song",
    "corresponding_authors": "",
    "abstract": "The effects of social influence and homophily suggest that both network structure and node-attribute information should inform the tasks of link prediction and node-attribute inference. Recently, Yin et al. [2010a, 2010b] proposed an attribute-augmented social network model, which we call Social-Attribute Network (SAN), to integrate network structure and node attributes to perform both link prediction and attribute inference. They focused on generalizing the random walk with a restart algorithm to the SAN framework and showed improved performance. In this article, we extend the SAN framework with several leading supervised and unsupervised link-prediction algorithms and demonstrate performance improvement for each algorithm on both link prediction and attribute inference. Moreover, we make the novel observation that attribute inference can help inform link prediction, that is, link-prediction accuracy is further improved by first inferring missing attributes. We comprehensively evaluate these algorithms and compare them with other existing algorithms using a novel, large-scale Google+ dataset, which we make publicly available (http://www.cs.berkeley.edu/~stevgong/gplus.html).",
    "cited_by_count": 204,
    "openalex_id": "https://openalex.org/W2107933610",
    "type": "article"
  },
  {
    "title": "Crowdsourcing Mechanism for Trust Evaluation in CPCS Based on Intelligent Mobile Edge Computing",
    "doi": "https://doi.org/10.1145/3324926",
    "publication_date": "2019-10-24",
    "publication_year": 2019,
    "authors": "Tian Wang; Hao Luo; Xi Zheng; Mande Xie",
    "corresponding_authors": "",
    "abstract": "Both academia and industry have directed tremendous interest toward the combination of Cyber Physical Systems and Cloud Computing, which enables a new breed of applications and services. However, due to the relative long distance between remote cloud and end nodes, Cloud Computing cannot provide effective and direct management for end nodes, which leads to security vulnerabilities. In this article, we first propose a novel trust evaluation mechanism using crowdsourcing and Intelligent Mobile Edge Computing. The mobile edge users with relatively strong computation and storage ability are exploited to provide direct management for end nodes. Through close access to end nodes, mobile edge users can obtain various information of the end nodes and determine whether the node is trustworthy. Then, two incentive mechanisms, i.e., Trustworthy Incentive and Quality-Aware Trustworthy Incentive Mechanisms, are proposed for motivating mobile edge users to conduct trust evaluation. The first one aims to motivate edge users to upload their real information about their capability and costs. The purpose of the second one is to motivate edge users to make trustworthy effort to conduct tasks and report results. Detailed theoretical analysis demonstrates the validity of Quality-Aware Trustworthy Incentive Mechanism from data trustfulness, effort trustfulness, and quality trustfulness, respectively. Extensive experiments are carried out to validate the proposed trust evaluation and incentive mechanisms. The results corroborate that the proposed mechanisms can efficiently stimulate mobile edge users to perform evaluation task and improve the accuracy of trust evaluation.",
    "cited_by_count": 179,
    "openalex_id": "https://openalex.org/W2981664222",
    "type": "article"
  },
  {
    "title": "Survey and Cross-benchmark Comparison of Remaining Time Prediction Methods in Business Process Monitoring",
    "doi": "https://doi.org/10.1145/3331449",
    "publication_date": "2019-07-18",
    "publication_year": 2019,
    "authors": "Ilya Verenich; Marlon Dumas; Marcello La Rosa; Fabrizio Maria Maggi; Irene Teinemaa",
    "corresponding_authors": "",
    "abstract": "Predictive business process monitoring methods exploit historical process execution logs to generate predictions about running instances (called cases) of a business process, such as the prediction of the outcome, next activity, or remaining cycle time of a given process case. These insights could be used to support operational managers in taking remedial actions as business processes unfold, e.g., shifting resources from one case onto another to ensure the latter is completed on time. A number of methods to tackle the remaining cycle time prediction problem have been proposed in the literature. However, due to differences in their experimental setup, choice of datasets, evaluation measures, and baselines, the relative merits of each method remain unclear. This article presents a systematic literature review and taxonomy of methods for remaining time prediction in the context of business processes, as well as a cross-benchmark comparison of 16 such methods based on 17 real-life datasets originating from different industry domains.",
    "cited_by_count": 169,
    "openalex_id": "https://openalex.org/W2964300152",
    "type": "article"
  },
  {
    "title": "Trustworthy AI: A Computational Perspective",
    "doi": "https://doi.org/10.1145/3546872",
    "publication_date": "2022-07-12",
    "publication_year": 2022,
    "authors": "Haochen Liu; Yiqi Wang; Wenqi Fan; Xiaorui Liu; Yaxin Li; Shaili Jain; Yunhao Liu; Anil K. Jain; Jiliang Tang",
    "corresponding_authors": "",
    "abstract": "In the past few decades, artificial intelligence (AI) technology has experienced swift developments, changing everyone’s daily life and profoundly altering the course of human society. The intention behind developing AI was and is to benefit humans by reducing labor, increasing everyday conveniences, and promoting social good. However, recent research and AI applications indicate that AI can cause unintentional harm to humans by, for example, making unreliable decisions in safety-critical scenarios or undermining fairness by inadvertently discriminating against a group or groups. Consequently, trustworthy AI has recently garnered increased attention regarding the need to avoid the adverse effects that AI could bring to people, so people can fully trust and live in harmony with AI technologies. A tremendous amount of research on trustworthy AI has been conducted and witnessed in recent years. In this survey, we present a comprehensive appraisal of trustworthy AI from a computational perspective to help readers understand the latest technologies for achieving trustworthy AI. Trustworthy AI is a large and complex subject, involving various dimensions. In this work, we focus on six of the most crucial dimensions in achieving trustworthy AI: (i) Safety &amp; Robustness, (ii) Nondiscrimination &amp; Fairness, (iii) Explainability, (iv) Privacy, (v) Accountability &amp; Auditability, and (vi) Environmental Well-being. For each dimension, we review the recent related technologies according to a taxonomy and summarize their applications in real-world systems. We also discuss the accordant and conflicting interactions among different dimensions and discuss potential aspects for trustworthy AI to investigate in the future.",
    "cited_by_count": 160,
    "openalex_id": "https://openalex.org/W3182221256",
    "type": "article"
  },
  {
    "title": "Video Object Segmentation and Tracking",
    "doi": "https://doi.org/10.1145/3391743",
    "publication_date": "2020-05-25",
    "publication_year": 2020,
    "authors": "Rui Yao; Guosheng Lin; Shixiong Xia; Jiaqi Zhao; Yong Zhou",
    "corresponding_authors": "",
    "abstract": "Object segmentation and object tracking are fundamental research areas in the computer vision community. These two topics are difficult to handle some common challenges, such as occlusion, deformation, motion blur, scale variation, and more. The former contains heterogeneous object, interacting object, edge ambiguity, and shape complexity; the latter suffers from difficulties in handling fast motion, out-of-view, and real-time processing. Combining the two problems of Video Object Segmentation and Tracking (VOST) can overcome their respective difficulties and improve their performance. VOST can be widely applied to many practical applications such as video summarization, high definition video compression, human computer interaction, and autonomous vehicles. This survey aims to provide a comprehensive review of the state-of-the-art VOST methods, classify these methods into different categories, and identify new trends. First, we broadly categorize VOST methods into Video Object Segmentation (VOS) and Segmentation-based Object Tracking (SOT). Each category is further classified into various types based on the segmentation and tracking mechanism. Moreover, we present some representative VOS and SOT methods of each time node. Second, we provide a detailed discussion and overview of the technical characteristics of the different methods. Third, we summarize the characteristics of the related video dataset and provide a variety of evaluation metrics. Finally, we point out a set of interesting future works and draw our own conclusions.",
    "cited_by_count": 156,
    "openalex_id": "https://openalex.org/W3033114334",
    "type": "article"
  },
  {
    "title": "Federated Social Recommendation with Graph Neural Network",
    "doi": "https://doi.org/10.1145/3501815",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Zhiwei Liu; Liangwei Yang; Ziwei Fan; Hao Peng; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Recommender systems have become prosperous nowadays, designed to predict users’ potential interests in items by learning embeddings. Recent developments of the Graph Neural Networks (GNNs) also provide recommender systems (RSs) with powerful backbones to learn embeddings from a user-item graph. However, only leveraging the user-item interactions suffers from the cold-start issue due to the difficulty in data collection. Hence, current endeavors propose fusing social information with user-item interactions to alleviate it, which is the social recommendation problem. Existing work employs GNNs to aggregate both social links and user-item interactions simultaneously. However, they all require centralized storage of the social links and item interactions of users, which leads to privacy concerns. Additionally, according to strict privacy protection under General Data Protection Regulation, centralized data storage may not be feasible in the future, urging a decentralized framework of social recommendation. As a result, we design a federated learning recommender system for the social recommendation task, which is rather challenging because of its heterogeneity, personalization, and privacy protection requirements. To this end, we devise a novel framework Fe drated So cial recommendation with G raph neural network ( FeSoG ). Firstly, FeSoG adopts relational attention and aggregation to handle heterogeneity. Secondly, FeSoG infers user embeddings using local data to retain personalization. Last but not least, the proposed model employs pseudo-labeling techniques with item sampling to protect the privacy and enhance training. Extensive experiments on three real-world datasets justify the effectiveness of FeSoG in completing social recommendation and privacy protection. We are the first work proposing a federated learning framework for social recommendation to the best of our knowledge.",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W3217045679",
    "type": "article"
  },
  {
    "title": "Graph Neural Networks: Taxonomy, Advances, and Trends",
    "doi": "https://doi.org/10.1145/3495161",
    "publication_date": "2022-01-10",
    "publication_year": 2022,
    "authors": "Yu Zhou; Haixia Zheng; Xin Huang; Shufeng Hao; Dengao Li; Jumin Zhao",
    "corresponding_authors": "",
    "abstract": "Graph neural networks provide a powerful toolkit for embedding real-world graphs into low-dimensional spaces according to specific tasks. Up to now, there have been several surveys on this topic. However, they usually lay emphasis on different angles so that the readers cannot see a panorama of the graph neural networks. This survey aims to overcome this limitation and provide a systematic and comprehensive review on the graph neural networks. First of all, we provide a novel taxonomy for the graph neural networks, and then refer to up to 327 relevant literatures to show the panorama of the graph neural networks. All of them are classified into the corresponding categories. In order to drive the graph neural networks into a new stage, we summarize four future research directions so as to overcome the challenges faced. It is expected that more and more scholars can understand and exploit the graph neural networks and use them in their research community.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W4206776774",
    "type": "article"
  },
  {
    "title": "A Survey on Graph Representation Learning Methods",
    "doi": "https://doi.org/10.1145/3633518",
    "publication_date": "2023-11-28",
    "publication_year": 2023,
    "authors": "Shima Khoshraftar; Aijun An",
    "corresponding_authors": "",
    "abstract": "Graph representation learning has been a very active research area in recent years. The goal of graph representation learning is to generate graph representation vectors that capture the structure and features of large graphs accurately. This is especially important because the quality of the graph representation vectors will affect the performance of these vectors in downstream tasks such as node classification, link prediction and anomaly detection. Many techniques have been proposed for generating effective graph representation vectors, which generally fall into two categories: traditional graph embedding methods and graph neural network (GNN)–based methods. These methods can be applied to both static and dynamic graphs. A static graph is a single fixed graph, whereas a dynamic graph evolves over time and its nodes and edges can be added or deleted from the graph. In this survey, we review the graph-embedding methods in both traditional and GNN-based categories for both static and dynamic graphs and include the recent papers published until the time of submission. In addition, we summarize a number of limitations of GNNs and the proposed solutions to these limitations. Such a summary has not been provided in previous surveys. Finally, we explore some open and ongoing research directions for future work.",
    "cited_by_count": 100,
    "openalex_id": "https://openalex.org/W4389098833",
    "type": "article"
  },
  {
    "title": "Generative Adversarial Networks for Spatio-temporal Data: A Survey",
    "doi": "https://doi.org/10.1145/3474838",
    "publication_date": "2022-02-06",
    "publication_year": 2022,
    "authors": "Nan Gao; Hao Xue; Wei Shao; Sichen Zhao; Kyle K. Qin; Arian Prabowo; Mohammad Saiedur Rahaman; Flora D. Salim",
    "corresponding_authors": "",
    "abstract": "Generative Adversarial Networks (GANs) have shown remarkable success in producing realistic-looking images in the computer vision area. Recently, GAN-based techniques are shown to be promising for spatio-temporal-based applications such as trajectory prediction, events generation, and time-series data imputation. While several reviews for GANs in computer vision have been presented, no one has considered addressing the practical applications and challenges relevant to spatio-temporal data. In this article, we have conducted a comprehensive review of the recent developments of GANs for spatio-temporal data. We summarise the application of popular GAN architectures for spatio-temporal data and the common practices for evaluating the performance of spatio-temporal applications with GANs. Finally, we point out future research directions to benefit researchers in this area.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W3055194044",
    "type": "article"
  },
  {
    "title": "A Bibliometric Review of Large Language Models Research from 2017 to 2023",
    "doi": "https://doi.org/10.1145/3664930",
    "publication_date": "2024-05-13",
    "publication_year": 2024,
    "authors": "Lizhou Fan; Lingyao Li; Zihui Ma; Sanggyu Lee; Huizi Yu; Libby Hemphill",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs), such as OpenAI's Generative Pre-trained Transformer (GPT), are a class of language models that have demonstrated outstanding performance across a range of natural language processing (NLP) tasks. LLMs have become a highly sought-after research area because of their ability to generate human-like language and their potential to revolutionize science and technology. In this study, we conduct bibliometric and discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000 publications, this article serves as a roadmap for researchers, practitioners, and policymakers to navigate the current landscape of LLMs research. We present the research trends from 2017 to early 2023, identifying patterns in research paradigms and collaborations. We start with analyzing the core algorithm developments and NLP tasks that are fundamental in LLMs research. We then investigate the applications of LLMs in various fields and domains, including medicine, engineering, social science, and humanities. Our review also reveals the dynamic, fast-paced evolution of LLMs research. Overall, this article offers valuable insights into the current state, impact, and potential of LLMs research and its applications.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W4396870811",
    "type": "review"
  },
  {
    "title": "GTG-Shapley: Efficient and Accurate Participant Contribution Evaluation in Federated Learning",
    "doi": "https://doi.org/10.1145/3501811",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Zelei Liu; Yuanyuan Chen; Han Yu; Yang Liu; Lizhen Cui",
    "corresponding_authors": "",
    "abstract": "Federated Learning (FL) bridges the gap between collaborative machine learning and preserving data privacy. To sustain the long-term operation of an FL ecosystem, it is important to attract high-quality data owners with appropriate incentive schemes. As an important building block of such incentive schemes, it is essential to fairly evaluate participants’ contribution to the performance of the final FL model without exposing their private data. Shapley Value (SV)–based techniques have been widely adopted to provide a fair evaluation of FL participant contributions. However, existing approaches incur significant computation costs, making them difficult to apply in practice. In this article, we propose the Guided Truncation Gradient Shapley (GTG-Shapley) approach to address this challenge. It reconstructs FL models from gradient updates for SV calculation instead of repeatedly training with different combinations of FL participants. In addition, we design a guided Monte Carlo sampling approach combined with within-round and between-round truncation to further reduce the number of model reconstructions and evaluations required. This is accomplished through extensive experiments under diverse realistic data distribution settings. The results demonstrate that GTG-Shapley can closely approximate actual Shapley values while significantly increasing computational efficiency compared with the state-of-the-art, especially under non-i.i.d. settings.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W3198837878",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Model Quantization for Deep Neural Networks in Image Classification",
    "doi": "https://doi.org/10.1145/3623402",
    "publication_date": "2023-09-11",
    "publication_year": 2023,
    "authors": "Babak Rokh; Ali Azarpeyvand; Alireza Khanteymoori",
    "corresponding_authors": "",
    "abstract": "Recent advancements in machine learning achieved by Deep Neural Networks (DNNs) have been significant. While demonstrating high accuracy, DNNs are associated with a huge number of parameters and computations, which leads to high memory usage and energy consumption. As a result, deploying DNNs on devices with constrained hardware resources poses significant challenges. To overcome this, various compression techniques have been widely employed to optimize DNN accelerators. A promising approach is quantization, in which the full-precision values are stored in low bit-width precision. Quantization not only reduces memory requirements but also replaces high-cost operations with low-cost ones. DNN quantization offers flexibility and efficiency in hardware design, making it a widely adopted technique in various methods. Since quantization has been extensively utilized in previous works, there is a need for an integrated report that provides an understanding, analysis, and comparison of different quantization approaches. Consequently, we present a comprehensive survey of quantization concepts and methods, with a focus on image classification. We describe clustering-based quantization methods and explore the use of a scale factor parameter for approximating full-precision values. Moreover, we thoroughly review the training of a quantized DNN, including the use of a straight-through estimator and quantization regularization. We explain the replacement of floating-point operations with low-cost bitwise operations in a quantized DNN and the sensitivity of different layers in quantization. Furthermore, we highlight the evaluation metrics for quantization methods and important benchmarks in the image classification task. We also present the accuracy of the state-of-the-art methods on CIFAR-10 and ImageNet. This article attempts to make the readers familiar with the basic and advanced concepts of quantization, introduce important works in DNN quantization, and highlight challenges for future research in this field.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W4386607611",
    "type": "article"
  },
  {
    "title": "Trustworthy Recommender Systems",
    "doi": "https://doi.org/10.1145/3627826",
    "publication_date": "2023-10-13",
    "publication_year": 2023,
    "authors": "Shoujin Wang; Xiuzhen Zhang; Yan Wang; Francesco Ricci⋆",
    "corresponding_authors": "",
    "abstract": "Recommender systems (RSs) aim at helping users to effectively retrieve items of their interests from a large catalogue. For a quite long time, researchers and practitioners have been focusing on developing accurate RSs. Recent years have witnessed an increasing number of threats to RSs, coming from attacks, system and user generated noise, and various types of biases. As a result, it has become clear that the focus on RS accuracy is too narrow, and the research must consider other important factors, particularly trustworthiness. A trustworthy recommender system (TRS) should not only be accurate but also transparent, unbiased, fair, and robust to noise and attacks. These observations actually led to a paradigm shift of the research on RSs: from accuracy-oriented RSs to TRSs. However, there is a lack of a systematic overview and discussion of the literature in this novel and fast-developing field of TRSs. To this end, in this article, we provide an overview of TRSs, including a discussion of the motivation and basic concepts of TRSs, a presentation of the challenges in building TRSs, and a perspective on the future directions in this area. We also provide a novel conceptual framework to support the construction of TRSs.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W4387618416",
    "type": "article"
  },
  {
    "title": "A Comprehensive Overview of Large Language Models",
    "doi": "https://doi.org/10.1145/3744746",
    "publication_date": "2025-06-18",
    "publication_year": 2025,
    "authors": "Humza Naveed; Asad Ullah Khan; Shi Qiu; Muhammad Saqib; Saeed Anwar; Muhammad Usman; Naveed Akhtar; Nick Barnes; Ajmal Mian",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations, better training strategies, context length improvements, fine-tuning, multi-modal LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides an overview of the literature on a broad range of LLM-related concepts. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of research in LLMs. This review article is intended to provide not only a systematic survey but also a quick, comprehensive reference for the researchers and practitioners to draw insights from extensive, informative summaries of the existing works to advance the LLM research.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W4411403346",
    "type": "article"
  },
  {
    "title": "Fairness and Diversity in Recommender Systems: A Survey",
    "doi": "https://doi.org/10.1145/3664928",
    "publication_date": "2024-05-21",
    "publication_year": 2024,
    "authors": "Yuying Zhao; Yu Wang; Yunchao Liu; Xueqi Cheng; Charų C. Aggarwal; Tyler Derr",
    "corresponding_authors": "",
    "abstract": "Recommender systems (RS) are effective tools for mitigating information overload and have seen extensive applications across various domains. However, the single focus on utility goals proves to be inadequate in addressing real-world concerns, leading to increasing attention to fairness-aware and diversity-aware RS. While most existing studies explore fairness and diversity independently, we identify strong connections between these two domains. In this survey, we first discuss each of them individually and then dive into their connections. Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level. With this expanded perspective on user and item-level diversity, we re-interpret fairness studies from the viewpoint of diversity. This fresh perspective enhances our understanding of fairness-related work and paves the way for potential future research directions. Papers discussed in this survey along with public code links are available at: https://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems .",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4398169514",
    "type": "article"
  },
  {
    "title": "LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters",
    "doi": "https://doi.org/10.1145/3719207",
    "publication_date": "2025-02-21",
    "publication_year": 2025,
    "authors": "Ching Chang; Wei‐Yao Wang; Wen-Chih Peng; Tien-Fu Chen",
    "corresponding_authors": "",
    "abstract": "Multivariate time-series forecasting is vital in various domains, e.g., economic planning and weather prediction. Deep train-from-scratch models have exhibited effective performance yet require large amounts of data, which limits real-world applicability. Recently, researchers have leveraged the representation learning transferability of pre-trained Large Language Models (LLMs) to handle limited non-linguistic datasets effectively. However, incorporating LLMs with time-series data presents challenges of limited adaptation due to different compositions between time-series and linguistic data, and the inability to process multi-scale temporal information. To tackle these challenges, we propose LLM4TS, a framework for time-series forecasting with pre-trained LLMs. LLM4TS consists of a two-stage fine-tuning strategy: the time-series alignment stage to align LLMs with the nuances of time-series data, and the forecasting fine-tuning stage for downstream time-series forecasting tasks. Furthermore, our framework features a novel two-level aggregation method that integrates multi-scale temporal data within pre-trained LLMs, enhancing their ability to interpret time-specific information. In experiments across 7 time-series forecasting datasets, LLM4TS is superior to existing state-of-the-art methods compared with trained-from-scratch models in full-shot scenarios, and also achieves the highest rank in few-shot scenarios. In addition, evaluations compared with different unsupervised representation learning approaches highlight LLM4TS’s effectiveness with representation learning in forecasting tasks. Ablation studies further validate each component’s contribution to LLM4TS and underscore the essential role of utilizing LLM’s pre-trained weights for optimal performance. The code is available at https://github.com/blacksnail789521/LLM4TS .",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4407838869",
    "type": "article"
  },
  {
    "title": "CFaiRLLM: Consumer Fairness Evaluation in Large-Language Model Recommender System",
    "doi": "https://doi.org/10.1145/3725853",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Yashar Deldjoo; Tommaso Di Noia",
    "corresponding_authors": "",
    "abstract": "This work takes a critical stance on previous studies concerning fairness evaluation in Large Language Model (LLM)-based recommender systems, which have primarily assessed consumer fairness by comparing recommendation lists generated with and without sensitive user attributes. Such approaches implicitly treat discrepancies in recommended items as biases, overlooking whether these changes might stem from genuine personalization aligned with true preferences of users. Moreover, these earlier studies typically address single sensitive attributes in isolation, neglecting the complex interplay of intersectional identities. In response to these shortcomings, we introduce CFaiRLLM, an enhanced evaluation framework that not only incorporates true preference alignment but also rigorously examines intersectional fairness by considering overlapping sensitive attributes. Additionally, CFaiRLLM introduces diverse user profile sampling strategies— random , top-rated , and recency-focused —to better understand the impact of profile generation fed to LLMs in light of inherent token limitations in these systems. Given that fairness depends on accurately understanding users’ tastes and preferences, these strategies provide a more realistic assessment of fairness within RecLLMs. To validate the efficacy of CFaiRLLM, we conducted extensive experiments using MovieLens and LastFM datasets, applying various sampling strategies and sensitive attribute configurations. The evaluation metrics include both item similarity measures and true preference alignment considering both hit and ranking (Jaccard Similarity and PRAG), thereby conducting a multifaceted analysis of recommendation fairness. The results demonstrated that true preference alignment offers a more personalized and fair assessment compared to similarity-based measures, revealing significant disparities when sensitive and intersectional attributes are incorporated. Notably, our study finds that intersectional attributes amplify fairness gaps more prominently, especially in less structured domains such as music recommendations in LastFM. These findings suggest that future fairness evaluations in RecLLMs should incorporate true preference alignment to ensure equitable and genuinely personalized recommendations.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4408813113",
    "type": "article"
  },
  {
    "title": "Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus",
    "doi": "https://doi.org/10.1145/3712701",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Seungpil Lee; Woochang Sim; Donghyeon Shin; Wongyu Seo; Jiwon Park; S. C. Lee; Sanha Hwang; Sejin Kim; Sundong Kim",
    "corresponding_authors": "",
    "abstract": "The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been predominantly results-centric, making it challenging to assess the inference process comprehensively. We introduce a novel approach using the Abstraction and Reasoning Corpus (ARC) benchmark to evaluate the inference and contextual understanding abilities of LLMs in a process-centric manner, focusing on three key components from the Language of Thought Hypothesis (LoTH): Logical Coherence, Compositionality, and Productivity. Our carefully designed experiments reveal that while LLMs demonstrate some inference capabilities, they still significantly lag behind human-level reasoning in these three aspects. The main contribution of this paper lies in introducing the LoTH perspective, which provides a method for evaluating the reasoning process that conventional results-oriented approaches fail to capture, thereby offering new insights into the development of human-level reasoning in artificial intelligence systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4406614997",
    "type": "article"
  },
  {
    "title": "Active learning in multimedia annotation and retrieval",
    "doi": "https://doi.org/10.1145/1899412.1899414",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Meng Wang; Xian‐Sheng Hua",
    "corresponding_authors": "",
    "abstract": "Active learning is a machine learning technique that selects the most informative samples for labeling and uses them as training data. It has been widely explored in multimedia research community for its capability of reducing human annotation effort. In this article, we provide a survey on the efforts of leveraging active learning in multimedia annotation and retrieval. We mainly focus on two application domains: image/video annotation and content-based image retrieval. We first briefly introduce the principle of active learning and then we analyze the sample selection criteria. We categorize the existing sample selection strategies used in multimedia annotation and retrieval into five criteria: risk reduction , uncertainty , diversity , density and relevance . We then introduce several classification models used in active learning-based multimedia annotation and retrieval, including semi-supervised learning, multilabel learning and multiple instance learning. We also provide a discussion on several future trends in this research direction. In particular, we discuss cost analysis of human annotation and large-scale interactive multimedia annotation.",
    "cited_by_count": 229,
    "openalex_id": "https://openalex.org/W1972508834",
    "type": "article"
  },
  {
    "title": "Nowcasting Events from the Social Web with Statistical Learning",
    "doi": "https://doi.org/10.1145/2337542.2337557",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Vasileios Lampos; Nello Cristianini",
    "corresponding_authors": "",
    "abstract": "We present a general methodology for inferring the occurrence and magnitude of an event or phenomenon by exploring the rich amount of unstructured textual information on the social part of the Web. Having geo-tagged user posts on the microblogging service of Twitter as our input data, we investigate two case studies. The first consists of a benchmark problem, where actual levels of rainfall in a given location and time are inferred from the content of tweets . The second one is a real-life task, where we infer regional Influenza-like Illness rates in the effort of detecting timely an emerging epidemic disease. Our analysis builds on a statistical learning framework, which performs sparse learning via the bootstrapped version of LASSO to select a consistent subset of textual features from a large amount of candidates. In both case studies, selected features indicate close semantic correlation with the target topics and inference, conducted by regression, has a significant performance, especially given the short length --approximately one year-- of Twitter’s data time series.",
    "cited_by_count": 215,
    "openalex_id": "https://openalex.org/W2126675855",
    "type": "article"
  },
  {
    "title": "Learning to detect malicious URLs",
    "doi": "https://doi.org/10.1145/1961189.1961202",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Justin Ma; Lawrence K. Saul; Stefan Savage; Geoffrey M. Voelker",
    "corresponding_authors": "",
    "abstract": "Malicious Web sites are a cornerstone of Internet criminal activities. The dangers of these sites have created a demand for safeguards that protect end-users from visiting them. This article explores how to detect malicious Web sites from the lexical and host-based features of their URLs. We show that this problem lends itself naturally to modern algorithms for online learning. Online algorithms not only process large numbers of URLs more efficiently than batch algorithms, they also adapt more quickly to new features in the continuously evolving distribution of malicious URLs. We develop a real-time system for gathering URL features and pair it with a real-time feed of labeled URLs from a large Web mail provider. From these features and labels, we are able to train an online classifier that detects malicious Web sites with 99% accuracy over a balanced dataset.",
    "cited_by_count": 213,
    "openalex_id": "https://openalex.org/W1975909792",
    "type": "article"
  },
  {
    "title": "Twitter, MySpace, Digg",
    "doi": "https://doi.org/10.1145/2337542.2337551",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "George Paltoglou; Mike Thelwall",
    "corresponding_authors": "",
    "abstract": "Sentiment analysis is a growing area of research with significant applications in both industry and academia. Most of the proposed solutions are centered around supervised, machine learning approaches and review-oriented datasets. In this article, we focus on the more common informal textual communication on the Web, such as online discussions, tweets and social network comments and propose an intuitive, less domain-specific, unsupervised, lexicon-based approach that estimates the level of emotional intensity contained in text in order to make a prediction. Our approach can be applied to, and is tested in, two different but complementary contexts: subjectivity detection and polarity classification. Extensive experiments were carried on three real-world datasets, extracted from online social Web sites and annotated by human evaluators, against state-of-the-art supervised approaches. The results demonstrate that the proposed algorithm, even though unsupervised, outperforms machine learning solutions in the majority of cases, overall presenting a very robust and reliable solution for sentiment analysis of informal communication on the Web.",
    "cited_by_count": 206,
    "openalex_id": "https://openalex.org/W2055729610",
    "type": "article"
  },
  {
    "title": "Identify Online Store Review Spammers via Social Review Graph",
    "doi": "https://doi.org/10.1145/2337542.2337546",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Guan Wang; Sihong Xie; Bing Liu; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Online shopping reviews provide valuable information for customers to compare the quality of products, store services, and many other aspects of future purchases. However, spammers are joining this community trying to mislead consumers by writing fake or unfair reviews to confuse the consumers. Previous attempts have used reviewers’ behaviors such as text similarity and rating patterns, to detect spammers. These studies are able to identify certain types of spammers, for instance, those who post many similar reviews about one target. However, in reality, there are other kinds of spammers who can manipulate their behaviors to act just like normal reviewers, and thus cannot be detected by the available techniques. In this article, we propose a novel concept of review graph to capture the relationships among all reviewers, reviews and stores that the reviewers have reviewed as a heterogeneous graph. We explore how interactions between nodes in this graph could reveal the cause of spam and propose an iterative computation model to identify suspicious reviewers. In the review graph, we have three kinds of nodes, namely, reviewer, review, and store. We capture their relationships by introducing three fundamental concepts, the trustiness of reviewers, the honesty of reviews, and the reliability of stores, and identifying their interrelationships: a reviewer is more trustworthy if the person has written more honesty reviews; a store is more reliable if it has more positive reviews from trustworthy reviewers; and a review is more honest if many other honest reviews support it. This is the first time such intricate relationships have been identified for spam detection and captured in a graph model. We further develop an effective computation method based on the proposed graph model. Different from any existing approaches, we do not use an review text information. Our model is thus complementary to existing approaches and able to find more difficult and subtle spamming activities, which are agreed upon by human judges after they evaluate our results.",
    "cited_by_count": 197,
    "openalex_id": "https://openalex.org/W2150281577",
    "type": "article"
  },
  {
    "title": "Home Location Identification of Twitter Users",
    "doi": "https://doi.org/10.1145/2528548",
    "publication_date": "2014-07-28",
    "publication_year": 2014,
    "authors": "Jalal Mahmud; Jeffrey Nichols; Clemens Drews",
    "corresponding_authors": "",
    "abstract": "We present a new algorithm for inferring the home location of Twitter users at different granularities, including city, state, time zone, or geographic region, using the content of users’ tweets and their tweeting behavior. Unlike existing approaches, our algorithm uses an ensemble of statistical and heuristic classifiers to predict locations and makes use of a geographic gazetteer dictionary to identify place-name entities. We find that a hierarchical classification approach, where time zone, state, or geographic region is predicted first and city is predicted next, can improve prediction accuracy. We have also analyzed movement variations of Twitter users, built a classifier to predict whether a user was travelling in a certain period of time, and use that to further improve the location detection accuracy. Experimental evidence suggests that our algorithm works well in practice and outperforms the best existing algorithms for predicting the home location of Twitter users.",
    "cited_by_count": 190,
    "openalex_id": "https://openalex.org/W2006239241",
    "type": "article"
  },
  {
    "title": "Lexical normalization for social media text",
    "doi": "https://doi.org/10.1145/2414425.2414430",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Bo Han; Paul Cook; Timothy Baldwin",
    "corresponding_authors": "",
    "abstract": "Twitter provides access to large volumes of data in real time, but is notoriously noisy, hampering its utility for NLP. In this article, we target out-of-vocabulary words in short text messages and propose a method for identifying and normalizing lexical variants. Our method uses a classifier to detect lexical variants, and generates correction candidates based on morphophonemic similarity. Both word similarity and context are then exploited to select the most probable correction candidate for the word. The proposed method doesn't require any annotations, and achieves state-of-the-art performance over an SMS corpus and a novel dataset based on Twitter.",
    "cited_by_count": 189,
    "openalex_id": "https://openalex.org/W2016443085",
    "type": "article"
  },
  {
    "title": "LocateMe",
    "doi": "https://doi.org/10.1145/2508037.2508054",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Kalyan Pathapati Subbu; Brandon Gozick; Ram Dantu",
    "corresponding_authors": "",
    "abstract": "Fine-grained localization is extremely important to accurately locate a user indoors. Although innovative solutions have already been proposed, there is no solution that is universally accepted, easily implemented, user centric, and, most importantly, works in the absence of GSM coverage or WiFi availability. The advent of sensor rich smartphones has paved a way to develop a solution that can cater to these requirements. By employing a smartphone's built-in magnetic field sensor, magnetic signatures were collected inside buildings. These signatures displayed a uniqueness in their patterns due to the presence of different kinds of pillars, doors, elevators, etc., that consist of ferromagnetic materials like steel or iron. We theoretically analyze the cause of this uniqueness and then present an indoor localization solution by classifying signatures based on their patterns. However, to account for user walking speed variations so as to provide an application usable to a variety of users, we follow a dynamic time-warping-based approach that is known to work on similar signals irrespective of their variations in the time axis. Our approach resulted in localization distances of approximately 2m--6m with accuracies between 80--100% implying that it is sufficient to walk short distances across hallways to be located by the smartphone. The implementation of the application on different smartphones yielded response times of less than five secs, thereby validating the feasibility of our approach and making it a viable solution.",
    "cited_by_count": 186,
    "openalex_id": "https://openalex.org/W1991295181",
    "type": "article"
  },
  {
    "title": "When Location Meets Social Multimedia",
    "doi": "https://doi.org/10.1145/2597181",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Rongrong Ji; Yue Gao; Wei Liu; Xing Xie; Qi Tian; Xuelong Li",
    "corresponding_authors": "",
    "abstract": "Coming with the popularity of multimedia sharing platforms such as Facebook and Flickr, recent years have witnessed an explosive growth of geographical tags on social multimedia content. This trend enables a wide variety of emerging applications, for example, mobile location search, landmark recognition, scene reconstruction, and touristic recommendation, which range from purely research prototype to commercial systems. In this article, we give a comprehensive survey on these applications, covering recent advances in recognition and mining of geographical-aware social multimedia. We review related work in the past decade regarding to location recognition, scene summarization, tourism suggestion, 3D building modeling, mobile visual search and city navigation. At the end, we further discuss potential challenges, future topics, as well as open issues related to geo-social multimedia computing, recognition, mining, and analytics.",
    "cited_by_count": 183,
    "openalex_id": "https://openalex.org/W2010097736",
    "type": "article"
  },
  {
    "title": "Performance metrics for activity recognition",
    "doi": "https://doi.org/10.1145/1889681.1889687",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Jamie A. Ward; Paul Lukowicz; Hans Gellersen",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce and evaluate a comprehensive set of performance metrics and visualisations for continuous activity recognition (AR). We demonstrate how standard evaluation methods, often borrowed from related pattern recognition problems, fail to capture common artefacts found in continuous AR—specifically event fragmentation, event merging and timing offsets. We support our assertion with an analysis on a set of recently published AR papers. Building on an earlier initial work on the topic, we develop a frame-based visualisation and corresponding set of class-skew invariant metrics for the one class versus all evaluation. These are complemented by a new complete set of event-based metrics that allow a quick graphical representation of system performance—showing events that are correct, inserted, deleted, fragmented, merged and those which are both fragmented and merged. We evaluate the utility of our approach through comparison with standard metrics on data from three different published experiments. This shows that where event- and frame-based precision and recall lead to an ambiguous interpretation of results in some cases, the proposed metrics provide a consistently unambiguous explanation.",
    "cited_by_count": 181,
    "openalex_id": "https://openalex.org/W2060233269",
    "type": "article"
  },
  {
    "title": "Social factors in group recommender systems",
    "doi": "https://doi.org/10.1145/2414425.2414433",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Lara Quijano-Sánchez; Juan A. Recio-Garcí­a; Belén Dí­az-Agudo; Guillermo Jiménez-Díaz",
    "corresponding_authors": "",
    "abstract": "In this article we review the existing techniques in group recommender systems and we propose some improvement based on the study of the different individual behaviors when carrying out a decision-making process. Our method includes an analysis of group personality composition and trust between each group member to improve the accuracy of group recommenders. This way we simulate the argumentation process followed by groups of people when agreeing on a common activity in a more realistic way. Moreover, we reflect how they expect the system to behave in a long term recommendation process. This is achieved by including a memory of past recommendations that increases the satisfaction of users whose preferences have not been taken into account in previous recommendations.",
    "cited_by_count": 180,
    "openalex_id": "https://openalex.org/W1989807148",
    "type": "article"
  },
  {
    "title": "TensorBeat",
    "doi": "https://doi.org/10.1145/3078855",
    "publication_date": "2017-09-04",
    "publication_year": 2017,
    "authors": "Xuyu Wang; Chao Yang; Shiwen Mao",
    "corresponding_authors": "",
    "abstract": "Breathing signal monitoring can provide important clues for health problems. Compared to existing techniques that require wearable devices and special equipment, a more desirable approach is to provide contact-free and long-term breathing rate monitoring by exploiting wireless signals. In this article, we propose TensorBeat, a system to employ channel state information (CSI) phase difference data to intelligently estimate breathing rates for multiple persons with commodity WiFi devices. The main idea is to leverage the tensor decomposition technique to handle the CSI phase difference data. The proposed TensorBeat scheme first obtains CSI phase difference data between pairs of antennas at the WiFi receiver to create CSI tensors. Then canonical polyadic (CP) decomposition is applied to obtain the desired breathing signals. A stable signal matching algorithm is developed to identify the decomposed signal pairs, and a peak detection method is applied to estimate the breathing rates for multiple persons. Our experimental study shows that TensorBeat can achieve high accuracy under different environments for multiperson breathing rate monitoring.",
    "cited_by_count": 175,
    "openalex_id": "https://openalex.org/W2587061937",
    "type": "article"
  },
  {
    "title": "Forecasting with twitter data",
    "doi": "https://doi.org/10.1145/2542182.2542190",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Marta Arias; Argimiro Arratia; Ramon Xuriguera",
    "corresponding_authors": "",
    "abstract": "The dramatic rise in the use of social network platforms such as Facebook or Twitter has resulted in the availability of vast and growing user-contributed repositories of data. Exploiting this data by extracting useful information from it has become a great challenge in data mining and knowledge discovery. A recently popular way of extracting useful information from social network platforms is to build indicators, often in the form of a time series, of general public mood by means of sentiment analysis. Such indicators have been shown to correlate with a diverse variety of phenomena. In this article we follow this line of work and set out to assess, in a rigorous manner, whether a public sentiment indicator extracted from daily Twitter messages can indeed improve the forecasting of social, economic, or commercial indicators. To this end we have collected and processed a large amount of Twitter posts from March 2011 to the present date for two very different domains: stock market and movie box office revenue . For each of these domains, we build and evaluate forecasting models for several target time series both using and ignoring the Twitter-related data. If Twitter does help, then this should be reflected in the fact that the predictions of models that use Twitter-related data are better than the models that do not use this data. By systematically varying the models that we use and their parameters, together with other tuning factors such as lag or the way in which we build our Twitter sentiment index, we obtain a large dataset that allows us to test our hypothesis under different experimental conditions. Using a novel decision-tree-based technique that we call summary tree we are able to mine this large dataset and obtain automatically those configurations that lead to an improvement in the prediction power of our forecasting models. As a general result, we have seen that nonlinear models do take advantage of Twitter data when forecasting trends in volatility indices, while linear ones fail systematically when forecasting any kind of financial time series. In the case of predicting box office revenue trend, it is support vector machines that make best use of Twitter data. In addition, we conduct statistical tests to determine the relation between our Twitter time series and the different target time series.",
    "cited_by_count": 170,
    "openalex_id": "https://openalex.org/W1979192143",
    "type": "article"
  },
  {
    "title": "CIM",
    "doi": "https://doi.org/10.1145/2532549",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Yi-Cheng Chen; Wen-Yuan Zhu; Wen-Chih Peng; Wang-Chien Lee; Suh-Yin Lee",
    "corresponding_authors": "",
    "abstract": "Given a social graph, the problem of influence maximization is to determine a set of nodes that maximizes the spread of influences. While some recent research has studied the problem of influence maximization, these works are generally too time consuming for practical use in a large-scale social network. In this article, we develop a new framework, community-based influence maximization (CIM), to tackle the influence maximization problem with an emphasis on the time efficiency issue. Our proposed framework, CIM, comprises three phases: (i) community detection, (ii) candidate generation, and (iii) seed selection. Specifically, phase (i) discovers the community structure of the network; phase (ii) uses the information of communities to narrow down the possible seed candidates; and phase (iii) finalizes the seed nodes from the candidate set. By exploiting the properties of the community structures, we are able to avoid overlapped information and thus efficiently select the number of seeds to maximize information spreads. The experimental results on both synthetic and real datasets show that the proposed CIM algorithm significantly outperforms the state-of-the-art algorithms in terms of efficiency and scalability, with almost no compromise of effectiveness.",
    "cited_by_count": 164,
    "openalex_id": "https://openalex.org/W2106597862",
    "type": "article"
  },
  {
    "title": "PLDA+",
    "doi": "https://doi.org/10.1145/1961189.1961198",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Zhiyuan Liu; Yuzhou Zhang; Edward Yi Chang; Maosong Sun",
    "corresponding_authors": "",
    "abstract": "Previous methods of distributed Gibbs sampling for LDA run into either memory or communication bottlenecks. To improve scalability, we propose four strategies: data placement , pipeline processing , word bundling , and priority-based scheduling . Experiments show that our strategies significantly reduce the unparallelizable communication bottleneck and achieve good load balancing, and hence improve scalability of LDA.",
    "cited_by_count": 163,
    "openalex_id": "https://openalex.org/W2087937280",
    "type": "article"
  },
  {
    "title": "Norms as a basis for governing sociotechnical systems",
    "doi": "https://doi.org/10.1145/2542182.2542203",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Munindar P. Singh",
    "corresponding_authors": "Munindar P. Singh",
    "abstract": "We understand a sociotechnical system as a multistakeholder cyber-physical system. We introduce governance as the administration of such a system by the stakeholders themselves. In this regard, governance is a peer-to-peer notion and contrasts with traditional management, which is a top-down hierarchical notion. Traditionally, there is no computational support for governance and it is achieved through out-of-band interactions among system administrators. Not surprisingly, traditional approaches simply do not scale up to large sociotechnical systems. We develop an approach for governance based on a computational representation of norms in organizations. Our approach is motivated by the Ocean Observatory Initiative, a thirty-year $400 million project, which supports a variety of resources dealing with monitoring and studying the world's oceans. These resources include autonomous underwater vehicles, ocean gliders, buoys, and other instrumentation as well as more traditional computational resources. Our approach has the benefit of directly reflecting stakeholder needs and assuring stakeholders of the correctness of the resulting governance decisions while yielding adaptive resource allocation in the face of changes in both stakeholder needs and physical circumstances.",
    "cited_by_count": 161,
    "openalex_id": "https://openalex.org/W2008300029",
    "type": "article"
  },
  {
    "title": "Mining Mobile User Preferences for Personalized Context-Aware Recommendation",
    "doi": "https://doi.org/10.1145/2532515",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Hengshu Zhu; Enhong Chen; Hui Xiong; Kuifei Yu; Huanhuan Cao; Jilei Tian",
    "corresponding_authors": "",
    "abstract": "Recent advances in mobile devices and their sensing capabilities have enabled the collection of rich contextual information and mobile device usage records through the device logs. These context-rich logs open a venue for mining the personal preferences of mobile users under varying contexts and thus enabling the development of personalized context-aware recommendation and other related services, such as mobile online advertising. In this article, we illustrate how to extract personal context-aware preferences from the context-rich device logs, or context logs for short, and exploit these identified preferences for building personalized context-aware recommender systems. A critical challenge along this line is that the context log of each individual user may not contain sufficient data for mining his or her context-aware preferences. Therefore, we propose to first learn common context-aware preferences from the context logs of many users. Then, the preference of each user can be represented as a distribution of these common context-aware preferences. Specifically, we develop two approaches for mining common context-aware preferences based on two different assumptions, namely, context-independent and context-dependent assumptions, which can fit into different application scenarios. Finally, extensive experiments on a real-world dataset show that both approaches are effective and outperform baselines with respect to mining personal context-aware preferences for mobile users.",
    "cited_by_count": 160,
    "openalex_id": "https://openalex.org/W2018936209",
    "type": "article"
  },
  {
    "title": "Social media as crisis platform",
    "doi": "https://doi.org/10.1145/1858948.1858955",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Rebecca Goolsby",
    "corresponding_authors": "Rebecca Goolsby",
    "abstract": "Social media provides the means for creating new communities and for reenergizing old communities. Recently, a new kind of quickly formulated, powerful community has formed as existing social media communities, news organizations, and users have converged in social media spaces to respond to sudden tragedies. This article addresses the ad-hoc crisis community, whith uses the social madia as a crisis platform to generate community crisis maps.",
    "cited_by_count": 157,
    "openalex_id": "https://openalex.org/W2056724369",
    "type": "article"
  },
  {
    "title": "Submodularity and its applications in optimized information gathering",
    "doi": "https://doi.org/10.1145/1989734.1989736",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Andreas Krause; Carlos Guestrin",
    "corresponding_authors": "",
    "abstract": "Where should we place sensors to efficiently monitor natural drinking water resources for contamination? Which blogs should we read to learn about the biggest stories on the Web? These problems share a fundamental challenge: How can we obtain the most useful information about the state of the world, at minimum cost? Such information gathering, or active learning, problems are typically NP-hard, and were commonly addressed using heuristics without theoretical guarantees about the solution quality. In this article, we describe algorithms which efficiently find provably near-optimal solutions to large, complex information gathering problems. Our algorithms exploit submodularity, an intuitive notion of diminishing returns common to many sensing problems: the more sensors we have already deployed, the less we learn by placing another sensor. In addition to identifying the most informative sensing locations, our algorithms can handle more challenging settings, where sensors need to be able to reliably communicate over lossy links, where mobile robots are used for collecting data, or where solutions need to be robust against adversaries and sensor failures. We also present results applying our algorithms to several real-world sensing tasks, including environmental monitoring using robotic sensors, activity recognition using a built sensing chair, a sensor placement challenge, and deciding which blogs to read on the Web.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2073110021",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1961189",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Predictive models in regression and classification problems typically have a single model that covers most, if not all, cases in the data. At the opposite end of the spectrum is a collection of models, each of which covers a very small subset of the ...",
    "cited_by_count": 151,
    "openalex_id": "https://openalex.org/W4252278281",
    "type": "paratext"
  },
  {
    "title": "Model-Based Count Series Clustering for Bike Sharing System Usage Mining: A Case Study with the Vélib’ System of Paris",
    "doi": "https://doi.org/10.1145/2560188",
    "publication_date": "2014-07-28",
    "publication_year": 2014,
    "authors": "Étienne Côme; Latifa Oukhellou",
    "corresponding_authors": "",
    "abstract": "Today, more and more bicycle sharing systems (BSSs) are being introduced in big cities. These transportation systems generate sizable transportation data, the mining of which can reveal the underlying urban phenomenon linked to city dynamics. This article presents a statistical model to automatically analyze the trip data of a bike sharing system. The proposed solution partitions (i.e., clusters) the stations according to their usage profiles. To do so, count series describing the stations’s usage through departure/arrival counts per hour throughout the day are built and analyzed. The model for processing these count series is based on Poisson mixtures and introduces a station scaling factor that handles the differences between the stations’s global usage. Differences between weekday and weekend usage are also taken into account. This model identifies the latent factors that shape the geography of trips, and the results may thus offer insights into the relationships between station neighborhood type (its amenities, its demographics, etc.) and the generated mobility patterns. In other words, the proposed method brings to light the different functions in different areas that induce specific patterns in BSS data. These potentials are demonstrated through an in-depth analysis of the results obtained on the Paris Vélib’ large-scale bike sharing system.",
    "cited_by_count": 150,
    "openalex_id": "https://openalex.org/W1972189565",
    "type": "article"
  },
  {
    "title": "TIARA",
    "doi": "https://doi.org/10.1145/2089094.2089101",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Shi‐Xia Liu; Michelle X. Zhou; Shimei Pan; Yangqiu Song; Weihong Qian; Weijia Cai; Xiaoxiao Lian",
    "corresponding_authors": "",
    "abstract": "We are building an interactive visual text analysis tool that aids users in analyzing large collections of text. Unlike existing work in visual text analytics, which focuses either on developing sophisticated text analytic techniques or inventing novel text visualization metaphors, ours tightly integrates state-of-the-art text analytics with interactive visualization to maximize the value of both. In this article, we present our work from two aspects. We first introduce an enhanced, LDA-based topic analysis technique that automatically derives a set of topics to summarize a collection of documents and their content evolution over time. To help users understand the complex summarization results produced by our topic analysis technique, we then present the design and development of a time-based visualization of the results. Furthermore, we provide users with a set of rich interaction tools that help them further interpret the visualized results in context and examine the text collection from multiple perspectives. As a result, our work offers three unique contributions. First, we present an enhanced topic modeling technique to provide users with a time-sensitive and more meaningful text summary. Second, we develop an effective visual metaphor to transform abstract and often complex text summarization results into a comprehensible visual representation. Third, we offer users flexible visual interaction tools as alternatives to compensate for the deficiencies of current text summarization techniques. We have applied our work to a number of text corpora and our evaluation shows promise, especially in support of complex text analyses.",
    "cited_by_count": 148,
    "openalex_id": "https://openalex.org/W1996034305",
    "type": "article"
  },
  {
    "title": "Take a Look Around",
    "doi": "https://doi.org/10.1145/3342240",
    "publication_date": "2019-09-09",
    "publication_year": 2019,
    "authors": "Stephen Law; Brooks Paige; Chris Russell",
    "corresponding_authors": "",
    "abstract": "When an individual purchases a home, they simultaneously purchase its structural features, its accessibility to work, and the neighborhood amenities. Some amenities, such as air quality, are measurable while others, such as the prestige or the visual impression of a neighborhood, are difficult to quantify. Despite the well-known impacts intangible housing features have on house prices, limited attention has been given to systematically quantifying these difficult to measure amenities. Two issues have led to this neglect. Not only do few quantitative methods exist that can measure the urban environment, but that the collection of such data is both costly and subjective. We show that street image and satellite image data can capture these urban qualities and improve the estimation of house prices. We propose a pipeline that uses a deep neural network model to automatically extract visual features from images to estimate house prices in London, UK. We make use of traditional housing features such as age, size, and accessibility as well as visual features from Google Street View images and Bing aerial images in estimating the house price model. We find encouraging results where learning to characterize the urban quality of a neighborhood improves house price prediction, even when generalizing to previously unseen London boroughs. We explore the use of non-linear vs. linear methods to fuse these cues with conventional models of house pricing, and show how the interpretability of linear models allows us to directly extract proxy variables for visual desirability of neighborhoods that are both of interest in their own right, and could be used as inputs to other econometric methods. This is particularly valuable as once the network has been trained with the training data, it can be applied elsewhere, allowing us to generate vivid dense maps of the visual appeal of London streets.",
    "cited_by_count": 148,
    "openalex_id": "https://openalex.org/W4288101107",
    "type": "article"
  },
  {
    "title": "A Real-Time Hand Posture Recognition System Using Deep Neural Networks",
    "doi": "https://doi.org/10.1145/2735952",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Ao Tang; Ke Lü; Yufei Wang; Jie Huang; Houqiang Li",
    "corresponding_authors": "",
    "abstract": "Hand posture recognition (HPR) is quite a challenging task, due to both the difficulty in detecting and tracking hands with normal cameras and the limitations of traditional manually selected features. In this article, we propose a two-stage HPR system for Sign Language Recognition using a Kinect sensor. In the first stage, we propose an effective algorithm to implement hand detection and tracking. The algorithm incorporates both color and depth information, without specific requirements on uniform-colored or stable background. It can handle the situations in which hands are very close to other parts of the body or hands are not the nearest objects to the camera and allows for occlusion of hands caused by faces or other hands. In the second stage, we apply deep neural networks (DNNs) to automatically learn features from hand posture images that are insensitive to movement, scaling, and rotation. Experiments verify that the proposed system works quickly and accurately and achieves a recognition accuracy as high as 98.12%.",
    "cited_by_count": 146,
    "openalex_id": "https://openalex.org/W2004074725",
    "type": "article"
  },
  {
    "title": "An Approach to Ballet Dance Training through MS Kinect and Visualization in a CAVE Virtual Reality Environment",
    "doi": "https://doi.org/10.1145/2735951",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Matthew Kyan; Guoyu Sun; Haiyan Li; Ling Zhong; Paisarn Muneesawang; Nan Dong; Bruce Elder; Ling Guan",
    "corresponding_authors": "",
    "abstract": "This article proposes a novel framework for the real-time capture, assessment, and visualization of ballet dance movements as performed by a student in an instructional, virtual reality (VR) setting. The acquisition of human movement data is facilitated by skeletal joint tracking captured using the popular Microsoft (MS) Kinect camera system, while instruction and performance evaluation are provided in the form of 3D visualizations and feedback through a CAVE virtual environment, in which the student is fully immersed. The proposed framework is based on the unsupervised parsing of ballet dance movement into a structured posture space using the spherical self-organizing map (SSOM). A unique feature descriptor is proposed to more appropriately reflect the subtleties of ballet dance movements, which are represented as gesture trajectories through posture space on the SSOM. This recognition subsystem is used to identify the category of movement the student is attempting when prompted (by a virtual instructor) to perform a particular dance sequence. The dance sequence is then segmented and cross-referenced against a library of gestural components performed by the teacher. This facilitates alignment and score-based assessment of individual movements within the context of the dance sequence. An immersive interface enables the student to review his or her performance from a number of vantage points, each providing a unique perspective and spatial context suggestive of how the student might make improvements in training. An evaluation of the recognition and virtual feedback systems is presented.",
    "cited_by_count": 144,
    "openalex_id": "https://openalex.org/W1993813055",
    "type": "article"
  },
  {
    "title": "A temporal pattern mining approach for classifying electronic health record data",
    "doi": "https://doi.org/10.1145/2508037.2508044",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Iyad Batal; Hamed Valizadegan; Gregory F. Cooper; Miloš Hauskrecht",
    "corresponding_authors": "",
    "abstract": "We study the problem of learning classification models from complex multivariate temporal data encountered in electronic health record systems. The challenge is to define a good set of features that are able to represent well the temporal aspect of the data. Our method relies on temporal abstractions and temporal pattern mining to extract the classification features. Temporal pattern mining usually returns a large number of temporal patterns, most of which may be irrelevant to the classification task. To address this problem, we present the Minimal Predictive Temporal Patterns framework to generate a small set of predictive and nonspurious patterns. We apply our approach to the real-world clinical task of predicting patients who are at risk of developing heparin-induced thrombocytopenia. The results demonstrate the benefit of our approach in efficiently learning accurate classifiers, which is a key step for developing intelligent clinical monitoring systems.",
    "cited_by_count": 144,
    "openalex_id": "https://openalex.org/W2086019232",
    "type": "article"
  },
  {
    "title": "TopicNets",
    "doi": "https://doi.org/10.1145/2089094.2089099",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Brynjar Gretarsson; John O’Donovan; Svetlin Bostandjiev; Tobias Höllerer; Arthur Asuncion; David Newman; Padhraic Smyth",
    "corresponding_authors": "",
    "abstract": "We present TopicNets , a Web-based system for visual and interactive analysis of large sets of documents using statistical topic models. A range of visualization types and control mechanisms to support knowledge discovery are presented. These include corpus- and document-specific views, iterative topic modeling, search, and visual filtering. Drill-down functionality is provided to allow analysts to visualize individual document sections and their relations within the global topic space. Analysts can search across a dataset through a set of expansion techniques on selected document and topic nodes. Furthermore, analysts can select relevant subsets of documents and perform real-time topic modeling on these subsets to interactively visualize topics at various levels of granularity, allowing for a better understanding of the documents. A discussion of the design and implementation choices for each visual analysis technique is presented. This is followed by a discussion of three diverse use cases in which TopicNets enables fast discovery of information that is otherwise hard to find. These include a corpus of 50,000 successful NSF grant proposals, 10,000 publications from a large research center, and single documents including a grant proposal and a PhD thesis.",
    "cited_by_count": 142,
    "openalex_id": "https://openalex.org/W2054052884",
    "type": "article"
  },
  {
    "title": "Fuzzy Cognitive Diagnosis for Modelling Examinee Performance",
    "doi": "https://doi.org/10.1145/3168361",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Qi Liu; Runze Wu; Enhong Chen; Guandong Xu; Yu Su; Zhigang Chen; Guoping Hu",
    "corresponding_authors": "",
    "abstract": "Recent decades have witnessed the rapid growth of educational data mining (EDM), which aims at automatically extracting valuable information from large repositories of data generated by or related to people’s learning activities in educational settings. One of the key EDM tasks is cognitive modelling with examination data, and cognitive modelling tries to profile examinees by discovering their latent knowledge state and cognitive level (e.g. the proficiency of specific skills). However, to the best of our knowledge, the problem of extracting information from both objective and subjective examination problems to achieve more precise and interpretable cognitive analysis remains underexplored. To this end, we propose a fuzzy cognitive diagnosis framework (FuzzyCDF) for examinees’ cognitive modelling with both objective and subjective problems. Specifically, to handle the partially correct responses on subjective problems, we first fuzzify the skill proficiency of examinees. Then we combine fuzzy set theory and educational hypotheses to model the examinees’ mastery on the problems based on their skill proficiency. Finally, we simulate the generation of examination score on each problem by considering slip and guess factors. In this way, the whole diagnosis framework is built. For further comprehensive verification, we apply our FuzzyCDF to three classical cognitive assessment tasks, i.e., predicting examinee performance, slip and guess detection, and cognitive diagnosis visualization. Extensive experiments on three real-world datasets for these assessment tasks prove that FuzzyCDF can reveal the knowledge states and cognitive level of the examinees effectively and interpretatively.",
    "cited_by_count": 141,
    "openalex_id": "https://openalex.org/W2787760162",
    "type": "article"
  },
  {
    "title": "Learning to recommend with explicit and implicit social relations",
    "doi": "https://doi.org/10.1145/1961189.1961201",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Hao Ma; Irwin King; Michael R. Lyu",
    "corresponding_authors": "",
    "abstract": "Recommender systems have been well studied and developed, both in academia and in industry recently. However, traditional recommender systems assume that all the users are independent and identically distributed; this assumption ignores the connections among users, which is not consistent with the real-world observations where we always turn to our trusted friends for recommendations. Aiming at modeling recommender systems more accurately and realistically, we propose a novel probabilistic factor analysis framework which naturally fuses the users' tastes and their trusted friends' favors together. The proposed framework is quite general, and it can also be applied to pure user-item rating matrix even if we do not have explicit social trust information among users. In this framework, we coin the term social trust ensemble to represent the formulation of the social trust restrictions on the recommender systems. The complexity analysis indicates that our approach can be applied to very large datasets since it scales linearly with the number of observations, while the experimental results show that our method outperforms state-of-the-art approaches.",
    "cited_by_count": 140,
    "openalex_id": "https://openalex.org/W2020488968",
    "type": "article"
  },
  {
    "title": "CORN",
    "doi": "https://doi.org/10.1145/1961189.1961193",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Bin Li; Steven C. H. Hoi; Vivekanand Gopalkrishnan",
    "corresponding_authors": "",
    "abstract": "Machine learning techniques have been adopted to select portfolios from financial markets in some emerging intelligent business applications. In this article, we propose a novel learning-to-trade algorithm termed COR relation-driven N onparametric learning strategy (CORN) for actively trading stocks. CORN effectively exploits statistical relations between stock market windows via a nonparametric learning approach. We evaluate the empirical performance of our algorithm extensively on several large historical and latest real stock markets, and show that it can easily beat both the market index and the best stock in the market substantially (without or with small transaction costs), and also surpass a variety of state-of-the-art techniques significantly.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W2029480990",
    "type": "article"
  },
  {
    "title": "Mining geographic-temporal-semantic patterns in trajectories for location prediction",
    "doi": "https://doi.org/10.1145/2542182.2542184",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Josh Jia-Ching Ying; Wang-Chien Lee; Vincent S. Tseng",
    "corresponding_authors": "",
    "abstract": "In recent years, research on location predictions by mining trajectories of users has attracted a lot of attention. Existing studies on this topic mostly treat such predictions as just a type of location recommendation, that is, they predict the next location of a user using location recommenders. However, an user usually visits somewhere for reasons other than interestingness. In this article, we propose a novel mining-based location prediction approach called Geographic-Temporal-Semantic-based Location Prediction (GTS-LP), which takes into account a user's geographic-triggered intentions, temporal-triggered intentions, and semantic-triggered intentions, to estimate the probability of the user in visiting a location. The core idea underlying our proposal is the discovery of trajectory patterns of users, namely GTS patterns , to capture frequent movements triggered by the three kinds of intentions. To achieve this goal, we define a new trajectory pattern to capture the key properties of the behaviors that are motivated by the three kinds of intentions from trajectories of users. In our GTS-LP approach, we propose a series of novel matching strategies to calculate the similarity between the current movement of a user and discovered GTS patterns based on various moving intentions. On the basis of similitude, we make an online prediction as to the location the user intends to visit. To the best of our knowledge, this is the first work on location prediction based on trajectory pattern mining that explores the geographic, temporal, and semantic properties simultaneously. By means of a comprehensive evaluation using various real trajectory datasets, we show that our proposed GTS-LP approach delivers excellent performance and significantly outperforms existing state-of-the-art location prediction methods.",
    "cited_by_count": 133,
    "openalex_id": "https://openalex.org/W2121161839",
    "type": "article"
  },
  {
    "title": "PlayeRank",
    "doi": "https://doi.org/10.1145/3343172",
    "publication_date": "2019-09-12",
    "publication_year": 2019,
    "authors": "Luca Pappalardo; Paolo Cintia; Paolo Ferragina; Emanuele Massucco; Dino Pedreschi; Fosca Giannotti",
    "corresponding_authors": "",
    "abstract": "The problem of evaluating the performance of soccer players is attracting the interest of many companies and the scientific community, thanks to the availability of massive data capturing all the events generated during a match (e.g., tackles, passes, shots, etc.). Unfortunately, there is no consolidated and widely accepted metric for measuring performance quality in all of its facets. In this article, we design and implement PlayeRank, a data-driven framework that offers a principled multi-dimensional and role-aware evaluation of the performance of soccer players. We build our framework by deploying a massive dataset of soccer-logs and consisting of millions of match events pertaining to four seasons of 18 prominent soccer competitions. By comparing PlayeRank to known algorithms for performance evaluation in soccer, and by exploiting a dataset of players’ evaluations made by professional soccer scouts, we show that PlayeRank significantly outperforms the competitors. We also explore the ratings produced by PlayeRank and discover interesting patterns about the nature of excellent performances and what distinguishes the top players from the others. At the end, we explore some applications of PlayeRank—i.e. searching players and player versatility—showing its flexibility and efficiency, which makes it worth to be used in the design of a scalable platform for soccer analytics.",
    "cited_by_count": 132,
    "openalex_id": "https://openalex.org/W3103549299",
    "type": "article"
  },
  {
    "title": "Sound and Music Recommendation with Knowledge Graphs",
    "doi": "https://doi.org/10.1145/2926718",
    "publication_date": "2016-10-21",
    "publication_year": 2016,
    "authors": "Sergio Oramas; Vito Claudio Ostuni; Tommaso Di Noia; Xavier Serra; Eugenio Di Sciascio",
    "corresponding_authors": "",
    "abstract": "The Web has moved, slowly but steadily, from a collection of documents towards a collection of structured data. Knowledge graphs have then emerged as a way of representing the knowledge encoded in such data as well as a tool to reason on them in order to extract new and implicit information. Knowledge graphs are currently used, for example, to explain search results, to explore knowledge spaces, to semantically enrich textual documents, or to feed knowledge-intensive applications such as recommender systems. In this work, we describe how to create and exploit a knowledge graph to supply a hybrid recommendation engine with information that builds on top of a collections of documents describing musical and sound items. Tags and textual descriptions are exploited to extract and link entities to external graphs such as WordNet and DBpedia, which are in turn used to semantically enrich the initial data. By means of the knowledge graph we build, recommendations are computed using a feature combination hybrid approach. Two explicit graph feature mappings are formulated to obtain meaningful item feature representations able to catch the knowledge embedded in the graph. Those content features are further combined with additional collaborative information deriving from implicit user feedback. An extensive evaluation on historical data is performed over two different datasets: a dataset of sounds composed of tags, textual descriptions, and user’s download information gathered from Freesound.org and a dataset of songs that mixes song textual descriptions with tags and user’s listening habits extracted from Songfacts.com and Last.fm, respectively. Results show significant improvements with respect to state-of-the-art collaborative algorithms in both datasets. In addition, we show how the semantic expansion of the initial descriptions helps in achieving much better recommendation quality in terms of aggregated diversity and novelty.",
    "cited_by_count": 131,
    "openalex_id": "https://openalex.org/W2532651260",
    "type": "article"
  },
  {
    "title": "MoveMine",
    "doi": "https://doi.org/10.1145/1989734.1989741",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Zhenhui Li; Jiawei Han; Ji Ming; Lu‐An Tang; Yintao Yu; Bolin Ding; Jae-Gil Lee; Roland Kays",
    "corresponding_authors": "",
    "abstract": "With the maturity and wide availability of GPS, wireless, telecommunication, and Web technologies, massive amounts of object movement data have been collected from various moving object targets, such as animals, mobile devices, vehicles, and climate radars. Analyzing such data has deep implications in many applications, such as, ecological study, traffic control, mobile communication management, and climatological forecast. In this article, we focus our study on animal movement data analysis and examine advanced data mining methods for discovery of various animal movement patterns. In particular, we introduce a moving object data mining system, MoveMine, which integrates multiple data mining functions, including sophisticated pattern mining and trajectory analysis. In this system, two interesting moving object pattern mining functions are newly developed: (1) periodic behavior mining and (2) swarm pattern mining . For mining periodic behaviors, a reference location-based method is developed, which first detects the reference locations, discovers the periods in complex movements, and then finds periodic patterns by hierarchical clustering. For mining swarm patterns, an efficient method is developed to uncover flexible moving object clusters by relaxing the popularly-enforced collective movement constraints. In the MoveMine system, a set of commonly used moving object mining functions are built and a user-friendly interface is provided to facilitate interactive exploration of moving object data mining and flexible tuning of the mining constraints and parameters. MoveMine has been tested on multiple kinds of real datasets, especially for MoveBank applications and other moving object data analysis. The system will benefit scientists and other users to carry out versatile analysis tasks to analyze object movement regularities and anomalies. Moreover, it will benefit researchers to realize the importance and limitations of current techniques and promote future studies on moving object data mining. As expected, a mastery of animal movement patterns and trends will improve our understanding of the interactions between and the changes of the animal world and the ecosystem and therefore help ensure the sustainability of our ecosystem.",
    "cited_by_count": 127,
    "openalex_id": "https://openalex.org/W2141296717",
    "type": "article"
  },
  {
    "title": "Multiobjective Pareto-Efficient Approaches for Recommender Systems",
    "doi": "https://doi.org/10.1145/2629350",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Marco Túlio Ribeiro; Nívio Ziviani; Edleno Silva de Moura; Itamar Hata; Anísio Lacerda; Adriano Veloso",
    "corresponding_authors": "",
    "abstract": "Recommender systems are quickly becoming ubiquitous in applications such as e-commerce, social media channels, and content providers, among others, acting as an enabling mechanism designed to overcome the information overload problem by improving browsing and consumption experience. A typical task in many recommender systems is to output a ranked list of items, so that items placed higher in the rank are more likely to be interesting to the users. Interestingness measures include how accurate, novel, and diverse are the suggested items, and the objective is usually to produce ranked lists optimizing one of these measures. Suggesting items that are simultaneously accurate, novel, and diverse is much more challenging, since this may lead to a conflicting-objective problem, in which the attempt to improve a measure further may result in worsening other measures. In this article, we propose new approaches for multiobjective recommender systems based on the concept of Pareto efficiency—a state achieved when the system is devised in the most efficient manner in the sense that there is no way to improve one of the objectives without making any other objective worse off. Given that existing multiobjective recommendation algorithms differ in their level of accuracy, diversity, and novelty, we exploit the Pareto-efficiency concept in two distinct manners: (i) the aggregation of ranked lists produced by existing algorithms into a single one, which we call Pareto-efficient ranking, and (ii) the weighted combination of existing algorithms resulting in a hybrid one, which we call Pareto-efficient hybridization. Our evaluation involves two real application scenarios: music recommendation with implicit feedback (i.e., Last.fm) and movie recommendation with explicit feedback (i.e., MovieLens). We show that the proposed Pareto-efficient approaches are effective in suggesting items that are likely to be simultaneously accurate, diverse, and novel. We discuss scenarios where the system achieves high levels of diversity and novelty without compromising its accuracy. Further, comparison against multiobjective baselines reveals improvements in terms of accuracy (from 10.4% to 10.9%), novelty (from 5.7% to 7.5%), and diversity (from 1.6% to 4.2%).",
    "cited_by_count": 126,
    "openalex_id": "https://openalex.org/W2125442594",
    "type": "article"
  },
  {
    "title": "A Simple Baseline for Travel Time Estimation using Large-scale Trip Data",
    "doi": "https://doi.org/10.1145/3293317",
    "publication_date": "2019-01-12",
    "publication_year": 2019,
    "authors": "Hongjian Wang; Xianfeng Tang; Yu-Hsuan Kuo; Daniel Kifer; Zhenhui Li",
    "corresponding_authors": "",
    "abstract": "The increased availability of large-scale trajectory data provides rich information for the study of urban dynamics. For example, New York City Taxi 8 Limousine Commission regularly releases source/destination information of taxi trips, where 173 million taxi trips released for Year 2013 [29]. Such a big dataset provides us potential new perspectives to address the traditional traffic problems. In this article, we study the travel time estimation problem. Instead of following the traditional route-based travel time estimation, we propose to simply use a large amount of taxi trips without using the intermediate trajectory points to estimate the travel time between source and destination. Our experiments show very promising results. The proposed big-data-driven approach significantly outperforms both state-of-the-art route-based method and online map services. Our study indicates that novel simple approaches could be empowered by big data and these approaches could serve as new baselines for some traditional computational problems.",
    "cited_by_count": 124,
    "openalex_id": "https://openalex.org/W2910952060",
    "type": "article"
  },
  {
    "title": "Agent-based homeostatic control for green energy in the smart grid",
    "doi": "https://doi.org/10.1145/1989734.1989739",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Sarvapali D. Ramchurn; Perukrishnen Vytelingum; Alex Rogers; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "With dwindling nonrenewable energy reserves and the adverse effects of climate change, the development of the smart electricity grid is seen as key to solving global energy security issues and to reducing carbon emissions. In this respect, there is a growing need to integrate renewable (or green) energy sources in the grid. However, the intermittency of these energy sources requires that demand must also be made more responsive to changes in supply, and a number of smart grid technologies are being developed, such as high-capacity batteries and smart meters for the home, to enable consumers to be more responsive to conditions on the grid in real time. Traditional solutions based on these technologies, however, tend to ignore the fact that individual consumers will behave in such a way that best satisfies their own preferences to use or store energy (as opposed to that of the supplier or the grid operator). Hence, in practice, it is unclear how these solutions will cope with large numbers of consumers using their devices in this way. Against this background, in this article, we develop novel control mechanisms based on the use of autonomous agents to better incorporate consumer preferences in managing demand. These agents, residing on consumers' smart meters, can both communicate with the grid and optimize their owner's energy consumption to satisfy their preferences. More specifically, we provide a novel control mechanism that models and controls a system comprising of a green energy supplier operating within the grid and a number of individual homes (each possibly owning a storage device). This control mechanism is based on the concept of homeostasis whereby control signals are sent to individual components of a system, based on their continuous feedback, in order to change their state so that the system may reach a stable equilibrium. Thus, we define a new carbon-based pricing mechanism for this green energy supplier that takes advantage of carbon-intensity signals available on the Internet in order to provide real-time pricing. The pricing scheme is designed in such a way that it can be readily implemented using existing communication technologies and is easily understandable by consumers. Building upon this, we develop new control signals that the supplier can use to incentivize agents to shift demand (using their storage device) to times when green energy is available. Moreover, we show how these signals can be adapted according to changes in supply and to various degrees of penetration of storage in the system. We empirically evaluate our system and show that, when all homes are equipped with storage devices, the supplier can significantly reduce its reliance on other carbon-emitting power sources to cater for its own shortfalls. By so doing, the supplier reduces the carbon emission of the system by up to 25% while the consumer reduces its costs by up to 14.5%. Finally, we demonstrate that our homeostatic control mechanism is not sensitive to small prediction errors and the supplier is incentivized to accurately predict its green production to minimize costs.",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W1977146286",
    "type": "article"
  },
  {
    "title": "P2P Lending Survey",
    "doi": "https://doi.org/10.1145/3078848",
    "publication_date": "2017-07-24",
    "publication_year": 2017,
    "authors": "Hongke Zhao; Yong Ge; Qi Liu; Guifeng Wang; Enhong Chen; Hefu Zhang",
    "corresponding_authors": "",
    "abstract": "P2P lending is an emerging Internet-based application where individuals can directly borrow money from each other. The past decade has witnessed the rapid development and prevalence of online P2P lending platforms, examples of which include Prosper, LendingClub, and Kiva. Meanwhile, extensive research has been done that mainly focuses on the studies of platform mechanisms and transaction data. In this article, we provide a comprehensive survey on the research about P2P lending, which, to the best of our knowledge, is the first focused effort in this field. Specifically, we first provide a systematic taxonomy for P2P lending by summarizing different types of mainstream platforms and comparing their working mechanisms in detail. Then, we review and organize the recent advances on P2P lending from various perspectives (e.g., economics and sociology perspective, and data-driven perspective). Finally, we propose our opinions on the prospects of P2P lending and suggest some future research directions in this field. Meanwhile, throughout this paper, some analysis on real-world data collected from Prosper and Kiva are also conducted.",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W2738900953",
    "type": "article"
  },
  {
    "title": "A Review of Co-Saliency Detection Algorithms",
    "doi": "https://doi.org/10.1145/3158674",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Dingwen Zhang; Huazhu Fu; Junwei Han; Ali Borji; Xuelong Li",
    "corresponding_authors": "",
    "abstract": "Co-saliency detection is a newly emerging and rapidly growing research area in the computer vision community. As a novel branch of visual saliency, co-saliency detection refers to the discovery of common and salient foregrounds from two or more relevant images, and it can be widely used in many computer vision tasks. The existing co-saliency detection algorithms mainly consist of three components: extracting effective features to represent the image regions, exploring the informative cues or factors to characterize co-saliency, and designing effective computational frameworks to formulate co-saliency. Although numerous methods have been developed, the literature is still lacking a deep review and evaluation of co-saliency detection techniques. In this article, we aim at providing a comprehensive review of the fundamentals, challenges, and applications of co-saliency detection. Specifically, we provide an overview of some related computer vision works, review the history of co-saliency detection, summarize and categorize the major algorithms in this research area, discuss some open issues in this area, present the potential applications of co-saliency detection, and finally point out some unsolved challenges and promising future works. We expect this review to be beneficial to both fresh and senior researchers in this field and to give insights to researchers in other related areas regarding the utility of co-saliency detection algorithms.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2792965491",
    "type": "review"
  },
  {
    "title": "Structure and Overlaps of Ground-Truth Communities in Networks",
    "doi": "https://doi.org/10.1145/2594454",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Jaewon Yang; Jure Leskovec",
    "corresponding_authors": "",
    "abstract": "One of the main organizing principles in real-world networks is that of network communities , where sets of nodes organize into densely linked clusters. Even though detection of such communities is of great interest, understanding the structure communities in large networks remains relatively limited. In particular, due to the unavailability of labeled ground-truth data, it was traditionally very hard to develop accurate models of network community structure. Here we use six large social, collaboration, and information networks where nodes explicitly state their ground-truth community memberships. For example, nodes in social networks join into explicitly defined interest based groups, and we use such groups as explicitly labeled ground-truth communities. We use such ground-truth communities to study their structural signatures by analyzing how ground-truth communities emerge in networks and how they overlap. We observe some surprising phenomena. First, ground-truth communities contain high-degree hub nodes that reside in community overlaps and link to most of the members of the community. Second, the overlaps of communities are more densely connected than the non-overlapping parts of communities. We show that this in contrast to the conventional wisdom that community overlaps are more sparsely connected than the non-overlapping parts themselves. We then show that many existing models of network communities do not capture dense community overlaps. This in turn means that most present models and community detection methods confuse overlaps as separate communities. In contrast, we present the community-affiliation graph model (AGM), a conceptual model of network community structure. We demonstrate that AGM reliably captures the overall structure of networks as well as the overlapping and hierarchical nature of network communities.",
    "cited_by_count": 117,
    "openalex_id": "https://openalex.org/W2020547732",
    "type": "article"
  },
  {
    "title": "Monitoring business constraints with the event calculus",
    "doi": "https://doi.org/10.1145/2542182.2542199",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Marco Montali; Fabrizio Maria Maggi; Federico Chesani; Paola Mello; Wil M. P. van der Aalst",
    "corresponding_authors": "",
    "abstract": "Today, large business processes are composed of smaller, autonomous, interconnected subsystems, achieving modularity and robustness. Quite often, these large processes comprise software components as well as human actors, they face highly dynamic environments and their subsystems are updated and evolve independently of each other. Due to their dynamic nature and complexity, it might be difficult, if not impossible, to ensure at design-time that such systems will always exhibit the desired/expected behaviors. This, in turn, triggers the need for runtime verification and monitoring facilities. These are needed to check whether the actual behavior complies with expected business constraints, internal/external regulations and desired best practices. In this work, we present Mobucon EC, a novel monitoring framework that tracks streams of events and continuously determines the state of business constraints. In Mobucon EC, business constraints are defined using the declarative language Declare. For the purpose of this work, Declare has been suitably extended to support quantitative time constraints and non-atomic, durative activities. The logic-based language Event Calculus (EC) has been adopted to provide a formal specification and semantics to Declare constraints, while a light-weight, logic programming-based EC tool supports dynamically reasoning about partial, evolving execution traces. To demonstrate the applicability of our approach, we describe a case study about maritime safety and security and provide a synthetic benchmark to evaluate its scalability.",
    "cited_by_count": 117,
    "openalex_id": "https://openalex.org/W2100680119",
    "type": "article"
  },
  {
    "title": "Mining contextual movie similarity with matrix factorization for context-aware recommendation",
    "doi": "https://doi.org/10.1145/2414425.2414441",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Yue Shi; Martha Larson; Alan Hanjalić",
    "corresponding_authors": "",
    "abstract": "Context-aware recommendation seeks to improve recommendation performance by exploiting various information sources in addition to the conventional user-item matrix used by recommender systems. We propose a novel context-aware movie recommendation algorithm based on joint matrix factorization (JMF). We jointly factorize the user-item matrix containing general movie ratings and other contextual movie similarity matrices to integrate contextual information into the recommendation process. The algorithm was developed within the scope of the mood-aware recommendation task that was offered by the Moviepilot mood track of the 2010 context-aware movie recommendation (CAMRa) challenge. Although the algorithm could generalize to other types of contextual information, in this work, we focus on two: movie mood tags and movie plot keywords. Since the objective in this challenge track is to recommend movies for a user given a specified mood, we devise a novel mood-specific movie similarity measure for this purpose. We enhance the recommendation based on this measure by also deploying the second movie similarity measure proposed in this article that takes into account the movie plot keywords. We validate the effectiveness of the proposed JMF algorithm with respect to the recommendation performance by carrying out experiments on the Moviepilot challenge dataset. We demonstrate that exploiting contextual information in JMF leads to significant improvement over several state-of-the-art approaches that generate movie recommendations without using contextual information. We also demonstrate that our proposed mood-specific movie similarity is better suited for the task than the conventional mood-based movie similarity measures. Finally, we show that the enhancement provided by the movie similarity capturing the plot keywords is particularly helpful in improving the recommendation to those users who are significantly more active in rating the movies than other users.",
    "cited_by_count": 105,
    "openalex_id": "https://openalex.org/W2030385985",
    "type": "article"
  },
  {
    "title": "Incentives for Effort in Crowdsourcing Using the Peer Truth Serum",
    "doi": "https://doi.org/10.1145/2856102",
    "publication_date": "2016-03-31",
    "publication_year": 2016,
    "authors": "Goran Radanović; Boi Faltings; Radu Jurca",
    "corresponding_authors": "",
    "abstract": "Crowdsourcing is widely proposed as a method to solve a large variety of judgment tasks, such as classifying website content, peer grading in online courses, or collecting real-world data. As the data reported by workers cannot be verified, there is a tendency to report random data without actually solving the task. This can be countered by making the reward for an answer depend on its consistency with answers given by other workers, an approach called peer consistency . However, it is obvious that the best strategy in such schemes is for all workers to report the same answer without solving the task. Dasgupta and Ghosh [2013] show that, in some cases, exerting high effort can be encouraged in the highest-paying equilibrium. In this article, we present a general mechanism that implements this idea and is applicable to most crowdsourcing settings. Furthermore, we experimentally test the novel mechanism, and validate its theoretical properties.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2267283990",
    "type": "article"
  },
  {
    "title": "Self-weighted Robust LDA for Multiclass Classification with Edge Classes",
    "doi": "https://doi.org/10.1145/3418284",
    "publication_date": "2020-12-22",
    "publication_year": 2020,
    "authors": "Caixia Yan; Xiaojun Chang; Minnan Luo; Qinghua Zheng; Xiaoqin Zhang; Zhihui Li; Feiping Nie",
    "corresponding_authors": "",
    "abstract": "Linear discriminant analysis (LDA) is a popular technique to learn the most discriminative features for multi-class classification. A vast majority of existing LDA algorithms are prone to be dominated by the class with very large deviation from the others, i.e., edge class, which occurs frequently in multi-class classification. First, the existence of edge classes often makes the total mean biased in the calculation of between-class scatter matrix. Second, the exploitation of ℓ 2 -norm based between-class distance criterion magnifies the extremely large distance corresponding to edge class. In this regard, a novel self-weighted robust LDA with ℓ 2,1 -norm based pairwise between-class distance criterion, called SWRLDA, is proposed for multi-class classification especially with edge classes. SWRLDA can automatically avoid the optimal mean calculation and simultaneously learn adaptive weights for each class pair without setting any additional parameter. An efficient re-weighted algorithm is exploited to derive the global optimum of the challenging ℓ 2,1 -norm maximization problem. The proposed SWRLDA is easy to implement and converges fast in practice. Extensive experiments demonstrate that SWRLDA performs favorably against other compared methods on both synthetic and real-world datasets while presenting superior computational efficiency in comparison with other techniques.",
    "cited_by_count": 103,
    "openalex_id": "https://openalex.org/W3117488606",
    "type": "article"
  },
  {
    "title": "Web Table Extraction, Retrieval, and Augmentation",
    "doi": "https://doi.org/10.1145/3372117",
    "publication_date": "2020-01-25",
    "publication_year": 2020,
    "authors": "Shuo Zhang; Krisztian Balog",
    "corresponding_authors": "",
    "abstract": "Tables are powerful and popular tools for organizing and manipulating data. A vast number of tables can be found on the Web, which represent a valuable knowledge resource. The objective of this survey is to synthesize and present two decades of research on web tables. In particular, we organize existing literature into six main categories of information access tasks: table extraction, table interpretation, table search, question answering, knowledge base augmentation, and table augmentation. For each of these tasks, we identify and describe seminal approaches, present relevant resources, and point out interdependencies among the different tasks.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W3008881932",
    "type": "article"
  },
  {
    "title": "Extracting City Traffic Events from Social Streams",
    "doi": "https://doi.org/10.1145/2717317",
    "publication_date": "2015-07-10",
    "publication_year": 2015,
    "authors": "Pramod Anantharam; Payam Barnaghi; Krishnaprasad Thirunarayan; Amit Sheth",
    "corresponding_authors": "",
    "abstract": "Cities are composed of complex systems with physical, cyber, and social components. Current works on extracting and understanding city events mainly rely on technology-enabled infrastructure to observe and record events. In this work, we propose an approach to leverage citizen observations of various city systems and services, such as traffic, public transport, water supply, weather, sewage, and public safety, as a source of city events. We investigate the feasibility of using such textual streams for extracting city events from annotated text. We formalize the problem of annotating social streams such as microblogs as a sequence labeling problem. We present a novel training data creation process for training sequence labeling models. Our automatic training data creation process utilizes instance-level domain knowledge (e.g., locations in a city, possible event terms). We compare this automated annotation process to a state-of-the-art tool that needs manually created training data and show that it has comparable performance in annotation tasks. An aggregation algorithm is then presented for event extraction from annotated text. We carry out a comprehensive evaluation of the event annotation and event extraction on a real-world dataset consisting of event reports and tweets collected over 4 months from the San Francisco Bay Area. The evaluation results are promising and provide insights into the utility of social stream for extracting city events.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W1892832513",
    "type": "article"
  },
  {
    "title": "Using Scalable Data Mining for Predicting Flight Delays",
    "doi": "https://doi.org/10.1145/2888402",
    "publication_date": "2016-07-15",
    "publication_year": 2016,
    "authors": "Loris Belcastro; Fabrizio Marozzo; Domenico Talia; Paolo Trunfio",
    "corresponding_authors": "",
    "abstract": "Flight delays are frequent all over the world (about 20% of airline flights arrive more than 15min late) and they are estimated to have an annual cost of billions of dollars. This scenario makes the prediction of flight delays a primary issue for airlines and travelers. The main goal of this work is to implement a predictor of the arrival delay of a scheduled flight due to weather conditions. The predicted arrival delay takes into consideration both flight information (origin airport, destination airport, scheduled departure and arrival time) and weather conditions at origin airport and destination airport according to the flight timetable. Airline flight and weather observation datasets have been analyzed and mined using parallel algorithms implemented as MapReduce programs executed on a Cloud platform. The results show a high accuracy in predicting delays above a given threshold. For instance, with a delay threshold of 15min, we achieve an accuracy of 74.2% and 71.8% recall on delayed flights, while with a threshold of 60min, the accuracy is 85.8% and the delay recall is 86.9%. Furthermore, the experimental results demonstrate the predictor scalability that can be achieved performing data preparation and mining tasks as MapReduce applications on the Cloud.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2475367951",
    "type": "article"
  },
  {
    "title": "SPrank",
    "doi": "https://doi.org/10.1145/2899005",
    "publication_date": "2016-09-20",
    "publication_year": 2016,
    "authors": "Tommaso Di Noia; Vito Claudio Ostuni; Paolo Tomeo; Eugenio Di Sciascio",
    "corresponding_authors": "",
    "abstract": "In most real-world scenarios, the ultimate goal of recommender system applications is to suggest a short ranked list of items, namely top- N recommendations, that will appeal to the end user. Often, the problem of computing top- N recommendations is mainly tackled with a two-step approach. The system focuses first on predicting the unknown ratings, which are eventually used to generate a ranked recommendation list. Actually, the top- N recommendation task can be directly seen as a ranking problem where the main goal is not to accurately predict ratings but to directly find the best-ranked list of items to recommend. In this article we present SPrank, a novel hybrid recommendation algorithm able to compute top- N recommendations exploiting freely available knowledge in the Web of Data. In particular, we employ DBpedia, a well-known encyclopedic knowledge base in the Linked Open Data cloud, to extract semantic path-based features and to eventually compute top- N recommendations in a learning-to-rank fashion. Experiments with three datasets related to different domains (books, music, and movies) prove the effectiveness of our approach compared to state-of-the-art recommendation algorithms.",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W2523367416",
    "type": "article"
  },
  {
    "title": "Multiview Discrete Hashing for Scalable Multimedia Search",
    "doi": "https://doi.org/10.1145/3178119",
    "publication_date": "2018-06-01",
    "publication_year": 2018,
    "authors": "Xiaobo Shen; Fumin Shen; Li Liu; Yunhao Yuan; Weiwei Liu; Quansen Sun",
    "corresponding_authors": "",
    "abstract": "Hashing techniques have recently gained increasing research interest in multimedia studies. Most existing hashing methods only employ single features for hash code learning. Multiview data with each view corresponding to a type of feature generally provides more comprehensive information. How to efficiently integrate multiple views for learning compact hash codes still remains challenging. In this article, we propose a novel unsupervised hashing method, dubbed multiview discrete hashing (MvDH), by effectively exploring multiview data. Specifically, MvDH performs matrix factorization to generate the hash codes as the latent representations shared by multiple views, during which spectral clustering is performed simultaneously. The joint learning of hash codes and cluster labels enables that MvDH can generate more discriminative hash codes, which are optimal for classification. An efficient alternating algorithm is developed to solve the proposed optimization problem with guaranteed convergence and low computational complexity. The binary codes are optimized via the discrete cyclic coordinate descent (DCC) method to reduce the quantization errors. Extensive experimental results on three large-scale benchmark datasets demonstrate the superiority of the proposed method over several state-of-the-art methods in terms of both accuracy and scalability.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2805087257",
    "type": "article"
  },
  {
    "title": "A Causal Dirichlet Mixture Model for Causal Inference from Observational Data",
    "doi": "https://doi.org/10.1145/3379500",
    "publication_date": "2020-04-29",
    "publication_year": 2020,
    "authors": "Adi Lin; Jie Lü; Junyu Xuan; Fujin Zhu; Guangquan Zhang",
    "corresponding_authors": "",
    "abstract": "Estimating causal effects by making causal inferences from observational data is common practice in scientific studies, business decision-making, and daily life. In today’s data-driven world, causal inference has become a key part of the evaluation process for many purposes, such as examining the effects of medicine or the impact of an economic policy on society. However, although the literature contains some excellent models, there is room to improve their representation power and their ability to capture complex relationships. For these reasons, we propose a novel prior called Causal DP and a model called CDP. The prior captures the complex relationships between covariates, treatments, and outcomes in observational data using a rational probabilistic dependency structure. The model is Bayesian, nonparametric, and generative and is not based on the assumption of any parametric distribution. CDP is designed to estimate various kinds of causal effects—average, conditional average, average treated, quantile, and so on. It performs well with missing covariates and does not suffer from overfitting. Comparative experiments on synthetic datasets against several state-of-the-art methods demonstrate that CDP has a superior ability to capture complex relationships. Further, a simple evaluation to infer the effect of a job training program on trainee earnings from real-world data shows that CDP is both effective and useful for causal inference.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W3023496898",
    "type": "article"
  },
  {
    "title": "Dynamic Planning of Bicycle Stations in Dockless Public Bicycle-sharing System Using Gated Graph Neural Network",
    "doi": "https://doi.org/10.1145/3446342",
    "publication_date": "2021-03-12",
    "publication_year": 2021,
    "authors": "Jianguo Chen; Kenli Li; Keqin Li; Philip S. Yu; Zeng Zeng",
    "corresponding_authors": "",
    "abstract": "Benefiting from convenient cycling and flexible parking locations, the Dockless Public Bicycle-sharing (DL-PBS) network becomes increasingly popular in many countries. However, redundant and low-utility stations waste public urban space and maintenance costs of DL-PBS vendors. In this article, we propose a Bicycle Station Dynamic Planning (BSDP) system to dynamically provide the optimal bicycle station layout for the DL-PBS network. The BSDP system contains four modules: bicycle drop-off location clustering, bicycle-station graph modeling, bicycle-station location prediction, and bicycle-station layout recommendation. In the bicycle drop-off location clustering module, candidate bicycle stations are clustered from each spatio-temporal subset of the large-scale cycling trajectory records. In the bicycle-station graph modeling module, a weighted digraph model is built based on the clustering results and inferior stations with low station revenue and utility are filtered. Then, graph models across time periods are combined to create a graph sequence model. In the bicycle-station location prediction module, the GGNN model is used to train the graph sequence data and dynamically predict bicycle stations in the next period. In the bicycle-station layout recommendation module, the predicted bicycle stations are fine-tuned according to the government urban management plan, which ensures that the recommended station layout is conducive to city management, vendor revenue, and user convenience. Experiments on actual DL-PBS networks verify the effectiveness, accuracy, and feasibility of the proposed BSDP system.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W3136758818",
    "type": "article"
  },
  {
    "title": "GRNN: Generative Regression Neural Network—A Data Leakage Attack for Federated Learning",
    "doi": "https://doi.org/10.1145/3510032",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Hanchi Ren; Jingjing Deng; Xianghua Xie",
    "corresponding_authors": "",
    "abstract": "Data privacy has become an increasingly important issue in Machine Learning (ML) , where many approaches have been developed to tackle this challenge, e.g., cryptography ( Homomorphic Encryption (HE) , Differential Privacy (DP) ) and collaborative training (Secure Multi-Party Computation (MPC) , Distributed Learning, and Federated Learning (FL) ). These techniques have a particular focus on data encryption or secure local computation. They transfer the intermediate information to the third party to compute the final result. Gradient exchanging is commonly considered to be a secure way of training a robust model collaboratively in Deep Learning (DL) . However, recent researches have demonstrated that sensitive information can be recovered from the shared gradient. Generative Adversarial Network (GAN) , in particular, has shown to be effective in recovering such information. However, GAN based techniques require additional information, such as class labels that are generally unavailable for privacy-preserved learning. In this article, we show that, in the FL system, image-based privacy data can be easily recovered in full from the shared gradient only via our proposed Generative Regression Neural Network (GRNN) . We formulate the attack to be a regression problem and optimize two branches of the generative model by minimizing the distance between gradients. We evaluate our method on several image classification tasks. The results illustrate that our proposed GRNN outperforms state-of-the-art methods with better stability, stronger robustness, and higher accuracy. It also has no convergence requirement to the global FL model. Moreover, we demonstrate information leakage using face re-identification. Some defense strategies are also discussed in this work.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W3158675315",
    "type": "article"
  },
  {
    "title": "Learning Generalizable and Identity-Discriminative Representations for Face Anti-Spoofing",
    "doi": "https://doi.org/10.1145/3402446",
    "publication_date": "2020-07-26",
    "publication_year": 2020,
    "authors": "Xiaoguang Tu; Zheng Ma; Jian Zhao; Guodong Du; Mei Xie; Jiashi Feng",
    "corresponding_authors": "",
    "abstract": "Face anti-spoofing aims to detect presentation attack to face recognition--based authentication systems. It has drawn growing attention due to the high security demand. The widely adopted CNN-based methods usually well recognize the spoofing faces when training and testing spoofing samples display similar patterns, but their performance would drop drastically on testing spoofing faces of novel patterns or unseen scenes, leading to poor generalization performance. Furthermore, almost all current methods treat face anti-spoofing as a prior step to face recognition, which prolongs the response time and makes face authentication inefficient. In this article, we try to boost the generalizability and applicability of face anti-spoofing methods by designing a new generalizable face authentication CNN (GFA-CNN) model with three novelties. First, GFA-CNN introduces a simple yet effective total pairwise confusion loss for CNN training that properly balances contributions of all spoofing patterns for recognizing the spoofing faces. Second, it incorporate a fast domain adaptation component to alleviate negative effects brought by domain variation. Third, it deploys filter diversification learning to make the learned representations more adaptable to new scenes. In addition, the proposed GFA-CNN works in a multi-task manner—it performs face anti-spoofing and face recognition simultaneously. Experimental results on five popular face anti-spoofing and face recognition benchmarks show that GFA-CNN outperforms previous face anti-spoofing methods on cross-test protocols significantly and also well preserves the identity information of input face images.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W3045675435",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey of the Key Technologies and Challenges Surrounding Vehicular Ad Hoc Networks",
    "doi": "https://doi.org/10.1145/3451984",
    "publication_date": "2021-06-08",
    "publication_year": 2021,
    "authors": "Zhenchang Xia; Jia Wu; Libing Wu; Yanjiao Chen; Jian Yang; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Vehicular ad hoc networks ( VANETs ) and the services they support are an essential part of intelligent transportation. Through physical technologies, applications, protocols, and standards, they help to ensure traffic moves efficiently and vehicles operate safely. This article surveys the current state of play in VANETs development. The summarized and classified include the key technologies critical to the field, the resource-management and safety applications needed for smooth operations, the communications and data transmission protocols that support networking, and the theoretical and environmental constructs underpinning research and development, such as graph neural networks and the Internet of Things. Additionally, we identify and discuss several challenges facing VANETs, including poor safety, poor reliability, non-uniform standards, and low intelligence levels. Finally, we touch on hot technologies and techniques, such as reinforcement learning and 5G communications, to provide an outlook for the future of intelligent transportation systems.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W3166863548",
    "type": "article"
  },
  {
    "title": "<scp>FedBERT</scp>: When Federated Learning Meets Pre-training",
    "doi": "https://doi.org/10.1145/3510033",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Yuanyishu Tian; Yao Wan; Lingjuan Lyu; Dezhong Yao; Hai Jin; Lichao Sun",
    "corresponding_authors": "",
    "abstract": "The fast growth of pre-trained models (PTMs) has brought natural language processing to a new era, which has become a dominant technique for various natural language processing (NLP) applications. Every user can download the weights of PTMs, then fine-tune the weights for a task on the local side. However, the pre-training of a model relies heavily on accessing a large-scale of training data and requires a vast amount of computing resources. These strict requirements make it impossible for any single client to pre-train such a model. To grant clients with limited computing capability to participate in pre-training a large model, we propose a new learning approach, FedBERT , that takes advantage of the federated learning and split learning approaches, resorting to pre-training BERT in a federated way. FedBERT can prevent sharing the raw data information and obtain excellent performance. Extensive experiments on seven GLUE tasks demonstrate that FedBERT can maintain its effectiveness without communicating to the sensitive local data of clients.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W4214607237",
    "type": "article"
  },
  {
    "title": "Federated Learning for Electronic Health Records",
    "doi": "https://doi.org/10.1145/3514500",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Trung Kien Dang; Lan Xiang; Jianshu Weng; Mengling Feng",
    "corresponding_authors": "",
    "abstract": "In data-driven medical research, multi-center studies have long been preferred over single-center ones due to a single institute sometimes not having enough data to obtain sufficient statistical power for certain hypothesis testings as well as predictive and subgroup studies. The wide adoption of electronic health records (EHRs) has made multi-institutional collaboration much more feasible. However, concerns over infrastructures, regulations, privacy, and data standardization present a challenge to data sharing across healthcare institutions. Federated Learning (FL), which allows multiple sites to collaboratively train a global model without directly sharing data, has become a promising paradigm to break the data isolation. In this study, we surveyed existing works on FL applications in EHRs and evaluated the performance of current state-of-the-art FL algorithms on two EHR machine learning tasks of significant clinical importance on a real world multi-center EHR dataset.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W4225272053",
    "type": "article"
  },
  {
    "title": "Multivariate Correlation-aware Spatio-temporal Graph Convolutional Networks for Multi-scale Traffic Prediction",
    "doi": "https://doi.org/10.1145/3469087",
    "publication_date": "2022-01-18",
    "publication_year": 2022,
    "authors": "Senzhang Wang; Meiyue Zhang; Hao Miao; Zhaohui Peng; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Traffic flow prediction based on vehicle trajectories collected from the installed GPS devices is critically important to Intelligent Transportation Systems (ITS). One limitation of existing traffic prediction models is that they mostly focus on predicting road-segment level traffic conditions, which can be considered as a fine-grained prediction. In many scenarios, however, a coarse-grained prediction, such as predicting the traffic flows among different urban areas covering multiple road links, is also required to help government have a better understanding on traffic conditions from the macroscopic point of view. This is especially useful in the applications of urban planning and public transportation planning. Another limitation is that the correlations among different types of traffic-related features are largely ignored. For example, the traffic flow and traffic speed are usually negatively correlated. Existing works regard these traffic-related features as independent features without considering their correlations. In this article, we for the first time study the novel problem of multivariate correlation-aware multi-scale traffic flow predicting, and we propose a feature correlation-aware spatio-temporal graph convolutional networks named MC-STGCN to effectively address it. Specifically, given a road graph, we first construct a coarse-grained road graph based on both the topology closeness and the traffic flow similarity among the nodes (road links). Then a cross-scale spatial-temporal feature learning and fusion technique is proposed for dealing with both the fine- and coarse-grained traffic data. In the spatial domain, a cross-scale GCN is proposed to learn the multi-scale spatial features jointly and fuse them together. In the temporal domain, a cross-scale temporal network that is composed of a hierarchical attention is designed for effectively capturing intra- and inter-scale temporal correlations. To effectively capture the feature correlations, a feature correlation learning component is also designed. Finally, a structural constraint is introduced to make the predictions on the two scale traffic data consistent. We conduct extensive evaluations over two real traffic datasets, and the results demonstrate the superior performance of the proposal on both fine- and coarse-grained traffic predictions.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W4206626673",
    "type": "article"
  },
  {
    "title": "Communication-Efficient Federated Learning with Adaptive Quantization",
    "doi": "https://doi.org/10.1145/3510587",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Yuzhu Mao; Zihao Zhao; Guangfeng Yan; Liu Yang; Tian Lan; Linqi Song; Wenbo Ding",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) has attracted tremendous attentions in recent years due to its privacy-preserving measures and great potential in some distributed but privacy-sensitive applications, such as finance and health. However, high communication overloads for transmitting high-dimensional networks and extra security masks remain a bottleneck of FL. This article proposes a communication-efficient FL framework with an Adaptive Quantized Gradient (AQG), which adaptively adjusts the quantization level based on a local gradient’s update to fully utilize the heterogeneity of local data distribution for reducing unnecessary transmissions. In addition, client dropout issues are taken into account and an Augmented AQG is developed, which could limit the dropout noise with an appropriate amplification mechanism for transmitted gradients. Theoretical analysis and experiment results show that the proposed AQG leads to 18% to 50% of additional transmission reduction as compared with existing popular methods, including Quantized Gradient Descent (QGD) and Lazily Aggregated Quantized (LAQ) gradient-based methods without deteriorating convergence properties. Experiments with heterogenous data distributions corroborate a more significant transmission reduction compared with independent identical data distributions. The proposed AQG is robust to a client dropping rate up to 90% empirically, and the Augmented AQG manages to further improve the FL system’s communication efficiency with the presence of moderate-scale client dropouts commonly seen in practical FL scenarios.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W4290003882",
    "type": "article"
  },
  {
    "title": "Fairness in Recommendation: Foundations, Methods, and Applications",
    "doi": "https://doi.org/10.1145/3610302",
    "publication_date": "2023-07-27",
    "publication_year": 2023,
    "authors": "Yunqi Li; Hanxiong Chen; Shuyuan Xu; Yingqiang Ge; Juntao Tan; Shuchang Liu; Yongfeng Zhang",
    "corresponding_authors": "",
    "abstract": "As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision-making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This survey focuses on the foundations for fairness in recommendation literature. It first presents a brief introduction about fairness in basic machine learning tasks such as classification and ranking to provide a general overview of fairness research, as well as introduce the more complex situations and challenges that need to be considered when studying fairness in recommender systems. After that, the survey will introduce fairness in recommendation with a focus on the taxonomies of current fairness definitions, the typical techniques for improving fairness, as well as the datasets for fairness studies in recommendation. The survey also talks about the challenges and opportunities in fairness research with the hope of promoting the fair recommendation research area and beyond.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W4385302663",
    "type": "article"
  },
  {
    "title": "PSDF: Privacy-aware IoV Service Deployment with Federated Learning in Cloud-Edge Computing",
    "doi": "https://doi.org/10.1145/3501810",
    "publication_date": "2022-08-17",
    "publication_year": 2022,
    "authors": "Xiaolong Xu; Wentao Liu; Yulan Zhang; Xuyun Zhang; Wanchun Dou; Lianyong Qi; Md Zakirul Alam Bhuiyan",
    "corresponding_authors": "",
    "abstract": "Through the collaboration of cloud and edge, cloud-edge computing allows the edge that approximates end-users undertakes those non-computationally intensive service processing of the cloud, reducing the communication overhead and satisfying the low latency requirement of Internet of Vehicle (IoV). With cloud-edge computing, the computing tasks in IoV is able to be delivered to the edge servers (ESs) instead of the cloud and rely on the deployed services of ESs for a series of processing. Due to the storage and computing resource limits of ESs, how to dynamically deploy partial services to the edge is still a puzzle. Moreover, the decision of service deployment often requires the transmission of local service requests from ESs to the cloud, which increases the risk of privacy leakage. In this article, a method for privacy-aware IoV service deployment with federated learning in cloud-edge computing, named PSDF, is proposed. Technically, federated learning secures the distributed training of deployment decision network on each ES by the exchange and aggregation of model weights, avoiding the original data transmission. Meanwhile, homomorphic encryption is adopted for the uploaded weights before the model aggregation on the cloud. Besides, a service deployment scheme based on deep deterministic policy gradient is proposed. Eventually, the performance of PSDF is evaluated by massive experiments.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W4292092864",
    "type": "article"
  },
  {
    "title": "Reinforcement Learning for Quantitative Trading",
    "doi": "https://doi.org/10.1145/3582560",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Shuo Sun; Rundong Wang; Bo An",
    "corresponding_authors": "",
    "abstract": "Quantitative trading (QT) , which refers to the usage of mathematical models and data-driven techniques in analyzing the financial market, has been a popular topic in both academia and financial industry since 1970s. In the last decade, reinforcement learning (RL) has garnered significant interest in many domains such as robotics and video games, owing to its outstanding ability on solving complex sequential decision making problems. RL’s impact is pervasive, recently demonstrating its ability to conquer many challenging QT tasks. It is a flourishing research direction to explore RL techniques’ potential on QT tasks. This paper aims at providing a comprehensive survey of research efforts on RL-based methods for QT tasks. More concretely, we devise a taxonomy of RL-based QT models, along with a comprehensive summary of the state of the art. Finally, we discuss current challenges and propose future research directions in this exciting field.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W3203375555",
    "type": "article"
  },
  {
    "title": "UrbanKG: An Urban Knowledge Graph System",
    "doi": "https://doi.org/10.1145/3588577",
    "publication_date": "2023-03-21",
    "publication_year": 2023,
    "authors": "Yu Liu; Jingtao Ding; Yanjie Fu; Yong Li",
    "corresponding_authors": "",
    "abstract": "Every day, our living city produces a tremendous amount of spatial-temporal data, involved with multiple sources from the individual scale to the city scale. Undoubtedly, such massive urban data can be explored for a better city and better life, as what the urban computing community has been dedicating in recent years. Nevertheless, existing studies are still facing the challenges of data fusion for the urban data as well as the knowledge distillation for specific applications. Moreover, there is a lack of full-featured and user-friendly platforms for both researchers and developers in the urban computing scenario. Therefore, in this article, we present UrbanKG, an urban knowledge graph system to incorporate a knowledge graph with urban computing. Specifically, the system introduces a complete scheme to construct a knowledge graph for urban data fusion. Built upon the data layer, the system further develops the multiple layers of construction, storage, algorithm, operation, and applications, which achieve knowledge distillation and support various functions to the users. We perform representative use cases and demonstrate the system capability of boosting performance in various downstream applications, indicating a promising research direction for knowledge-driven urban computing.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W4328127395",
    "type": "article"
  },
  {
    "title": "Trading Off Privacy, Utility, and Efficiency in Federated Learning",
    "doi": "https://doi.org/10.1145/3595185",
    "publication_date": "2023-05-05",
    "publication_year": 2023,
    "authors": "Xiaojin Zhang; Yan Kang; Kai Chen; Lixin Fan; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) enables participating parties to collaboratively build a global model with boosted utility without disclosing private data information. Appropriate protection mechanisms have to be adopted to fulfill the opposing requirements in preserving privacy and maintaining high model utility . In addition, it is a mandate for a federated learning system to achieve high efficiency in order to enable large-scale model training and deployment. We propose a unified federated learning framework that reconciles horizontal and vertical federated learning. Based on this framework, we formulate and quantify the trade-offs between privacy leakage, utility loss, and efficiency reduction, which leads us to the No-Free-Lunch (NFL) theorem for the federated learning system. NFL indicates that it is unrealistic to expect an FL algorithm to simultaneously provide excellent privacy, utility, and efficiency in certain scenarios. We then analyze the lower bounds for the privacy leakage, utility loss, and efficiency reduction for several widely-adopted protection mechanisms, including Randomization , Homomorphic Encryption , Secret Sharing, and Compression . Our analysis could serve as a guide for selecting protection parameters to meet particular requirements.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W4372348664",
    "type": "article"
  },
  {
    "title": "You Are How You Use Apps: User Profiling Based on Spatiotemporal App Usage Behavior",
    "doi": "https://doi.org/10.1145/3597212",
    "publication_date": "2023-05-17",
    "publication_year": 2023,
    "authors": "Tong Li; Yong Li; Mingyang Zhang; Sasu Tarkoma; Pan Hui",
    "corresponding_authors": "",
    "abstract": "Mobile apps have become an indispensable part of people’s daily lives. Users determine what apps to use and when and where to use them based on their tastes, interests, and personal demands, depending on their personality traits. This article aims to infer user profiles from their spatiotemporal mobile app usage behavior. Specifically, we first transform mobile app usage records into a heterogeneous graph. On the graph, nodes represent users, apps, locations, and time slots. Edges describe the co-occurrence of entities in usage records. We then develop a multi-relational heterogeneous graph attention network (MRel-HGAN), an end-to-end system for user profiling. MRel-HGAN first adopts a neighbor sampling strategy based on bootstrapping to sample heavily connected neighbors of a fixed size for each node. Next, we design a relational graph convolutional operation and a multi-relational attention operation. Through such modules, MRel-HGAN can generate node embedding by sufficiently leveraging the rich semantic information of the multi-relational structure in the mobile app usage graph. Experimental results on real-world mobile app usage datasets show the effectiveness and superiority of our MRel-HGAN in the user profiling task for attributes of gender and age.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W4376877198",
    "type": "article"
  },
  {
    "title": "Recent Few-shot Object Detection Algorithms: A Survey with Performance Comparison",
    "doi": "https://doi.org/10.1145/3593588",
    "publication_date": "2023-05-02",
    "publication_year": 2023,
    "authors": "Tianying Liu; Lu Zhang; Yang Wang; Jihong Guan; Yanwei Fu; Jiajia Zhao; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "The generic object detection (GOD) task has been successfully tackled by recent deep neural networks, trained by an avalanche of annotated training samples from some common classes. However, it is still non-trivial to generalize these object detectors to the novel long-tailed object classes, which have only few labeled training samples. To this end, the Few-Shot Object Detection (FSOD) has been topical recently, as it mimics the humans’ ability of learning to learn and intelligently transfers the learned generic object knowledge from the common heavy-tailed to the novel long-tailed object classes. Especially, the research in this emerging field has been flourishing in recent years with various benchmarks, backbones, and methodologies proposed. To review these FSOD works, there are several insightful FSOD survey articles [ 58 , 59 , 74 , 78 ] that systematically study and compare them as the groups of fine-tuning/transfer learning and meta-learning methods. In contrast, we review the existing FSOD algorithms from a new perspective under a new taxonomy based on their contributions, i.e., data-oriented, model-oriented, and algorithm-oriented. Thus, a comprehensive survey with performance comparison is conducted on recent achievements of FSOD. Furthermore, we also analyze the technical challenges, the merits and demerits of these methods, and envision the future directions of FSOD. Specifically, we give an overview of FSOD, including the problem definition, common datasets, and evaluation protocols. The taxonomy is then proposed that groups FSOD methods into three types. Following this taxonomy, we provide a systematic review of the advances in FSOD. Finally, further discussions on performance, challenges, and future directions are presented.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4367680936",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Point-of-interest Recommendation based on Simplified Graph Convolutional Network for Geological Traveling",
    "doi": "https://doi.org/10.1145/3620677",
    "publication_date": "2023-09-04",
    "publication_year": 2023,
    "authors": "Yuwen Liu; Xiaokang Zhou; Huaizhen Kou; Yawu Zhao; Xiaolong Xu; Xuyun Zhang; Lianyong Qi",
    "corresponding_authors": "",
    "abstract": "The provision of privacy-preserving recommendations for geological tourist attractions is an important research area. The historical check-in data collected from location-based social networks (LBSNs) can be utilized to mine their preferences, thereby facilitating the promotion of the geological tourism industry. However, such check-ins often contain sensitive user information that poses privacy leakage risks. To address this issue, some methods have been proposed to develop privacy-preserving point-of-interest (POI) recommendation systems. These methods commonly rely on either perturbation-based or federated learning techniques to protect users’ privacy. However, the former can hinder preference capture, while the latter remains vulnerable to privacy breaches during the parameter-sharing process. To overcome these challenges, we propose a novel privacy-preserving POI recommendation model that incorporates users’ privacy preferences based on a simplified graph convolutional neural network. Specifically, we employ a generative model to create a subset of POIs that reflect users’ preferences but do not reveal their private information, and then we design a simplified graph convolutional network to analyze the high-order connectivity between users and POIs that are privacy-preserving. The resulting model enables efficient POI recommendation under strict privacy protection, which is particularly relevant to geological tourism. Experimental results on two public datasets demonstrate the effectiveness of our proposed approach.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4386422321",
    "type": "article"
  },
  {
    "title": "A Survey of Trustworthy Federated Learning: Issues, Solutions, and Challenges",
    "doi": "https://doi.org/10.1145/3678181",
    "publication_date": "2024-07-23",
    "publication_year": 2024,
    "authors": "Yifei Zhang; Dun Zeng; Jinglong Luo; Xinyu Fu; Guanzhong Chen; Zenglin Xu; Irwin King",
    "corresponding_authors": "",
    "abstract": "Trustworthy artificial intelligence (TAI) has proven invaluable in curbing potential negative repercussions tied to AI applications. Within the TAI spectrum, federated learning (FL) emerges as a promising solution to safeguard personal information in distributed settings across a multitude of practical contexts. However, the realm of FL is not without its challenges. Especially worrisome are adversarial attacks targeting its algorithmic robustness and systemic confidentiality. Moreover, the presence of biases and opacity in prediction outcomes further complicates FL’s broader adoption. Consequently, there is a growing expectation for FL to instill trust. To address this, we chart out a comprehensive road-map for Trustworthy Federated Learning (TFL) and provide an overview of existing efforts across four pivotal dimensions: Privacy and Security , Robustness , Fairness , and Explainability . For each dimension, we identify potential pitfalls that might undermine TFL and present a curated selection of defensive strategies, enriched by a discourse on technical solutions tailored for TFL. Furthermore, we present potential challenges and future directions to be explored for in-depth TFL research with broader impacts.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4400915925",
    "type": "article"
  },
  {
    "title": "Boosting Healthiness Exposure in Category-Constrained Meal Recommendation Using Nutritional Standards",
    "doi": "https://doi.org/10.1145/3643859",
    "publication_date": "2024-02-05",
    "publication_year": 2024,
    "authors": "Ming Li; Lin Li; Xiaohui Tao; Zhongwei Xie; Qing Xie; Jingling Yuan",
    "corresponding_authors": "",
    "abstract": "Food computing, a newly emerging topic, is closely linked to human life through computational methodologies. Meal recommendation, a food-related study about human health, aims to provide users a meal with courses constrained from specific categories (e.g., appetizers, main dishes) that can be enjoyed as a service. Historical interaction data, important user information, is often used by existing models to learn user preferences. However, if a user’s preferences favor less healthy meals, the model will follow that preference and make similar recommendations, potentially negatively impacting the user’s long-term health. This emphasizes the necessity for health-oriented and responsible meal recommendation systems. In this article, we propose a healthiness-aware and category-wise meal recommendation model called CateRec, which boosts healthiness exposure by using nutritional standards as knowledge to guide the model training. Two fundamental questions are raised and answered: (1) How can the healthiness of meals be evaluated? Two well-known nutritional standards from the World Health Organization and the United Kingdom Food Standards Agency are used to calculate the healthiness score of the meal. (2) How can the model training be guided in a health-oriented manner? We construct category-wise personalization partial rankings and category-wise healthiness partial rankings, and theoretically analyze that they meet the necessary properties and assumptions required to be trained by the maximum posterior estimator under Bayesian probability. The data analysis confirms the existence of user preferences leaning towards less healthy meals in two public datasets. A comprehensive experiment demonstrates that our CateRec effectively boosts healthiness exposure in terms of mean healthiness score and ranking exposure while being comparable to the state-of-the-art model in terms of recommendation accuracy.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4391540800",
    "type": "article"
  },
  {
    "title": "CGKPN: Cross-Graph Knowledge Propagation Network with Adaptive Connection for Reasoning-Based Machine Reading Comprehension",
    "doi": "https://doi.org/10.1145/3658673",
    "publication_date": "2024-04-17",
    "publication_year": 2024,
    "authors": "Zhuo Zhao; Guangyou Zhou; Zhiwen Xie; Lingfei Wu; Jimmy Xiangji Huang",
    "corresponding_authors": "",
    "abstract": "The task of machine reading comprehension (MRC) is to enable machine to read and understand a piece of text and then answer the corresponding question correctly. This task requires machine to not only be able to perform semantic understanding but also possess logical reasoning capabilities. Just like human reading, it involves thinking about the text from two interacting perspectives of semantics and logic. However, previous methods based on reading comprehension either consider only the logical structure of the text or only the semantic structure of the text and cannot simultaneously balance semantic understanding and logical reasoning. This single form of reasoning cannot make the machine fully understand the meaning of the text. Additionally, the issue of sparsity in composition presents a significant challenge for models that rely on graph-based reasoning. To this end, a cross-graph knowledge propagation network (CGKPN) with adaptive connection is presented to address the above issues. The model first performs self-view node embedding on the constructed logical graph and semantic graph to update the representations of the graphs. Specifically, a relevance matrix between nodes is introduced to adaptively adjust node connections in response to the challenge posed by sparse graph. Subsequently, CGKPN conducts cross-graph knowledge propagation on nodes that are identical in both graphs, effectively resolving conflicts arising from identical nodes in different views, and enabling the model to better integrate the logical and semantic relationships of the text through efficient interaction. Experiments on the two MRC datasets ReClor and LogiQA indicate the superior performance of our proposed model CGKPN compared to other existing baselines.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4394877201",
    "type": "article"
  },
  {
    "title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application",
    "doi": "https://doi.org/10.1145/3699518",
    "publication_date": "2024-10-08",
    "publication_year": 2024,
    "authors": "Chuanpeng Yang; Yao Zhu; Lu Wang; Yidong Wang; Qian Chen; Chenlong Gao; Bingjie Yan; Yiqiang Chen",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in various domains, attracting significant interest from both academia and industry. Despite their impressive performance, the substantial size and computational demands of LLMs pose considerable challenges for practical deployment, particularly in environments with limited resources. The endeavor to compress language models while maintaining their accuracy has become a focal point of research. Among the various methods, knowledge distillation has emerged as an effective technique to enhance inference speed without greatly compromising performance. This paper presents a thorough survey from three aspects: method, evaluation, and application, exploring knowledge distillation techniques tailored specifically for LLMs. Specifically, we divide the methods into white-box KD and black-box KD to better illustrate their differences. Furthermore, we also explored the evaluation tasks and distillation effects between different distillation methods, and proposed directions for future research. Through in-depth understanding of the latest advancements and practical applications, this survey provides valuable resources for researchers, paving the way for sustained progress in this field.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4403221502",
    "type": "article"
  },
  {
    "title": "Knowledge Graph Enhanced Contextualized Attention-Based Network for Responsible User-Specific Recommendation",
    "doi": "https://doi.org/10.1145/3641288",
    "publication_date": "2024-01-22",
    "publication_year": 2024,
    "authors": "Ehsan Elahi; Sajid Anwar; Babar Shah; Zahid Halim; Abrar Ullah; Imad Rida; Muhammad Waqas",
    "corresponding_authors": "",
    "abstract": "With ever-increasing dataset size and data storage capacity, there is a strong need to build systems that can effectively utilize these vast datasets to extract valuable information. Large datasets often exhibit sparsity and pose cold start problems, necessitating the development of responsible recommender systems. Knowledge graphs have utility in responsibly representing information related to recommendation scenarios. However, many studies overlook explicitly encoding contextual information, which is crucial for reducing the bias of multi-layer propagation. Additionally, existing methods stack multiple layers to encode high-order neighbor information while disregarding the relational information between items and entities. This oversight hampers their ability to capture the collaborative signal latent in user-item interactions. This is particularly important in health informatics, where knowledge graphs consist of various entities connected to items through different relations. Ignoring the relational information renders them insufficient for modeling user preferences. This work presents an end-to-end recommendation framework named KGCAN (Knowledge Graph Enhanced Contextualized Attention-Based Network), which explicitly encodes both relational and contextual information of entities to preserve the original entity information. Furthermore, a user-specific attention mechanism is employed to capture personalized recommendations. The proposed model is validated on three benchmark datasets through extensive experiments. The experimental results demonstrate that KGCAN outperforms existing knowledge graph based recommendation models. Additionally, a case study from the healthcare domain is discussed, highlighting the importance of attention mechanisms and high-order connectivity in the responsible recommendation system for health informatics.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4391103444",
    "type": "article"
  },
  {
    "title": "Reinforcement Learning for Solving Multiple Vehicle Routing Problem with Time Window",
    "doi": "https://doi.org/10.1145/3625232",
    "publication_date": "2024-01-25",
    "publication_year": 2024,
    "authors": "Zefang Zong; Xia Tong; Meng Zheng; Yong Li",
    "corresponding_authors": "",
    "abstract": "Vehicle routing problem with time window (VRPTW) is of great importance for a wide spectrum of services and real-life applications, such as online take-out and car-hailing platforms. A promising method should generate high-qualified solutions within limited inference time, and there are three major challenges: (a) directly optimizing the goal with several practical constraints; (b) efficiently handling individual time-window limits; and (c) modeling the cooperation among the vehicle fleet. In this article, we present an end-to-end reinforcement learning framework to solve VRPTW. First, we propose an agent model that encodes constraints into features as the input and conducts harsh policy on the output when generating deterministic results. Second, we design a time penalty augmented reward to model the time-window limits during gradient propagation. Third, we design a task handler to enable the cooperation among different vehicles. We perform extensive experiments on two real-world datasets and one public benchmark dataset. Results demonstrate that our solution improves the performance by up to 11.7% compared to other RL baselines and could generate solutions for instances within seconds, while existing heuristic baselines take for minutes as well as maintain the quality of solutions. Moreover, our solution is thoroughly analyzed with meaningful implications due to the real-time response ability.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4391221820",
    "type": "article"
  },
  {
    "title": "Credit Card Fraud Detection via Intelligent Sampling and Self-supervised Learning",
    "doi": "https://doi.org/10.1145/3641283",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "Chiao-Ting Chen; Chi Lee; Szu-Hao Huang; Wen-Chih Peng",
    "corresponding_authors": "",
    "abstract": "The significant increase in credit card transactions can be attributed to the rapid growth of online shopping and digital payments, particularly during the COVID-19 pandemic. To safeguard cardholders, e-commerce companies, and financial institutions, the implementation of an effective and real-time fraud detection method using modern artificial intelligence techniques is imperative. However, the development of machine-learning-based approaches for fraud detection faces challenges such as inadequate transaction representation, noise labels, and data imbalance. Additionally, practical considerations like dynamic thresholds, concept drift, and verification latency need to be appropriately addressed. In this study, we designed a fraud detection method that accurately extracts a series of spatial and temporal representative features to precisely describe credit card transactions. Furthermore, several auxiliary self-supervised objectives were developed to model cardholders’ behavior sequences. By employing intelligent sampling strategies, potential noise labels were eliminated, thereby reducing the level of data imbalance. The developed method encompasses various innovative functions that cater to practical usage requirements. We applied this method to two real-world datasets, and the results indicated a higher F1 score compared to the most commonly used online fraud detection methods.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4391145632",
    "type": "article"
  },
  {
    "title": "Large Language Models are Zero-Shot Recognizers for Activities of Daily Living",
    "doi": "https://doi.org/10.1145/3725856",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Gabriele Civitarese; Michele Fiori; Priyankar Choudhary; Cláudio Bettini",
    "corresponding_authors": "",
    "abstract": "The sensor-based recognition of Activities of Daily Living (ADLs) in smart home environments enables several applications in the areas of energy management, safety, well-being, and healthcare. ADL recognition is typically based on deep learning methods requiring large datasets to be trained. Recently, several studies proved that Large Language Models (LLMs) effectively capture common-sense knowledge about human activities. However, the effectiveness of LLMs for ADL recognition in smart home environments still deserves to be investigated. In this work, we propose ADL-LLM, a novel LLM-based ADL recognition system. ADL-LLM transforms raw sensor data into textual representations, that are processed by an LLM to perform zero-shot ADL recognition. Moreover, in the scenario where a small labeled dataset is available, ADL-LLM can also be empowered with few-shot prompting. We evaluated ADL-LLM on two public datasets, showing its effectiveness in this domain.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4408812746",
    "type": "article"
  },
  {
    "title": "Graph Machine Learning in the Era of Large Language Models (LLMs)",
    "doi": "https://doi.org/10.1145/3732786",
    "publication_date": "2025-05-06",
    "publication_year": 2025,
    "authors": "Shijie Wang; Jiani Huang; Zhikai Chen; Yu Song; Wenzhuo Tang; Haitao Mao; Wenqi Fan; Hui Liu; Xiaorui Liu; Dawei Yin; Qing Li",
    "corresponding_authors": "",
    "abstract": "Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graphs. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML’s generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph Heterophily and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4410120638",
    "type": "article"
  },
  {
    "title": "Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification",
    "doi": "https://doi.org/10.1145/3725816",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Iain J. Cruickshank; Lynnette Hui Xian Ng",
    "corresponding_authors": "",
    "abstract": "Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily lead to better performance. In general, we discover that LLMs do not routinely outperform their smaller supervised machine learning models, and thus call for stance detection to be a benchmark for which LLMs also optimize for. The code used in this study is available at https://github.com/ijcruic/LLM-Stance-Labeling .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4408812939",
    "type": "article"
  },
  {
    "title": "Applying planning to interactive storytelling",
    "doi": "https://doi.org/10.1145/1869397.1869399",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Julie Porteous; Marc Cavazza; Fred Charles",
    "corresponding_authors": "",
    "abstract": "We have seen ten years of the application of AI planning to the problem of narrative generation in Interactive Storytelling (IS). In that time planning has emerged as the dominant technology and has featured in a number of prototype systems. Nevertheless key issues remain, such as how best to control the shape of the narrative that is generated (e.g., by using narrative control knowledge , i.e., knowledge about narrative features that enhance user experience) and also how best to provide support for real-time interactive performance in order to scale up to more realistic sized systems. Recent progress in planning technology has opened up new avenues for IS and we have developed a novel approach to narrative generation that builds on this. Our approach is to specify narrative control knowledge for a given story world using state trajectory constraints and then to treat these state constraints as landmarks and to use them to decompose narrative generation in order to address scalability issues and the goal of real-time performance in larger story domains. This approach to narrative generation is fully implemented in an interactive narrative based on the “Merchant of Venice.” The contribution of the work lies both in our novel use of state constraints to specify narrative control knowledge for interactive storytelling and also our development of an approach to narrative generation that exploits such constraints. In the article we show how the use of state constraints can provide a unified perspective on important problems faced in IS.",
    "cited_by_count": 119,
    "openalex_id": "https://openalex.org/W2012538724",
    "type": "article"
  },
  {
    "title": "AEGIS Automated Science Targeting for the MER Opportunity Rover",
    "doi": "https://doi.org/10.1145/2168752.2168764",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Tara Estlin; Benjamin Bornstein; Daniel Gaines; Robert C. Anderson; David R. Thompson; Michael C. Burl; Rebecca Castaño; M. Judd",
    "corresponding_authors": "",
    "abstract": "The Autonomous Exploration for Gathering Increased Science (AEGIS) system enables automated data collection by planetary rovers. AEGIS software was uploaded to the Mars Exploration Rover (MER) mission’s Opportunity rover in December 2009 and has successfully demonstrated automated onboard targeting based on scientist-specified objectives. Prior to AEGIS, images were transmitted from the rover to the operations team on Earth; scientists manually analyzed the images, selected geological targets for the rover’s remote-sensing instruments, and then generated a command sequence to execute the new measurements. AEGIS represents a significant paradigm shift---by using onboard data analysis techniques, the AEGIS software uses scientist input to select high-quality science targets with no human in the loop. This approach allows the rover to autonomously select and sequence targeted observations in an opportunistic fashion, which is particularly applicable for narrow field-of-view instruments (such as the MER Mini-TES spectrometer, the MER Panoramic camera, and the 2011 Mars Science Laboratory (MSL) ChemCam spectrometer). This article provides an overview of the AEGIS automated targeting capability and describes how it is currently being used onboard the MER mission Opportunity rover.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2065828016",
    "type": "article"
  },
  {
    "title": "Paraphrase acquisition via crowdsourcing and machine learning",
    "doi": "https://doi.org/10.1145/2483669.2483676",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Steven Burrows; Martin Potthast; Benno Stein",
    "corresponding_authors": "",
    "abstract": "To paraphrase means to rewrite content while preserving the original meaning. Paraphrasing is important in fields such as text reuse in journalism, anonymizing work, and improving the quality of customer-written reviews. This article contributes to paraphrase acquisition and focuses on two aspects that are not addressed by current research: (1) acquisition via crowdsourcing, and (2) acquisition of passage-level samples. The challenge of the first aspect is automatic quality assurance; without such a means the crowdsourcing paradigm is not effective, and without crowdsourcing the creation of test corpora is unacceptably expensive for realistic order of magnitudes. The second aspect addresses the deficit that most of the previous work in generating and evaluating paraphrases has been conducted using sentence-level paraphrases or shorter; these short-sample analyses are limited in terms of application to plagiarism detection, for example. We present the Webis Crowd Paraphrase Corpus 2011 (Webis-CPC-11), which recently formed part of the PAN 2010 international plagiarism detection competition. This corpus comprises passage-level paraphrases with 4067 positive samples and 3792 negative samples that failed our criteria, using Amazon's Mechanical Turk for crowdsourcing. In this article, we review the lessons learned at PAN 2010, and explain in detail the method used to construct the corpus. The empirical contributions include machine learning experiments to explore if passage-level paraphrases can be identified in a two-class classification problem using paraphrase similarity features, and we find that a k-nearest-neighbor classifier can correctly distinguish between paraphrased and nonparaphrased samples with 0.980 precision at 0.523 recall. This result implies that just under half of our samples must be discarded (remaining 0.477 fraction), but our cost analysis shows that the automation we introduce results in a 18% financial saving and over 100 hours of time returned to the researchers when repeating a similar corpus design. On the other hand, when building an unrelated corpus requiring, say, 25% training data for the automated component, we show that the financial outcome is cost neutral, while still returning over 70 hours of time to the researchers. The work presented here is the first to join the paraphrasing and plagiarism communities.",
    "cited_by_count": 95,
    "openalex_id": "https://openalex.org/W2008127487",
    "type": "article"
  },
  {
    "title": "Latent Community Topic Analysis",
    "doi": "https://doi.org/10.1145/2337542.2337548",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Zhijun Yin; Liangliang Cao; Quanquan Gu; Jiawei Han",
    "corresponding_authors": "",
    "abstract": "This article studies the problem of latent community topic analysis in text-associated graphs. With the development of social media, a lot of user-generated content is available with user networks. Along with rich information in networks, user graphs can be extended with text information associated with nodes. Topic modeling is a classic problem in text mining and it is interesting to discover the latent topics in text-associated graphs. Different from traditional topic modeling methods considering links, we incorporate community discovery into topic analysis in text-associated graphs to guarantee the topical coherence in the communities so that users in the same community are closely linked to each other and share common latent topics. We handle topic modeling and community discovery in the same framework. In our model we separate the concepts of community and topic, so one community can correspond to multiple topics and multiple communities can share the same topic. We compare different methods and perform extensive experiments on two real datasets. The results confirm our hypothesis that topics could help understand community structure, while community structure could help model topics.",
    "cited_by_count": 95,
    "openalex_id": "https://openalex.org/W2059047669",
    "type": "article"
  },
  {
    "title": "An approach to social recommendation for context-aware mobile services",
    "doi": "https://doi.org/10.1145/2414425.2414435",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Claudio Biancalana; Fabio Gasparetti; Alessandro Micarelli; Giuseppe Sansonetti",
    "corresponding_authors": "",
    "abstract": "Nowadays, several location-based services (LBSs) allow their users to take advantage of information from the Web about points of interest (POIs) such as cultural events or restaurants. To the best of our knowledge, however, none of these provides information taking into account user preferences, or other elements, in addition to location, that contribute to define the context of use. The provided suggestions do not consider, for example, time, day of week, weather, user activity or means of transport. This article describes a social recommender system able to identify user preferences and information needs, thus suggesting personalized recommendations related to POIs in the surroundings of the user's current location. The proposed approach achieves the following goals: (i) to supply, unlike the current LBSs, a methodology for identifying user preferences and needs to be used in the information filtering process; (ii) to exploit the ever-growing amount of information from social networking, user reviews, and local search Web sites; (iii) to establish procedures for defining the context of use to be employed in the recommendation of POIs with low effort. The flexibility of the architecture is such that our approach can be easily extended to any category of POI. Experimental tests carried out on real users enabled us to quantify the benefits of the proposed approach in terms of performance improvement.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2160217907",
    "type": "article"
  },
  {
    "title": "A Fast Parallel Stochastic Gradient Method for Matrix Factorization in Shared Memory Systems",
    "doi": "https://doi.org/10.1145/2668133",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Wei-Sheng Chin; Yong Zhuang; Yu-Chin Juan; Chih‐Jen Lin",
    "corresponding_authors": "",
    "abstract": "Matrix factorization is known to be an effective method for recommender systems that are given only the ratings from users to items. Currently, stochastic gradient (SG) method is one of the most popular algorithms for matrix factorization. However, as a sequential approach, SG is difficult to be parallelized for handling web-scale problems. In this article, we develop a fast parallel SG method, FPSG, for shared memory systems. By dramatically reducing the cache-miss rate and carefully addressing the load balance of threads, FPSG is more efficient than state-of-the-art parallel algorithms for matrix factorization.",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W2078670469",
    "type": "article"
  },
  {
    "title": "Learning to Rank from Noisy Data",
    "doi": "https://doi.org/10.1145/2576230",
    "publication_date": "2015-09-29",
    "publication_year": 2015,
    "authors": "Wenkui Ding; Xiubo Geng; Xudong Zhang",
    "corresponding_authors": "",
    "abstract": "Learning to rank, which learns the ranking function from training data, has become an emerging research area in information retrieval and machine learning. Most existing work on learning to rank assumes that the training data is clean, which is not always true, however. The ambiguity of query intent, the lack of domain knowledge, and the vague definition of relevance levels all make it difficult for common annotators to give reliable relevance labels to some documents. As a result, the relevance labels in the training data of learning to rank usually contain noise. If we ignore this fact, the performance of learning-to-rank algorithms will be damaged. In this article, we propose considering the labeling noise in the process of learning to rank and using a two-step approach to extend existing algorithms to handle noisy training data. In the first step, we estimate the degree of labeling noise for a training document. To this end, we assume that the majority of the relevance labels in the training data are reliable and we use a graphical model to describe the generative process of a training query, the feature vectors of its associated documents, and the relevance labels of these documents. The parameters in the graphical model are learned by means of maximum likelihood estimation. Then the conditional probability of the relevance label given the feature vector of a document is computed. If the probability is large, we regard the degree of labeling noise for this document as small; otherwise, we regard the degree as large. In the second step, we extend existing learning-to-rank algorithms by incorporating the estimated degree of labeling noise into their loss functions. Specifically, we give larger weights to those training documents with smaller degrees of labeling noise and smaller weights to those with larger degrees of labeling noise. As examples, we demonstrate the extensions for McRank, RankSVM, RankBoost, and RankNet. Empirical results on benchmark datasets show that the proposed approach can effectively distinguish noisy documents from clean ones, and the extended learning-to-rank algorithms can achieve better performances than baselines.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W1967533108",
    "type": "article"
  },
  {
    "title": "Computationally efficient link prediction in a variety of social networks",
    "doi": "https://doi.org/10.1145/2542182.2542192",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Michael Fire; Lena Tenenboim-Chekina; Rami Puzis; Ofrit Lesser; Lior Rokach; Yuval Elovici",
    "corresponding_authors": "",
    "abstract": "Online social networking sites have become increasingly popular over the last few years. As a result, new interdisciplinary research directions have emerged in which social network analysis methods are applied to networks containing hundreds of millions of users. Unfortunately, links between individuals may be missing either due to an imperfect acquirement process or because they are not yet reflected in the online network (i.e., friends in the real world did not form a virtual connection). The primary bottleneck in link prediction techniques is extracting the structural features required for classifying links. In this article, we propose a set of simple, easy-to-compute structural features that can be analyzed to identify missing links. We show that by using simple structural features, a machine learning classifier can successfully identify missing links, even when applied to a predicament of classifying links between individuals with at least one common friend. We also present a method for calculating the amount of data needed in order to build more accurate classifiers. The new Friends measure and Same community features we developed are shown to be good predictors for missing links. An evaluation experiment was performed on ten large social networks datasets: Academia.edu, DBLP, Facebook, Flickr, Flixster, Google+, Gowalla, TheMarker, Twitter, and YouTube. Our methods can provide social network site operators with the capability of helping users to find known, offline contacts and to discover new friends online. They may also be used for exposing hidden links in online social networks.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2069186598",
    "type": "article"
  },
  {
    "title": "COM",
    "doi": "https://doi.org/10.1145/2508037.2508045",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Parisa Rashidi; Diane J. Cook",
    "corresponding_authors": "",
    "abstract": "The increasing aging population in the coming decades will result in many complications for society and in particular for the healthcare system due to the shortage of healthcare professionals and healthcare facilities. To remedy this problem, researchers have pursued developing remote monitoring systems and assisted living technologies by utilizing recent advances in sensor and networking technology, as well as in the data mining and machine learning fields. In this article, we report on our fully automated approach for discovering and monitoring patterns of daily activities. Discovering and tracking patterns of daily activities can provide unprecedented opportunities for health monitoring and assisted living applications, especially for older adults and individuals with mental disabilities. Previous approaches usually rely on preselected activities or labeled data to track and monitor daily activities. In this article, we present a fully automated approach by discovering natural activity patterns and their variations in real-life data. We will show how our activity discovery component can be integrated with an activity recognition component to track and monitor various daily activity patterns. We also provide an activity visualization component to allow caregivers to visually observe and examine the activity patterns using a user-friendly interface. We validate our algorithms using real-life data obtained from two apartments during a three-month period.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2141136456",
    "type": "article"
  },
  {
    "title": "Planning for human-robot teaming in open worlds",
    "doi": "https://doi.org/10.1145/1869397.1869403",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Kartik Talamadupula; J. Benton; Subbarao Kambhampati; Paul Schermerhorn; Matthias Scheutz",
    "corresponding_authors": "",
    "abstract": "As the number of applications for human-robot teaming continue to rise, there is an increasing need for planning technologies that can guide robots in such teaming scenarios. In this article, we focus on adapting planning technology to Urban Search And Rescue (USAR) with a human-robot team. We start by showing that several aspects of state-of-the-art planning technology, including temporal planning, partial satisfaction planning, and replanning, can be gainfully adapted to this scenario. We then note that human-robot teaming also throws up an additional critical challenge, namely, enabling existing planners, which work under closed-world assumptions, to cope with the open worlds that are characteristic of teaming problems such as USAR. In response, we discuss the notion of conditional goals, and describe how we represent and handle a specific class of them called open world quantified goals. Finally, we describe how the planner, and its open world extensions, are integrated into a robot control architecture, and provide an empirical evaluation over USAR experimental runs to establish the effectiveness of the planning components.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2033821732",
    "type": "article"
  },
  {
    "title": "Transfer Learning across Feature-Rich Heterogeneous Feature Spaces via Feature-Space Remapping (FSR)",
    "doi": "https://doi.org/10.1145/2629528",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Kyle Feuz; Diane J. Cook",
    "corresponding_authors": "",
    "abstract": "Transfer learning aims to improve performance on a target task by utilizing previous knowledge learned from source tasks. In this paper we introduce a novel heterogeneous transfer learning technique, Feature-Space Remapping (FSR), which transfers knowledge between domains with different feature spaces. This is accomplished without requiring typical feature-feature, feature instance, or instance-instance co-occurrence data. Instead we relate features in different feature-spaces through the construction of metafeatures. We show how these techniques can utilize multiple source datasets to construct an ensemble learner which further improves performance. We apply FSR to an activity recognition problem and a document classification problem. The ensemble technique is able to outperform all other baselines and even performs better than a classifier trained using a large amount of labeled data in the target domain. These problems are especially difficult because, in addition to having different feature-spaces, the marginal probability distributions and the class labels are also different. This work extends the state of the art in transfer learning by considering large transfer across dramatically different spaces.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2034852725",
    "type": "article"
  },
  {
    "title": "A framework of traveling companion discovery on trajectory data streams",
    "doi": "https://doi.org/10.1145/2542182.2542185",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Lu‐An Tang; Yu Zheng; Jing Yuan; Jiawei Han; Alice Leung; Wen-Chih Peng; Thomas La Porta",
    "corresponding_authors": "",
    "abstract": "The advance of mobile technologies leads to huge volumes of spatio-temporal data collected in the form of trajectory data streams. In this study, we investigate the problem of discovering object groups that travel together (i.e., traveling companions ) from trajectory data streams. Such technique has broad applications in the areas of scientific study, transportation management, and military surveillance. To discover traveling companions, the monitoring system should cluster the objects of each snapshot and intersect the clustering results to retrieve moving-together objects. Since both clustering and intersection steps involve high computational overhead, the key issue of companion discovery is to improve the efficiency of algorithms. We propose the models of closed companion candidates and smart intersection to accelerate data processing. A data structure termed traveling buddy is designed to facilitate scalable and flexible companion discovery from trajectory streams. The traveling buddies are microgroups of objects that are tightly bound together. By only storing the object relationships rather than their spatial coordinates, the buddies can be dynamically maintained along the trajectory stream with low cost. Based on traveling buddies, the system can discover companions without accessing the object details. In addition, we extend the proposed framework to discover companions on more complicated scenarios with spatial and temporal constraints, such as on the road network and battlefield. The proposed methods are evaluated with extensive experiments on both real and synthetic datasets. Experimental results show that our proposed buddy-based approach is an order of magnitude faster than the baselines and achieves higher accuracy in companion discovery.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2105772399",
    "type": "article"
  },
  {
    "title": "Modality-Dependent Cross-Media Retrieval",
    "doi": "https://doi.org/10.1145/2775109",
    "publication_date": "2016-03-22",
    "publication_year": 2016,
    "authors": "Yunchao Wei; Yao Zhao; Zhenfeng Zhu; Shikui Wei; Yanhui Xiao; Jiashi Feng; Shuicheng Yan",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate the cross-media retrieval between images and text, that is, using image to search text (I2T) and using text to search images (T2I). Existing cross-media retrieval methods usually learn one couple of projections, by which the original features of images and text can be projected into a common latent space to measure the content similarity. However, using the same projections for the two different retrieval tasks (I2T and T2I) may lead to a tradeoff between their respective performances, rather than their best performances. Different from previous works, we propose a modality-dependent cross-media retrieval (MDCR) model, where two couples of projections are learned for different cross-media retrieval tasks instead of one couple of projections. Specifically, by jointly optimizing the correlation between images and text and the linear regression from one modal space (image or text) to the semantic space, two couples of mappings are learned to project images and text from their original feature spaces into two common latent subspaces (one for I2T and the other for T2I). Extensive experiments show the superiority of the proposed MDCR compared with other methods. In particular, based on the 4,096-dimensional convolutional neural network (CNN) visual feature and 100-dimensional Latent Dirichlet Allocation (LDA) textual feature, the mAP of the proposed method achieves the mAP score of 41.5%, which is a new state-of-the-art performance on the Wikipedia dataset.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W1123427201",
    "type": "article"
  },
  {
    "title": "Generating virtual ratings from chinese reviews to augment online recommendations",
    "doi": "https://doi.org/10.1145/2414425.2414434",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Weishi Zhang; Guiguang Ding; Li Chen; Chunping Li; Chengbo Zhang",
    "corresponding_authors": "",
    "abstract": "Collaborative filtering (CF) recommenders based on User-Item rating matrix as explicitly obtained from end users have recently appeared promising in recommender systems. However, User-Item rating matrix is not always available or very sparse in some web applications, which has critical impact to the application of CF recommenders. In this article we aim to enhance the online recommender system by fusing virtual ratings as derived from user reviews. Specifically, taking into account of Chinese reviews' characteristics, we propose to fuse the self-supervised emotion-integrated sentiment classification results into CF recommenders, by which the User-Item Rating Matrix can be inferred by decomposing item reviews that users gave to the items. The main advantage of this approach is that it can extend CF recommenders to some web applications without user rating information. In the experiments, we have first identified the self-supervised sentiment classification's higher precision and recall by comparing it with traditional classification methods. Furthermore, the classification results, as behaving as virtual ratings, were incorporated into both user-based and item-based CF algorithms. We have also conducted an experiment to evaluate the proximity between the virtual and real ratings and clarified the effectiveness of the virtual ratings. The experimental results demonstrated the significant impact of virtual ratings on increasing system's recommendation accuracy in different data conditions (i.e., conditions with real ratings and without).",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W2049478259",
    "type": "article"
  },
  {
    "title": "Description-Driven Community Detection",
    "doi": "https://doi.org/10.1145/2517088",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Simon Pool; Francesco Bonchi; Matthijs van Leeuwen",
    "corresponding_authors": "",
    "abstract": "Traditional approaches to community detection, as studied by physicists, sociologists, and more recently computer scientists, aim at simply partitioning the social network graph. However, with the advent of online social networking sites, richer data has become available: beyond the link information, each user in the network is annotated with additional information, for example, demographics, shopping behavior, or interests. In this context, it is therefore important to develop mining methods which can take advantage of all available information. In the case of community detection, this means finding good communities (a set of nodes cohesive in the social graph) which are associated with good descriptions in terms of user information (node attributes). Having good descriptions associated to our models make them understandable by domain experts and thus more useful in real-world applications. Another requirement dictated by real-world applications, is to develop methods that can use, when available, any domain-specific background knowledge. In the case of community detection the background knowledge could be a vague description of the communities sought in a specific application, or some prototypical nodes (e.g., good customers in the past), that represent what the analyst is looking for (a community of similar users). Towards this goal, in this article, we define and study the problem of finding a diverse set of cohesive communities with concise descriptions. We propose an effective algorithm that alternates between two phases: a hill-climbing phase producing (possibly overlapping) communities, and a description induction phase which uses techniques from supervised pattern set mining. Our framework has the nice feature of being able to build well-described cohesive communities starting from any given description or seed set of nodes, which makes it very flexible and easily applicable in real-world applications. Our experimental evaluation confirms that the proposed method discovers cohesive communities with concise descriptions in realistic and large online social networks such as D elicious , F lickr , and L ast FM.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W1963502056",
    "type": "article"
  },
  {
    "title": "Social temporal collaborative ranking for context aware movie recommendation",
    "doi": "https://doi.org/10.1145/2414425.2414440",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Nathan N. Liu; Luheng He; Min Zhao",
    "corresponding_authors": "",
    "abstract": "Most existing collaborative filtering models only consider the use of user feedback (e.g., ratings) and meta data (e.g., content, demographics). However, in most real world recommender systems, context information, such as time and social networks, are also very important factors that could be considered in order to produce more accurate recommendations. In this work, we address several challenges for the context aware movie recommendation tasks in CAMRa 2010: (1) how to combine multiple heterogeneous forms of user feedback? (2) how to cope with dynamic user and item characteristics? (3) how to capture and utilize social connections among users? For the first challenge, we propose a novel ranking based matrix factorization model to aggregate explicit and implicit user feedback. For the second challenge, we extend this model to a sequential matrix factorization model to enable time-aware parametrization. Finally, we introduce a network regularization function to constrain user parameters based on social connections. To the best of our knowledge, this is the first study that investigates the collective modeling of social and temporal dynamics. Experiments on the CAMRa 2010 dataset demonstrated clear improvements over many baselines.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2000308636",
    "type": "article"
  },
  {
    "title": "CEPR",
    "doi": "https://doi.org/10.1145/2629557",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Defu Lian; Xing Xie; Vincent W. Zheng; Nicholas Jing Yuan; Fuzheng Zhang; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "With the growing popularity of location-based social networks, numerous location visiting records (e.g., check-ins) continue to accumulate over time. The more these records are collected, the better we can understand users’ mobility patterns and the more accurately we can predict their future locations. However, due to the personality trait of neophilia, people also show propensities of novelty seeking in human mobility, that is, exploring unvisited but tailored locations for them to visit. As such, the existing prediction algorithms, mainly relying on regular mobility patterns, face severe challenges because such behavior is beyond the reach of regularity. As a matter of fact, the prediction of this behavior not only relies on the forecast of novelty-seeking tendency but also depends on how to determine unvisited candidate locations. To this end, we put forward a Collaborative Exploration and Periodically Returning model (CEPR), based on a novel problem, Exploration Prediction (EP), which forecasts whether people will seek unvisited locations to visit, in the following. When people are predicted to do exploration, a state-of-the-art recommendation algorithm, armed with collaborative social knowledge and assisted by geographical influence, will be applied for seeking the suitable candidates; otherwise, a traditional prediction algorithm, incorporating both regularity and the Markov model, will be put into use for figuring out the most possible locations to visit. We then perform case studies on check-ins and evaluate them on two large-scale check-in datasets with 6M and 36M records, respectively. The evaluation results show that EP achieves a roughly 20% classification error rate on both datasets, greatly outperforming the baselines, and that CEPR improves performances by as much as 30% compared to the traditional location prediction algorithms.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2074020083",
    "type": "article"
  },
  {
    "title": "Interactive Image Search by Color Map",
    "doi": "https://doi.org/10.1145/2036264.2036276",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Jingdong Wang; Xian‐Sheng Hua",
    "corresponding_authors": "",
    "abstract": "The availability of large-scale images from the Internet has made the research on image search attract a lot of attention. Text-based image search engines, for example, Google/Microsoft Bing/Yahoo! image search engines using the surrounding text, have been developed and widely used. However, they suffer from an inability to search image content. In this article, we present an interactive image search system, image search by color map, which can be applied to, but not limited to, enhance text-based image search. This system enables users to indicate how the colors are spatially distributed in the desired images, by scribbling a few color strokes, or dragging an image and highlighting a few regions of interest in an intuitive way. In contrast to the conventional sketch-based image retrieval techniques, our system searches images based on colors rather than shapes, and we, technically, propose a simple but effective scheme to mine the latent search intention from the user’s input, and exploit the dominant color filter strategy to make our system more efficient. We integrate our system to existing Web image search engines to demonstrate its superior performance over text-based image search. The user study shows that our system can indeed help users conveniently find desired images.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2086898388",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on twitter and microblogging services",
    "doi": "https://doi.org/10.1145/2414425.2414426",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Irwin King; Wolfgang Nejdl",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2092733554",
    "type": "article"
  },
  {
    "title": "An empirical comparison of social, collaborative filtering, and hybrid recommenders",
    "doi": "https://doi.org/10.1145/2414425.2414439",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Alejandro Bellogín; Iván Cantador; Fernando Díez; Pablo Castells; Enrique Chavarriaga",
    "corresponding_authors": "",
    "abstract": "In the Social Web, a number of diverse recommendation approaches have been proposed to exploit the user generated contents available in the Web, such as rating, tagging, and social networking information. In general, these approaches naturally require the availability of a wide amount of these user preferences. This may represent an important limitation for real applications, and may be somewhat unnoticed in studies focusing on overall precision, in which a failure to produce recommendations gets blurred when averaging the obtained results or, even worse, is just not accounted for, as users with no recommendations are typically excluded from the performance calculations. In this article, we propose a coverage metric that uncovers and compensates for the incompleteness of performance evaluations based only on precision. We use this metric together with precision metrics in an empirical comparison of several social, collaborative filtering, and hybrid recommenders. The obtained results show that a better balance between precision and coverage can be achieved by combining social-based filtering (high accuracy, low coverage) and collaborative filtering (low accuracy, high coverage) recommendation techniques. We thus explore several hybrid recommendation approaches to balance this trade-off. In particular, we compare, on the one hand, techniques integrating collaborative and social information into a single model, and on the other, linear combinations of recommenders. For the last approach, we also propose a novel strategy to dynamically adjust the weight of each recommender on a user-basis, utilizing graph measures as indicators of the target user's connectedness and relevance in a social network.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W1977517101",
    "type": "article"
  },
  {
    "title": "EEMC",
    "doi": "https://doi.org/10.1145/2644827",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Haoyi Xiong; Daqing Zhang; Leye Wang; J. Paul Gibson; Jie Zhu",
    "corresponding_authors": "",
    "abstract": "Mobile Crowdsensing (MCS) requires users to be motivated to participate. However, concerns regarding energy consumption and privacy—among other things—may compromise their willingness to join such a crowd. Our preliminary observations and analysis of common MCS applications have shown that the data transfer in MCS applications may incur significant energy consumption due to the 3G connection setup. However, if data are transferred in parallel with a traditional phone call, then such transfer can be done almost “for free”: with only an insignificant additional amount of energy required to piggy-back the data—usually incoming task assignments and outgoing sensor results—on top of the call. Here, we present an &lt;i&gt;Energy-Efficient Mobile Crowdsensing&lt;/i&gt; (EEMC) framework where task assignments and sensing results are transferred in parallel with phone calls. The main objective, and the principal contribution of this article, is an MCS task assignment scheme that guarantees that a minimum number of anonymous participants return sensor results within a specified time frame, while also minimizing the waste of energy due to redundant task assignments and considering privacy concerns of participants. Evaluations with a large-scale real-world phone call dataset show that our proposed &lt;i&gt;EEMC&lt;/i&gt; framework outperforms the baseline approaches, and it can reduce overall energy consumption in data transfer by 54--66% when compared to the 3G-based solution.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W2101637528",
    "type": "article"
  },
  {
    "title": "SPACE-TA",
    "doi": "https://doi.org/10.1145/3131671",
    "publication_date": "2017-10-23",
    "publication_year": 2017,
    "authors": "Leye Wang; Daqing Zhang; Dingqi Yang; Animesh Pathak; Chao Chen; Xiao Han; Haoyi Xiong; Yasha Wang",
    "corresponding_authors": "",
    "abstract": "Data quality and budget are two primary concerns in urban-scale mobile crowdsensing. Traditional research on mobile crowdsensing mainly takes sensing coverage ratio as the data quality metric rather than the overall sensed data error in the target-sensing area. In this article, we propose to leverage spatiotemporal correlations among the sensed data in the target-sensing area to significantly reduce the number of sensing task assignments. In particular, we exploit both intradata correlations within the same type of sensed data and interdata correlations among different types of sensed data in the sensing task. We propose a novel crowdsensing task allocation framework called SPACE-TA (SPArse Cost-Effective Task Allocation) , combining compressive sensing, statistical analysis, active learning, and transfer learning, to dynamically select a small set of subareas for sensing in each timeslot (cycle), while inferring the data of unsensed subareas under a probabilistic data quality guarantee. Evaluations on real-life temperature, humidity, air quality, and traffic monitoring datasets verify the effectiveness of SPACE-TA. In the temperature-monitoring task leveraging intradata correlations, SPACE-TA requires data from only 15.5% of the subareas while keeping the inference error below 0.25°C in 95% of the cycles, reducing the number of sensed subareas by 18.0% to 26.5% compared to baselines. When multiple tasks run simultaneously, for example, for temperature and humidity monitoring, SPACE-TA can further reduce ∼10% of the sensed subareas by exploiting interdata correlations.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W2765580447",
    "type": "article"
  },
  {
    "title": "Spatiotemporal Sequential Influence Modeling for Location Recommendations",
    "doi": "https://doi.org/10.1145/2786761",
    "publication_date": "2015-10-07",
    "publication_year": 2015,
    "authors": "Jia-Dong Zhang; Chi-Yin Chow",
    "corresponding_authors": "",
    "abstract": "Recommending to users personalized locations is an important feature of Location-Based Social Networks (LBSNs), which benefits users who wish to explore new places and businesses to discover potential customers. In LBSNs, social and geographical influences have been intensively used in location recommendations. However, human movement also exhibits spatiotemporal sequential patterns, but only a few current studies consider the spatiotemporal sequential influence of locations on users’ check-in behaviors. In this article, we propose a new gravity model for location recommendations, called LORE, to exploit the spatiotemporal sequential influence on location recommendations. First, LORE extracts sequential patterns from historical check-in location sequences of all users as a Location-Location Transition Graph (L 2 TG), and utilizes the L 2 TG to predict the probability of a user visiting a new location through the developed additive Markov chain that considers the effect of all visited locations in the check-in history of the user on the new location. Furthermore, LORE applies our contrived gravity model to weigh the effect of each visited location on the new location derived from the personalized attractive force (i.e., the weight) between the visited location and the new location. The gravity model effectively integrates the spatiotemporal, social, and popularity influences by estimating a power-law distribution based on (i) the spatial distance and temporal difference between two consecutive check-in locations of the same user, (ii) the check-in frequency of social friends, and (iii) the popularity of locations from all users. Finally, we conduct a comprehensive performance evaluation for LORE using three large-scale real-world datasets collected from Foursquare, Gowalla, and Brightkite. Experimental results show that LORE achieves significantly superior location recommendations compared to other state-of-the-art location recommendation techniques.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2055852858",
    "type": "article"
  },
  {
    "title": "Intelligent Process Adaptation in the SmartPM System",
    "doi": "https://doi.org/10.1145/2948071",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "Andrea Marrella; Massimo Mecella; Sebastian Sardiña",
    "corresponding_authors": "",
    "abstract": "The increasing application of process-oriented approaches in new challenging dynamic domains beyond business computing (e.g., healthcare, emergency management, factories of the future, home automation, etc.) has led to reconsider the level of flexibility and support required to manage complex knowledge-intensive processes in such domains. A knowledge-intensive process is influenced by user decision making and coupled with contextual data and knowledge production, and involves performing complex tasks in the “physical” real world to achieve a common goal. The physical world, however, is not entirely predictable, and knowledge-intensive processes must be robust to unexpected conditions and adaptable to unanticipated exceptions, recognizing that in real-world environments it is not adequate to assume that all possible recovery activities can be predefined for dealing with the exceptions that can ensue. To tackle this issue, in this paper we present SmartPM, a model and a prototype Process Management System featuring a set of techniques providing support for automated adaptation of knowledge-intensive processes at runtime. Such techniques are able to automatically adapt process instances when unanticipated exceptions occur, without explicitly defining policies to recover from exceptions and without the intervention of domain experts at runtime, aiming at reducing error-prone and costly manual ad-hoc changes, and thus at relieving users from complex adaptations tasks. To accomplish this, we make use of well-established techniques and frameworks from Artificial Intelligence, such as situation calculus, IndiGolog and classical planning. The approach, which is backed by a formal model, has been implemented and validated with a case study based on real knowledge-intensive processes coming from an emergency management domain.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2547378852",
    "type": "article"
  },
  {
    "title": "Personalized Recommendations of Locally Interesting Venues to Tourists via Cross-Region Community Matching",
    "doi": "https://doi.org/10.1145/2532439",
    "publication_date": "2014-07-17",
    "publication_year": 2014,
    "authors": "Yiliang Zhao; Liqiang Nie; Xiangyu Wang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "You are in a new city. You are not familiar with the places and neighborhoods. You want to know all about the exciting sights, food outlets, and cultural venues that the locals frequent, in particular those that suit your personal interests. Even though there exist many mapping, local search, and travel assistance sites, they mostly provide popular and famous listings such as Statue of Liberty and Eiffel Tower, which are well-known places but may not suit your personal needs or interests. Therefore, there is a gap between what tourists want and what dominant tourism resources are providing. In this work, we seek to provide a solution to bridge this gap by exploiting the rich user-generated location contents in location-based social networks in order to offer tourists the most relevant and personalized local venue recommendations. In particular, we first propose a novel Bayesian approach to extract the social dimensions of people at different geographical regions to capture their latent local interests. We next mine the local interest communities in each geographical region. We then represent each local community using aggregated behaviors of community members. Finally, we correlate communities across different regions and generate venue recommendations to tourists via cross-region community matching. We have sampled a representative subset of check-ins from Foursquare and experimentally verified the effectiveness of our proposed approaches.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2035237009",
    "type": "article"
  },
  {
    "title": "Cluster-Based Collaborative Filtering for Sign Prediction in Social Networks with Positive and Negative Links",
    "doi": "https://doi.org/10.1145/2501977",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Amin Javari; Mahdi Jalili",
    "corresponding_authors": "",
    "abstract": "Social network analysis and mining get ever-increasingly important in recent years, which is mainly due to the availability of large datasets and advances in computing systems. A class of social networks is those with positive and negative links. In such networks, a positive link indicates friendship (or trust), whereas links with a negative sign correspond to enmity (or distrust). Predicting the sign of the links in these networks is an important issue and has many applications, such as friendship recommendation and identifying malicious nodes in the network. In this manuscript, we proposed a new method for sign prediction in networks with positive and negative links. Our algorithm is based first on clustering the network into a number of clusters and then applying a collaborative filtering algorithm. The clusters are such that the number of intra-cluster negative links and inter-cluster positive links are minimal, that is, the clusters are socially balanced as much as possible (a signed graph is socially balanced if it can be divided into clusters with all positive links inside the clusters and all negative links between them). We then used similarity between the clusters (based on the links between them) in a collaborative filtering algorithm. Our experiments on a number of real datasets showed that the proposed method outperformed previous methods, including those based on social balance and status theories and one based on a machine learning framework (logistic regression in this work).",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W1967955538",
    "type": "article"
  },
  {
    "title": "Intelligent Evacuation Management Systems",
    "doi": "https://doi.org/10.1145/2842630",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Azhar Mohd Ibrahim; Ibrahim Venkat; K. G. Subramanian; Ahamad Tajudin Khader; Philippe De Wilde",
    "corresponding_authors": "",
    "abstract": "Crowd and evacuation management have been active areas of research and study in the recent past. Various developments continue to take place in the process of efficient evacuation of crowds in mass gatherings. This article is intended to provide a review of intelligent evacuation management systems covering the aspects of crowd monitoring, crowd disaster prediction, evacuation modelling, and evacuation path guidelines. Soft computing approaches play a vital role in the design and deployment of intelligent evacuation applications pertaining to crowd control management. While the review deals with video and nonvideo based aspects of crowd monitoring and crowd disaster prediction, evacuation techniques are reviewed via the theme of soft computing, along with a brief review on the evacuation navigation path. We believe that this review will assist researchers in developing reliable automated evacuation systems that will help in ensuring the safety of the evacuees especially during emergency evacuation scenarios.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2269617815",
    "type": "article"
  },
  {
    "title": "Distributed Deep Forest and its Application to Automatic Detection of Cash-Out Fraud",
    "doi": "https://doi.org/10.1145/3342241",
    "publication_date": "2019-09-05",
    "publication_year": 2019,
    "authors": "Yalin Zhang; Jun Zhou; Wenhao Zheng; Ji Feng; Longfei Li; Ziqi Liu; Ming Li; Zhiqiang Zhang; Chaochao Chen; Xiaolong Li; Qi Yuan; Zhi‐Hua Zhou",
    "corresponding_authors": "",
    "abstract": "Internet companies are facing the need for handling large-scale machine learning applications on a daily basis and distributed implementation of machine learning algorithms which can handle extra-large-scale tasks with great performance is widely needed. Deep forest is a recently proposed deep learning framework which uses tree ensembles as its building blocks and it has achieved highly competitive results on various domains of tasks. However, it has not been tested on extremely large-scale tasks. In this work, based on our parameter server system, we developed the distributed version of deep forest. To meet the need for real-world tasks, many improvements are introduced to the original deep forest model, including MART (Multiple Additive Regression Tree) as base learners for efficiency and effectiveness consideration, the cost-based method for handling prevalent class-imbalanced data, MART based feature selection for high dimension data, and different evaluation metrics for automatically determining the cascade level. We tested the deep forest model on an extra-large-scale task, i.e., automatic detection of cash-out fraud, with more than 100 million training samples. Experimental results showed that the deep forest model has the best performance according to the evaluation metrics from different perspectives even with very little effort for parameter tuning. This model can block fraud transactions in a large amount of money each day. Even compared with the best-deployed model, the deep forest model can additionally bring a significant decrease in economic loss each day.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2972156159",
    "type": "article"
  },
  {
    "title": "Active learning strategies for rating elicitation in collaborative filtering",
    "doi": "https://doi.org/10.1145/2542182.2542195",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Mehdi Elahi; Francesco Ricci⋆; Neil Rubens",
    "corresponding_authors": "",
    "abstract": "The accuracy of collaborative-filtering recommender systems largely depends on three factors: the quality of the rating prediction algorithm, and the quantity and quality of available ratings. While research in the field of recommender systems often concentrates on improving prediction algorithms, even the best algorithms will fail if they are fed poor-quality data during training, that is, garbage in, garbage out. Active learning aims to remedy this problem by focusing on obtaining better-quality data that more aptly reflects a user's preferences. However, traditional evaluation of active learning strategies has two major flaws, which have significant negative ramifications on accurately evaluating the system's performance (prediction error, precision, and quantity of elicited ratings). (1) Performance has been evaluated for each user independently (ignoring system-wide improvements). (2) Active learning strategies have been evaluated in isolation from unsolicited user ratings (natural acquisition). In this article we show that an elicited rating has effects across the system, so a typical user-centric evaluation which ignores any changes of rating prediction of other users also ignores these cumulative effects, which may be more influential on the performance of the system as a whole (system centric). We propose a new evaluation methodology and use it to evaluate some novel and state-of-the-art rating elicitation strategies. We found that the system-wide effectiveness of a rating elicitation strategy depends on the stage of the rating elicitation process, and on the evaluation measures (MAE, NDCG, and Precision). In particular, we show that using some common user-centric strategies may actually degrade the overall performance of a system. Finally, we show that the performance of many common active learning strategies changes significantly when evaluated concurrently with the natural acquisition of ratings in recommender systems.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2005660593",
    "type": "article"
  },
  {
    "title": "Mining User Check-In Behavior with a Random Walk for Urban Point-of-Interest Recommendations",
    "doi": "https://doi.org/10.1145/2523068",
    "publication_date": "2014-09-16",
    "publication_year": 2014,
    "authors": "Josh Jia-Ching Ying; Wen-Ning Kuo; Vincent S. Tseng; Eric Hsueh-Chan Lu",
    "corresponding_authors": "",
    "abstract": "In recent years, research into the mining of user check-in behavior for point-of-interest (POI) recommendations has attracted a lot of attention. Existing studies on this topic mainly treat such recommendations in a traditional manner—that is, they treat POIs as items and check-ins as ratings. However, users usually visit a place for reasons other than to simply say that they have visited. In this article, we propose an approach referred to as Urban POI-Walk (UPOI-Walk), which takes into account a user's social-triggered intentions (SI), preference-triggered intentions (PreI), and popularity-triggered intentions (PopI), to estimate the probability of a user checking-in to a POI. The core idea of UPOI-Walk involves building a HITS-based random walk on the normalized check-in network, thus supporting the prediction of POI properties related to each user's preferences. To achieve this goal, we define several user--POI graphs to capture the key properties of the check-in behavior motivated by user intentions. In our UPOI-Walk approach, we propose a new kind of random walk model—Dynamic HITS-based Random Walk—which comprehensively considers the relevance between POIs and users from different aspects. On the basis of similitude, we make an online recommendation as to the POI the user intends to visit. To the best of our knowledge, this is the first work on urban POI recommendations that considers user check-in behavior motivated by SI, PreI, and PopI in location-based social network data. Through comprehensive experimental evaluations on two real datasets, the proposed UPOI-Walk is shown to deliver excellent performance.",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W2051234849",
    "type": "article"
  },
  {
    "title": "Multi-View Fusion with Extreme Learning Machine for Clustering",
    "doi": "https://doi.org/10.1145/3340268",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Yongshan Zhang; Jia Wu; Chuan Zhou; Zhihua Cai; Jian Yang; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Unlabeled, multi-view data presents a considerable challenge in many real-world data analysis tasks. These data are worth exploring because they often contain complementary information that improves the quality of the analysis results. Clustering with multi-view data is a particularly challenging problem as revealing the complex data structures between many feature spaces demands discriminative features that are specific to the task and, when too few of these features are present, performance suffers. Extreme learning machines (ELMs) are an emerging form of learning model that have shown an outstanding representation ability and superior performance in a range of different learning tasks. Motivated by the promise of this advancement, we have developed a novel multi-view fusion clustering framework based on an ELM, called MVEC. MVEC learns the embeddings from each view of the data via the ELM network, then constructs a single unified embedding according to the correlations and dependencies between each embedding and automatically weighting the contribution of each. This process exposes the underlying clustering structures embedded within multi-view data with a high degree of accuracy. A simple yet efficient solution is also provided to solve the optimization problem within MVEC. Experiments and comparisons on eight different benchmarks from different domains confirm MVEC’s clustering accuracy.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2979744929",
    "type": "article"
  },
  {
    "title": "Improved Approaches with Calibrated Neighboring Joint Density to Steganalysis and Seam-Carved Forgery Detection in JPEG Images",
    "doi": "https://doi.org/10.1145/2560365",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Qingzhong Liu; Zhongxue Chen",
    "corresponding_authors": "",
    "abstract": "Steganalysis and forgery detection in image forensics are generally investigated separately. We have designed a method targeting the detection of both steganography and seam-carved forgery in JPEG images. We analyze the neighboring joint density of the DCT coefficients and reveal the difference between the untouched image and the modified version. In realistic detection, the untouched image and the modified version may not be obtained at the same time, and different JPEG images may have different neighboring joint density features. By exploring the self-calibration under different shift recompressions, we propose calibrated neighboring joint density-based approaches with a simple feature set to distinguish steganograms and tampered images from untouched ones. Our study shows that this approach has multiple promising applications in image forensics. Compared to the state-of-the-art steganalysis detectors, our approach delivers better or comparable detection performances with a much smaller feature set while detecting several JPEG-based steganographic systems including DCT-embedding-based adaptive steganography and Yet Another Steganographic Scheme (YASS). Our approach is also effective in detecting seam-carved forgery in JPEG images. By integrating calibrated neighboring density with spatial domain rich models that were originally designed for steganalysis, the hybrid approach obtains the best detection accuracy to discriminate seam-carved forgery from an untouched image. Our study also offers a promising manner to explore steganalysis and forgery detection together.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2088023168",
    "type": "article"
  },
  {
    "title": "Incentive Mechanism Design for Crowdsourcing",
    "doi": "https://doi.org/10.1145/2837029",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Tie Luo; Sajal K. Das; Hwee-Pink Tan; Lirong Xia",
    "corresponding_authors": "",
    "abstract": "Crowdsourcing can be modeled as a principal-agent problem in which the principal (crowdsourcer) desires to solicit a maximal contribution from a group of agents (participants) while agents are only motivated to act according to their own respective advantages. To reconcile this tension, we propose an all-pay auction approach to incentivize agents to act in the principal’s interest, i.e., maximizing profit, while allowing agents to reap strictly positive utility. Our rationale for advocating all-pay auctions is based on two merits that we identify, namely all-pay auctions (i) compress the common, two-stage “bid-contribute” crowdsourcing process into a single “bid-cum-contribute” stage, and (ii) eliminate the risk of task nonfulfillment. In our proposed approach, we enhance all-pay auctions with two additional features: an adaptive prize and a general crowdsourcing environment. The prize or reward adapts itself as per a function of the unknown winning agent’s contribution, and the environment or setting generally accommodates incomplete and asymmetric information, risk-averse (and risk-neutral) agents, and a stochastic (and deterministic) population. We analytically derive this all-pay auction-based mechanism and extensively evaluate it in comparison to classic and optimized mechanisms. The results demonstrate that our proposed approach remarkably outperforms its counterparts in terms of the principal’s profit, agent’s utility, and social welfare.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2227813210",
    "type": "article"
  },
  {
    "title": "Predicting Academic Performance for College Students",
    "doi": "https://doi.org/10.1145/3299087",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Huaxiu Yao; Defu Lian; Yi Cao; Yifan Wu; Tao Zhou",
    "corresponding_authors": "",
    "abstract": "Detecting abnormal behaviors of students in time and providing personalized intervention and guidance at the early stage is important in educational management. Academic performance prediction is an important building block to enabling this pre-intervention and guidance. Most of the previous studies are based on questionnaire surveys and self-reports, which suffer from small sample size and social desirability bias. In this article, we collect longitudinal behavioral data from the smart cards of 6,597 students and propose three major types of discriminative behavioral factors, diligence, orderliness, and sleep patterns. Empirical analysis demonstrates these behavioral factors are strongly correlated with academic performance. Furthermore, motivated by the social influence theory, we analyze the correlation between each student’s academic performance with his/her behaviorally similar students’. Statistical tests indicate this correlation is significant. Based on these factors, we further build a multi-task predictive framework based on a learning-to-rank algorithm for academic performance prediction. This framework captures inter-semester correlation, inter-major correlation, and integrates student similarity to predict students’ academic performance. The experiments on a large-scale real-world dataset show the effectiveness of our methods for predicting academic performance and the effectiveness of proposed behavioral factors.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2921752035",
    "type": "article"
  },
  {
    "title": "A Real-Time Framework for Task Assignment in Hyperlocal Spatial Crowdsourcing",
    "doi": "https://doi.org/10.1145/3078853",
    "publication_date": "2018-01-18",
    "publication_year": 2018,
    "authors": "Luan Tran; Hien To; Liyue Fan; Cyrus Shahabi",
    "corresponding_authors": "",
    "abstract": "Spatial Crowdsourcing (SC) is a novel platform that engages individuals in the act of collecting various types of spatial data. This method of data collection can significantly reduce cost and turnover time and is particularly useful in urban environmental sensing, where traditional means fail to provide fine-grained field data. In this study, we introduce hyperlocal spatial crowdsourcing, where all workers who are located within the spatiotemporal vicinity of a task are eligible to perform the task (e.g., reporting the precipitation level at their area and time). In this setting, there is often a budget constraint, either for every time period or for the entire campaign, on the number of workers to activate to perform tasks. The challenge is thus to maximize the number of assigned tasks under the budget constraint despite the dynamic arrivals of workers and tasks. We introduce a taxonomy of several problem variants, such as budget-per-time-period vs. budget-per-campaign and binary-utility vs. distance-based-utility . We study the hardness of the task assignment problem in the offline setting and propose online heuristics which exploit the spatial and temporal knowledge acquired over time. Our experiments are conducted with spatial crowdsourcing workloads generated by the SCAWG tool, and extensive results show the effectiveness and efficiency of our proposed solutions.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2608394281",
    "type": "article"
  },
  {
    "title": "Trembr",
    "doi": "https://doi.org/10.1145/3361741",
    "publication_date": "2020-02-04",
    "publication_year": 2020,
    "authors": "Tao-Yang Fu; Wang-Chien Lee",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a novel representation learning framework, namely TRajectory EMBedding via Road networks (Trembr) , to learn trajectory embeddings (low-dimensional feature vectors) for use in a variety of trajectory applications. The novelty of Trembr lies in (1) the design of a recurrent neural network--(RNN) based encoder--decoder model, namely Traj2Vec , that encodes spatial and temporal properties inherent in trajectories into trajectory embeddings by exploiting the underlying road networks to constrain the learning process in accordance with the matched road segments obtained using road network matching techniques (e.g., Barefoot [24, 27]), and (2) the design of a neural network--based model, namely Road2Vec , to learn road segment embeddings in road networks that captures various relationships amongst road segments in preparation for trajectory representation learning. In addition to model design, several unique technical issues raising in Trembr, including data preparation in Road2Vec, the road segment relevance-aware loss, and the network topology constraint in Traj2Vec, are examined. To validate our ideas, we learn trajectory embeddings using multiple large-scale real-world trajectory datasets and use them in three tasks, including trajectory similarity measure, travel time prediction, and destination prediction. Empirical results show that Trembr soundly outperforms the state-of-the-art trajectory representation learning models, trajectory2vec and t2vec , by at least one order of magnitude in terms of mean rank in trajectory similarity measure, 23.3% to 41.7% in terms of mean absolute error (MAE) in travel time prediction, and 39.6% to 52.4% in terms of MAE in destination prediction.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W3013563398",
    "type": "article"
  },
  {
    "title": "Learning Urban Community Structures",
    "doi": "https://doi.org/10.1145/3209686",
    "publication_date": "2018-11-15",
    "publication_year": 2018,
    "authors": "Pengyang Wang; Yanjie Fu; Jiawei Zhang; Xiaolin Li; Dan Lin",
    "corresponding_authors": "",
    "abstract": "Learning urban community structures refers to the efforts of quantifying, summarizing, and representing an urban community’s (i) static structures, e.g., Point-Of-Interests (POIs) buildings and corresponding geographic allocations, and (ii) dynamic structures, e.g., human mobility patterns among POIs. By learning the community structures, we can better quantitatively represent urban communities and understand their evolutions in the development of cities. This can help us boost commercial activities, enhance public security, foster social interactions, and, ultimately, yield livable, sustainable, and viable environments. However, due to the complex nature of urban systems, it is traditionally challenging to learn the structures of urban communities. To address this problem, in this article, we propose a collective embedding framework to learn the community structure from multiple periodic spatial-temporal graphs of human mobility. Specifically, we first exploit a probabilistic propagation-based approach to create a set of mobility graphs from periodic human mobility records. In these mobility graphs, the static POIs are regarded as vertexes, the dynamic mobility connectivities between POI pairs are regarded as edges, and the edge weights periodically evolve over time. A collective deep auto-encoder method is then developed to collaboratively learn the embeddings of POIs from multiple spatial-temporal mobility graphs. In addition, we develop a Unsupervised Graph based Weighted Aggregation method to align and aggregate the POI embeddings into the representation of the community structures. We apply the proposed embedding framework to two applications (i.e., spotting vibrant communities and predicting housing price return rates) to evaluate the performance of our proposed method. Extensive experimental results on real-world urban communities and human mobility data demonstrate the effectiveness of the proposed collective embedding framework.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2901188091",
    "type": "article"
  },
  {
    "title": "A Local Mean Representation-based <i>K</i> -Nearest Neighbor Classifier",
    "doi": "https://doi.org/10.1145/3319532",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Jianping Gou; Wenmo Qiu; Yi Zhang; Yong Xu; Qirong Mao; Yongzhao Zhan",
    "corresponding_authors": "",
    "abstract": "K -nearest neighbor classification method (KNN), as one of the top 10 algorithms in data mining, is a very simple and yet effective nonparametric technique for pattern recognition. However, due to the selective sensitiveness of the neighborhood size k , the simple majority vote, and the conventional metric measure, the KNN-based classification performance can be easily degraded, especially in the small training sample size cases. In this article, to further improve the classification performance and overcome the main issues in the KNN-based classification, we propose a local mean representation-based k -nearest neighbor classifier (LMRKNN). In the LMRKNN, the categorical k -nearest neighbors of a query sample are first chosen to calculate the corresponding categorical k -local mean vectors, and then the query sample is represented by the linear combination of the categorical k -local mean vectors; finally, the class-specific representation-based distances between the query sample and the categorical k -local mean vectors are adopted to determine the class of the query sample. Extensive experiments on many UCI and KEEL datasets and three popular face databases are carried out by comparing LMRKNN to the state-of-art KNN-based methods. The experimental results demonstrate that the proposed LMRKNN outperforms the related competitive KNN-based methods with more robustness and effectiveness.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2939009161",
    "type": "article"
  },
  {
    "title": "Flexible Multi-modal Hashing for Scalable Multimedia Retrieval",
    "doi": "https://doi.org/10.1145/3365841",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Lei Zhu; Xu Lu; Zhiyong Cheng; Jingjing Li; Huaxiang Zhang",
    "corresponding_authors": "",
    "abstract": "Multi-modal hashing methods could support efficient multimedia retrieval by combining multi-modal features for binary hash learning at the both offline training and online query stages. However, existing multi-modal methods cannot binarize the queries, when only one or part of modalities are provided. In this article, we propose a novel Flexible Multi-modal Hashing (FMH) method to address this problem. FMH learns multiple modality-specific hash codes and multi-modal collaborative hash codes simultaneously within a single model. The hash codes are flexibly generated according to the newly coming queries, which provide any one or combination of modality features. Besides, the hashing learning procedure is efficiently supervised by the pair-wise semantic matrix to enhance the discriminative capability. It could successfully avoid the challenging symmetric semantic matrix factorization and O ( n 2 ) storage cost of semantic matrix. Finally, we design a fast discrete optimization to learn hash codes directly with simple operations. Experiments validate the superiority of the proposed approach.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W3008014442",
    "type": "article"
  },
  {
    "title": "Practical Privacy Preserving POI Recommendation",
    "doi": "https://doi.org/10.1145/3394138",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Chaochao Chen; Jun Zhou; Bingzhe Wu; Wenjing Fang; Li Wang; Qi Yuan; Xiaolin Zheng",
    "corresponding_authors": "",
    "abstract": "Point-of-Interest (POI) recommendation has been extensively studied and successfully applied in industry recently. However, most existing approaches build centralized models on the basis of collecting users’ data. Both private data and models are held by the recommender, which causes serious privacy concerns. In this article, we propose a novel Privacy preserving POI Recommendation (PriRec) framework. First, to protect data privacy, users’ private data (features and actions) are kept on their own side, e.g., Cellphone or Pad. Meanwhile, the public data that need to be accessed by all the users are kept by the recommender to reduce the storage costs of users’ devices. Those public data include: (1) static data only related to the status of POI, such as POI categories, and (2) dynamic data dependent on user-POI actions such as visited counts. The dynamic data could be sensitive, and we develop local differential privacy techniques to release such data to the public with privacy guarantees. Second, PriRec follows the representations of Factorization Machine (FM) that consists of a linear model and the feature interaction model. To protect the model privacy, the linear models are saved on the users’ side, and we propose a secure decentralized gradient descent protocol for users to learn it collaboratively. The feature interaction model is kept by the recommender since there is no privacy risk, and we adopt a secure aggregation strategy in a federated learning paradigm to learn it. To this end, PriRec keeps users’ private raw data and models in users’ own hands, and protects user privacy to a large extent. We apply PriRec in real-world datasets, and comprehensive experiments demonstrate that, compared with FM, PriRec achieves comparable or even better recommendation accuracy.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W3039440100",
    "type": "article"
  },
  {
    "title": "An Attention-based Rumor Detection Model with Tree-structured Recursive Neural Networks",
    "doi": "https://doi.org/10.1145/3391250",
    "publication_date": "2020-06-08",
    "publication_year": 2020,
    "authors": "Jing Ma; Wei Gao; Shafiq Joty; Kam‐Fai Wong",
    "corresponding_authors": "",
    "abstract": "Rumor spread in social media severely jeopardizes the credibility of online content. Thus, automatic debunking of rumors is of great importance to keep social media a healthy environment. While facing a dubious claim, people often dispute its truthfulness sporadically in their posts containing various cues, which can form useful evidence with long-distance dependencies. In this work, we propose to learn discriminative features from microblog posts by following their non-sequential propagation structure and generate more powerful representations for identifying rumors. For modeling non-sequential structure, we first represent the diffusion of microblog posts with propagation trees, which provide valuable clues on how a claim in the original post is transmitted and developed over time. We then present a bottom-up and a top-down tree-structured models based on Recursive Neural Networks (RvNN) for rumor representation learning and classification, which naturally conform to the message propagation process in microblogs. To enhance the rumor representation learning, we reveal that effective rumor detection is highly related to finding evidential posts, e.g., the posts expressing specific attitude towards the veracity of a claim, as an extension of the previous RvNN-based detection models that treat every post equally. For this reason, we design discriminative attention mechanisms for the RvNN-based models to selectively attend on the subset of evidential posts during the bottom-up/top-down recursive composition. Experimental results on four datasets collected from real-world microblog platforms confirm that (1) our RvNN-based models achieve much better rumor detection and classification performance than state-of-the-art approaches; (2) the attention mechanisms for focusing on evidential posts can further improve the performance of our RvNN-based method; and (3) our approach possesses superior capacity on detecting rumors at a very early stage.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W3083982479",
    "type": "article"
  },
  {
    "title": "A Survey of AIOps Methods for Failure Management",
    "doi": "https://doi.org/10.1145/3483424",
    "publication_date": "2021-11-30",
    "publication_year": 2021,
    "authors": "Paolo Notaro; Jorge Cardoso; Michael Gerndt",
    "corresponding_authors": "",
    "abstract": "Modern society is increasingly moving toward complex and distributed computing systems. The increase in scale and complexity of these systems challenges O&amp;M teams that perform daily monitoring and repair operations, in contrast with the increasing demand for reliability and scalability of modern applications. For this reason, the study of automated and intelligent monitoring systems has recently sparked much interest across applied IT industry and academia. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to Machine Learning, AI, and Big Data. However, AIOps as a research topic is still largely unstructured and unexplored, due to missing conventions in categorizing contributions for their data requirements, target goals, and components. In this work, we focus on AIOps for Failure Management (FM), characterizing and describing 5 different categories and 14 subcategories of contributions, based on their time intervention window and the target problem being solved. We review 100 FM solutions, focusing on applicability requirements and the quantitative results achieved, to facilitate an effective application of AIOps solutions. Finally, we discuss current development problems in the areas covered by AIOps and delineate possible future trends for AI-based failure management.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W3217360625",
    "type": "article"
  },
  {
    "title": "A Novel Multi-task Tensor Correlation Neural Network for Facial Attribute Prediction",
    "doi": "https://doi.org/10.1145/3418285",
    "publication_date": "2020-11-13",
    "publication_year": 2020,
    "authors": "Mingxing Duan; Kenli Li; Keqin Li; Qi Tian",
    "corresponding_authors": "",
    "abstract": "Multi-task learning plays an important role in face multi-attribute prediction. At present, most researches excavate the shared information between attributes by sharing all convolutional layers. However, it is not appropriate to treat the low-level and high-level features of the face multi-attribute equally, because the high-level features are more biased toward the specific content of the category. In this article, a novel multi-attribute tensor correlation neural network (MTCN) is used to predict face attributes. MTCN shares all attribute features at the low-level layers, and then distinguishes each attribute feature at the high-level layers. To better excavate the correlations among high-level attribute features, each sub-network explores useful information from other networks to enhance its original information. Then a tensor canonical correlation analysis method is used to seek the correlations among the highest-level attributes, which enhances the original information of each attribute. After that, these features are mapped into a highly correlated space through the correlation matrix. Finally, we use sufficient experiments to verify the performance of MTCN on the CelebA and LFWA datasets and our MTCN achieves the best performance compared with the latest multi-attribute recognition algorithms under the same settings.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W3107615494",
    "type": "article"
  },
  {
    "title": "The OARF Benchmark Suite: Characterization and Implications for Federated Learning Systems",
    "doi": "https://doi.org/10.1145/3510540",
    "publication_date": "2022-06-28",
    "publication_year": 2022,
    "authors": "Sixu Hu; Yuan Li; Xu Liu; Qinbin Li; Zhaomin Wu; Bingsheng He",
    "corresponding_authors": "",
    "abstract": "This article presents and characterizes an Open Application Repository for Federated Learning (OARF), a benchmark suite for federated machine learning systems. Previously available benchmarks for federated learning (FL) have focused mainly on synthetic datasets and use a limited number of applications. OARF mimics more realistic application scenarios with publicly available datasets as different data silos in image, text, and structured data. Our characterization shows that the benchmark suite is diverse in data size, distribution, feature distribution, and learning task complexity. The extensive evaluations with reference implementations show the future research opportunities for important aspects of FL systems. We have developed reference implementations, and evaluated the important aspects of FL, including model accuracy, communication cost, throughput, and convergence time. Through these evaluations, we discovered some interesting findings such as FL can effectively increase end-to-end throughput. The code of OARF is publicly available on GitHub. 1",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W3035054364",
    "type": "article"
  },
  {
    "title": "FedCVT: Semi-supervised Vertical Federated Learning with Cross-view Training",
    "doi": "https://doi.org/10.1145/3510031",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Yan Kang; Yang Liu; Xinle Liang",
    "corresponding_authors": "",
    "abstract": "Federated learning allows multiple parties to build machine learning models collaboratively without exposing data. In particular, vertical federated learning (VFL) enables participating parties to build a joint machine learning model based on distributed features of aligned samples. However, VFL requires all parties to share a sufficient amount of aligned samples. In reality, the set of aligned samples may be small, leaving the majority of the non-aligned data unused. In this article, we propose Federated Cross-view Training (FedCVT), a semi-supervised learning approach that improves the performance of the VFL model with limited aligned samples. More specifically, FedCVT estimates representations for missing features, predicts pseudo-labels for unlabeled samples to expand the training set, and trains three classifiers jointly based on different views of the expanded training set to improve the VFL model's performance. FedCVT does not require parties to share their original data and model parameters, thus preserving data privacy. We conduct experiments on NUS-WIDE, Vehicle, and CIFAR10 datasets. The experimental results demonstrate that FedCVT significantly outperforms vanilla VFL that only utilizes aligned samples. Finally, we perform ablation studies to investigate the contribution of each component of FedCVT to the performance of FedCVT. Code is available at https://github.com/yankang18/FedCVT",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W4214626077",
    "type": "article"
  },
  {
    "title": "FairSR: Fairness-aware Sequential Recommendation through Multi-Task Learning with Preference Graph Embeddings",
    "doi": "https://doi.org/10.1145/3495163",
    "publication_date": "2022-02-06",
    "publication_year": 2022,
    "authors": "Cheng–Te Li; Cheng Hsu; Yang Zhang",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation (SR) learns from the temporal dynamics of user-item interactions to predict the next ones. Fairness-aware recommendation mitigates a variety of algorithmic biases in the learning of user preferences. This article aims at bringing a marriage between SR and algorithmic fairness. We propose a novel fairness-aware sequential recommendation task, in which a new metric, interaction fairness , is defined to estimate how recommended items are fairly interacted by users with different protected attribute groups. We propose a multi-task learning-based deep end-to-end model, FairSR, which consists of two parts. One is to learn and distill personalized sequential features from the given user and her item sequence for SR. The other is fairness-aware preference graph embedding (FPGE). The aim of FPGE is two-fold: incorporating the knowledge of users’ and items’ attributes and their correlation into entity representations, and alleviating the unfair distributions of user attributes on items. Extensive experiments conducted on three datasets show FairSR can outperform state-of-the-art SR models in recommendation performance. In addition, the recommended items by FairSR also exhibit promising interaction fairness.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W4210690077",
    "type": "article"
  },
  {
    "title": "Deep Spatio-temporal Adaptive 3D Convolutional Neural Networks for Traffic Flow Prediction",
    "doi": "https://doi.org/10.1145/3510829",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "He Li; Xuejiao Li; Liangcai Su; Duo Jin; Jianbin Huang; De-Shuang Huang",
    "corresponding_authors": "",
    "abstract": "Traffic flow prediction is the upstream problem of path planning, intelligent transportation system, and other tasks. Many studies have been carried out on the traffic flow prediction of the spatio-temporal network, but the effects of spatio-temporal flexibility (historical data of the same type of time intervals in the same location will change flexibly) and spatio-temporal correlation (different road conditions have different effects at different times) have not been considered at the same time. We propose the Deep Spatio-temporal Adaptive 3D Convolution Neural Network (ST-A3DNet), which is a new scheme to solve both spatio-temporal correlation and flexibility, and consider spatio-temporal complexity (complex external factors, such as weather and holidays). Different from other traffic forecasting models, ST-A3DNet captures the spatio-temporal relationship at the same time through the Adaptive 3D convolution module, assigns different weights flexibly according to the influence of historical data, and obtains the impact of external factors on the flow through the ex-mask module. Considering the holidays and weather conditions, we train our model for experiments in Xi’an and Chengdu. We evaluate the ST-A3DNet and the results show that we have better results than the other 11 baselines.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W4206160093",
    "type": "article"
  },
  {
    "title": "An Efficient Learning Framework for Federated XGBoost Using Secret Sharing and Distributed Optimization",
    "doi": "https://doi.org/10.1145/3523061",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Lunchen Xie; Jiaqi Liu; Songtao Lu; Tsung‐Hui Chang; Qingjiang Shi",
    "corresponding_authors": "",
    "abstract": "XGBoost is one of the most widely used machine learning models in the industry due to its superior learning accuracy and efficiency. Targeting at data isolation issues in the big data problems, it is crucial to deploy a secure and efficient federated XGBoost (FedXGB) model. Existing FedXGB models either have data leakage issues or are only applicable to the two-party setting with heavy communication and computation overheads. In this article, a lossless multi-party federated XGB learning framework is proposed with a security guarantee, which reshapes the XGBoost’s split criterion calculation process under a secret sharing setting and solves the leaf weight calculation problem by leveraging distributed optimization. Remarkably, a thorough analysis of model security is provided as well, and multiple numerical results showcase the superiority of the proposed FedXGB compared with the state-of-the-art models on benchmark datasets.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3162518478",
    "type": "article"
  },
  {
    "title": "No Free Lunch Theorem for Security and Utility in Federated Learning",
    "doi": "https://doi.org/10.1145/3563219",
    "publication_date": "2022-09-20",
    "publication_year": 2022,
    "authors": "Xiaojin Zhang; Hanlin Gu; Lixin Fan; Kai Chen; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "In a federated learning scenario where multiple parties jointly learn a model from their respective data, there exist two conflicting goals for the choice of appropriate algorithms. On one hand, private and sensitive training data must be kept secure as much as possible in the presence of semi-honest partners; on the other hand, a certain amount of information has to be exchanged among different parties for the sake of learning utility. Such a challenge calls for the privacy-preserving federated learning solution, which maximizes the utility of the learned model and maintains a provable privacy guarantee of participating parties’ private data. This article illustrates a general framework that (1) formulates the trade-off between privacy loss and utility loss from a unified information-theoretic point of view, and (2) delineates quantitative bounds of the privacy-utility trade-off when different protection mechanisms including randomization, sparsity, and homomorphic encryption are used. It was shown that in general there is no free lunch for the privacy-utility trade-off , and one has to trade the preserving of privacy with a certain degree of degraded utility. The quantitative analysis illustrated in this article may serve as the guidance for the design of practical federated learning algorithms.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W4221156096",
    "type": "article"
  },
  {
    "title": "Location-Centered House Price Prediction: A Multi-Task Learning Approach",
    "doi": "https://doi.org/10.1145/3501806",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Guangliang Gao; Zhifeng Bao; Jie Cao; A. K. Qin; Timos Sellis",
    "corresponding_authors": "",
    "abstract": "Accurate house prediction is of great significance to various real estate stakeholders such as house owners, buyers, and investors. We propose a location-centered prediction framework that differs from existing work in terms of data profiling and prediction model. Regarding data profiling, we make an important observation as follows – besides the in-house features such as floor area, the location plays a critical role in house price prediction. Unfortunately, existing work either overlooked it or had a coarse grained measurement of locations. Thereby, we define and capture a fine-grained location profile powered by a diverse range of location data sources, including transportation profile, education profile, suburb profile based on census data, and facility profile. Regarding the choice of prediction model, we observe that a variety of approaches either consider the entire data for modeling, or split the entire house data and model each partition independently. However, such modeling ignores the relatedness among partitions, and for all prediction scenarios, there may not be sufficient training samples per partition for the latter approach. We address this problem by conducting a careful study of exploiting the Multi-Task Learning (MTL) model. Specifically, we map the strategies for splitting the entire house data to the ways the tasks are defined in MTL, and select specific MTL-based methods with different regularization terms to capture and exploit the relatedness among tasks. Based on real-world house transaction data collected in Melbourne, Australia, we design extensive experimental evaluations, and the results indicate a significant superiority of MTL-based methods over state-of-the-art approaches. Meanwhile, we conduct an in-depth analysis on the impact of task definitions and method selections in MTL on the prediction performance, and demonstrate that the impact of task definitions on prediction performance far exceeds that of method selections.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2907001860",
    "type": "article"
  },
  {
    "title": "Contrastive Learning Models for Sentence Representations",
    "doi": "https://doi.org/10.1145/3593590",
    "publication_date": "2023-05-02",
    "publication_year": 2023,
    "authors": "Lingling Xu; Haoran Xie; Zongxi Li; Fu Lee Wang; Weiming Wang; Qing Li",
    "corresponding_authors": "",
    "abstract": "Sentence representation learning is a crucial task in natural language processing, as the quality of learned representations directly influences downstream tasks, such as sentence classification and sentiment analysis. Transformer-based pretrained language models such as bidirectional encoder representations from transformers (BERT) have been extensively applied to various natural language processing tasks, and have exhibited moderately good performance. However, the anisotropy of the learned embedding space prevents BERT sentence embeddings from achieving good results in the semantic textual similarity tasks. It has been shown that contrastive learning can alleviate the anisotropy problem and significantly improve sentence representation performance. Therefore, there has been a surge in the development of models that utilize contrastive learning to fine-tune BERT-like pretrained language models to learn sentence representations. But no systematic review of contrastive learning models for sentence representations has been conducted. To fill this gap, this article summarizes and categorizes the contrastive learning based sentence representation models, common evaluation tasks for assessing the quality of learned representations, and future research directions. Furthermore, we select several representative models for exhaustive experiments to illustrate the quantitative improvement of various strategies on sentence representations.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4367680667",
    "type": "article"
  },
  {
    "title": "Reinforced Explainable Knowledge Concept Recommendation in MOOCs",
    "doi": "https://doi.org/10.1145/3579991",
    "publication_date": "2023-02-01",
    "publication_year": 2023,
    "authors": "Lu Jiang; Kunpeng Liu; Yibin Wang; Dongjie Wang; Pengyang Wang; Yanjie Fu; Minghao Yin",
    "corresponding_authors": "",
    "abstract": "In this article, we study knowledge concept recommendation in Massive Open Online Courses (MOOCs) in an explainable manner. Knowledge concepts, composing course units (e.g., videos) in MOOCs, refer to topics and skills that students are expected to master. Compared to traditional course recommendation in MOOCs, knowledge concepts recommendation has drawn more attention because students’ interests over knowledge concepts can better revealstudents’ real intention in a more refined granularity. However, there are three unique challenges in knowledge concept recommendation: (1) How to design an appropriate data structure to capture complex relationships between knowledge concepts, course units, and other participants (e.g., students, teachers)? (2) How to model interactions between students and knowledge concepts? (3) How to make explainable recommendation results to students? To tackle these challenges, we formulate the knowledge concept recommendation as a reinforcement learning task integrated with MOOC knowledge graph (KG). Specifically, we first construct MOOC KG as the environment to capture all the relationships and behavioral histories by considering all the entities (e.g., students, teachers, videos, courses, and knowledge concepts) on the MOOC provider. Then, to model the interactions between students and knowledge concepts, we train an agent to mimic students’ learning behavioral patterns facing the complex environment. Moreover, to provide explainable recommendation results, we generate recommended knowledge concepts in the format of a path from MOOC KG to indicate semantic reasons. Finally, we conduct extensive experiments on a real-world MOOC dataset to demonstrate the effectiveness of our proposed method.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W4318776534",
    "type": "article"
  },
  {
    "title": "Spatio-temporal Graph Learning for Epidemic Prediction",
    "doi": "https://doi.org/10.1145/3579815",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Shuo Yu; Feng Xia; Shihao Li; Mingliang Hou; Quan Z. Sheng",
    "corresponding_authors": "",
    "abstract": "The COVID-19 pandemic has posed great challenges to public health services, government agencies, and policymakers, raising huge social conflicts between public health and economic resilience. Policies such as reopening or closure of business activities are formulated based on scientific projections of infection risks obtained from infection dynamics models. Though most parameters in epidemic prediction service models can be set with domain knowledge of COVID-19, a key parameter, namely, human mobility, is often challenging to estimate due to complex spatio-temporal correlations and social contexts under escalating COVID-19 facilities. Moreover, how to integrate the various implicit features to accurately predict infectious cases is still an open issue. To address this challenge, we formulate the problem as a spatio-temporal network representation problem and propose STEP, a Spatio-Temporal Epidemic Prediction framework, to estimate pandemic infection risk of a city by integrating various real-world conditions (e.g., City Risk Index, climate, and medical conditions) into graph-structured data. We also employ a multi-head attention mechanism in representation learning to extract implicit features for a given city. Extensive experiments have been conducted upon the real-world dataset for 51 states (50 states and Washington, D.C.) of the USA. Experimental results show that STEP can yield more accurate pandemic infection risk estimation than baseline methods. Moreover, STEP outperforms other methods in both short-term and long-term prediction.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4315779632",
    "type": "article"
  },
  {
    "title": "Fairness and Bias in Algorithmic Hiring: A Multidisciplinary Survey",
    "doi": "https://doi.org/10.1145/3696457",
    "publication_date": "2024-09-23",
    "publication_year": 2024,
    "authors": "Alessandro Fabris; Nina Baranowska; Matthew Dennis; David Graus; Philipp Hacker; Jorge Saldivar; Frederik Zuiderveen Borgesius; Asia J. Biega",
    "corresponding_authors": "",
    "abstract": "Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of , algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4402747641",
    "type": "article"
  },
  {
    "title": "Deep Learning in Single-cell Analysis",
    "doi": "https://doi.org/10.1145/3641284",
    "publication_date": "2024-01-26",
    "publication_year": 2024,
    "authors": "Dylan Molho; Jiayuan Ding; Wenzhuo Tang; Zhaoheng Li; Hongzhi Wen; Yixin Wang; Julian Venegas; Wei Jin; Renming Liu; Runze Su; Patrick Danaher; Robert Yang; Yu L. Lei; Yuying Xie; Jiliang Tang",
    "corresponding_authors": "",
    "abstract": "Single-cell technologies are revolutionizing the entire field of biology. The large volumes of data generated by single-cell technologies are high dimensional, sparse, and heterogeneous and have complicated dependency structures, making analyses using conventional machine learning approaches challenging and impractical. In tackling these challenges, deep learning often demonstrates superior performance compared to traditional machine learning methods. In this work, we give a comprehensive survey on deep learning in single-cell analysis. We first introduce background on single-cell technologies and their development, as well as fundamental concepts of deep learning including the most popular deep architectures. We present an overview of the single-cell analytic pipeline pursued in research applications while noting divergences due to data sources or specific applications. We then review seven popular tasks spanning different stages of the single-cell analysis pipeline, including multimodal integration, imputation, clustering, spatial domain identification, cell-type deconvolution, cell segmentation, and cell-type annotation. Under each task, we describe the most recent developments in classical and deep learning methods and discuss their advantages and disadvantages. Deep learning tools and benchmark datasets are also summarized for each task. Finally, we discuss the future directions and the most recent challenges. This survey will serve as a reference for biologists and computer scientists, encouraging collaborations.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4391262644",
    "type": "article"
  },
  {
    "title": "Generative AI in Fashion: Overview",
    "doi": "https://doi.org/10.1145/3718098",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Wei-Pei Shi; Wai Keung Wong; Xingxing Zou",
    "corresponding_authors": "",
    "abstract": "Generative Artificial Intelligence (GenAI) has recently gained immense popularity by offering various applications for generating high-quality and aesthetically pleasing content of image, 3D, and video data format. The innovative GenAI solutions have shifted paradigms across various design-related industries, particularly fashion. In this paper, we explore the incorporation of GenAI into fashion-related tasks and applications. Our examination encompasses a thorough review of more than 470 research papers and an in-depth analysis of over 300 applications, focusing on their contributions to the field. These contributions are identified as 13 tasks within four categories: multi-modal fashion understanding, and fashion synthesis of image, 3D, and dynamic (video and animatable 3D) formats We delve into these methods, recognizing their potential to propel future endeavours toward achieving state-of-the-art (SOTA) performance. Furthermore, we present a comprehensive overview of 53 publicly available datasets suitable for training and benchmarking fashion-centric models, accompanied by the relevant evaluation metrics. Finally, we review real-world applications, unveiling existing challenges and future directions. With comprehensive investigation and in-depth analysis, this paper is targeted to serve as a useful resource for understanding the current landscape of GenAI in fashion, paving the way for future innovations in this dynamic field. Papers discussed in this paper, along with public code and datasets links are available at: https://github.com/wendashi/Cool-GenAI-Fashion-Papers/ .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4407682177",
    "type": "article"
  },
  {
    "title": "Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications",
    "doi": "https://doi.org/10.1145/3735648",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Fouad Trad; Ali Chehab",
    "corresponding_authors": "",
    "abstract": "The success of Large Language Models (LLMs) has spurred the rise of Large Multimodal Models (LMMs), which integrate multiple modalities, such as text and images, to address complex data analysis tasks. As these black-box models gain popularity due to their ease of use and adaptability, there is growing interest in understanding their potential to replace or complement task-specific models in domain-specific applications. This paper evaluates the applicability and effectiveness of prompt-engineered LMMs, specifically LLaVA, BakLLaVA, Moondream, Gemini 1.5 Flash, and GPT-4o, compared to fine-tuned Vision Transformer (ViT) models in addressing cybersecurity challenges of varying complexity. Our study examines three distinct tasks: (1) detecting visual triggers indicative of potential backdoors in two scenarios (digit recognition and traffic sign classification), (2) identifying phishing attempts from website screenshots, and (3) classifying malware based on visual representations. The results reveal that prompt-engineered LMMs perform competitively on tasks with visually evident or moderately complex features, such as trigger detection and phishing classification, with GPT-4o and Gemini 1.5 Flash demonstrating superior performance among LMMs. However, for the highly specialized task of malware classification, LMMs exhibit notable limitations when relying solely on prompting. Fine-tuning GPT-4o significantly improves its performance, yet it still lags behind fine-tuned ViT models, which consistently achieve higher accuracy across all tasks. While ViTs deliver superior precision and robustness, they require substantial resources for training, fine-tuning, and maintenance. In contrast, LMMs provide flexibility and ease of deployment, making them an appealing alternative for scenarios where resource constraints or rapid implementation are critical. This study highlights the trade-offs between these approaches, emphasizing that while ViTs are indispensable for high-precision, specialized applications, LMMs offer a scalable and versatile solution for less complex or resource-limited tasks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4410343643",
    "type": "article"
  },
  {
    "title": "A Survey of Machine Unlearning",
    "doi": "https://doi.org/10.1145/3749987",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Thành Tâm Nguyên; Thanh Trung Huynh; Zhao Ren; Phi Le Nguyen; Alan Wee‐Chung Liew; Hongzhi Yin; Quoc Viet Hung Nguyen",
    "corresponding_authors": "",
    "abstract": "Today, computer systems hold large amounts of personal data. Yet while such an abundance of data allows breakthroughs in artificial intelligence, and especially machine learning, its existence can be a threat to user privacy, and it can weaken the bonds of trust between humans and AI. Recent regulations now require that, on request, private information about a user must be removed from both computer systems and from machine learning models – this legislation is more colloquially called “the right to be forgotten”). While removing data from back-end databases should be straightforward, it is not sufficient in the AI context as machine learning models often ‘remember’ the old data. Contemporary adversarial attacks on trained models have proven that we can learn whether an instance or an attribute belonged to the training data. This phenomenon calls for a new paradigm, namely machine unlearning , to make machine learning models forget about particular data. It turns out that recent works on machine unlearning have not been able to completely solve the problem due to the lack of common frameworks and resources. Therefore, this paper aspires to present a comprehensive examination of machine unlearning’s concepts, designs, methods, and applications. Specifically, as a category collection of cutting-edge studies, the intention behind this article is to serve as a comprehensive resource for researchers and practitioners seeking an introduction to machine unlearning and its formulations, design criteria, removal requests, algorithms, and applications. In addition, we aim to highlight the key findings, current trends, and new research areas that have not yet featured the use of machine unlearning but could benefit greatly from it. We hope this survey serves as a valuable resource for machine learning researchers and those seeking to innovate privacy technologies. Our resources are publicly available at https://github.com/tamlhp/awesome-machine-unlearning .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4412565294",
    "type": "article"
  },
  {
    "title": "Inferring colocation and conversation networks from privacy-sensitive audio with implications for computational social science",
    "doi": "https://doi.org/10.1145/1889681.1889688",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Danny Wyatt; Tanzeem Choudhury; Jeff Bilmes; James A. Kitts",
    "corresponding_authors": "",
    "abstract": "New technologies have made it possible to collect information about social networks as they are acted and observed in the wild , instead of as they are reported in retrospective surveys. These technologies offer opportunities to address many new research questions: How can meaningful information about social interaction be extracted from automatically recorded raw data on human behavior? What can we learn about social networks from such fine-grained behavioral data? And how can all of this be done while protecting privacy? With the goal of addressing these questions, this article presents new methods for inferring colocation and conversation networks from privacy-sensitive audio. These methods are applied in a study of face-to-face interactions among 24 students in a graduate school cohort during an academic year. The resulting analysis shows that networks derived from colocation and conversation inferences are quite different. This distinction can inform future research in computational social science, especially work that only measures colocation or employs colocation data as a proxy for conversation networks.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2096449229",
    "type": "article"
  },
  {
    "title": "Subkilometer crater discovery with boosting and transfer learning",
    "doi": "https://doi.org/10.1145/1989734.1989743",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Wei Ding; T. F. Stepinski; Yang Mu; L. Bandeira; Ricardo Ricardo; Youxi Wu; Zhenyu Lu; Tianyu Cao; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "Counting craters in remotely sensed images is the only tool that provides relative dating of remote planetary surfaces. Surveying craters requires counting a large amount of small subkilometer craters, which calls for highly efficient automatic crater detection. In this article, we present an integrated framework on autodetection of subkilometer craters with boosting and transfer learning. The framework contains three key components. First, we utilize mathematical morphology to efficiently identify crater candidates , the regions of an image that can potentially contain craters. Only those regions occupying relatively small portions of the original image are the subjects of further processing. Second, we extract and select image texture features, in combination with supervised boosting ensemble learning algorithms, to accurately classify crater candidates into craters and noncraters. Third, we integrate transfer learning into boosting, to enhance detection performance in the regions where surface morphology differs from what is characterized by the training set. Our framework is evaluated on a large test image of 37,500 × 56,250 m 2 on Mars, which exhibits a heavily cratered Martian terrain characterized by nonuniform surface morphology. Empirical studies demonstrate that the proposed crater detection framework can achieve an F1 score above 0.85, a significant improvement over the other crater detection algorithms.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2158830116",
    "type": "article"
  },
  {
    "title": "Multiview Metric Learning with Global Consistency and Local Smoothness",
    "doi": "https://doi.org/10.1145/2168752.2168767",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Deming Zhai; Hong Chang; Shiguang Shan; Xilin Chen; Wen Gao",
    "corresponding_authors": "",
    "abstract": "In many real-world applications, the same object may have different observations (or descriptions) from multiview observation spaces, which are highly related but sometimes look different from each other. Conventional metric-learning methods achieve satisfactory performance on distance metric computation of data in a single-view observation space, but fail to handle well data sampled from multiview observation spaces, especially those with highly nonlinear structure. To tackle this problem, we propose a new method called Multiview Metric Learning with Global consistency and Local smoothness (MVML-GL) under a semisupervised learning setting, which jointly considers global consistency and local smoothness. The basic idea is to reveal the shared latent feature space of the multiview observations by embodying global consistency constraints and preserving local geometric structures. Specifically, this framework is composed of two main steps. In the first step, we seek a global consistent shared latent feature space, which not only preserves the local geometric structure in each space but also makes those labeled corresponding instances as close as possible. In the second step, the explicit mapping functions between the input spaces and the shared latent space are learned via regularized locally linear regression. Furthermore, these two steps both can be solved by convex optimizations in closed form. Experimental results with application to manifold alignment on real-world datasets of pose and facial expression demonstrate the effectiveness of the proposed method.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2107407880",
    "type": "article"
  },
  {
    "title": "A Reliable People Counting System via Multiple Cameras",
    "doi": "https://doi.org/10.1145/2089094.2089107",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Huadóng Ma; Chengbin Zeng; Charles X. Ling",
    "corresponding_authors": "",
    "abstract": "Reliable and real-time people counting is crucial in many applications. Most previous works can only count moving people from a single camera, which cannot count still people or can fail badly when there is a crowd (i.e., heavy occlusion occurs). In this article, we build a system for robust and fast people counting under occlusion through multiple cameras. To improve the reliability of human detection from a single camera, we use a dimensionality reduction method on the multilevel edge and texture features to handle the large variations in human appearance and poses. To accelerate the detection speed, we propose a novel two-stage cascade-of-rejectors method. To handle the heavy occlusion in crowded scenes, we present a fusion method with error tolerance to combine human detection from multiple cameras. To improve the speed and accuracy of moving people counting, we combine our multiview fusion detection method with particle tracking to count the number of people moving in/out the camera view (“border control”). Extensive experiments and analyses show that our method outperforms state-of-the-art techniques in single- and multicamera datasets for both speed and reliability. We also design a deployed system for fast and reliable people (still or moving) counting by using multiple cameras.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W1978531778",
    "type": "article"
  },
  {
    "title": "Cross-Lingual Adaptation Using Structural Correspondence Learning",
    "doi": "https://doi.org/10.1145/2036264.2036277",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Peter Prettenhofer; Benno Stein",
    "corresponding_authors": "",
    "abstract": "Cross-lingual adaptation is a special case of domain adaptation and refers to the transfer of classification knowledge between two languages. In this article we describe an extension of Structural Correspondence Learning (SCL), a recently proposed algorithm for domain adaptation, for cross-lingual adaptation in the context of text classification. The proposed method uses unlabeled documents from both languages, along with a word translation oracle, to induce a cross-lingual representation that enables the transfer of classification knowledge from the source to the target language. The main advantages of this method over existing methods are resource efficiency and task specificity. We conduct experiments in the area of cross-language topic and sentiment classification involving English as source language and German, French, and Japanese as target languages. The results show a significant improvement of the proposed method over a machine translation baseline, reducing the relative error due to cross-lingual adaptation by an average of 30% (topic classification) and 59% (sentiment classification). We further report on empirical analyses that reveal insights into the use of unlabeled data, the sensitivity with respect to important hyperparameters, and the nature of the induced cross-lingual word correspondences.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2027570514",
    "type": "article"
  },
  {
    "title": "Ranking User Influence in Healthcare Social Media",
    "doi": "https://doi.org/10.1145/2337542.2337558",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Xuning Tang; Christopher C. Yang",
    "corresponding_authors": "",
    "abstract": "Due to the revolutionary development of Web 2.0 technology, individual users have become major contributors of Web content in online social media. In light of the growing activities, how to measure a user’s influence to other users in online social media becomes increasingly important. This research need is urgent especially in the online healthcare community since positive influence can be beneficial while negative influence may cause-negative impact on other users of the same community. In this article, a research framework was proposed to study user influence within the online healthcare community. We proposed a new approach to incorporate users’ reply relationship, conversation content and response immediacy which capture both explicit and implicit interaction between users to identify influential users of online healthcare community. A weighted social network is developed to represent the influence between users. We tested our proposed techniques thoroughly on two medical support forums. Two algorithms UserRank and Weighted in-degree are benchmarked with PageRank and in-degree. Experiment results demonstrated the validity and effectiveness of our proposed approaches.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2055943171",
    "type": "article"
  },
  {
    "title": "From manifesta to krypta",
    "doi": null,
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Rino Falcone; Michele Piunti; Matteo Venanzi; Cristiano Castelfranchi",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W3216595727",
    "type": "article"
  },
  {
    "title": "Neighboring joint density-based JPEG steganalysis",
    "doi": "https://doi.org/10.1145/1899412.1899420",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Qingzhong Liu; Andrew H. Sung; Mengyu Qiao",
    "corresponding_authors": "",
    "abstract": "The threat posed by hackers, spies, terrorists, and criminals, etc. using steganography for stealthy communications and other illegal purposes is a serious concern of cyber security. Several steganographic systems that have been developed and made readily available utilize JPEG images as carriers. Due to the popularity of JPEG images on the Internet, effective steganalysis techniques are called for to counter the threat of JPEG steganography. In this article, we propose a new approach based on feature mining on the discrete cosine transform (DCT) domain and machine learning for steganalysis of JPEG images. First, neighboring joint density features on both intra-block and inter-block are extracted from the DCT coefficient array and the absolute array, respectively; then a support vector machine (SVM) is applied to the features for detection. An evolving neural-fuzzy inference system is employed to predict the hiding amount in JPEG steganograms. We also adopt a feature selection method of support vector machine recursive feature elimination to reduce the number of features. Experimental results show that, in detecting several JPEG-based steganographic systems, our method prominently outperforms the well-known Markov-process based approach.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2036190666",
    "type": "article"
  },
  {
    "title": "Analyzing user behavior across social sharing environments",
    "doi": "https://doi.org/10.1145/2535526",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Pasquale De Meo; Emilio Ferrara; Fabian Abel; Lora Aroyo; Geert‐Jan Houben",
    "corresponding_authors": "",
    "abstract": "In this work we present an in-depth analysis of the user behaviors on different Social Sharing systems. We consider three popular platforms, Flickr, Delicious and StumbleUpon, and, by combining techniques from social network analysis with techniques from semantic analysis, we characterize the tagging behavior as well as the tendency to create friendship relationships of the users of these platforms. The aim of our investigation is to see if (and how) the features and goals of a given Social Sharing system reflect on the behavior of its users and, moreover, if there exists a correlation between the social and tagging behavior of the users. We report our findings in terms of the characteristics of user profiles according to three different dimensions: (i) intensity of user activities, (ii) tag-based characteristics of user profiles, and (iii) semantic characteristics of user profiles.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W3104624354",
    "type": "article"
  },
  {
    "title": "Ohmage",
    "doi": "https://doi.org/10.1145/2717318",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Hongsuda Tangmunarunkit; Cheng-Kang Hsieh; Brent Longstaff; Sara L Nolen; Jonathan Jenkins; Cameron Ketcham; Joshua Selsky; Faisal Alquaddoomi; Dony George; Jinha Kang; Z. Khalapyan; Jeroen Ooms; Nithya Ramanathan; Deborah Estrin",
    "corresponding_authors": "",
    "abstract": "Participatory sensing (PS) is a distributed data collection and analysis approach where individuals, acting alone or in groups, use their personal mobile devices to systematically explore interesting aspects of their lives and communities [Burke et al. 2006]. These mobile devices can be used to capture diverse spatiotemporal data through both intermittent self-report and continuous recording from on-board sensors and applications. Ohmage (http://ohmage.org) is a modular and extensible open-source, mobile to Web PS platform that records, stores, analyzes, and visualizes data from both prompted self-report and continuous data streams. These data streams are authorable and can dynamically be deployed in diverse settings. Feedback from hundreds of behavioral and technology researchers, focus group participants, and end users has been integrated into ohmage through an iterative participatory design process. Ohmage has been used as an enabling platform in more than 20 independent projects in many disciplines. We summarize the PS requirements, challenges and key design objectives learned through our design process, and ohmage system architecture to achieve those objectives. The flexibility, modularity, and extensibility of ohmage in supporting diverse deployment settings are presented through three distinct case studies in education, health, and clinical research.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W1988294160",
    "type": "article"
  },
  {
    "title": "Reliable medical recommendation systems with patient privacy",
    "doi": "https://doi.org/10.1145/2508037.2508048",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "T. Ryan Hoens; Marina Blanton; Aaron Steele; Nitesh V. Chawla",
    "corresponding_authors": "",
    "abstract": "One of the concerns patients have when confronted with a medical condition is which physician to trust. Any recommendation system that seeks to answer this question must ensure that any sensitive medical information collected by the system is properly secured. In this article, we codify these privacy concerns in a privacy-friendly framework and present two architectures that realize it: the Secure Processing Architecture (SPA) and the Anonymous Contributions Architecture (ACA). In SPA, patients submit their ratings in a protected form without revealing any information about their data and the computation of recommendations proceeds over the protected data using secure multiparty computation techniques. In ACA, patients submit their ratings in the clear, but no link between a submission and patient data can be made. We discuss various aspects of both architectures, including techniques for ensuring reliability of computed recommendations and system performance, and provide their comparison.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2216175760",
    "type": "article"
  },
  {
    "title": "Latent Support Vector Machine Modeling for Sign Language Recognition with Kinect",
    "doi": "https://doi.org/10.1145/2629481",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Chao Sun; Tianzhu Zhang; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "Vision-based sign language recognition has attracted more and more interest from researchers in the computer vision field. In this article, we propose a novel algorithm to model and recognize sign language performed in front of a Microsoft Kinect sensor. Under the assumption that some frames are expected to be both discriminative and representative in a sign language video, we first assign a binary latent variable to each frame in training videos for indicating its discriminative capability, then develop a latent support vector machine model to classify the signs, as well as localize the discriminative and representative frames in each video. In addition, we utilize the depth map together with the color image captured by the Kinect sensor to obtain a more effective and accurate feature to enhance the recognition accuracy. To evaluate our approach, we conducted experiments on both word-level sign language and sentence-level sign language. An American Sign Language dataset including approximately 2,000 word-level sign language phrases and 2,000 sentence-level sign language phrases was collected using the Kinect sensor, and each phrase contains color, depth, and skeleton information. Experiments on our dataset demonstrate the effectiveness of the proposed method for sign language recognition.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2014233635",
    "type": "article"
  },
  {
    "title": "Mining search and browse logs for web search",
    "doi": "https://doi.org/10.1145/2508037.2508038",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Daxin Jiang; Jian Pei; Hang Li",
    "corresponding_authors": "",
    "abstract": "Huge amounts of search log data have been accumulated at Web search engines. Currently, a popular Web search engine may receive billions of queries and collect terabytes of records about user search behavior daily. Beside search log data, huge amounts of browse log data have also been collected through client-side browser plugins. Such massive amounts of search and browse log data provide great opportunities for mining the wisdom of crowds and improving Web search. At the same time, designing effective and efficient methods to clean, process, and model log data also presents great challenges. In this survey, we focus on mining search and browse log data for Web search. We start with an introduction to search and browse log data and an overview of frequently-used data summarizations in log mining. We then elaborate how log mining applications enhance the five major components of a search engine, namely, query understanding, document understanding, document ranking, user understanding, and monitoring and feedback. For each aspect, we survey the major tasks, fundamental principles, and state-of-the-art methods.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2056767790",
    "type": "article"
  },
  {
    "title": "Prediction and Simulation of Human Mobility Following Natural Disasters",
    "doi": "https://doi.org/10.1145/2970819",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "Xuan Song; Quanshi Zhang; Yoshihide Sekimoto; Ryosuke Shibasaki; Nicholas Jing Yuan; Xing Xie",
    "corresponding_authors": "",
    "abstract": "In recent decades, the frequency and intensity of natural disasters has increased significantly, and this trend is expected to continue. Therefore, understanding and predicting human behavior and mobility during a disaster will play a vital role in planning effective humanitarian relief, disaster management, and long-term societal reconstruction. However, such research is very difficult to perform owing to the uniqueness of various disasters and the unavailability of reliable and large-scale human mobility data. In this study, we collect big and heterogeneous data (e.g., GPS records of 1.6 million users 1 over 3 years, data on earthquakes that have occurred in Japan over 4 years, news report data, and transportation network data) to study human mobility following natural disasters. An empirical analysis is conducted to explore the basic laws governing human mobility following disasters, and an effective human mobility model is developed to predict and simulate population movements. The experimental results demonstrate the efficiency of our model, and they suggest that human mobility following disasters can be significantly more predictable and be more easily simulated than previously thought.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2546912553",
    "type": "article"
  },
  {
    "title": "Dynamic joint sentiment-topic model",
    "doi": "https://doi.org/10.1145/2542182.2542188",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Yulan He; Chenghua Lin; Wei Gao; Kam‐Fai Wong",
    "corresponding_authors": "",
    "abstract": "Social media data are produced continuously by a large and uncontrolled number of users. The dynamic nature of such data requires the sentiment and topic analysis model to be also dynamically updated, capturing the most recent language use of sentiments and topics in text. We propose a dynamic Joint Sentiment-Topic model (dJST) which allows the detection and tracking of views of current and recurrent interests and shifts in topic and sentiment. Both topic and sentiment dynamics are captured by assuming that the current sentiment-topic-specific word distributions are generated according to the word distributions at previous epochs. We study three different ways of accounting for such dependency information: (1) sliding window where the current sentiment-topic word distributions are dependent on the previous sentiment-topic-specific word distributions in the last S epochs; (2) skip model where history sentiment topic word distributions are considered by skipping some epochs in between; and (3) multiscale model where previous long- and short- timescale distributions are taken into consideration. We derive efficient online inference procedures to sequentially update the model with newly arrived data and show the effectiveness of our proposed model on the Mozilla add-on reviews crawled between 2007 and 2011.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2017291483",
    "type": "article"
  },
  {
    "title": "Sensing the Pulse of Urban Refueling Behavior",
    "doi": "https://doi.org/10.1145/2644828",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Fuzheng Zhang; Nicholas Jing Yuan; David A. Wilkie; Yu Zheng; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Urban transportation is an important factor in energy consumption and pollution, and is of increasing concern due to its complexity and economic significance. Its importance will only increase as urbanization continues around the world. In this article, we explore drivers’ refueling behavior in urban areas. Compared to questionnaire-based methods of the past, we propose a complete data-driven system that pushes towards real-time sensing of individual refueling behavior and citywide petrol consumption. Our system provides the following: detection of individual refueling events (REs) from which refueling preference can be analyzed; estimates of gas station wait times from which recommendations can be made; an indication of overall fuel demand from which macroscale economic decisions can be made, and a spatial, temporal, and economic view of urban refueling characteristics. For individual behavior, we use reported trajectories from a fleet of GPS-equipped taxicabs to detect gas station visits. For time spent estimates, to solve the sparsity issue along time and stations, we propose context-aware tensor factorization (CATF), a factorization model that considers a variety of contextual factors (e.g., price, brand, and weather condition) that affect consumers’ refueling decision. For fuel demand estimates, we apply a queue model to calculate the overall visits based on the time spent inside the station. We evaluated our system on large-scale and real-world datasets, which contain 4-month trajectories of 32,476 taxicabs, 689 gas stations, and the self-reported refueling details of 8,326 online users. The results show that our system can determine REs with an accuracy of more than 90%, estimate time spent with less than 2 minutes of error, and measure overall visits in the same order of magnitude with the records in the field study.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2116111642",
    "type": "article"
  },
  {
    "title": "Named entity recognition for tweets",
    "doi": "https://doi.org/10.1145/2414425.2414428",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Xiaohua Liu; Furu Wei; Shaodian Zhang; Ming Zhou",
    "corresponding_authors": "",
    "abstract": "Two main challenges of Named Entity Recognition (NER) for tweets are the insufficient information in a tweet and the lack of training data. We propose a novel method consisting of three core elements: (1) normalization of tweets; (2) combination of a K-Nearest Neighbors (KNN) classifier with a linear Conditional Random Fields (CRF) model; and (3) semisupervised learning framework. The tweet normalization preprocessing corrects common ill-formed words using a global linear model. The KNN-based classifier conducts prelabeling to collect global coarse evidence across tweets while the CRF model conducts sequential labeling to capture fine-grained information encoded in a tweet. The semisupervised learning plus the gazetteers alleviate the lack of training data. Extensive experiments show the advantages of our method over the baselines as well as the effectiveness of normalization, KNN, and semisupervised learning.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2048613595",
    "type": "article"
  },
  {
    "title": "Learning Perceptual Causality from Video",
    "doi": "https://doi.org/10.1145/2809782",
    "publication_date": "2015-11-26",
    "publication_year": 2015,
    "authors": "Amy Sue Fire; Song‐Chun Zhu",
    "corresponding_authors": "",
    "abstract": "Perceptual causality is the perception of causal relationships from observation. Humans, even as infants, form such models from observation of the world around them [Saxe and Carey 2006]. For a deeper understanding, the computer must make similar models through the analogous form of observation: video. In this article, we provide a framework for the unsupervised learning of this perceptual causal structure from video. Our method takes action and object status detections as input and uses heuristics suggested by cognitive science research to produce the causal links perceived between them. We greedily modify an initial distribution featuring independence between potential causes and effects by adding dependencies that maximize information gain. We compile the learned causal relationships into a Causal And-Or Graph, a probabilistic and-or representation of causality that adds a prior to causality. Validated against human perception, experiments show that our method correctly learns causal relations, attributing status changes of objects to causing actions amid irrelevant actions. Our method outperforms Hellinger’s χ 2 -statistic by considering hierarchical action selection, and outperforms the treatment effect by discounting coincidental relationships.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2263753396",
    "type": "article"
  },
  {
    "title": "A Unified Point-of-Interest Recommendation Framework in Location-Based Social Networks",
    "doi": "https://doi.org/10.1145/2901299",
    "publication_date": "2016-09-20",
    "publication_year": 2016,
    "authors": "Cheng Chen; Haiqin Yang; Irwin King; Michael R. Lyu",
    "corresponding_authors": "",
    "abstract": "Location-based social networks (LBSNs), such as Gowalla, Facebook, Foursquare, Brightkite, and so on, have attracted millions of users to share their social friendship and their locations via check-ins in the past few years. Plenty of valuable information is accumulated based on the check-in behaviors, which makes it possible to learn users’ moving patterns as well as their preferences. In LBSNs, point-of-interest (POI) recommendation is one of the most significant tasks because it can help targeted users explore their surroundings as well as help third-party developers provide personalized services. Matrix factorization is a promising method for this task because it can capture users’ preferences to locations and is widely adopted in traditional recommender systems such as movie recommendation. However, the sparsity of the check-in data makes it difficult to capture users’ preferences accurately. Geographical influence can help alleviate this problem and have a large impact on the final recommendation result. By studying users’ moving patterns, we find that users tend to check in around several centers and different users have different numbers of centers. Based on this, we propose a Multi-center Gaussian Model (MGM) to capture this pattern via modeling the probability of a user’s check-in on a location. Moreover, users are usually more interested in the top 20 or even top 10 recommended POIs, which makes personalized ranking important in this task. From previous work, directly optimizing for pairwise ranking like Bayesian Personalized Ranking (BPR) achieves better performance in the top- k recommendation than directly using matrix matrix factorization that aims to minimize the point-wise rating error. To consider users’ preferences, geographical influence and personalized ranking, we propose a unified POI recommendation framework, which unifies all of them together. Specifically, we first fuse MGM with matrix factorization methods and further with BPR using two different approaches. We conduct experiments on Gowalla and Foursquare datasets, which are two large-scale real-world LBSN datasets publicly available online. The results on both datasets show that our unified POI recommendation framework can produce better performance.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2521595004",
    "type": "article"
  },
  {
    "title": "User-Specific Feature-Based Similarity Models for Top- <i>n</i> Recommendation of New Items",
    "doi": "https://doi.org/10.1145/2700495",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Asmaa Elbadrawy; George Karypis",
    "corresponding_authors": "",
    "abstract": "Recommending new items for suitable users is an important yet challenging problem due to the lack of preference history for the new items. Noncollaborative user modeling techniques that rely on the item features can be used to recommend new items. However, they only use the past preferences of each user to provide recommendations for that user. They do not utilize information from the past preferences of other users, which can potentially be ignoring useful information. More recent factor models transfer knowledge across users using their preference information in order to provide more accurate recommendations. These methods learn a low-rank approximation for the preference matrix, which can lead to loss of information. Moreover, they might not be able to learn useful patterns given very sparse datasets. In this work, we present &lt;scp&gt;UFSM&lt;/scp&gt;, a method for top-&lt;i&gt;n&lt;/i&gt; recommendation of new items given binary user preferences. &lt;scp&gt;UFSM&lt;/scp&gt; learns &lt;b&gt;U&lt;/b&gt;ser-specific &lt;b&gt;F&lt;/b&gt;eature-based item-&lt;b&gt;S&lt;/b&gt;imilarity &lt;b&gt;M&lt;/b&gt;odels, and its strength lies in combining two points: (1) exploiting preference information across all users to learn multiple global item similarity functions and (2) learning user-specific weights that determine the contribution of each global similarity function in generating recommendations for each user. &lt;scp&gt;UFSM&lt;/scp&gt; can be considered as a sparse high-dimensional factor model where the previous preferences of each user are incorporated within his or her latent representation. This way, &lt;scp&gt;UFSM&lt;/scp&gt; combines the merits of item similarity models that capture local relations among items and factor models that learn global preference patterns. A comprehensive set of experiments was conduced to compare &lt;scp&gt;UFSM&lt;/scp&gt; against state-of-the-art collaborative factor models and noncollaborative user modeling techniques. Results show that &lt;scp&gt;UFSM&lt;/scp&gt; outperforms other techniques in terms of recommendation quality. &lt;scp&gt;UFSM&lt;/scp&gt; manages to yield better recommendations even with very sparse datasets. Results also show that &lt;scp&gt;UFSM&lt;/scp&gt; can efficiently handle high-dimensional as well as low-dimensional item feature spaces.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2066642579",
    "type": "article"
  },
  {
    "title": "BAMB",
    "doi": "https://doi.org/10.1145/3335676",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Zhaolong Ling; Kui Yu; Hao Wang; Lin Liu; Wei Ding; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "The discovery of Markov blanket (MB) for feature selection has attracted much attention in recent years, since the MB of the class attribute is the optimal feature subset for feature selection. However, almost all existing MB discovery algorithms focus on either improving computational efficiency or boosting learning accuracy, instead of both. In this article, we propose a novel MB discovery algorithm for balancing efficiency and accuracy, called &lt;underline&gt;BA&lt;/underline&gt;lanced &lt;underline&gt;M&lt;/underline&gt;arkov &lt;underline&gt;B&lt;/underline&gt;lanket (BAMB) discovery. To achieve this goal, given a class attribute of interest, BAMB finds candidate PC (parents and children) and spouses and removes false positives from the candidate MB set in one go. Specifically, once a feature is successfully added to the current PC set, BAMB finds the spouses with regard to this feature, then uses the updated PC and the spouse set to remove false positives from the current MB set. This makes the PC and spouses of the target as small as possible and thus achieves a trade-off between computational efficiency and learning accuracy. In the experiments, we first compare BAMB with 8 state-of-the-art MB discovery algorithms on 7 benchmark Bayesian networks, then we use 10 real-world datasets and compare BAMB with 12 feature selection algorithms, including 8 state-of-the-art MB discovery algorithms and 4 other well-established feature selection methods. On prediction accuracy, BAMB outperforms 12 feature selection algorithms compared. On computational efficiency, BAMB is close to the IAMB algorithm while it is much faster than the remaining seven MB discovery algorithms.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2980507899",
    "type": "article"
  },
  {
    "title": "Robust Fake News Detection Over Time and Attack",
    "doi": "https://doi.org/10.1145/3363818",
    "publication_date": "2019-12-14",
    "publication_year": 2019,
    "authors": "Benjamin D. Horne; Jeppe Nørregaard; Sibel Adalı",
    "corresponding_authors": "",
    "abstract": "In this study, we examine the impact of time on state-of-the-art news veracity classifiers. We show that, as time progresses, classification performance for both unreliable and hyper-partisan news classification slowly degrade. While this degradation does happen, it happens slower than expected, illustrating that hand-crafted, content-based features, such as style of writing, are fairly robust to changes in the news cycle.We show that this small degradation can bemitigated using online learning. Last, we examine the impact of adversarial content manipulation by malicious news producers. Specifically, we test three types of attack based on changes in the input space and data availability. We show that static models are susceptible to content manipulation attacks, but online models can recover from such attacks.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W3001172084",
    "type": "article"
  },
  {
    "title": "Identifying Authorities in Online Communities",
    "doi": "https://doi.org/10.1145/2700481",
    "publication_date": "2015-04-24",
    "publication_year": 2015,
    "authors": "Mohamed Bouguessa; Lotfi Romdhane",
    "corresponding_authors": "",
    "abstract": "Several approaches have been proposed for the problem of identifying authoritative actors in online communities. However, the majority of existing methods suffer from one or more of the following limitations: (1) There is a lack of an automatic mechanism to formally discriminate between authoritative and nonauthoritative users. In fact, a common approach to authoritative user identification is to provide a ranked list of users expecting authorities to come first. A major problem of such an approach is the question of where to stop reading the ranked list of users. How many users should be chosen as authoritative? (2) Supervised learning approaches for authoritative user identification suffer from their dependency on the training data. The problem here is that labeled samples are more difficult, expensive, and time consuming to obtain than unlabeled ones. (3) Several approaches rely on some user parameters to estimate an authority score. Detection accuracy of authoritative users can be seriously affected if incorrect values are used. In this article, we propose a parameterless mixture model-based approach that is capable of addressing the three aforementioned issues in a single framework. In our approach, we first represent each user with a feature vector composed of information related to its social behavior and activity in an online community. Next, we propose a statistical framework, based on the multivariate beta mixtures, in order to model the estimated set of feature vectors. The probability density function is therefore estimated and the beta component that corresponds to the most authoritative users is identified. The suitability of the proposed approach is illustrated on real data extracted from the Stack Exchange question-answering network and Twitter.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W1988374254",
    "type": "article"
  },
  {
    "title": "City-Scale Social Event Detection and Evaluation with Taxi Traces",
    "doi": "https://doi.org/10.1145/2700478",
    "publication_date": "2015-05-20",
    "publication_year": 2015,
    "authors": "Wangsheng Zhang; Guande Qi; Gang Pan; Hua Lu; Shijian Li; Zhaohui Wu",
    "corresponding_authors": "",
    "abstract": "A social event is an occurrence that involves lots of people and is accompanied by an obvious rise in human flow. Analysis of social events has real-world importance because events bring about impacts on many aspects of city life. Traditionally, detection and impact measurement of social events rely on social investigation, which involves considerable human effort. Recently, by analyzing messages in social networks, researchers can also detect and evaluate country-scale events. Nevertheless, the analysis of city-scale events has not been explored. In this article, we use human flow dynamics, which reflect the social activeness of a region, to detect social events and measure their impacts. We first extract human flow dynamics from taxi traces. Second, we propose a method that can not only discover the happening time and venue of events from abnormal social activeness, but also measure the scale of events through changes in such activeness. Third, we extract traffic congestion information from traces and use its change during social events to measure their impact. The results of experiments validate the effectiveness of both the event detection and impact measurement methods.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W1994412661",
    "type": "article"
  },
  {
    "title": "Who Will Retweet This? Detecting Strangers from Twitter to Retweet Information",
    "doi": "https://doi.org/10.1145/2700466",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Kyumin Lee; Jalal Mahmud; Jilin Chen; Michelle X. Zhou; Jeffrey Nichols",
    "corresponding_authors": "",
    "abstract": "There has been much effort on studying how social media sites, such as Twitter, help propagate information in different situations, including spreading alerts and SOS messages in an emergency. However, existing work has not addressed how to actively identify and engage the right strangers at the right time on social media to help effectively propagate intended information within a desired time frame. To address this problem, we have developed three models: (1) a feature-based model that leverages people's exhibited social behavior, including the content of their tweets and social interactions, to characterize their willingness and readiness to propagate information on Twitter via the act of retweeting; (2) a wait-time model based on a user's previous retweeting wait times to predict his or her next retweeting time when asked; and (3) a subset selection model that automatically selects a subset of people from a set of available people using probabilities predicted by the feature-based model and maximizes retweeting rate. Based on these three models, we build a recommender system that predicts the likelihood of a stranger to retweet information when asked, within a specific time window, and recommends the top-N qualified strangers to engage with. Our experiments, including live studies in the real world, demonstrate the effectiveness of our work.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2025310159",
    "type": "article"
  },
  {
    "title": "Multimedia News Summarization in Search",
    "doi": "https://doi.org/10.1145/2822907",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Zechao Li; Jinhui Tang; Wang Xue-ming; Jing Liu; Hanqing Lu",
    "corresponding_authors": "",
    "abstract": "It is a necessary but challenging task to relieve users from the proliferative news information and allow them to quickly and comprehensively master the information of the whats and hows that are happening in the world every day. In this article, we develop a novel approach of multimedia news summarization for searching results on the Internet, which uncovers the underlying topics among query-related news information and threads the news events within each topic to generate a query-related brief overview. First, the hierarchical latent Dirichlet allocation (hLDA) model is introduced to discover the hierarchical topic structure from query-related news documents, and a new approach based on the weighted aggregation and max pooling is proposed to identify one representative news article for each topic. One representative image is also selected to visualize each topic as a complement to the text information. Given the representative documents selected for each topic, a time-bias maximum spanning tree (MST) algorithm is proposed to thread them into a coherent and compact summary of their parent topic. Finally, we design a friendly interface to present users with the hierarchical summarization of their required news information. Extensive experiments conducted on a large-scale news dataset collected from multiple news Web sites demonstrate the encouraging performance of the proposed solution for news summarization in news retrieval.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2259890326",
    "type": "article"
  },
  {
    "title": "Dynamic Scheduling of Cybersecurity Analysts for Minimizing Risk Using Reinforcement Learning",
    "doi": "https://doi.org/10.1145/2882969",
    "publication_date": "2016-07-25",
    "publication_year": 2016,
    "authors": "Rajesh Ganesan; Sushil Jajodia; Ankit Shah; Hasan Çam",
    "corresponding_authors": "",
    "abstract": "An important component of the cyber-defense mechanism is the adequate staffing levels of its cybersecurity analyst workforce and their optimal assignment to sensors for investigating the dynamic alert traffic. The ever-increasing cybersecurity threats faced by today’s digital systems require a strong cyber-defense mechanism that is both reactive in its response to mitigate the known risk and proactive in being prepared for handling the unknown risks. In order to be proactive for handling the unknown risks, the above workforce must be scheduled dynamically so the system is adaptive to meet the day-to-day stochastic demands on its workforce (both size and expertise mix). The stochastic demands on the workforce stem from the varying alert generation and their significance rate, which causes an uncertainty for the cybersecurity analyst scheduler that is attempting to schedule analysts for work and allocate sensors to analysts. Sensor data are analyzed by automatic processing systems, and alerts are generated. A portion of these alerts is categorized to be significant , which requires thorough examination by a cybersecurity analyst. Risk, in this article, is defined as the percentage of significant alerts that are not thoroughly analyzed by analysts. In order to minimize risk, it is imperative that the cyber-defense system accurately estimates the future significant alert generation rate and dynamically schedules its workforce to meet the stochastic workload demand to analyze them. The article presents a reinforcement learning-based stochastic dynamic programming optimization model that incorporates the above estimates of future alert rates and responds by dynamically scheduling cybersecurity analysts to minimize risk (i.e., maximize significant alert coverage by analysts) and maintain the risk under a pre-determined upper bound. The article tests the dynamic optimization model and compares the results to an integer programming model that optimizes the static staffing needs based on a daily-average alert generation rate with no estimation of future alert rates (static workforce model). Results indicate that over a finite planning horizon, the learning-based optimization model, through a dynamic (on-call) workforce in addition to the static workforce, (a) is capable of balancing risk between days and reducing overall risk better than the static model, (b) is scalable and capable of identifying the quantity and the right mix of analyst expertise in an organization, and (c) is able to determine their dynamic (on-call) schedule and their sensor-to-analyst allocation in order to maintain risk below a given upper bound. Several meta-principles are presented, which are derived from the optimization model, and they further serve as guiding principles for hiring and scheduling cybersecurity analysts. Days-off scheduling was performed to determine analyst weekly work schedules that met the cybersecurity system’s workforce constraints and requirements.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2506654222",
    "type": "article"
  },
  {
    "title": "Sparse Online Learning of Image Similarity",
    "doi": "https://doi.org/10.1145/3065950",
    "publication_date": "2017-08-12",
    "publication_year": 2017,
    "authors": "Xingyu Gao; Steven C. H. Hoi; Yongdong Zhang; Jianshe Zhou; Ji Wan; Zhenyu Chen; Jintao Li; Jianke Zhu",
    "corresponding_authors": "",
    "abstract": "Learning image similarity plays a critical role in real-world multimedia information retrieval applications, especially in Content-Based Image Retrieval (CBIR) tasks, in which an accurate retrieval of visually similar objects largely relies on an effective image similarity function. Crafting a good similarity function is very challenging because visual contents of images are often represented as feature vectors in high-dimensional spaces, for example, via bag-of-words (BoW) representations, and traditional rigid similarity functions, for example, cosine similarity, are often suboptimal for CBIR tasks. In this article, we address this fundamental problem, that is, learning to optimize image similarity with sparse and high-dimensional representations from large-scale training data, and propose a novel scheme of Sparse Online Learning of Image Similarity (SOLIS). In contrast to many existing image-similarity learning algorithms that are designed to work with low-dimensional data, SOLIS is able to learn image similarity from large-scale image data in sparse and high-dimensional spaces. Our encouraging results showed that the proposed new technique achieves highly competitive accuracy as compared to the state-of-the-art approaches but enjoys significant advantages in computational efficiency, model sparsity, and retrieval scalability, making it more practical for real-world multimedia retrieval applications.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2745351268",
    "type": "article"
  },
  {
    "title": "Tracking Illicit Drug Dealing and Abuse on Instagram Using Multimodal Analysis",
    "doi": "https://doi.org/10.1145/3011871",
    "publication_date": "2017-02-24",
    "publication_year": 2017,
    "authors": "Xitong Yang; Jiebo Luo",
    "corresponding_authors": "",
    "abstract": "Illicit drug trade via social media sites, especially photo-oriented Instagram, has become a severe problem in recent years. As a result, tracking drug dealing and abuse on Instagram is of interest to law enforcement agencies and public health agencies. However, traditional approaches are based on manual search and browsing by trained domain experts, which suffers from the problem of poor scalability and reproducibility. In this article, we propose a novel approach to detecting drug abuse and dealing automatically by utilizing multimodal data on social media. This approach also enables us to identify drug-related posts and analyze the behavior patterns of drug-related user accounts. To better utilize multimodal data on social media, multimodal analysis methods including multi-task learning and decision-level fusion are employed in our framework. We collect three datasets using Instagram and web search engine for training and testing our models. Experiment results on expertly labeled data have demonstrated the effectiveness of our approach, as well as its scalability and reproducibility over labor-intensive conventional approaches.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2369596206",
    "type": "article"
  },
  {
    "title": "Algorithms for Graph-Constrained Coalition Formation in the Real World",
    "doi": "https://doi.org/10.1145/3040967",
    "publication_date": "2017-02-24",
    "publication_year": 2017,
    "authors": "Filippo Bistaffa; Alessandro Farinelli; Jesús Cerquides; Juan A. Rodríguez-Aguilar; Sarvapali D. Ramchurn",
    "corresponding_authors": "",
    "abstract": "Coalition formation typically involves the coming together of multiple, heterogeneous, agents to achieve both their individual and collective goals. In this paper, we focus on a special case of coalition formation known as Graph-Constrained Coalition Formation (GCCF) whereby a network connecting the agents constrains the formation of coalitions. We focus on this type of problem given that in many real-world applications, agents may be connected by a communication network or only trust certain peers in their social network. We propose a novel representation of this problem based on the concept of edge contraction, which allows us to model the search space induced by the GCCF problem as a rooted tree. Then, we propose an anytime solution algorithm (CFSS), which is particularly efficient when applied to a general class of characteristic functions called $m+a$ functions. Moreover, we show how CFSS can be efficiently parallelised to solve GCCF using a non-redundant partition of the search space. We benchmark CFSS on both synthetic and realistic scenarios, using a real-world dataset consisting of the energy consumption of a large number of households in the UK. Our results show that, in the best case, the serial version of CFSS is 4 orders of magnitude faster than the state of the art, while the parallel version is 9.44 times faster than the serial version on a 12-core machine. Moreover, CFSS is the first approach to provide anytime approximate solutions with quality guarantees for very large systems of agents (i.e., with more than 2700 agents).",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2563748333",
    "type": "article"
  },
  {
    "title": "Bridging the Air Gap between Isolated Networks and Mobile Phones in a Practical Cyber-Attack",
    "doi": "https://doi.org/10.1145/2870641",
    "publication_date": "2017-05-06",
    "publication_year": 2017,
    "authors": "Mordechai Guri; Matan Monitz; Yuval Elovici",
    "corresponding_authors": "",
    "abstract": "Information is the most critical asset of modern organizations, and accordingly it is one of the resources most coveted by adversaries. When highly sensitive data is involved, an organization may resort to air gap isolation in which there is no networking connection between the inner network and the external world. While infiltrating an air-gapped network has been proven feasible in recent years, data exfiltration from an air-gapped network is still considered one of the most challenging phases of an advanced cyber-attack. In this article, we present “AirHopper,” a bifurcated malware that bridges the air gap between an isolated network and nearby infected mobile phones using FM signals. While it is known that software can intentionally create radio emissions from a video card, this is the first time that mobile phones serve as the intended receivers of the maliciously crafted electromagnetic signals. We examine the attack model and its limitations and discuss implementation considerations such as modulation methods, signal collision, and signal reconstruction. We test AirHopper in an existing workplace at a typical office building and demonstrate how valuable data such as keylogging and files can be exfiltrated from physically isolated computers to mobile phones at a distance of 1--7 meters, with an effective bandwidth of 13--60 bytes per second.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2613930629",
    "type": "article"
  },
  {
    "title": "Relevance Meets Coverage",
    "doi": "https://doi.org/10.1145/2700496",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Le Wu; Qi Liu; Enhong Chen; Nicholas Jing Yuan; Guangming Guo; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Collaborative filtering (CF) models offer users personalized recommendations by measuring the relevance between the active user and each individual candidate item. Following this idea, user-based collaborative filtering (UCF) usually selects the local popular items from the like-minded neighbor users. However, these traditional relevance-based models only consider the individuals (i.e., each neighbor user and candidate item) separately during neighbor set selection and recommendation set generation, thus usually incurring highly similar recommendations that lack diversity. While many researchers have recognized the importance of diversified recommendations, the proposed solutions either needed additional semantic information of items or decreased accuracy in this process. In this article, we describe how to generate both accurate and diversified recommendations from a new perspective. Along this line, we first introduce a simple measure of coverage that quantifies the usefulness of the whole set, that is, the neighbor userset and the recommended itemset as a complete entity. Then we propose a recommendation framework named REC that considers both traditional relevance-based scores and the new coverage measure based on UCF. Under REC, we further prove that the goals of maximizing relevance and coverage measures simultaneously in both the neighbor set selection step and the recommendation set generation step are NP-hard. Luckily, we can solve them effectively and efficiently by exploiting the inherent submodular property. Furthermore, we generalize the coverage notion and the REC framework from both a data perspective and an algorithm perspective. Finally, extensive experimental results on three real-world datasets show that the REC-based recommendation models can naturally generate more diversified recommendations without decreasing accuracy compared to some state-of-the-art models.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2267735350",
    "type": "article"
  },
  {
    "title": "A Data Mining Approach to Assess Privacy Risk in Human Mobility Data",
    "doi": "https://doi.org/10.1145/3106774",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Roberto Pellungrini; Luca Pappalardo; Francesca Pratesi; Anna Monreale",
    "corresponding_authors": "",
    "abstract": "Human mobility data are an important proxy to understand human mobility dynamics, develop analytical services, and design mathematical models for simulation and what-if analysis. Unfortunately mobility data are very sensitive since they may enable the re-identification of individuals in a database. Existing frameworks for privacy risk assessment provide data providers with tools to control and mitigate privacy risks, but they suffer two main shortcomings: (i) they have a high computational complexity; (ii) the privacy risk must be recomputed every time new data records become available and for every selection of individuals, geographic areas, or time windows. In this article, we propose a fast and flexible approach to estimate privacy risk in human mobility data. The idea is to train classifiers to capture the relation between individual mobility patterns and the level of privacy risk of individuals. We show the effectiveness of our approach by an extensive experiment on real-world GPS data in two urban areas and investigate the relations between human mobility patterns and the privacy risk of individuals.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2771725595",
    "type": "article"
  },
  {
    "title": "GeoBurst+",
    "doi": "https://doi.org/10.1145/3066166",
    "publication_date": "2018-01-18",
    "publication_year": 2018,
    "authors": "Chao Zhang; Dongming Lei; Quan Yuan; Honglei Zhuang; Lance Kaplan; Shaowen Wang; Jiawei Han",
    "corresponding_authors": "",
    "abstract": "The real-time discovery of local events (e.g., protests, disasters) has been widely recognized as a fundamental socioeconomic task. Recent studies have demonstrated that the geo-tagged tweet stream serves as an unprecedentedly valuable source for local event detection. Nevertheless, how to effectively extract local events from massive geo-tagged tweet streams in real time remains challenging. To bridge the gap, we propose a method for effective and real-time local event detection from geo-tagged tweet streams. Our method, named G eo B urst+ , first leverages a novel cross-modal authority measure to identify several pivots in the query window. Such pivots reveal different geo-topical activities and naturally attract similar tweets to form candidate events. G eo B urst+ further summarizes the continuous stream and compares the candidates against the historical summaries to pinpoint truly interesting local events. Better still, as the query window shifts, G eo B urst+ is capable of updating the event list with little time cost, thus achieving continuous monitoring of the stream. We used crowdsourcing to evaluate G eo B urst+ on two million-scale datasets and found it significantly more effective than existing methods while being orders of magnitude faster.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2793222259",
    "type": "article"
  },
  {
    "title": "An Analysis of Approaches Taken in the ACM RecSys Challenge 2018 for Automatic Music Playlist Continuation",
    "doi": "https://doi.org/10.1145/3344257",
    "publication_date": "2019-09-18",
    "publication_year": 2019,
    "authors": "Hamed Zamani; Markus Schedl; Paul Lamere; Ching-Wei Chen",
    "corresponding_authors": "",
    "abstract": "The ACM Recommender Systems Challenge 2018 focused on the task of automatic music playlist continuation, which is a form of the more general task of sequential recommendation. Given a playlist of arbitrary length with some additional meta-data, the task was to recommend up to 500 tracks that fit the target characteristics of the original playlist. For the RecSys Challenge, Spotify released a dataset of one million user-generated playlists. Participants could compete in two tracks, i.e., main and creative tracks. Participants in the main track were only allowed to use the provided training set, however, in the creative track, the use of external public sources was permitted. In total, 113 teams submitted 1,228 runs to the main track; 33 teams submitted 239 runs to the creative track. The highest performing team in the main track achieved an R-precision of 0.2241, an NDCG of 0.3946, and an average number of recommended songs clicks of 1.784. In the creative track, an R-precision of 0.2233, an NDCG of 0.3939, and a click rate of 1.785 was obtained by the best team. This article provides an overview of the challenge, including motivation, task definition, dataset description, and evaluation. We further report and analyze the results obtained by the top-performing teams in each track and explore the approaches taken by the winners. We finally summarize our key findings, discuss generalizability of approaches and results to domains other than music, and list the open avenues and possible future directions in the area of automatic playlist continuation.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2974397365",
    "type": "article"
  },
  {
    "title": "SMARTS",
    "doi": "https://doi.org/10.1145/2898363",
    "publication_date": "2016-12-06",
    "publication_year": 2016,
    "authors": "Kotagiri Ramamohanarao; Hairuo Xie; Lars Kulik; Shanika Karunasekera; Egemen Tanin; Rui Zhang; Eman Bin Khunayn",
    "corresponding_authors": "",
    "abstract": "Microscopic traffic simulators are important tools for studying transportation systems as they describe the evolution of traffic to the highest level of detail. A major challenge to microscopic simulators is the slow simulation speed due to the complexity of traffic models. We have developed the Scalable Microscopic Adaptive Road Traffic Simulator (SMARTS), a distributed microscopic traffic simulator that can utilize multiple independent processes in parallel. SMARTS can perform fast large-scale simulations. For example, when simulating 1 million vehicles in an area the size of Melbourne, the system runs 1.14 times faster than real time with 30 computing nodes and 0.2s simulation timestep. SMARTS supports various driver models and traffic rules, such as the car-following model and lane-changing model, which can be driver dependent. It can simulate multiple vehicle types, including bus and tram. The simulator is equipped with a wide range of features that help to customize, calibrate, and monitor simulations. Simulations are accurate and confirm with real traffic behaviours. For example, it achieves 79.1% accuracy in predicting traffic on a 10km freeway 90 minutes into the future. The simulator can be used for predictive traffic advisories as well as traffic management decisions as simulations complete well ahead of real time. SMARTS can be easily deployed to different operating systems as it is developed with the standard Java libraries.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2559878382",
    "type": "article"
  },
  {
    "title": "Lightweight Convolution Neural Networks for Mobile Edge Computing in Transportation Cyber Physical Systems",
    "doi": "https://doi.org/10.1145/3339308",
    "publication_date": "2019-10-24",
    "publication_year": 2019,
    "authors": "Junhao Zhou; Hong‐Ning Dai; Hao Wang",
    "corresponding_authors": "",
    "abstract": "Cloud computing extends Transportation Cyber-Physical Systems (T-CPS) with provision of enhanced computing and storage capability via offloading computing tasks to remote cloud servers. However, cloud computing cannot fulfill the requirements such as low latency and context awareness in T-CPS. The appearance of Mobile Edge Computing (MEC) can overcome the limitations of cloud computing via offloading the computing tasks at edge servers in approximation to users, consequently reducing the latency and improving the context awareness. Although MEC has the potential in improving T-CPS, it is incapable of processing computational-intensive tasks such as deep learning algorithms due to the intrinsic storage and computing-capability constraints. Therefore, we design and develop a lightweight deep learning model to support MEC applications in T-CPS. In particular, we put forth a stacked convolutional neural network (CNN) consisting of factorization convolutional layers alternating with compression layers (namely, lightweight CNN-FC). Extensive experimental results show that our proposed lightweight CNN-FC can greatly decrease the number of unnecessary parameters, thereby reducing the model size while maintaining the high accuracy in contrast to conventional CNN models. In addition, we also evaluate the performance of our proposed model via conducting experiments at a realistic MEC platform. Specifically, experimental results at this MEC platform show that our model can maintain the high accuracy while preserving the portable model size.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2981579652",
    "type": "article"
  },
  {
    "title": "Efficient and Privacy-preserving Fog-assisted Health Data Sharing Scheme",
    "doi": "https://doi.org/10.1145/3341104",
    "publication_date": "2019-10-24",
    "publication_year": 2019,
    "authors": "Wenjuan Tang; Ju Ren; Kuan Zhang; Deyu Zhang; Yaoxue Zhang; Xuemin Shen",
    "corresponding_authors": "",
    "abstract": "Pervasive data collected from e-healthcare devices possess significant medical value through data sharing with professional healthcare service providers. However, health data sharing poses several security issues, such as access control and privacy leakage, as well as faces critical challenges to obtain efficient data analysis and services. In this article, we propose an efficient and privacy-preserving fog-assisted health data sharing (PFHDS) scheme for e-healthcare systems. Specifically, we integrate the fog node to classify the shared data into different categories according to disease risks for efficient health data analysis. Meanwhile, we design an enhanced attribute-based encryption method through combination of a personal access policy on patients and a professional access policy on the fog node for effective medical service provision. Furthermore, we achieve significant encryption consumption reduction for patients by offloading a portion of the computation and storage burden from patients to the fog node. Security discussions show that PFHDS realizes data confidentiality and fine-grained access control with collusion resistance. Performance evaluations demonstrate cost-efficient encryption computation, storage and energy consumption.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2981449178",
    "type": "article"
  },
  {
    "title": "Personalized Reason Generation for Explainable Song Recommendation",
    "doi": "https://doi.org/10.1145/3337967",
    "publication_date": "2019-07-10",
    "publication_year": 2019,
    "authors": "Guoshuai Zhao; Hao Fu; Ruihua Song; Tetsuya Sakai; Zhongxia Chen; Xing Xie; Xueming Qian",
    "corresponding_authors": "",
    "abstract": "Personalized recommendation has received a lot of attention as a highly practical research topic. However, existing recommender systems provide the recommendations with a generic statement such as “Customers who bought this item also bought…”. Explainable recommendation, which makes a user aware of why such items are recommended, is in demand. The goal of our research is to make the users feel as if they are receiving recommendations from their friends. To this end, we formulate a new challenging problem called personalized reason generation for explainable recommendation for songs in conversation applications and propose a solution that generates a natural language explanation of the reason for recommending a song to that particular user. For example, if the user is a student, our method can generate an output such as “Campus radio plays this song at noon every day, and I think it sounds wonderful,” which the student may find easy to relate to. In the offline experiments, through manual assessments, the gain of our method is statistically significant on the relevance to songs and personalization to users comparing with baselines. Large-scale online experiments show that our method outperforms manually selected reasons by 8.2% in terms of click-through rate. Evaluation results indicate that our generated reasons are relevant to songs and personalized to users, and they attract users to click the recommendations.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2998405411",
    "type": "article"
  },
  {
    "title": "StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing",
    "doi": "https://doi.org/10.1145/3467956",
    "publication_date": "2021-08-01",
    "publication_year": 2021,
    "authors": "Anbu Huang; Yang Liu; Tianjian Chen; Yongkai Zhou; Quan Sun; Hongfeng Chai; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "From facial recognition to autonomous driving, Artificial Intelligence (AI) will transform the way we live and work over the next couple of decades. Existing AI approaches for urban computing suffer from various challenges, including dealing with synchronization and processing of vast amount of data generated from the edge devices, as well as the privacy and security of individual users, including their bio-metrics, locations, and itineraries. Traditional centralized-based approaches require data in each organization be uploaded to the central database, which may be prohibited by data protection acts, such as GDPR and CCPA. To decouple model training from the need to store the data in the cloud, a new training paradigm called Federated Learning (FL) is proposed. FL enables multiple devices to collaboratively learn a shared model while keeping the training data on devices locally, which can significantly mitigate privacy leakage risk. However, under urban computing scenarios, data are often communication-heavy, high-frequent, and asynchronized, posing new challenges to FL implementation. To handle these challenges, we propose a new hybrid federated learning architecture called StarFL. By combining with Trusted Execution Environment (TEE), Secure Multi-Party Computation (MPC), and (Beidou) satellites, StarFL enables safe key distribution, encryption, and decryption, and provides a verification mechanism for each participant to ensure the security of the local data. In addition, StarFL can provide accurate timestamp matching to facilitate synchronization of multiple clients. All these improvements make StarFL more applicable to the security-sensitive scenarios for the next generation of urban computing.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W3188785851",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey of Grammatical Error Correction",
    "doi": "https://doi.org/10.1145/3474840",
    "publication_date": "2021-10-31",
    "publication_year": 2021,
    "authors": "Yu Wang; Yuelin Wang; Kai Dang; Jie Liu; Zhuo Liu",
    "corresponding_authors": "",
    "abstract": "Grammatical error correction (GEC) is an important application aspect of natural language processing techniques, and GEC system is a kind of very important intelligent system that has long been explored both in academic and industrial communities. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning. However, there is not a survey that untangles the large amount of research works and progress in this field. We present the first survey in GEC for a comprehensive retrospective of the literature in this area. We first give the definition of GEC task and introduce the public datasets and data annotation schema. After that, we discuss six kinds of basic approaches, six commonly applied performance boosting techniques for GEC systems, and three data augmentation methods. Since GEC is typically viewed as a sister task of Machine Translation (MT), we put more emphasis on the statistical machine translation (SMT)-based approaches and neural machine translation (NMT)-based approaches for the sake of their importance. Similarly, some performance-boosting techniques are adapted from MT and are successfully combined with GEC systems for enhancement on the final performance. More importantly, after the introduction of the evaluation in GEC, we make an in-depth analysis based on empirical results in aspects of GEC approaches and GEC systems for a clearer pattern of progress in GEC, where error type analysis and system recapitulation are clearly presented. Finally, we discuss five prospective directions for future GEC researches.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W4200585851",
    "type": "article"
  },
  {
    "title": "MVGAN: Multi-View Graph Attention Network for Social Event Detection",
    "doi": "https://doi.org/10.1145/3447270",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Wanqiu Cui; Junping Du; Dawei Wang; Feifei Kou; Zhe Xue",
    "corresponding_authors": "",
    "abstract": "Social networks are critical sources for event detection thanks to the characteristics of publicity and dissemination. Unfortunately, the randomness and semantic sparsity of the social network text bring significant challenges to the event detection task. In addition to text, time is another vital element in reflecting events since events are often followed for a while. Therefore, in this article, we propose a novel method named Multi-View Graph Attention Network (MVGAN) for event detection in social networks. It enriches event semantics through both neighbor aggregation and multi-view fusion in a heterogeneous social event graph. Specifically, we first construct a heterogeneous graph by adding the hashtag to associate the isolated short texts and describe events comprehensively. Then, we learn view-specific representations of events through graph convolutional networks from the perspectives of text semantics and time distribution, respectively. Finally, we design a hashtag-based multi-view graph attention mechanism to capture the intrinsic interaction across different views and integrate the feature representations to discover events. Extensive experiments on public benchmark datasets demonstrate that MVGAN performs favorably against many state-of-the-art social network event detection algorithms. It also proves that more meaningful signals can contribute to improving the event detection effect in social networks, such as published time and hashtags.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W3183448130",
    "type": "article"
  },
  {
    "title": "Predicting Attributes of Nodes Using Network Structure",
    "doi": "https://doi.org/10.1145/3442390",
    "publication_date": "2021-02-04",
    "publication_year": 2021,
    "authors": "Sarwan Ali; Muhammad Haroon Shakeel; Imdadullah Khan; Safiullah Faizullah; Muhammad Asad Khan",
    "corresponding_authors": "",
    "abstract": "In many graphs such as social networks, nodes have associated attributes representing their behavior. Predicting node attributes in such graphs is an important task with applications in many domains like recommendation systems, privacy preservation, and targeted advertisement. Attribute values can be predicted by treating each node as a data point described by attributes and employing classification/regression algorithms. However, in social networks, there is complex interdependence between node attributes and pairwise interaction. For instance, attributes of nodes are influenced by their neighbors (social influence), and neighborhoods (friendships) between nodes are established based on pairwise (dis)similarity between their attributes (social selection). In this article, we establish that information in network topology is extremely useful in determining node attributes. In particular, we use self- and cross-proclivity measures (quantitative measures of how much a node attribute depends on the same and other attributes of its neighbors) to predict node attributes. We propose a feature map to represent a node with respect to a specific attribute a , using all attributes of its h -hop neighbors. Different classifiers are then learned on these feature vectors to predict the value of attribute a . We perform extensive experimentation on 10 real-world datasets and show that the proposed method significantly outperforms known approaches in terms of prediction accuracy.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W3126641925",
    "type": "article"
  },
  {
    "title": "<i>CoPhy</i> -PGNN: Learning Physics-guided Neural Networks with Competing Loss Functions for Solving Eigenvalue Problems",
    "doi": "https://doi.org/10.1145/3530911",
    "publication_date": "2022-04-29",
    "publication_year": 2022,
    "authors": "Mohannad Elhamod; Jie Bu; Christopher N. Singh; Matthew Redell; Abantika Ghosh; Viktor A. Podolskiy; Wei‐Cheng Lee; Anuj Karpatne",
    "corresponding_authors": "",
    "abstract": "Physics-guided Neural Networks (PGNNs) represent an emerging class of neural networks that are trained using physics-guided (PG) loss functions (capturing violations in network outputs with known physics), along with the supervision contained in data. Existing work in PGNNs has demonstrated the efficacy of adding single PG loss functions in the neural network objectives, using constant tradeoff parameters, to ensure better generalizability. However, in the presence of multiple PG functions with competing gradient directions, there is a need to adaptively tune the contribution of different PG loss functions during the course of training to arrive at generalizable solutions. We demonstrate the presence of competing PG losses in the generic neural network problem of solving for the lowest (or highest) eigenvector of a physics-based eigenvalue equation, which is commonly encountered in many scientific problems. We present a novel approach to handle competing PG losses and demonstrate its efficacy in learning generalizable solutions in two motivating applications of quantum mechanics and electromagnetic propagation. All the code and data used in this work are available at https://github.com/jayroxis/Cophy-PGNN.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W3094381768",
    "type": "article"
  },
  {
    "title": "Federated Multi-view Learning for Private Medical Data Integration and Analysis",
    "doi": "https://doi.org/10.1145/3501816",
    "publication_date": "2022-05-18",
    "publication_year": 2022,
    "authors": "Sicong Che; Zhaoming Kong; Hao Peng; Lichao Sun; Alex Leow; Yong Chen; Lifang He",
    "corresponding_authors": "",
    "abstract": "Along with the rapid expansion of information technology and digitalization of health data, there is an increasing concern on maintaining data privacy while garnering the benefits in the medical field. Two critical challenges are identified: First, medical data is naturally distributed across multiple local sites, making it difficult to collectively train machine learning models without data leakage. Second, in medical applications, data are often collected from different sources and views, resulting in heterogeneity and complexity that requires reconciliation. In this article, we present a generic Federated Multi-view Learning (FedMV) framework for multi-view data leakage prevention. Specifically, we apply this framework to two types of problems based on local data availability: Vertical Federated Multi-view Learning (V-FedMV) and Horizontal Federated Multi-view Learning (H-FedMV). We experimented with real-world keyboard data collected from BiAffect study. Our results demonstrated that the proposed approach can make full use of multi-view data in a privacy-preserving way, and both V-FedMV and H-FedMV perform better than their single-view and pairwise counterparts. Besides, the framework can be easily adapted to deal with multi-view sequential data. We have developed a sequential model (S-FedMV) that takes sequence of multi-view data as input and demonstrated it experimentally. To the best of our knowledge, this framework is the first to consider both vertical and horizontal diversification in the multi-view setting, as well as their sequential federated learning.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3158968177",
    "type": "article"
  },
  {
    "title": "Deep Reinforcement Learning-based Trajectory Pricing on Ride-hailing Platforms",
    "doi": "https://doi.org/10.1145/3474841",
    "publication_date": "2022-03-03",
    "publication_year": 2022,
    "authors": "Jianbin Huang; Longji Huang; Meijuan Liu; He Li; Qinglin Tan; Xiaoke Ma; Jiangtao Cui; De-Shuang Huang",
    "corresponding_authors": "",
    "abstract": "Dynamic pricing plays an important role in solving the problems such as traffic load reduction, congestion control, and revenue improvement. Efficient dynamic pricing strategies can increase capacity utilization, total revenue of service providers, and the satisfaction of both passengers and drivers. Many proposed dynamic pricing technologies focus on short-term optimization and face poor scalability in modeling long-term goals for the limitations of solution optimality and prohibitive computation. In this article, a deep reinforcement learning framework is proposed to tackle the dynamic pricing problem for ride-hailing platforms. A soft actor-critic (SAC) algorithm is adopted in the reinforcement learning framework. First, the dynamic pricing problem is translated into a Markov Decision Process (MDP) and is set up in continuous action spaces, which is no need for the discretization of action space. Then, a new reward function is obtained by the order response rate and the KL-divergence between supply distribution and demand distribution. Experiments and case studies demonstrate that the proposed method outperforms the baselines in terms of order response rate and total revenue.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4214886000",
    "type": "article"
  },
  {
    "title": "Domain Generalization for Activity Recognition via Adaptive Feature Fusion",
    "doi": "https://doi.org/10.1145/3552434",
    "publication_date": "2022-08-02",
    "publication_year": 2022,
    "authors": "Xin Qin; Jindong Wang; Yiqiang Chen; Lu Wang; Xinlong Jiang",
    "corresponding_authors": "",
    "abstract": "Human activity recognition requires the efforts to build a generalizable model using the training datasets with the hope to achieve good performance in test datasets. However, in real applications, the training and testing datasets may have totally different distributions due to various reasons such as different body shapes, acting styles, and habits, damaging the model’s generalization performance. While such a distribution gap can be reduced by existing domain adaptation approaches, they typically assume that the test data can be accessed in the training stage, which is not realistic. In this article, we consider a more practical and challenging scenario: domain-generalized activity recognition (DGAR) where the test dataset cannot be accessed during training. To this end, we propose Adaptive Feature Fusion for Activity Recognition (AFFAR) , a domain generalization approach that learns to fuse the domain-invariant and domain-specific representations to improve the model’s generalization performance. AFFAR takes the best of both worlds where domain-invariant representations enhance the transferability across domains and domain-specific representations leverage the model discrimination power from each domain. Extensive experiments on three public HAR datasets show its effectiveness. Furthermore, we apply AFFAR to a real application, i.e., the diagnosis of Children’s Attention Deficit Hyperactivity Disorder (ADHD), which also demonstrates the superiority of our approach.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4289517877",
    "type": "article"
  },
  {
    "title": "Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges",
    "doi": "https://doi.org/10.1145/3570906",
    "publication_date": "2022-11-08",
    "publication_year": 2022,
    "authors": "Jing Ren; Feng Xia; Ivan Lee; Azadeh Noori Hoshyar; Charų C. Aggarwal",
    "corresponding_authors": "",
    "abstract": "Anomaly analytics is a popular and vital task in various research contexts that has been studied for several decades. At the same time, deep learning has shown its capacity in solving many graph-based tasks, like node classification, link prediction, and graph classification. Recently, many studies are extending graph learning models for solving anomaly analytics problems, resulting in beneficial advances in graph-based anomaly analytics techniques. In this survey, we provide a comprehensive overview of graph learning methods for anomaly analytics tasks. We classify them into four categories based on their model architectures, namely graph convolutional network, graph attention network, graph autoencoder, and other graph learning models. The differences between these methods are also compared in a systematic manner. Furthermore, we outline several graph-based anomaly analytics applications across various domains in the real world. Finally, we discuss five potential future research directions in this rapidly growing field.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W4308588518",
    "type": "article"
  },
  {
    "title": "FedCTR: Federated Native Ad CTR Prediction with Cross-platform User Behavior Data",
    "doi": "https://doi.org/10.1145/3506715",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Chuhan Wu; Fangzhao Wu; Lingjuan Lyu; Yongfeng Huang; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Native ad is a popular type of online advertisement that has similar forms with the native content displayed on websites. Native ad click-through rate (CTR) prediction is useful for improving user experience and platform revenue. However, it is challenging due to the lack of explicit user intent, and user behaviors on the platform with native ads may be insufficient to infer users’ interest in ads. Fortunately, user behaviors exist on many online platforms that can provide complementary information for user-interest mining. Thus, leveraging multi-platform user behaviors is useful for native ad CTR prediction. However, user behaviors are highly privacy-sensitive, and the behavior data on different platforms cannot be directly aggregated due to user privacy concerns and data protection regulations. Existing CTR prediction methods usually require centralized storage of user behavior data for user modeling, which cannot be directly applied to the CTR prediction task with multi-platform user behaviors. In this article, we propose a federated native ad CTR prediction method named FedCTR, which can learn user-interest representations from cross-platform user behaviors in a privacy-preserving way. On each platform a local user model learns user embeddings from the local user behaviors on that platform. The local user embeddings from different platforms are uploaded to a server for aggregation, and the aggregated ones are sent to the ad platform for CTR prediction. Besides, we apply local differential privacy and differential privacy to the local and aggregated user embeddings, respectively, for better privacy protection. Moreover, we propose a federated framework for collaborative model training with distributed models and user behaviors. Extensive experiments on real-world dataset show that FedCTR can effectively leverage multi-platform user behaviors for native ad CTR prediction in a privacy-preserving manner.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4214771572",
    "type": "article"
  },
  {
    "title": "Semi-Synchronous Federated Learning for Energy-Efficient Training and Accelerated Convergence in Cross-Silo Settings",
    "doi": "https://doi.org/10.1145/3524885",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Dimitris Stripelis; Paul M. Thompson; José Luis Ambite",
    "corresponding_authors": "",
    "abstract": "There are situations where data relevant to machine learning problems are distributed across multiple locations that cannot share the data due to regulatory, competitiveness, or privacy reasons. Machine learning approaches that require data to be copied to a single location are hampered by the challenges of data sharing. Federated Learning (FL) is a promising approach to learn a joint model over all the available data across silos. In many cases, the sites participating in a federation have different data distributions and computational capabilities. In these heterogeneous environments existing approaches exhibit poor performance: synchronous FL protocols are communication efficient, but have slow learning convergence and high energy cost; conversely, asynchronous FL protocols have faster convergence with lower energy cost, but higher communication. In this work, we introduce a novel energy-efficient Semi-Synchronous Federated Learning protocol that mixes local models periodically with minimal idle time and fast convergence. We show through extensive experiments over established benchmark datasets in the computer-vision domain as well as in real-world biomedical settings that our approach significantly outperforms previous work in data and computationally heterogeneous environments .",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4224289290",
    "type": "article"
  },
  {
    "title": "ReuseKNN: Neighborhood Reuse for Differentially Private KNN-Based Recommendations",
    "doi": "https://doi.org/10.1145/3608481",
    "publication_date": "2023-07-13",
    "publication_year": 2023,
    "authors": "Peter Müllner; Elisabeth Lex; Markus Schedl; Dominik Kowald",
    "corresponding_authors": "",
    "abstract": "User-based KNN recommender systems ( UserKNN ) utilize the rating data of a target user’s k nearest neighbors in the recommendation process. This, however, increases the privacy risk of the neighbors, since the recommendations could expose the neighbors’ rating data to other users or malicious parties. To reduce this risk, existing work applies differential privacy by adding randomness to the neighbors’ ratings, which unfortunately reduces the accuracy of UserKNN . In this work, we introduce ReuseKNN , a novel differentially private KNN-based recommender system. The main idea is to identify small but highly reusable neighborhoods so that (i) only a minimal set of users requires protection with differential privacy and (ii) most users do not need to be protected with differential privacy since they are only rarely exploited as neighbors. In our experiments on five diverse datasets, we make two key observations. Firstly, ReuseKNN requires significantly smaller neighborhoods and, thus, fewer neighbors need to be protected with differential privacy compared with traditional UserKNN . Secondly, despite the small neighborhoods, ReuseKNN outperforms UserKNN and a fully differentially private approach in terms of accuracy. Overall, ReuseKNN leads to significantly less privacy risk for users than in the case of UserKNN .",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4384201236",
    "type": "article"
  },
  {
    "title": "Explicit Knowledge Graph Reasoning for Conversational Recommendation",
    "doi": "https://doi.org/10.1145/3637216",
    "publication_date": "2023-12-11",
    "publication_year": 2023,
    "authors": "Xuhui Ren; Tong Chen; Quoc Viet Hung Nguyen; Lizhen Cui; Zi Huang; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Traditional recommender systems estimate user preference on items purely based on historical interaction records, thus failing to capture fine-grained yet dynamic user interests and letting users receive recommendation only passively. Recent conversational recommender systems (CRSs) tackle those limitations by enabling recommender systems to interact with the user to obtain her/his current preference through a sequence of clarifying questions. Recently, there has been a rise of using knowledge graphs (KGs) for CRSs, where the core motivation is to incorporate the abundant side information carried by a KG into both the recommendation and conversation processes. However, existing KG-based CRSs are subject to two defects: (1) there is a semantic gap between the learned representations of utterances and KG entities, hindering the retrieval of relevant KG information; (2) the reasoning over KG is mostly performed with the implicitly learned user interests, overlooking the explicit signals from the entities actually mentioned in the conversation. To address these drawbacks, we propose a new CRS framework, namely, the Knowledge Enhanced Conversational Reasoning (KECR) model. As a user can reflect her/his preferences via both attribute- and item-level expressions, KECR jointly embeds the structured knowledge from two levels in the KG. A mutual information maximization constraint is further proposed for semantic alignment between the embedding spaces of utterances and KG entities. Meanwhile, KECR utilizes the connectivity within the KG to conduct explicit reasoning of the user demand, making the model less dependent on the user’s feedback to clarifying questions. As such, the semantic alignment and explicit KG reasoning can jointly facilitate accurate recommendation and quality dialogue generation. By comparing with strong baselines on two real-world datasets, we demonstrate that KECR obtains state-of-the-art recommendation effectiveness, as well as competitive dialogue generation performance.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4389561397",
    "type": "article"
  },
  {
    "title": "Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation",
    "doi": "https://doi.org/10.1145/3639369",
    "publication_date": "2023-12-29",
    "publication_year": 2023,
    "authors": "Zhiyuan Wu; Sheng Sun; Yuwei Wang; Min Liu; Quyang Pan; Junbo Zhang; Zeju Li; Qingxiang Liu",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) is a privacy-preserving machine learning paradigm in which the server periodically aggregates local model parameters from cli ents without assembling their private data. Constrained communication and personalization requirements pose severe challenges to FL. Federated distillation (FD) is proposed to simultaneously address the above two problems, which exchanges knowledge between the server and clients, supporting heterogeneous local models while significantly reducing communication overhead. However, most existing FD methods require a proxy dataset, which is often unavailable in reality. A few recent proxy-data-free FD approaches can eliminate the need for additional public data, but suffer from remarkable discrepancy among local knowledge due to client-side model heterogeneity, leading to ambiguous representation on the server and inevitable accuracy degradation. To tackle this issue, we propose a proxy-data-free FD algorithm based on distributed knowledge congruence (FedDKC). FedDKC leverages well-designed refinement strategies to narrow local knowledge differences into an acceptable upper bound, so as to mitigate the negative effects of knowledge incongruence. Specifically, from perspectives of peak probability and Shannon entropy of local knowledge, we design kernel-based knowledge refinement (KKR) and searching-based knowledge refinement (SKR) respectively, and theoretically guarantee that the refined-local knowledge can satisfy an approximately-similar distribution and be regarded as congruent. Extensive experiments conducted on three common datasets demonstrate that our proposed FedDKC significantly outperforms the state-of-the-art on various heterogeneous settings while evidently improving the convergence speed.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4390399890",
    "type": "article"
  },
  {
    "title": "Deep Learning Inferencing with High-performance Hardware Accelerators",
    "doi": "https://doi.org/10.1145/3594221",
    "publication_date": "2023-05-02",
    "publication_year": 2023,
    "authors": "Luke Kljucaric; Alan D. George",
    "corresponding_authors": "",
    "abstract": "As computer architectures continue to integrate application-specific hardware, it is critical to understand the relative performance of devices for maximum app acceleration. The goal of benchmarking suites, such as MLPerf for analyzing machine learning (ML) hardware performance, is to standardize a fair comparison of different hardware architectures. However, there are many apps that are not well represented by these standards that require different workloads, such as ML models and datasets, to achieve similar goals. Additionally, many apps, like real-time video processing, are focused on latency of computations rather than strictly on throughput. This research analyzes multiple compute architectures that feature ML-specific hardware on a case study of handwritten Chinese character recognition. Specifically, AlexNet and a custom version of GoogLeNet are benchmarked in terms of their streaming latency and maximum throughput for optical character recognition. Considering that these models are composed of fundamental neural network operations yet architecturally different from each other, these models can stress devices in different yet insightful ways that generalizations of the performance of other models can be drawn from. Many devices featuring ML-specific hardware and optimizations are analyzed including Intel and AMD CPUs, Xilinx and Intel FPGAs, NVIDIA GPUs, and Google TPUs. Overall, ML-oriented hardware added to the Intel Xeon CPUs helps to boost throughput by 3.7× and to reduce latency by up to 34.7×, which makes the latency of Intel Xeon CPUs competitive on more parallel models. The TPU devices were limited in terms of throughput due to large data transfer times and not competitive in terms of latency. The FPGA frameworks showcase the lowest latency on the Xilinx Alveo U200 FPGA achieving 0.48 ms on AlexNet using Mipsology Zebra and 0.39 ms on GoogLeNet using Vitis-AI. Through their custom acceleration datapaths coupled with high-performance SRAM, the FPGAs are able to keep critical model data closer to processing elements for lower latency. The massively parallel and high-memory GPU devices with Tensor Core accelerators achieve the best throughput. The NVIDIA Tesla A100 GPU showcases the highest throughput at 42,513 and 52,484 images/second for AlexNet and GoogLeNet, respectively. 1",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4367680684",
    "type": "article"
  },
  {
    "title": "Dual Graph Convolution Architecture Search for Travel Time Estimation",
    "doi": "https://doi.org/10.1145/3591361",
    "publication_date": "2023-04-26",
    "publication_year": 2023,
    "authors": "Guangyin Jin; Huan Yan; Fuxian Li; Yong Li; Jincai Huang",
    "corresponding_authors": "",
    "abstract": "Travel time estimation (TTE) is a crucial task in intelligent transportation systems, which has been widely used in navigation and route planning. In recent years, several deep learning frameworks have been proposed to capture the dynamic features of road segments or intersections for travel time estimation. However, most existing works do not consider the joint features of the intersections and road segments. Moreover, most deep neural networks for TTE are designed based on empirical knowledge. Since the independent and joint features of intersections and road segments commonly vary with different datasets, the empirical deterministic neural architectures have limited adaptability to different scenarios. To tackle the above problems, we propose a novel automated deep learning framework, namely Automated Spatio-Temporal Dual Graph Convolutional Networks (Auto-STDGCN), for travel time estimation. Specifically, we propose to construct the node-wise graph and edge-wise graph to characterize the spatio-temporal features of intersections and road segments, respectively. In order to capture the joint spatio-temporal correlations of the dual graphs, a hierarchical neural architecture search approach is introduced, whose search space is composed of internal and external search space. In the internal search space, spatial graph convolution and temporal convolution operations are adopted to capture the respective spatio-temporal correlations of the dual graphs. Further, we design the external search space including the node-wise and edge-wise graph convolution operations from the internal architecture search to capture the interaction patterns between the intersections and road segments. We evaluate our proposed model Auto-STDGCN on three real-world datasets, which demonstrates that our model is significantly superior to the state-of-the-art methods. In addition, we also conduct case studies to visualize and explain the neural architectures learned by our model.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4367051006",
    "type": "article"
  },
  {
    "title": "GNNUERS: Fairness Explanation in GNNs for Recommendation via Counterfactual Reasoning",
    "doi": "https://doi.org/10.1145/3655631",
    "publication_date": "2024-04-03",
    "publication_year": 2024,
    "authors": "Giacomo Medda; Francesco� Fabbri; Mirko Marras; Ludovico Boratto; Gianni Fenu",
    "corresponding_authors": "",
    "abstract": "Nowadays, research into personalization has been focusing on explainability and fairness. Several approaches proposed in recent works are able to explain individual recommendations in a post-hoc manner or by explanation paths. However, explainability techniques applied to unfairness in recommendation have been limited to finding user/item features mostly related to biased recommendations. In this paper, we devised a novel algorithm that leverages counterfactuality methods to discover user unfairness explanations in the form of user-item interactions. In our counterfactual framework, interactions are represented as edges in a bipartite graph, with users and items as nodes. Our bipartite graph explainer perturbs the topological structure to find an altered version that minimizes the disparity in utility between the protected and unprotected demographic groups. Experiments on four real-world graphs coming from various domains showed that our method can systematically explain user unfairness on three state-of-the-art GNN-based recommendation models. Moreover, an empirical evaluation of the perturbed network uncovered relevant patterns that justify the nature of the unfairness discovered by the generated explanations. The source code and the preprocessed data sets are available at https://github.com/jackmedda/RS-BGExplainer.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4393855546",
    "type": "article"
  },
  {
    "title": "Decentralized Federated Recommendation with Privacy-aware Structured Client-level Graph",
    "doi": "https://doi.org/10.1145/3641287",
    "publication_date": "2024-01-22",
    "publication_year": 2024,
    "authors": "Zhitao Li; Zhaohao Lin; Feng Liang; Weike Pan; Qiang Yang; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Recommendation models are deployed in a variety of commercial applications to provide personalized services for users. However, most of them rely on the users’ original rating records that are often collected by a centralized server for model training, which may cause privacy issues. Recently, some centralized federated recommendation models are proposed for the protection of users’ privacy, which however requires a server for coordination in the whole process of model training. As a response, we propose a novel privacy-aware decentralized federated recommendation (DFedRec) model, which is lossless compared with the traditional model in recommendation performance and is thus more accurate than other models in this line. Specifically, we design a privacy-aware structured client-level graph for the sharing of the model parameters in the process of model training, which is a one-stone-two-bird strategy, i.e., it protects users’ privacy via some randomly sampled fake entries and reduces the communication cost by sharing the model parameters only with the related neighboring users. With the help of the privacy-aware structured client-level graph, we propose two novel collaborative training mechanisms in the setting without a server, including a batch algorithm DFedRec(b) and a stochastic one DFedRec(s), where the former requires the anonymity mechanism while the latter does not. They are both equivalent to probabilistic matrix factorization trained in a centralized server and are thus lossless. We then provide formal analysis of privacy guarantee of our methods and conduct extensive empirical studies on three public datasets with explicit feedback, which show the effectiveness of our DFedRec, i.e., it is privacy aware, communication efficient, and lossless.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4391103862",
    "type": "article"
  },
  {
    "title": "Ensuring Fairness and Gradient Privacy in Personalized Heterogeneous Federated Learning",
    "doi": "https://doi.org/10.1145/3652613",
    "publication_date": "2024-03-13",
    "publication_year": 2024,
    "authors": "Cody Lewis; Vijay Varadharajan; Nasimul Noman; Udaya Tupakula",
    "corresponding_authors": "",
    "abstract": "With the increasing tension between conflicting requirements of the availability of large amounts of data for effective machine learning-based analysis, and for ensuring their privacy, the paradigm of federated learning has emerged, a distributed machine learning setting where the clients provide only the machine learning model updates to the server rather than the actual data for decision making. However, the distributed nature of federated learning raises specific challenges related to fairness in a heterogeneous setting. This motivates the focus of our article, on the heterogeneity of client devices having different computational capabilities and their impact on fairness in federated learning. Furthermore, our aim is to achieve fairness in heterogeneity while ensuring privacy. As far as we are aware there are no existing works that address all three aspects of fairness, device heterogeneity, and privacy simultaneously in federated learning. In this article, we propose a novel federated learning algorithm with personalization in the context of heterogeneous devices while maintaining compatibility with the gradient privacy preservation techniques of secure aggregation. We analyze the proposed federated learning algorithm under different environments with different datasets and show that it achieves performance close to or greater than the state-of-the-art in heterogeneous device personalized federated learning. We also provide theoretical proofs for the fairness and convergence properties of our proposed algorithm.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4392749960",
    "type": "article"
  },
  {
    "title": "Addressing Data Challenges to Drive the Transformation of Smart Cities",
    "doi": "https://doi.org/10.1145/3663482",
    "publication_date": "2024-05-03",
    "publication_year": 2024,
    "authors": "Ekaterina Gilman; Francesca Bugiotti; Ahmed Khalid; Hassan Mehmood; Panos Kostakos; Lauri Tuovinen; Johanna Ylipulli; Xiang Su; Denzil Ferreira",
    "corresponding_authors": "",
    "abstract": "Cities serve as vital hubs of economic activity and knowledge generation and dissemination. As such, cities bear a significant responsibility to uphold environmental protection measures while promoting the welfare and living comfort of their residents. There are diverse views on the development of smart cities, from integrating Information and Communication Technologies into urban environments for better operational decisions to supporting sustainability, wealth, and comfort of people. However, for all these cases, data are the key ingredient and enabler for the vision and realization of smart cities. This article explores the challenges associated with smart city data. We start with gaining an understanding of the concept of a smart city, how to measure that the city is a smart one, and what architectures and platforms exist to develop one. Afterwards, we research the challenges associated with the data of the cities, including availability, heterogeneity, management, analysis, privacy, and security. Finally, we discuss ethical issues. This article aims to serve as a “one-stop shop” covering data-related issues of smart cities with references for diving deeper into particular topics of interest.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4396608392",
    "type": "article"
  },
  {
    "title": "PerFedRec++: Enhancing Personalized Federated Recommendation with Self-Supervised Pre-Training",
    "doi": "https://doi.org/10.1145/3664927",
    "publication_date": "2024-05-14",
    "publication_year": 2024,
    "authors": "Sichun Luo; Yuanzhang Xiao; X Zhang; Yang Liu; Wenbo Ding; Linqi Song",
    "corresponding_authors": "",
    "abstract": "Federated recommendation systems employ federated learning techniques to safeguard user privacy by transmitting model parameters instead of raw user data between user devices and the central server. Nevertheless, the current federated recommender system faces three significant challenges: (1) data heterogeneity: the heterogeneity of users’ attributes and local data necessitates the acquisition of personalized models to improve the performance of federated recommendation; (2) model performance degradation: the privacy-preserving protocol design in the federated recommendation, such as pseudo item labeling and differential privacy, would deteriorate the model performance; (3) communication bottleneck: the standard federated recommendation algorithm can have a high communication overhead. Previous studies have attempted to address these issues, but none have been able to solve them simultaneously. In this article, we propose a novel framework, named PerFedRec++ , to enhance the personalized federated recommendation with self-supervised pre-training. Specifically, we utilize the privacy-preserving mechanism of federated recommender systems to generate two augmented graph views, which are used as contrastive tasks in self-supervised graph learning to pre-train the model. Pre-training enhances the performance of federated models by improving the uniformity of representation learning. Also, by providing a better initial state for federated training, pre-training makes the overall training converge faster, thus alleviating the heavy communication burden. We then construct a collaborative graph to learn the client representation through a federated graph neural network. Based on these learned representations, we cluster users into different user groups and learn personalized models for each cluster. Each user learns a personalized model by combining the global federated model, the cluster-level federated model, and its own fine-tuned local model. Experiments on three real-world datasets show that our proposed method achieves superior performance over existing methods.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4396894903",
    "type": "article"
  },
  {
    "title": "Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data",
    "doi": "https://doi.org/10.1145/3696461",
    "publication_date": "2024-09-20",
    "publication_year": 2024,
    "authors": "Aritra Hota; Soumyajit Chatterjee; Sandip Chakraborty",
    "corresponding_authors": "",
    "abstract": "Traditional human-in-the-loop-based annotation for time-series data like inertial data often requires access to alternate modalities like video or audio from the environment. These alternate sources provide the necessary information to the human annotator, as the raw numeric data is often too obfuscated even for an expert. However, this traditional approach has many concerns surrounding overall cost, efficiency, storage of additional modalities, time, scalability, and privacy. Interestingly, recent large language models (LLMs) are also trained with vast amounts of publicly available alphanumeric data, which allows them to comprehend and perform well on tasks beyond natural language processing. Naturally, this opens up a potential avenue to explore the opportunities in using these LLMs as virtual annotators where the LLMs will be directly provided the raw sensor data for annotation instead of relying on any alternate modality. Naturally, this could mitigate the problems of the traditional human-in-the-loop approach. Motivated by this observation, we perform a detailed study in this paper to assess whether the state-of-the-art (SOTA) LLMs can be used as virtual annotators for labeling time-series physical sensing data. To perform this in a principled manner, we segregate the study into two major phases. In the first phase, we investigate the challenges an LLM like GPT-4 faces in comprehending raw sensor data. Considering the observations from phase 1, in the next phase, we investigate the possibility of encoding the raw sensor data using SOTA SSL approaches and utilizing the projected time-series data to get annotations from the LLM. Detailed evaluation with four benchmark HAR datasets shows that SSL-based encoding and metric-based guidance allow the LLM to make more reasonable decisions and provide accurate annotations without requiring computationally expensive fine-tuning or sophisticated prompt engineering.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4402675515",
    "type": "article"
  },
  {
    "title": "Causal Inference for Recommendation: Foundations, Methods and Applications",
    "doi": "https://doi.org/10.1145/3714430",
    "publication_date": "2025-01-27",
    "publication_year": 2025,
    "authors": "Shuyuan Xu; Jianchao Ji; Yunqi Li; Yingqiang Ge; Juntao Tan; Yongfeng Zhang",
    "corresponding_authors": "",
    "abstract": "Recommender systems are important and powerful tools for various personalized services. Traditionally, these systems use data mining and machine learning techniques to make recommendations based on correlations found in the data. However, relying solely on correlation without considering the underlying causal mechanism may lead to various practical issues such as fairness, explainability, robustness, bias, echo chamber and controllability problems. Therefore, researchers in related area have begun incorporating causality into recommendation systems to address these issues. In this survey, we review the existing literature on causal inference in recommender systems. We discuss the fundamental concepts of both recommender systems and causal inference as well as their relationship, and review the existing work on causal methods for different problems in recommender systems. Finally, we discuss open problems and future directions in the field of causal inference for recommendations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4406847088",
    "type": "article"
  },
  {
    "title": "LLM-enhanced Multiple Instance Learning for Joint Rumor and Stance Detection with Social Context Information",
    "doi": "https://doi.org/10.1145/3716856",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Ruichao Yang; Jing Ma; Wei Gao; Hongzhan Lin",
    "corresponding_authors": "",
    "abstract": "The proliferation of misinformation, such as rumors on social media, has drawn significant attention, prompting various expressions of stance among users. Although rumor detection and stance detection are distinct tasks, they can complement each other. Rumors can be identified by cross-referencing stances in related posts, and stances are influenced by the nature of the rumor. However, existing stance detection methods often require post-level stance annotations, which are costly to obtain. We propose a novel LLM-enhanced MIL approach to jointly predict post stance and claim class labels, supervised solely by claim labels, using an undirected microblog propagation model. Our weakly supervised approach relies only on bag-level labels of claim veracity, aligning with multi-instance learning (MIL) principles. To achieve this, we transform the multi-class problem into multiple MIL-based binary classification problems. We then employ a discriminative attention layer to aggregate the outputs from these classifiers into finer-grained classes. Experiments conducted on three rumor datasets and two stance datasets demonstrate the effectiveness of our approach, highlighting strong connections between rumor veracity and expressed stances in responding posts. Our method shows promising performance in joint rumor and stance detection compared to the state-of-the-art methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4407369317",
    "type": "article"
  },
  {
    "title": "Joint Structural-Functional Brain Graph Transformer",
    "doi": "https://doi.org/10.1145/3729243",
    "publication_date": "2025-04-12",
    "publication_year": 2025,
    "authors": "Ciyuan Peng; Huafei Huang; Tianqi Guo; Chinchun Meng; Jingjing Zhou; Wenhong Zhao; Ruwan Tennakoon; Feng Xia",
    "corresponding_authors": "",
    "abstract": "Multimodal brain graph transformers have become one of the foundational architectures of graph foundation models for brain science, relying on multimodal brain network fusion. However, most current multimodal brain network fusion methods primarily focus on modality-specific information fusion. The interplays within structural-functional brain networks are often ignored. Therefore, they fail to acquire essential coupling information, which is crucial for obtaining robust joint brain network representations. This oversight inevitably limits the effectiveness and generalization of these representations in various downstream tasks. To this end, we propose a novel joint structural-functional brain graph transformer model (namely sfBGT). Technically, we design a cross-network assortativity quantification mechanism to enable structural-functional brain network coupling, thus capturing the interplays of brain structure and function. We then employ a multimodal graph transformer to effectively learn joint representations of structural-functional brain networks along with their coupling relation representations. Experimental results on three real-world datasets demonstrate the superiority of sfBGT over state-of-the-art baselines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4409391351",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness",
    "doi": "https://doi.org/10.1145/3768165",
    "publication_date": "2025-09-18",
    "publication_year": 2025,
    "authors": "Fali Wang; Zhiwei Zhang; Xianren Zhang; Zongyu Wu; Tzuhao Mo; Qiuhao Lu; Wanjing Wang; Rui Li; Junjie Xu; Xianfeng Tang; Qi He; Yao Ma; Ming Huang; Suhang Wang",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs) have demonstrated emergent abilities in text generation, question answering, and reasoning, facilitating various tasks and domains. Despite their proficiency in various tasks, LLMs like PaLM 540B and Llama-3.1 405B face limitations due to large parameter sizes and computational demands, often requiring cloud API use which raises privacy concerns, limits real-time applications on edge devices, and increases fine-tuning costs. Additionally, LLMs often underperform in specialized domains such as healthcare and law due to insufficient domain-specific knowledge, necessitating specialized models. Therefore, Small Language Models (SLMs) are increasingly favored for their low inference latency, cost-effectiveness, efficient development, and easy customization and adaptability. These models are particularly well-suited for resource-limited environments and domain knowledge acquisition, addressing LLMs’ challenges and proving ideal for applications that require localized data handling for privacy, minimal inference latency for efficiency, and domain knowledge acquisition through lightweight fine-tuning. The rising demand for SLMs has spurred extensive research and development. However, a comprehensive survey investigating issues related to the definition, acquisition, application, enhancement, and reliability of SLM remains lacking, prompting us to conduct a detailed survey on these topics. The definition of SLMs varies widely, thus to standardize, we propose defining SLMs by their capability to perform specialized tasks and suitability for resource-constrained settings, setting boundaries based on the minimal size for emergent abilities and the maximum size sustainable under resource constraints. For other aspects, we provide a taxonomy of relevant models/methods and develop general frameworks for each category to enhance and utilize SLMs effectively. We have compiled the collected SLM models and related methods on GitHub: https://github.com/FairyFali/SLMs-Survey .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4414320956",
    "type": "article"
  },
  {
    "title": "Human-aware task planning",
    "doi": "https://doi.org/10.1145/1869397.1869404",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Marcello Cirillo; Lars Karlsson; Alessandro Saffiotti",
    "corresponding_authors": "",
    "abstract": "Consider a house cleaning robot planning its activities for the day. Assume that the robot expects the human inhabitant to first dress, then have breakfast, and finally go out. Then, it should plan not to clean the bedroom while the human is dressing, and to clean the kitchen after the human has had breakfast. In general, robots operating in inhabited environments, like households and future factory floors, should plan their behavior taking into account the actions that will be performed by the humans sharing the same environment. This would improve human-robot cohabitation, for example, by avoiding undesired situations for the human. Unfortunately, current task planners only consider the robot's actions and unexpected external events in the planning process, and cannot accommodate expectations about the actions of the humans. In this article, we present a human-aware planner able to address this problem. Our planner supports alternative hypotheses of the human plan, temporal duration for the actions of both the robot and the human, constraints on the interaction between robot and human, partial goal achievement and, most importantly, the possibility to use observations of human actions in the policy generated for the robot. Our planner has been tested both as a stand-alone component and within a full framework for human-robot interaction in a real environment.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2047123785",
    "type": "article"
  },
  {
    "title": "Mining Recurring Concept Drifts with Limited Labeled Streaming Data",
    "doi": "https://doi.org/10.1145/2089094.2089105",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Peipei Li; Xindong Wu; Xuegang Hu",
    "corresponding_authors": "",
    "abstract": "Tracking recurring concept drifts is a significant issue for machine learning and data mining that frequently appears in real-world stream classification problems. It is a challenge for many streaming classification algorithms to learn recurring concepts in a data stream environment with unlabeled data, and this challenge has received little attention from the research community. Motivated by this challenge, this article focuses on the problem of recurring contexts in streaming environments with limited labeled data. We propose a semi-supervised classification algorithm for data streams with REcurring concept Drifts and Limited LAbeled data, called REDLLA, in which a decision tree is adopted as the classification model. When growing a tree, a clustering algorithm based on k -means is installed to produce concept clusters and unlabeled data are labeled in the method of majority-class at leaves. In view of deviations between history and new concept clusters, potential concept drifts are distinguished and recurring concepts are maintained. Extensive studies on both synthetic and real-world data confirm the advantages of our REDLLA algorithm over three state-of-the-art online classification algorithms of CVFDT, DWCDS, and CDRDT and several known online semi-supervised algorithms, even in the case with more than 90% unlabeled data.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2172080108",
    "type": "article"
  },
  {
    "title": "Social semantic query expansion",
    "doi": "https://doi.org/10.1145/2508037.2508041",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Claudio Biancalana; Fabio Gasparetti; Alessandro Micarelli; Giuseppe Sansonetti",
    "corresponding_authors": "",
    "abstract": "Weak semantic techniques rely on the integration of Semantic Web techniques with social annotations and aim to embrace the strengths of both. In this article, we propose a novel weak semantic technique for query expansion. Traditional query expansion techniques are based on the computation of two-dimensional co-occurrence matrices. Our approach proposes the use of three-dimensional matrices, where the added dimension is represented by semantic classes (i.e., categories comprising all the terms that share a semantic property) related to the folksonomy extracted from social bookmarking services, such as delicious and StumbleUpon . The results of an indepth experimental evaluation performed on both artificial datasets and real users show that our approach outperforms traditional techniques, such as relevance feedback and personalized PageRank, so confirming the validity and usefulness of the categorization of the user needs and preferences in semantic classes. We also present the results of a questionnaire aimed to know the users opinion regarding the system. As one drawback of several query expansion techniques is their high computational costs, we also provide a complexity analysis of our system, in order to show its capability of operating in real time.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2015860767",
    "type": "article"
  },
  {
    "title": "Spatiotemporal correlations in criminal offense records",
    "doi": "https://doi.org/10.1145/1989734.1989742",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Jameson L. Toole; Nathan Eagle; Joshua B. Plotkin",
    "corresponding_authors": "",
    "abstract": "With the increased availability of rich behavioral datasets, we present a novel application of tools to analyze this information. Using criminal offense records as an example, we employ cross-correlation measures, eigenvalue spectrum analysis, and results from random matrix theory to identify spatiotemporal patterns on multiple scales. With these techniques, we show that most significant correlation exists on the time scale of weeks and identify clusters of neighborhoods whose crime rates are affected simultaneously by external forces.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2035770620",
    "type": "article"
  },
  {
    "title": "PTIME",
    "doi": "https://doi.org/10.1145/1989734.1989744",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Pauline M. Berry; Melinda Gervasio; Bart Peintner; Neil Yorke‐Smith",
    "corresponding_authors": "",
    "abstract": "In a world of electronic calendars, the prospect of intelligent, personalized time management assistance seems a plausible and desirable application of AI. PTIME ( Personalized Time Management ) is a learning cognitive assistant agent that helps users handle email meeting requests, reserve venues, and schedule events. PTIME is designed to unobtrusively learn scheduling preferences, adapting to its user over time. The agent allows its user to flexibly express requirements for new meetings, as they would to an assistant. It interfaces with commercial enterprise calendaring platforms, and it operates seamlessly with users who do not have PTIME. This article overviews the system design and describes the models and technical advances required to satisfy the competing needs of preference modeling and elicitation, constraint reasoning, and machine learning. We further report on a multifaceted evaluation of the perceived usefulness of the system.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2064054920",
    "type": "article"
  },
  {
    "title": "Improving recommendation accuracy based on item-specific tag preferences",
    "doi": "https://doi.org/10.1145/2414425.2414436",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Fatih Gedikli; Dietmar Jannach",
    "corresponding_authors": "",
    "abstract": "In recent years, different proposals have been made to exploit Social Web tagging information to build more effective recommender systems. The tagging data, for example, were used to identify similar users or were viewed as additional information about the recommendable items. Recent research has indicated that “attaching feelings to tags” is experienced by users as a valuable means to express which features of an item they particularly like or dislike. When following such an approach, users would therefore not only add tags to an item as in usual Web 2.0 applications, but also attach a preference ( affect ) to the tag itself, expressing, for example, whether or not they liked a certain actor in a given movie. In this work, we show how this additional preference data can be exploited by a recommender system to make more accurate predictions. In contrast to previous work, which also relied on so-called tag preferences to enhance the predictive accuracy of recommender systems, we argue that tag preferences should be considered in the context of an item. We therefore propose new schemes to infer and exploit context-specific tag preferences in the recommendation process. An evaluation on two different datasets reveals that our approach is capable of providing more accurate recommendations than previous tag-based recommender algorithms and recent tag-agnostic matrix factorization techniques.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2079632420",
    "type": "article"
  },
  {
    "title": "Stereotypical trust and bias in dynamic multiagent systems",
    "doi": "https://doi.org/10.1145/2438653.2438661",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Chris Burnett; Timothy J. Norman; Katia Sycara",
    "corresponding_authors": "",
    "abstract": "Large-scale multiagent systems have the potential to be highly dynamic. Trust and reputation are crucial concepts in these environments, as it may be necessary for agents to rely on their peers to perform as expected, and learn to avoid untrustworthy partners. However, aspects of highly dynamic systems introduce issues which make the formation of trust relationships difficult. For example, they may be short-lived, precluding agents from gaining the necessary experiences to make an accurate trust evaluation. This article describes a new approach, inspired by theories of human organizational behavior, whereby agents generalize their experiences with previously encountered partners as stereotypes , based on the observable features of those partners and their behaviors. Subsequently, these stereotypes are applied when evaluating new and unknown partners. Furthermore, these stereotypical opinions can be communicated within the society, resulting in the notion of stereotypical reputation . We show how this approach can complement existing state-of-the-art trust models, and enhance the confidence in the evaluations that can be made about trustees when direct and reputational information is lacking or limited. Furthermore, we show how a stereotyping approach can help agents detect unwanted biases in the reputational opinions they receive from others in the society.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2059138755",
    "type": "article"
  },
  {
    "title": "Hazy Image Restoration by Bi-Histogram Modification",
    "doi": "https://doi.org/10.1145/2710024",
    "publication_date": "2015-07-13",
    "publication_year": 2015,
    "authors": "Bo‐Hao Chen; Shih-Chia Huang; Jian Hui Ye",
    "corresponding_authors": "",
    "abstract": "Visibility restoration techniques are widely used for information recovery of hazy images in many computer vision applications. Estimation of haze density is an essential task of visibility restoration techniques. However, conventional visibility restoration techniques often suffer from either the generation of serious artifacts or the loss of object information in the restored images due to uneven haze density, which usually means that the images contain heavy haze formation within their background regions and little haze formation within their foreground regions. This frequently occurs when the images feature real-world scenes with a deep depth of field. How to effectively and accurately estimate the haze density in the transmission map for these images is the most challenging aspect of the traditional state-of-the-art techniques. In response to this problem, this work proposes a novel visibility restoration approach that is based on Bi-Histogram modification, and which integrates a haze density estimation module and a haze formation removal module for effective and accurate estimation of haze density in the transmission map. As our experimental results demonstrate, the proposed approach achieves superior visibility restoration efficacy in comparison with the other state-of-the-art approaches based on both qualitative and quantitative evaluations. The proposed approach proves effective and accurate in terms of both background and foreground restoration of various hazy scenarios.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2209832953",
    "type": "article"
  },
  {
    "title": "Supervised Representation Learning with Double Encoding-Layer Autoencoder for Transfer Learning",
    "doi": "https://doi.org/10.1145/3108257",
    "publication_date": "2017-10-23",
    "publication_year": 2017,
    "authors": "Fuzhen Zhuang; Xiaohu Cheng; Ping Luo; Sinno Jialin Pan; Qing He",
    "corresponding_authors": "",
    "abstract": "Transfer learning has gained a lot of attention and interest in the past decade. One crucial research issue in transfer learning is how to find a good representation for instances of different domains such that the divergence between domains can be reduced with the new representation. Recently, deep learning has been proposed to learn more robust or higher-level features for transfer learning. In this article, we adapt the autoencoder technique to transfer learning and propose a supervised representation learning method based on double encoding-layer autoencoder. The proposed framework consists of two encoding layers: one for embedding and the other one for label encoding. In the embedding layer, the distribution distance of the embedded instances between the source and target domains is minimized in terms of KL-Divergence. In the label encoding layer, label information of the source domain is encoded using a softmax regression model. Moreover, to empirically explore why the proposed framework can work well for transfer learning, we propose a new effective measure based on autoencoder to compute the distribution distance between different domains. Experimental results show that the proposed new measure can better reflect the degree of transfer difficulty and has stronger correlation with the performance from supervised learning algorithms (e.g., Logistic Regression), compared with previous ones, such as KL-Divergence and Maximum Mean Discrepancy. Therefore, in our model, we have incorporated two distribution distance measures to minimize the difference between source and target domains in the embedding representations. Extensive experiments conducted on three real-world image datasets and one text data demonstrate the effectiveness of our proposed method compared with several state-of-the-art baseline methods.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2766328202",
    "type": "article"
  },
  {
    "title": "Understanding the Relationship between Human Behavior and Susceptibility to Cyber Attacks",
    "doi": "https://doi.org/10.1145/2890509",
    "publication_date": "2017-03-22",
    "publication_year": 2017,
    "authors": "Michael Ovelgönne; Tudor Dumitraş; B. Aditya Prakash; V. S. Subrahmanian; Benjamin Wang",
    "corresponding_authors": "",
    "abstract": "Despite growing speculation about the role of human behavior in cyber-security of machines, concrete data-driven analysis and evidence have been lacking. Using Symantec’s WINE platform, we conduct a detailed study of 1.6 million machines over an 8-month period in order to learn the relationship between user behavior and cyber attacks against their personal computers. We classify users into 4 categories (gamers, professionals, software developers, and others, plus a fifth category comprising everyone) and identify a total of 7 features that act as proxies for human behavior. For each of the 35 possible combinations (5 categories times 7 features), we studied the relationship between each of these seven features and one dependent variable, namely the number of attempted malware attacks detected by Symantec on the machine. Our results show that there is a strong relationship between several features and the number of attempted malware attacks. Had these hosts not been protected by Symantec’s anti-virus product or a similar product, they would likely have been infected. Surprisingly, our results show that software developers are more at risk of engaging in risky cyber-behavior than other categories.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2602218799",
    "type": "article"
  },
  {
    "title": "Web media semantic concept retrieval via tag removal and model fusion",
    "doi": "https://doi.org/10.1145/2508037.2508042",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Chao Chen; Qiusha Zhu; Lin Lin; Mei‐Ling Shyu",
    "corresponding_authors": "",
    "abstract": "Multimedia data on social websites contain rich semantics and are often accompanied with user-defined tags. To enhance Web media semantic concept retrieval, the fusion of tag-based and content-based models can be used, though it is very challenging. In this article, a novel semantic concept retrieval framework that incorporates tag removal and model fusion is proposed to tackle such a challenge. Tags with useful information can facilitate media search, but they are often imprecise, which makes it important to apply noisy tag removal (by deleting uncorrelated tags) to improve the performance of semantic concept retrieval. Therefore, a multiple correspondence analysis (MCA)-based tag removal algorithm is proposed, which utilizes MCA's ability to capture the relationships among nominal features and identify representative and discriminative tags holding strong correlations with the target semantic concepts. To further improve the retrieval performance, a novel model fusion method is also proposed to combine ranking scores from both tag-based and content-based models, where the adjustment of ranking scores, the reliability of models, and the correlations between the intervals divided on the ranking scores and the semantic concepts are all considered. Comparative results with extensive experiments on the NUS-WIDE-LITE as well as the NUS-WIDE-270K benchmark datasets with 81 semantic concepts show that the proposed framework outperforms baseline results and the other comparison methods with each component being evaluated separately.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2086505500",
    "type": "article"
  },
  {
    "title": "Diversifying Citation Recommendations",
    "doi": "https://doi.org/10.1145/2668106",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Onur Küçüktunç; Érik Saule; Kamer Kaya; Ümit V. Çatalyürek",
    "corresponding_authors": "",
    "abstract": "Literature search is one of the most important steps of academic research. With more than 100,000 papers published each year just in computer science, performing a complete literature search becomes a Herculean task. Some of the existing approaches and tools for literature search cannot compete with the characteristics of today’s literature, and they suffer from ambiguity and homonymy. Techniques based on citation information are more robust to the mentioned issues. Thus, we recently built a Web service called the advisor, which provides personalized recommendations to researchers based on their papers of interest. Since most recommendation methods may return redundant results, diversifying the results of the search process is necessary to increase the amount of information that one can reach via an automated search. This article targets the problem of result diversification in citation-based bibliographic search, assuming that the citation graph itself is the only information available and no categories or intents are known. The contribution of this work is threefold. We survey various random walk--based diversification methods and enhance them with the direction awareness property to allow users to reach either old, foundational (possibly well-cited and well-known) research papers or recent (most likely less-known) ones. Next, we propose a set of novel algorithms based on vertex selection and query refinement. A set of experiments with various evaluation criteria shows that the proposed γ-RLM algorithm performs better than the existing approaches and is suitable for real-time bibliographic search in practice.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2115984558",
    "type": "article"
  },
  {
    "title": "DeepTracker",
    "doi": "https://doi.org/10.1145/3200489",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Dongyu Liu; Weiwei Cui; Kai Jin; Yuxiao Guo; Huamin Qu",
    "corresponding_authors": "",
    "abstract": "Deep Convolutional Neural Networks (CNNs) have achieved remarkable success in various fields. However, training an excellent CNN is practically a trial-and-error process that consumes a tremendous amount of time and computer resources. To accelerate the training process and reduce the number of trials, experts need to understand what has occurred in the training process and why the resulting CNN behaves as it does. However, current popular training platforms, such as TensorFlow, only provide very little and general information, such as training/validation errors, which is far from enough to serve this purpose. To bridge this gap and help domain experts with their training tasks in a practical environment, we propose a visual analytics system, DeepTracker, to facilitate the exploration of the rich dynamics of CNN training processes and to identify the unusual patterns that are hidden behind the huge amount of information in training log. Specifically, we combine a hierarchical index mechanism and a set of hierarchical small multiples to help experts explore the entire training log from different levels of detail. We also introduce a novel cube-style visualization to reveal the complex correlations among multiple types of heterogeneous training data, including neuron weights, validation images, and training iterations. Three case studies are conducted to demonstrate how DeepTracker provides its users with valuable knowledge in an industry-level CNN training process; namely, in our case, training ResNet-50 on the ImageNet dataset. We show that our method can be easily applied to other state-of-the-art “very deep” CNN models.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2888685797",
    "type": "article"
  },
  {
    "title": "From Observational Studies to Causal Rule Mining",
    "doi": "https://doi.org/10.1145/2746410",
    "publication_date": "2015-11-24",
    "publication_year": 2015,
    "authors": "Jiuyong Li; Thuc Duy Le; Lin Liu; Jixue Liu; Jin Zhou; Bingyu Sun; Saisai Ma",
    "corresponding_authors": "",
    "abstract": "Randomised controlled trials (RCTs) are the most effective approach to causal discovery, but in many circumstances it is impossible to conduct RCTs. Therefore observational studies based on passively observed data are widely accepted as an alternative to RCTs. However, in observational studies, prior knowledge is required to generate the hypotheses about the cause-effect relationships to be tested, hence they can only be applied to problems with available domain knowledge and a handful of variables. In practice, many data sets are of high dimensionality, which leaves observational studies out of the opportunities for causal discovery from such a wealth of data sources. In another direction, many efficient data mining methods have been developed to identify associations among variables in large data sets. The problem is, causal relationships imply associations, but the reverse is not always true. However we can see the synergy between the two paradigms here. Specifically, association rule mining can be used to deal with the high-dimensionality problem while observational studies can be utilised to eliminate non-causal associations. In this paper we propose the concept of causal rules (CRs) and develop an algorithm for mining CRs in large data sets. We use the idea of retrospective cohort studies to detect CRs based on the results of association rule mining. Experiments with both synthetic and real world data sets have demonstrated the effectiveness and efficiency of CR mining. In comparison with the commonly used causal discovery methods, the proposed approach in general is faster and has better or competitive performance in finding correct or sensible causes. It is also capable of finding a cause consisting of multiple variables, a feature that other causal discovery methods do not possess.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W3098060673",
    "type": "article"
  },
  {
    "title": "Research directions in agent communication",
    "doi": "https://doi.org/10.1145/2438653.2438655",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Amit K. Chopra; Alexander Artikis; Jamal Bentahar; Marco Colombetti; Frank Dignum; Nicoletta Fornara; Andrew Jones; Munindar P. Singh; Pınar Yolum",
    "corresponding_authors": "",
    "abstract": "Increasingly, software engineering involves open systems consisting of autonomous and heterogeneous participants or agents who carry out loosely coupled interactions. Accordingly, understanding and specifying communications among agents is a key concern. A focus on ways to formalize meaning distinguishes agent communication from traditional distributed computing: meaning provides a basis for flexible interactions and compliance checking. Over the years, a number of approaches have emerged with some essential and some irrelevant distinctions drawn among them. As agent abstractions gain increasing traction in the software engineering of open systems, it is important to resolve the irrelevant and highlight the essential distinctions, so that future research can be focused in the most productive directions. This article is an outcome of extensive discussions among agent communication researchers, aimed at taking stock of the field and at developing, criticizing, and refining their positions on specific approaches and future challenges. This article serves some important purposes, including identifying (1) points of broad consensus; (2) points where substantive differences remain; and (3) interesting directions of future work.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2019200853",
    "type": "article"
  },
  {
    "title": "Gestures à Go Go",
    "doi": "https://doi.org/10.1145/2799648",
    "publication_date": "2015-11-24",
    "publication_year": 2015,
    "authors": "Luis A. Leiva; Daniel Martín-Albo; Réjean Plamondon",
    "corresponding_authors": "",
    "abstract": "Training a high-quality gesture recognizer requires providing a large number of examples to enable good performance on unseen, future data. However, recruiting participants, data collection, and labeling, etc., necessary for achieving this goal are usually time consuming and expensive. Thus, it is important to investigate how to empower developers to quickly collect gesture samples for improving UI usage and user experience. In response to this need, we introduce Gestures à Go Go ( g 3), a web service plus an accompanying web application for bootstrapping stroke gesture samples based on the kinematic theory of rapid human movements. The user only has to provide a gesture example once, and g 3 will create a model of that gesture. Then, by introducing local and global perturbations to the model parameters, g 3 generates from tens to thousands of synthetic human-like samples. Through a comprehensive evaluation, we show that synthesized gestures perform equally similar to gestures generated by human users. Ultimately, this work informs our understanding of designing better user interfaces that are driven by gestures.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2265696903",
    "type": "article"
  },
  {
    "title": "Campaign extraction from social media",
    "doi": "https://doi.org/10.1145/2542182.2542191",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Kyumin Lee; James Caverlee; Zhiyuan Cheng; Daniel Z. Sui",
    "corresponding_authors": "",
    "abstract": "In this manuscript, we study the problem of detecting coordinated free text campaigns in large-scale social media. These campaigns—ranging from coordinated spam messages to promotional and advertising campaigns to political astro-turfing—are growing in significance and reach with the commensurate rise in massive-scale social systems. Specifically, we propose and evaluate a content-driven framework for effectively linking free text posts with common “talking points” and extracting campaigns from large-scale social media. Three of the salient features of the campaign extraction framework are: (i) first, we investigate graph mining techniques for isolating coherent campaigns from large message-based graphs; (ii) second, we conduct a comprehensive comparative study of text-based message correlation in message and user levels; and (iii) finally, we analyze temporal behaviors of various campaign types. Through an experimental study over millions of Twitter messages we identify five major types of campaigns—namely Spam, Promotion, Template, News, and Celebrity campaigns—and we show how these campaigns may be extracted with high precision and recall.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2019077935",
    "type": "article"
  },
  {
    "title": "A content-driven framework for geolocating microblog users",
    "doi": "https://doi.org/10.1145/2414425.2414427",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Zhiyuan Cheng; James Caverlee; Kyumin Lee",
    "corresponding_authors": "",
    "abstract": "Highly dynamic real-time microblog systems have already published petabytes of real-time human sensor data in the form of status updates. However, the lack of user adoption of geo-based features per user or per post signals that the promise of microblog services as location-based sensing systems may have only limited reach and impact. Thus, in this article, we propose and evaluate a probabilistic framework for estimating a microblog user's location based purely on the content of the user's posts. Our framework can overcome the sparsity of geo-enabled features in these services and bring augmented scope and breadth to emerging location-based personalized information services. Three of the key features of the proposed approach are: (i) its reliance purely on publicly available content; (ii) a classification component for automatically identifying words in posts with a strong local geo-scope; and (iii) a lattice-based neighborhood smoothing model for refining a user's location estimate. On average we find that the location estimates converge quickly, placing 51% of users within 100 miles of their actual location.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2139540129",
    "type": "article"
  },
  {
    "title": "Large-Scale Frequent Episode Mining from Complex Event Sequences with Hierarchies",
    "doi": "https://doi.org/10.1145/3326163",
    "publication_date": "2019-07-20",
    "publication_year": 2019,
    "authors": "Xiang Ao; Haoran Shi; Jin Wang; Luo Zuo; Hongwei Li; Qing He",
    "corresponding_authors": "",
    "abstract": "Frequent Episode Mining (FEM), which aims at mining frequent sub-sequences from a single long event sequence, is one of the essential building blocks for the sequence mining research field. Existing studies about FEM suffer from unsatisfied scalability when faced with complex sequences as it is an NP-complete problem for testing whether an episode occurs in a sequence. In this article, we propose a scalable, distributed framework to support FEM on “big” event sequences. As a rule of thumb, “big” illustrates an event sequence is either very long or with masses of simultaneous events. Meanwhile, the events in this article are arranged in a predefined hierarchy. It derives some abstractive events that can form episodes that may not directly appear in the input sequence. Specifically, we devise an event-centered and hierarchy-aware partitioning strategy to allocate events from different levels of the hierarchy into local processes. We then present an efficient special-purpose algorithm to improve the local mining performance. We also extend our framework to support maximal and closed episode mining in the context of event hierarchy, and to the best of our knowledge, we are the first attempt to define and discover hierarchy-aware maximal and closed episodes. We implement the proposed framework on Apache Spark and conduct experiments on both synthetic and real-world datasets. Experimental results demonstrate the efficiency and scalability of the proposed approach and show that we can find practical patterns when taking event hierarchies into account.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2963212997",
    "type": "article"
  },
  {
    "title": "Trajectory Data Classification",
    "doi": "https://doi.org/10.1145/3330138",
    "publication_date": "2019-07-31",
    "publication_year": 2019,
    "authors": "Jiang Bian; Dayong Tian; Yuanyan Tang; Dacheng Tao",
    "corresponding_authors": "",
    "abstract": "This article comprehensively surveys the development of trajectory data classification. Considering the critical role of trajectory data classification in modern intelligent systems for surveillance security, abnormal behavior detection, crowd behavior analysis, and traffic control, trajectory data classification has attracted growing attention. According to the availability of manual labels, which is critical to the classification performances, the methods can be classified into three categories, i.e., unsupervised, semi-supervised, and supervised. Furthermore, classification methods are divided into some sub-categories according to what extracted features are used. We provide a holistic understanding and deep insight into three types of trajectory data classification methods and present some promising future directions.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2969079355",
    "type": "article"
  },
  {
    "title": "Energy-efficient Static Task Scheduling on VFI-based NoC-HMPSoCs for Intelligent Edge Devices in Cyber-physical Systems",
    "doi": "https://doi.org/10.1145/3336121",
    "publication_date": "2019-10-18",
    "publication_year": 2019,
    "authors": "Umair Ullah Tariq; Haider Ali; Lu Liu; John Panneerselvam; Xiaojun Zhai",
    "corresponding_authors": "",
    "abstract": "The interlinked processing units in modern Cyber-Physical Systems (CPS) creates a large network of connected computing embedded systems. Network-on-Chip (NoC)-based Multiprocessor System-on-Chip (MPSoC) architecture is becoming a de facto computing platform for real-time applications due to its higher performance and Quality-of-Service (QoS). The number of processors has increased significantly on the multiprocessor systems in CPS; therefore, Voltage Frequency Island (VFI) has been recently adopted for effective energy management mechanism in the large-scale multiprocessor chip designs. In this article, we investigated energy-efficient and contention-aware static scheduling for tasks with precedence and deadline constraints on intelligent edge devices deploying heterogeneous VFI-based NoC-MPSoCs (VFI-NoC-HMPSoC) with DVFS-enabled processors. Unlike the existing population-based optimization algorithms, we proposed a novel population-based algorithm called ARSH-FATI that can dynamically switch between explorative and exploitative search modes at run-time. Our static scheduler ARHS-FATI collectively performs task mapping, scheduling, and voltage scaling. Consequently, its performance is superior to the existing state-of-the-art approach proposed for homogeneous VFI-based NoC-MPSoCs. We also developed a communication contention-aware Earliest Edge Consistent Deadline First (EECDF) scheduling algorithm and gradient descent--inspired voltage scaling algorithm called Energy Gradient Decent (EGD). We introduced a notion of Energy Gradient (EG) that guides EGD in its search for island voltage settings and minimize the total energy consumption. We conducted the experiments on eight real benchmarks adopted from Embedded Systems Synthesis Benchmarks (E3S). Our static scheduling approach ARSH-FATI outperformed state-of-the-art technique and achieved an average energy-efficiency of ∼24% and ∼30% over CA-TMES-Search and CA-TMES-Quick, respectively.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2978703344",
    "type": "article"
  },
  {
    "title": "Peacock",
    "doi": "https://doi.org/10.1145/2700497",
    "publication_date": "2015-07-15",
    "publication_year": 2015,
    "authors": "Yi Wang; Xuemin Zhao; Zhenlong Sun; Hao Yan; Lifeng Wang; Zhihui Jin; Liubin Wang; Yang Gao; Ching Law; Jia Zeng",
    "corresponding_authors": "",
    "abstract": "Latent Dirichlet allocation (LDA) is a popular topic modeling technique in academia but less so in industry, especially in large-scale applications involving search engine and online advertising systems. A main underlying reason is that the topic models used have been too small in scale to be useful; for example, some of the largest LDA models reported in literature have up to 10 3 topics, which difficultly cover the long-tail semantic word sets. In this article, we show that the number of topics is a key factor that can significantly boost the utility of topic-modeling systems. In particular, we show that a “big” LDA model with at least 10 5 topics inferred from 10 9 search queries can achieve a significant improvement on industrial search engine and online advertising systems, both of which serve hundreds of millions of users. We develop a novel distributed system called Peacock to learn big LDA models from big data. The main features of Peacock include hierarchical distributed architecture, real-time prediction, and topic de-duplication. We empirically demonstrate that the Peacock system is capable of providing significant benefits via highly scalable LDA topic models for several industrial applications.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W1546359014",
    "type": "article"
  },
  {
    "title": "Nonnegative Matrix Factorization with Integrated Graph and Feature Learning",
    "doi": "https://doi.org/10.1145/2987378",
    "publication_date": "2017-01-12",
    "publication_year": 2017,
    "authors": "Chong Peng; Zhao Kang; Yunhong Hu; Jie Cheng; Qiang Cheng",
    "corresponding_authors": "",
    "abstract": "Matrix factorization is a useful technique for data representation in many data mining and machine learning tasks. Particularly, for data sets with all nonnegative entries, matrix factorization often requires that factor matrices be nonnegative, leading to nonnegative matrix factorization (NMF). One important application of NMF is for clustering with reduced dimensions of the data represented in the new feature space. In this paper, we propose a new graph regularized NMF method capable of feature learning and apply it to clustering. Unlike existing NMF methods that treat all features in the original feature space equally, our method distinguishes features by incorporating a feature-wise sparse approximation error matrix in the formulation. It enables important features to be more closely approximated by the factor matrices. Meanwhile, the graph of the data is constructed using cleaner features in the feature learning process, which integrates feature learning and manifold learning procedures into a unified NMF model. This distinctly differs from applying the existing graph-based NMF models after feature selection in that, when these two procedures are independently used, they often fail to align themselves toward obtaining a compact and most expressive data representation. Comprehensive experimental results demonstrate the effectiveness of the proposed method, which outperforms state-of-the-art algorithms when applied to clustering.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2573763768",
    "type": "article"
  },
  {
    "title": "Fusing Multiple Features for Depth-Based Action Recognition",
    "doi": "https://doi.org/10.1145/2629483",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Yu Zhu; Wenbin Chen; Guodong Guo",
    "corresponding_authors": "",
    "abstract": "Human action recognition is a very active research topic in computer vision and pattern recognition. Recently, it has shown a great potential for human action recognition using the three-dimensional (3D) depth data captured by the emerging RGB-D sensors. Several features and/or algorithms have been proposed for depth-based action recognition. A question is raised: Can we find some complementary features and combine them to improve the accuracy significantly for depth-based action recognition? To address the question and have a better understanding of the problem, we study the fusion of different features for depth-based action recognition. Although data fusion has shown great success in other areas, it has not been well studied yet on 3D action recognition. Some issues need to be addressed, for example, whether the fusion is helpful or not for depth-based action recognition, and how to do the fusion properly. In this article, we study different fusion schemes comprehensively, using diverse features for action characterization in depth videos. Two different levels of fusion schemes are investigated, that is, feature level and decision level. Various methods are explored at each fusion level. Four different features are considered to characterize the depth action patterns from different aspects. The experiments are conducted on four challenging depth action databases, in order to evaluate and find the best fusion methods generally. Our experimental results show that the four different features investigated in the article can complement each other, and appropriate fusion methods can improve the recognition accuracies significantly over each individual feature. More importantly, our fusion-based action recognition outperforms the state-of-the-art approaches on these challenging databases.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2078885226",
    "type": "article"
  },
  {
    "title": "On Estimation of Functional Causal Models",
    "doi": "https://doi.org/10.1145/2700476",
    "publication_date": "2015-12-17",
    "publication_year": 2015,
    "authors": "Kun Zhang; Zhikun Wang; Jiji Zhang; Bernhard Schölkopf",
    "corresponding_authors": "",
    "abstract": "Compared to constraint-based causal discovery, causal discovery based on functional causal models is able to identify the whole causal model under appropriate assumptions [Shimizu et al. 2006; Hoyer et al. 2009; Zhang and Hyvärinen 2009b]. Functional causal models represent the effect as a function of the direct causes together with an independent noise term. Examples include the linear non-Gaussian acyclic model (LiNGAM), nonlinear additive noise model, and post-nonlinear (PNL) model. Currently, there are two ways to estimate the parameters in the models: dependence minimization and maximum likelihood. In this article, we show that for any acyclic functional causal model, minimizing the mutual information between the hypothetical cause and the noise term is equivalent to maximizing the data likelihood with a flexible model for the distribution of the noise term. We then focus on estimation of the PNL causal model and propose to estimate it with the warped Gaussian process with the noise modeled by the mixture of Gaussians. As a Bayesian nonparametric approach, it outperforms the previous one based on mutual information minimization with nonlinear functions represented by multilayer perceptrons; we also show that unlike the ordinary regression, estimation results of the PNL causal model are sensitive to the assumption on the noise distribution. Experimental results on both synthetic and real data support our theoretical claims.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2186461911",
    "type": "article"
  },
  {
    "title": "A Spatial-Temporal Topic Model for the Semantic Annotation of POIs in LBSNs",
    "doi": "https://doi.org/10.1145/2905373",
    "publication_date": "2016-07-25",
    "publication_year": 2016,
    "authors": "Tieke He; Hongzhi Yin; Zhenyu Chen; Xiaofang Zhou; Shazia Sadiq; Bin Luo",
    "corresponding_authors": "",
    "abstract": "Semantic tags of points of interest (POIs) are a crucial prerequisite for location search, recommendation services, and data cleaning. However, most POIs in location-based social networks (LBSNs) are either tag-missing or tag-incomplete. This article aims to develop semantic annotation techniques to automatically infer tags for POIs. We first analyze two LBSN datasets and observe that there are two types of tags, category-related ones and sentimental ones, which have unique characteristics. Category-related tags are hierarchical, whereas sentimental ones are category-aware. All existing related work has adopted classification methods to predict high-level category-related tags in the hierarchy, but they cannot apply to infer either low-level category tags or sentimental ones. In light of this, we propose a latent-class probabilistic generative model, namely the spatial-temporal topic model (STM), to infer personal interests, the temporal and spatial patterns of topics/semantics embedded in users’ check-in activities, the interdependence between category-topic and sentiment-topic, and the correlation between sentimental tags and rating scores from users’ check-in and rating behaviors. Then, this learned knowledge is utilized to automatically annotate all POIs with both category-related and sentimental tags in a unified way. We conduct extensive experiments to evaluate the performance of the proposed STM on a real large-scale dataset. The experimental results show the superiority of our proposed STM, and we also observe that the real challenge of inferring category-related tags for POIs lies in the low-level ones of the hierarchy and that the challenge of predicting sentimental tags are those with neutral ratings.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2499345104",
    "type": "article"
  },
  {
    "title": "Transfer Learning for Behavior Ranking",
    "doi": "https://doi.org/10.1145/3057732",
    "publication_date": "2017-06-30",
    "publication_year": 2017,
    "authors": "Weike Pan; Qiang Yang; Yuchao Duan; Ben Tan; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Intelligent recommendation has been well recognized as one of the major approaches to address the information overload problem in the big data era. A typical intelligent recommendation engine usually consists of three major components, that is, data as the main input, algorithms for preference learning, and system for user interaction and high-performance computation. We observe that the data (e.g., users’ behavior) are usually in different forms, such as examinations (e.g., browse and collection) and ratings, where the former are often much more abundant than the latter. Although the data are in different representations, they are both related to users’ true preferences and are also deemed complementary to each other for preference learning. However, very few ranking or recommendation algorithms have been developed to exploit such two types of user behavior. In this article, we focus on jointly modeling the examination behavior and rating behavior and develop a novel and efficient ranking-oriented recommendation algorithm accordingly. First, we formally define a new recommendation problem termed behavior ranking , which aims to build a ranking-oriented model by exploiting both the examination behavior and rating behavior. Second, we develop a simple and generic transfer to rank (ToR) algorithm for behavior ranking, which transfers knowledge of candidate items from a global preference learning task to a local preference learning task. Compared with the previous work on integrating heterogeneous user behavior, our ToR algorithm is the first ranking-oriented solution, which can effectively generate recommendations in a more direct manner than those regression-oriented methods. Extensive empirical studies show that our ToR algorithm performs significantly more accurately than the state-of-the-art methods in most cases. Furthermore, our ToR algorithm is very efficient in terms of the time complexity, which is similar to those for homogeneous user behavior alone.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2724526379",
    "type": "article"
  },
  {
    "title": "Adult Image and Video Recognition by a Deep Multicontext Network and Fine-to-Coarse Strategy",
    "doi": "https://doi.org/10.1145/3057733",
    "publication_date": "2017-07-12",
    "publication_year": 2017,
    "authors": "Xinyu Ou; Hefei Ling; Yu Han; Ping Li; Fuhao Zou; Si Liu",
    "corresponding_authors": "",
    "abstract": "Adult image and video recognition is an important and challenging problem in the real world. Low-level feature cues do not produce good enough information, especially when the dataset is very large and has various data distributions. This issue raises a serious problem for conventional approaches. In this article, we tackle this problem by proposing a deep multicontext network with fine-to-coarse strategy for adult image and video recognition. We employ a deep convolution networks to model fusion features of sensitive objects in images. Global contexts and local contexts are both taken into consideration and are jointly modeled in a unified multicontext deep learning framework. To make the model more discriminative for diverse target objects, we investigate a novel hierarchical method, and a task-specific fine-to-coarse strategy is designed to make the multicontext modeling more suitable for adult object recognition. Furthermore, some recently proposed deep models are investigated. Our approach is extensively evaluated on four different datasets. One dataset is used for ablation experiments, whereas others are used for generalization experiments. Results show significant and consistent improvements over the state-of-the-art methods.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2734726005",
    "type": "article"
  },
  {
    "title": "Using Crowdsourcing for Scientific Analysis of Industrial Tomographic Images",
    "doi": "https://doi.org/10.1145/2897370",
    "publication_date": "2016-07-12",
    "publication_year": 2016,
    "authors": "Chen Chen; Paweł W. Woźniak; Andrzej Romanowski; Mohammad Obaid; Tomasz Jaworski; J. Kucharski; Krzysztof Grudzień; Shengdong Zhao; Morten Fjeld",
    "corresponding_authors": "",
    "abstract": "In this article, we present a novel application domain for human computation, specifically for crowdsourcing, which can help in understanding particle-tracking problems. Through an interdisciplinary inquiry, we built a crowdsourcing system designed to detect tracer particles in industrial tomographic images, and applied it to the problem of bulk solid flow in silos. As images from silo-sensing systems cannot be adequately analyzed using the currently available computational methods, human intelligence is required. However, limited availability of experts, as well as their high cost, motivates employing additional nonexperts. We report on the results of a study that assesses the task completion time and accuracy of employing nonexpert workers to process large datasets of images in order to generate data for bulk flow research. We prove the feasibility of this approach by comparing results from a user study with data generated from a computational algorithm. The study shows that the crowd is more scalable and more economical than an automatic solution. The system can help analyze and understand the physics of flow phenomena to better inform the future design of silos, and is generalized enough to be applicable to other domains.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2462197426",
    "type": "article"
  },
  {
    "title": "Optimal Scheduling of Cybersecurity Analysts for Minimizing Risk",
    "doi": "https://doi.org/10.1145/2914795",
    "publication_date": "2017-02-24",
    "publication_year": 2017,
    "authors": "Rajesh Ganesan; Sushil Jajodia; Hasan Çam",
    "corresponding_authors": "",
    "abstract": "Cybersecurity threats are on the rise with evermore digitization of the information that many day-to-day systems depend upon. The demand for cybersecurity analysts outpaces supply, which calls for optimal management of the analyst resource. Therefore, a key component of the cybersecurity defense system is the optimal scheduling of its analysts. Sensor data is analyzed by automatic processing systems, and alerts are generated. A portion of these alerts is considered to be significant , which requires thorough examination by a cybersecurity analyst. Risk, in this article, is defined as the percentage of unanalyzed or not thoroughly analyzed alerts among the significant alerts by analysts. The article presents a generalized optimization model for scheduling cybersecurity analysts to minimize risk (a.k.a., maximize significant alert coverage by analysts) and maintain risk under a pre-determined upper bound. The article tests the optimization model and its scalability on a set of given sensors with varying analyst experiences, alert generation rates, system constraints, and system requirements. Results indicate that the optimization model is scalable and is capable of identifying both the right mix of analyst expertise in an organization and the sensor-to-analyst allocation in order to maintain risk below a given upper bound. Several meta-principles are presented, which are derived from the optimization model, and they further serve as guiding principles for hiring and scheduling cybersecurity analysts. The simulation studies (validation) of the optimization model outputs indicate that risk varies non-linearly with an analyst/sensor ratio, and for a given analyst/sensor ratio, the risk is independent of the number of sensors in the system.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2593932391",
    "type": "article"
  },
  {
    "title": "A Comfort-Based Approach to Smart Heating and Air Conditioning",
    "doi": "https://doi.org/10.1145/3057730",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Frederik Auffenberg; Stephen Snow; Sebastian Stein; Alex Rogers",
    "corresponding_authors": "",
    "abstract": "In this article, we address the interrelated challenges of predicting user comfort and using this to reduce energy consumption in smart heating, ventilation, and air conditioning (HVAC) systems. At present, such systems use simple models of user comfort when deciding on a set-point temperature. Being built using broad population statistics, these models generally fail to represent individual users’ preferences, resulting in poor estimates of the users’ preferred temperatures. To address this issue, we propose the Bayesian Comfort Model (BCM). This personalised thermal comfort model uses a Bayesian network to learn from a user’s feedback, allowing it to adapt to the users’ individual preferences over time. We further propose an alternative to the ASHRAE 7-point scale used to assess user comfort. Using this model, we create an optimal HVAC control algorithm that minimizes energy consumption while preserving user comfort. Through an empirical evaluation based on the ASHRAE RP-884 dataset and data collected in a separate deployment by us, we show that our model is consistently 13.2% to 25.8% more accurate than current models and how using our alternative comfort scale can increase our model’s accuracy. Through simulations we show that using this model, our HVAC control algorithm can reduce energy consumption by 7.3% to 13.5% while decreasing user discomfort by 24.8% simultaneously.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2613519073",
    "type": "article"
  },
  {
    "title": "Spotting Trip Purposes from Taxi Trajectories",
    "doi": "https://doi.org/10.1145/3078849",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Pengfei Wang; Guannan Liu; Yanjie Fu; Yuanchun Zhou; Jianhui Li",
    "corresponding_authors": "",
    "abstract": "What is the purpose of a trip? What are the unique human mobility patterns and spatial contexts in or near the pickup points and delivery points of trajectories for a specific trip purpose? Many prior studies have modeled human mobility patterns in urban regions; however, these analytics mainly focus on interpreting the semantic meanings of geographic topics at an aggregate level. Given the lack of information about human activities at pick-up and dropoff points, it is challenging to convert the prior studies into effective tools for inferring trip purposes. To address this challenge, in this article, we study large-scale taxi trajectories from an unsupervised perspective in light of the following observations. First, the POI configurations of origin and destination regions closely relate to the urban functionality of these regions and further indicate various human activities. Second, with respect to the functionality of neighborhood environments, trip purposes can be discerned from the transitions between regions with different functionality at particular time periods. Along these lines, we develop a general probabilistic framework for spotting trip purposes from massive taxi GPS trajectories. Specifically, we first augment the origin and destination regions of trajectories by attaching neighborhood POIs. Then, we introduce a latent factor, POI Topic , to represent the mixed functionality of the regions, such that each origin or destination point in the city can be modeled as a mixture over POI Topics. In addition, considering the transitions from origins to destinations at specific time periods, the trip time is generated collaboratively from the pairwise POI Topics at both ends of the O-D pairs, constituting POI Links , and hence the trip purpose can be explained semantically by the POI Links. Finally, we present extensive experiments with the real-world data of New York City to demonstrate the effectiveness of our proposed method for spotting trip purposes, and moreover, the model is validated to perform well in predicting the destinations and trip time among all the baseline methods.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2772869742",
    "type": "article"
  },
  {
    "title": "DHPA",
    "doi": "https://doi.org/10.1145/3360312",
    "publication_date": "2020-01-17",
    "publication_year": 2020,
    "authors": "Menghai Pan; Weixiao Huang; Yanhua Li; Xun Zhou; Zhenming Liu; Rui Song; Hui Lu; Zhihong Tian; Jun Luo",
    "corresponding_authors": "",
    "abstract": "Many real-world human behaviors can be modeled and characterized as sequential decision-making processes, such as a taxi driver’s choices of working regions and times. Each driver possesses unique preferences on the sequential choices over time and improves the driver’s working efficiency. Understanding the dynamics of such preferences helps accelerate the learning process of taxi drivers. Prior works on taxi operation management mostly focus on finding optimal driving strategies or routes, lacking in-depth analysis on what the drivers learned during the process and how they affect the performance of the driver. In this work, we make the first attempt to establish Dynamic Human Preference Analytics. We inversely learn the taxi drivers’ preferences from data and characterize the dynamics of such preferences over time. We extract two types of features (i.e., profile features and habit features) to model the decision space of drivers. Then through inverse reinforcement learning, we learn the preferences of drivers with respect to these features. The results illustrate that self-improving drivers tend to keep adjusting their preferences to habit features to increase their earning efficiency while keeping the preferences to profile features invariant. However, experienced drivers have stable preferences over time. The exploring drivers tend to randomly adjust the preferences over time.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W3013077068",
    "type": "article"
  },
  {
    "title": "Evolutionary Strategy to Perform Batch-Mode Active Learning on Multi-Label Data",
    "doi": "https://doi.org/10.1145/3161606",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Óscar Reyes; Sebastián Ventura",
    "corresponding_authors": "",
    "abstract": "Multi-label learning has become an important area of research owing to the increasing number of real-world problems that contain multi-label data. Data labeling is an expensive process that requires expert handling. The annotation of multi-label data is laborious since a human expert needs to consider the presence/absence of each possible label. Consequently, numerous modern multi-label problems may involve a small number of labeled examples and plentiful unlabeled examples simultaneously. Active learning methods allow us to induce better classifiers by selecting the most useful unlabeled data, thus considerably reducing the labeling effort and the cost of training an accurate model. Batch-mode active learning methods focus on selecting a set of unlabeled examples in each iteration in such a way that the selected examples are informative and as diverse as possible. This article presents a strategy to perform batch-mode active learning on multi-label data. The batch-mode active learning is formulated as a multi-objective problem, and it is solved by means of an evolutionary algorithm. Extensive experiments were conducted in a large collection of datasets, and the experimental results confirmed the effectiveness of our proposal for better batch-mode multi-label active learning.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2791998777",
    "type": "article"
  },
  {
    "title": "Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-identification",
    "doi": "https://doi.org/10.1145/3372121",
    "publication_date": "2020-01-27",
    "publication_year": 2020,
    "authors": "Wenhe Liu; Xiaojun Chang; Ling Chen; Dinh Phung; Xiaoqin Zhang; Yi Yang; Alexander G. Hauptmann",
    "corresponding_authors": "",
    "abstract": "The effective training of supervised Person Re-identification (Re-ID) models requires sufficient pairwise labeled data. However, when there is limited annotation resource, it is difficult to collect pairwise labeled data. We consider a challenging and practical problem called Early Active Learning, which is applied to the early stage of experiments when there is no pre-labeled sample available as references for human annotating. Previous early active learning methods suffer from two limitations for Re-ID. First, these instance-based algorithms select instances rather than pairs, which can result in missing optimal pairs for Re-ID. Second, most of these methods only consider the representativeness of instances, which can result in selecting less diverse and less informative pairs. To overcome these limitations, we propose a novel pair-based active learning for Re-ID. Our algorithm selects pairs instead of instances from the entire dataset for annotation. Besides representativeness, we further take into account the uncertainty and the diversity in terms of pairwise relations. Therefore, our algorithm can produce the most representative, informative, and diverse pairs for Re-ID data annotation. Extensive experimental results on five benchmark Re-ID datasets have demonstrated the superiority of the proposed pair-based early active learning algorithm.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W3026089740",
    "type": "article"
  },
  {
    "title": "Mutual Component Analysis for Heterogeneous Face Recognition",
    "doi": "https://doi.org/10.1145/2807705",
    "publication_date": "2016-03-08",
    "publication_year": 2016,
    "authors": "Zhifeng Li; Dihong Gong; Qiang Li; Dacheng Tao; Xuelong Li",
    "corresponding_authors": "",
    "abstract": "Heterogeneous face recognition, also known as cross-modality face recognition or intermodality face recognition, refers to matching two face images from alternative image modalities. Since face images from different image modalities of the same person are associated with the same face object, there should be mutual components that reflect those intrinsic face characteristics that are invariant to the image modalities. Motivated by this rationality, we propose a novel approach called Mutual Component Analysis (MCA) to infer the mutual components for robust heterogeneous face recognition. In the MCA approach, a generative model is first proposed to model the process of generating face images in different modalities, and then an Expectation Maximization (EM) algorithm is designed to iteratively learn the model parameters. The learned generative model is able to infer the mutual components (which we call the hidden factor , where hidden means the factor is unreachable and invisible, and can only be inferred from observations) that are associated with the person’s identity, thus enabling fast and effective matching for cross-modality face recognition. To enhance recognition performance, we propose an MCA-based multiclassifier framework using multiple local features. Experimental results show that our new approach significantly outperforms the state-of-the-art results on two typical application scenarios: sketch-to-photo and infrared-to-visible face recognition.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2300234500",
    "type": "article"
  },
  {
    "title": "Deep Learning Thermal Image Translation for Night Vision Perception",
    "doi": "https://doi.org/10.1145/3426239",
    "publication_date": "2020-12-22",
    "publication_year": 2020,
    "authors": "Shuo Liu; Mingliang Gao; Vijay John; Zheng Liu; Erik Blasch",
    "corresponding_authors": "",
    "abstract": "Context enhancement is critical for the environmental perception in night vision applications, especially for the dark night situation without sufficient illumination. In this article, we propose a thermal image translation method, which can translate thermal/infrared (IR) images into color visible (VI) images, called IR2VI. The IR2VI consists of two cascaded steps: translation from nighttime thermal IR images to gray-scale visible images (GVI), which is called IR-GVI; and the translation from GVI to color visible images (CVI), which is known as GVI-CVI in this article. For the first step, we develop the Texture-Net, a novel unsupervised image translation neural network based on generative adversarial networks. Texture-Net can learn the intrinsic characteristics from the GVI and integrate them into the IR image. In comparison with the state-of-the-art unsupervised image translation methods, the proposed Texture-Net is able to address some common challenges, e.g., incorrect mapping and lack of fine details, with a structure connection module and a region-of-interest focal loss. For the second step, we investigated the state-of-the-art gray-scale image colorization methods and integrate the deep convolutional neural network into the IR2VI framework. The results of the comprehensive evaluation experiments demonstrate the effectiveness of the proposed IR2VI image translation method. This solution will contribute to the environmental perception and understanding in varied night vision applications.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W3115729019",
    "type": "article"
  },
  {
    "title": "Spatio-temporal Adaptive Pricing for Balancing Mobility-on-Demand Networks",
    "doi": "https://doi.org/10.1145/3331450",
    "publication_date": "2019-07-24",
    "publication_year": 2019,
    "authors": "Suining He; Kang G. Shin",
    "corresponding_authors": "",
    "abstract": "Pricing in mobility-on-demand (MOD) networks, such as Uber, Lyft, and connected taxicabs, is done adaptively by leveraging the price responsiveness of drivers (supplies) and passengers (demands) to achieve such goals as maximizing drivers’ incomes, improving riders’ experience, and sustaining platform operation. Existing pricing policies only respond to short-term demand fluctuations without accurate trip forecast and spatial demand-supply balancing, thus mismatching drivers to riders and resulting in loss of profit. We propose CAPrice, a novel adaptive pricing scheme for urban MOD networks. It uses a new spatio-temporal deep capsule network (STCapsNet) that accurately predicts ride demands and driver supplies with vectorized neuron capsules while accounting for comprehensive spatio-temporal and external factors. Given accurate perception of zone-to-zone traffic flows in a city, CAPrice formulates a joint optimization problem by considering spatial equilibrium to balance the platform, providing drivers and riders/passengers with proactive pricing “signals.” We have conducted an extensive experimental evaluation upon over 4.0× 10 8 MOD trips (Uber, Didi Chuxing, and connected taxicabs) in New York City, Beijing, and Chengdu, validating the accuracy, effectiveness, and profitability (often 20% ride prediction accuracy and 30% profit improvements over the state-of-the-arts) of CAPrice in managing urban MOD networks.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2962787757",
    "type": "article"
  },
  {
    "title": "RHUPS",
    "doi": "https://doi.org/10.1145/3430767",
    "publication_date": "2021-01-13",
    "publication_year": 2021,
    "authors": "Yoonji Baek; Unil Yun; Heonho Kim; Hyoju Nam; Hyunsoo Kim; Jerry Chun‐Wei Lin; Bay Vo; Witold Pedrycz",
    "corresponding_authors": "",
    "abstract": "Databases that deal with the real world have various characteristics. New data is continuously inserted over time without limiting the length of the database, and a variety of information about the items constituting the database is contained. Recently generated data has a greater influence than the previously generated data. These are called the time-sensitive non-binary stream databases, and they include databases such as web-server click data, market sales data, data from sensor networks, and network traffic measurement. Many high utility pattern mining and stream pattern mining methods have been proposed so far. However, they have a limitation that they are not suitable to analyze these databases, because they find valid patterns by analyzing a database with only some of the features described above. Therefore, knowledge-based software about how to find meaningful information efficiently by analyzing databases with these characteristics is required. In this article, we propose an intelligent information system that calculates the influence of the insertion time of each batch in a large-scale stream database by applying the sliding window model and mines recent high utility patterns without generating candidate patterns. In addition, a novel list-based data structure is suggested for a fast and efficient management of the time-sensitive stream databases. Moreover, our technique is compared with state-of-the-art algorithms through various experiments using real datasets and synthetic datasets. The experimental results show that our approach outperforms the previously proposed methods in terms of runtime, memory usage, and scalability.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3119260152",
    "type": "article"
  },
  {
    "title": "TWIST-GAN: Towards Wavelet Transform and Transferred GAN for Spatio-Temporal Single Image Super Resolution",
    "doi": "https://doi.org/10.1145/3456726",
    "publication_date": "2021-12-20",
    "publication_year": 2021,
    "authors": "Fayaz Ali Dharejo; Farah Deeba; Yuanchun Zhou; Bhagwan Das; Munsif Ali Jatoi; Muhammad Zawish; Yi Du; Xuezhi Wang",
    "corresponding_authors": "",
    "abstract": "Single Image Super-resolution (SISR) produces high-resolution images with fine spatial resolutions from aremotely sensed image with low spatial resolution. Recently, deep learning and generative adversarial networks(GANs) have made breakthroughs for the challenging task of single image super-resolution (SISR). However, thegenerated image still suffers from undesirable artifacts such as, the absence of texture-feature representationand high-frequency information. We propose a frequency domain-based spatio-temporal remote sensingsingle image super-resolution technique to reconstruct the HR image combined with generative adversarialnetworks (GANs) on various frequency bands (TWIST-GAN). We have introduced a new method incorporatingWavelet Transform (WT) characteristics and transferred generative adversarial network. The LR image hasbeen split into various frequency bands by using the WT, whereas, the transfer generative adversarial networkpredicts high-frequency components via a proposed architecture. Finally, the inverse transfer of waveletsproduces a reconstructed image with super-resolution. The model is first trained on an external DIV2 Kdataset and validated with the UC Merceed Landsat remote sensing dataset and Set14 with each image sizeof 256x256. Following that, transferred GANs are used to process spatio-temporal remote sensing images inorder to minimize computation cost differences and improve texture information. The findings are comparedqualitatively and qualitatively with the current state-of-art approaches. In addition, we saved about 43% of theGPU memory during training and accelerated the execution of our simplified version by eliminating batchnormalization layers.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W3152711328",
    "type": "article"
  },
  {
    "title": "Indirectly Supervised Anomaly Detection of Clinically Meaningful Health Events from Smart Home Data",
    "doi": "https://doi.org/10.1145/3439870",
    "publication_date": "2021-02-11",
    "publication_year": 2021,
    "authors": "Jessamyn Dahmen; Diane J. Cook",
    "corresponding_authors": "",
    "abstract": "Anomaly detection techniques can extract a wealth of information about unusual events. Unfortunately, these methods yield an abundance of findings that are not of interest, obscuring relevant anomalies. In this work, we improve upon traditional anomaly detection methods by introducing Isudra, an Indirectly-Supervised Detector of Relevant Anomalies from time series data. Isudra employs Bayesian optimization to select time scales, features, base detector algorithms, and algorithm hyperparameters that increase true positive and decrease false positive detection. This optimization is driven by a small amount of example anomalies, driving an indirectly-supervised approach to anomaly detection. Additionally, we enhance the approach by introducing a warm start method that reduces optimization time between similar problems. We validate the feasibility of Isudra to detect clinically-relevant behavior anomalies from over 2 million sensor readings collected in 5 smart homes, reflecting 26 health events. Results indicate that indirectly-supervised anomaly detection outperforms both supervised and unsupervised algorithms at detecting instances of health-related anomalies such as falls, nocturia, depression, and weakness.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3133320643",
    "type": "article"
  },
  {
    "title": "Contrastive Trajectory Learning for Tour Recommendation",
    "doi": "https://doi.org/10.1145/3462331",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Fan Zhou; Pengyu Wang; Xovee Xu; Wenxin Tai; Goce Trajcevski",
    "corresponding_authors": "",
    "abstract": "The main objective of Personalized Tour Recommendation (PTR) is to generate a sequence of point-of-interest (POIs) for a particular tourist, according to the user-specific constraints such as duration time, start and end points, the number of attractions planned to visit, and so on. Previous PTR solutions are based on either heuristics for solving the orienteering problem to maximize a global reward with a specified budget or approaches attempting to learn user visiting preferences and transition patterns with the stochastic process or recurrent neural networks. However, existing learning methodologies rely on historical trips to train the model and use the next visited POI as the supervised signal, which may not fully capture the coherence of preferences and thus recommend similar trips to different users, primarily due to the data sparsity problem and long-tailed distribution of POI popularity. This work presents a novel tour recommendation model by distilling knowledge and supervision signals from the trips in a self-supervised manner. We propose Contrastive Trajectory Learning for Tour Recommendation (CTLTR), which utilizes the intrinsic POI dependencies and traveling intent to discover extra knowledge and augments the sparse data via pre-training auxiliary self-supervised objectives. CTLTR provides a principled way to characterize the inherent data correlations while tackling the implicit feedback and weak supervision problems by learning robust representations applicable for tour planning. We introduce a hierarchical recurrent encoder-decoder to identify tourists’ intentions and use the contrastive loss to discover subsequence semantics and their sequential patterns through maximizing the mutual information. Additionally, we observe that a data augmentation step as the preliminary of contrastive learning can solve the overfitting issue resulting from data sparsity. We conduct extensive experiments on a range of real-world datasets and demonstrate that our model can significantly improve the recommendation performance over the state-of-the-art baselines in terms of both recommendation accuracy and visiting orders.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3217176841",
    "type": "article"
  },
  {
    "title": "Auto-weighted Robust Federated Learning with Corrupted Data Sources",
    "doi": "https://doi.org/10.1145/3517821",
    "publication_date": "2022-02-23",
    "publication_year": 2022,
    "authors": "Shenghui Li; Edith C.‐H. Ngai; Fanghua Ye; Thiemo Voigt",
    "corresponding_authors": "",
    "abstract": "Federated learning provides a communication-efficient and privacy-preserving training process by enabling learning statistical models with massive participants without accessing their local data. Standard federated learning techniques that naively minimize an average loss function are vulnerable to data corruptions from outliers, systematic mislabeling, or even adversaries. In this article, we address this challenge by proposing Auto-weighted Robust Federated Learning ( ARFL ), a novel approach that jointly learns the global model and the weights of local updates to provide robustness against corrupted data sources. We prove a learning bound on the expected loss with respect to the predictor and the weights of clients, which guides the definition of the objective for robust federated learning. We present an objective that minimizes the weighted sum of empirical risk of clients with a regularization term, where the weights can be allocated by comparing the empirical risk of each client with the average empirical risk of the best \\( p \\) clients. This method can downweight the clients with significantly higher losses, thereby lowering their contributions to the global model. We show that this approach achieves robustness when the data of corrupted clients is distributed differently from the benign ones. To optimize the objective function, we propose a communication-efficient algorithm based on the blockwise minimization paradigm. We conduct extensive experiments on multiple benchmark datasets, including CIFAR-10, FEMNIST, and Shakespeare, considering different neural network models. The results show that our solution is robust against different scenarios, including label shuffling, label flipping, and noisy features, and outperforms the state-of-the-art methods in most scenarios.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3123411108",
    "type": "article"
  },
  {
    "title": "Make More Connections: Urban Traffic Flow Forecasting with Spatiotemporal Adaptive Gated Graph Convolution Network",
    "doi": "https://doi.org/10.1145/3488902",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Bin Lü; Xiaoying Gan; Haiming Jin; Luoyi Fu; Xinbing Wang; Haisong Zhang",
    "corresponding_authors": "",
    "abstract": "Urban traffic flow forecasting is a critical issue in intelligent transportation systems. Due to the complexity and uncertainty of urban road conditions, how to capture the dynamic spatiotemporal correlation and make accurate predictions is very challenging. In most of existing works, urban road network is often modeled as a fixed graph based on local proximity. However, such modeling is not sufficient to describe the dynamics of the road network and capture the global contextual information. In this paper, we consider constructing the road network as a dynamic weighted graph through attention mechanism. Furthermore, we propose to seek both spatial neighbors and semantic neighbors to make more connections between road nodes. We propose a novel Spatiotemporal Adaptive Gated Graph Convolution Network ( STAG-GCN ) to predict traffic conditions for several time steps ahead. STAG-GCN mainly consists of two major components: (1) multivariate self-attention Temporal Convolution Network ( TCN ) is utilized to capture local and long-range temporal dependencies across recent, daily-periodic and weekly-periodic observations; (2) mix-hop AG-GCN extracts selective spatial and semantic dependencies within multi-layer stacking through adaptive graph gating mechanism and mix-hop propagation mechanism. The output of different components are weighted fused to generate the final prediction results. Extensive experiments on two real-world large scale urban traffic dataset have verified the effectiveness, and the multi-step forecasting performance of our proposed models outperforms the state-of-the-art baselines.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4205945573",
    "type": "article"
  },
  {
    "title": "Federated Dynamic Graph Neural Networks with Secure Aggregation for Video-based Distributed Surveillance",
    "doi": "https://doi.org/10.1145/3501808",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Meng Jiang; Taeho Jung; Ryan Karl; Tong Zhao",
    "corresponding_authors": "",
    "abstract": "Distributed surveillance systems have the ability to detect, track, and snapshot objects moving around in a certain space. The systems generate video data from multiple personal devices or street cameras. Intelligent video-analysis models are needed to learn dynamic representation of the objects for detection and tracking. Can we exploit the structural and dynamic information without storing the spatiotemporal video data at a central server that leads to a violation of user privacy? In this work, we introduce Federated Dynamic Graph Neural Network (Feddy), a distributed and secured framework to learn the object representations from graph sequences: (1) It aggregates structural information from nearby objects in the current graph as well as dynamic information from those in the previous graph. It uses a self-supervised loss of predicting the trajectories of objects. (2) It is trained in a federated learning manner. The centrally located server sends the model to user devices. Local models on the respective user devices learn and periodically send their learning to the central server without ever exposing the user’s data to server. (3) Studies showed that the aggregated parameters could be inspected though decrypted when broadcast to clients for model synchronizing, after the server performed a weighted average. We design an appropriate aggregation mechanism of secure aggregation primitives that can protect the security and privacy in federated learning with scalability. Experiments on four video camera datasets as well as simulation demonstrate that Feddy achieves great effectiveness and security.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4214578516",
    "type": "article"
  },
  {
    "title": "TreeSketchNet: From Sketch to 3D Tree Parameters Generation",
    "doi": "https://doi.org/10.1145/3579831",
    "publication_date": "2023-01-09",
    "publication_year": 2023,
    "authors": "Gilda Manfredi; Nicola Capece; Ugo Erra; Monica Gruosso",
    "corresponding_authors": "",
    "abstract": "3D modeling of non-linear objects from stylized sketches is a challenge even for experts in Computer Graphics (CG). The extrapolation of objects parameters from a stylized sketch is a very complex and cumbersome task. In the present study, we propose a broker system that mediates between the modeler and the 3D modelling software and can transform a stylized sketch of a tree into a complete 3D model. The input sketches do not need to be accurate or detailed, and only need to represent a rudimentary outline of the tree that the modeler wishes to 3D-model. Our approach is based on a well-defined Deep Neural Network (DNN) architecture, we called TreeSketchNet (TSN), based on convolutions and able to generate Weber and Penn parameters that can be interpreted by the modelling software to generate a 3D model of a tree starting from a simple sketch. The training dataset consists of Synthetically-Generated \\revision{(SG)} sketches that are associated with Weber-Penn parameters generated by a dedicated Blender modelling software add-on. The accuracy of the proposed method is demonstrated by testing the TSN with both synthetic and hand-made sketches. Finally, we provide a qualitative analysis of our results, by evaluating the coherence of the predicted parameters with several distinguishing features.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4313828784",
    "type": "article"
  },
  {
    "title": "Graph Neural Rough Differential Equations for Traffic Forecasting",
    "doi": "https://doi.org/10.1145/3604808",
    "publication_date": "2023-06-15",
    "publication_year": 2023,
    "authors": "Jeongwhan Choi; Noseong Park",
    "corresponding_authors": "",
    "abstract": "Traffic forecasting is one of the most popular spatio-temporal tasks in the field of machine learning. A prevalent approach in the field is to combine graph convolutional networks and recurrent neural networks for the spatio-temporal processing. There has been fierce competition and many novel methods have been proposed. In this article, we present the method of spatio-temporal graph neural rough differential equation (STG-NRDE). Neural rough differential equations (NRDEs) are a breakthrough concept for processing time-series data. Their main concept is to use the log-signature transform to convert a time-series sample into a relatively shorter series of feature vectors. We extend the concept and design two NRDEs: one for the temporal processing and the other for the spatial processing. After that, we combine them into a single framework. We conduct experiments with 6 benchmark datasets and 27 baselines. STG-NRDE shows the best accuracy in all cases, outperforming all those 27 baselines by non-trivial margins.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4380677112",
    "type": "article"
  },
  {
    "title": "Few-shot Named Entity Recognition: Definition, Taxonomy and Research Directions",
    "doi": "https://doi.org/10.1145/3609483",
    "publication_date": "2023-07-18",
    "publication_year": 2023,
    "authors": "Vincenzo Moscato; Marco Postiglione; Giancarlo Sperlì",
    "corresponding_authors": "",
    "abstract": "Recent years have seen an exponential growth (+98% in 2022 w.r.t. the previous year) of the number of research articles in the few-shot learning field, which aims at training machine learning models with extremely limited available data. The research interest toward few-shot learning systems for Named Entity Recognition (NER) is thus at the same time increasing. NER consists in identifying mentions of pre-defined entities from unstructured text, and serves as a fundamental step in many downstream tasks, such as the construction of Knowledge Graphs, or Question Answering. The need for a NER system able to be trained with few-annotated examples comes in all its urgency in domains where the annotation process requires time, knowledge and expertise (e.g., healthcare, finance, legal), and in low-resource languages. In this survey, starting from a clear definition and description of the few-shot NER (FS-NER) problem, we take stock of the current state-of-the-art and propose a taxonomy which divides algorithms in two macro-categories according to the underlying mechanisms: model-centric and data-centric. For each category, we line-up works as a story to show how the field is moving toward new research directions. Eventually, techniques, limitations, and key aspects are deeply analyzed to facilitate future studies.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4384697538",
    "type": "article"
  },
  {
    "title": "Adversarial Attacks on Deep Reinforcement Learning-based Traffic Signal Control Systems with Colluding Vehicles",
    "doi": "https://doi.org/10.1145/3625236",
    "publication_date": "2023-09-21",
    "publication_year": 2023,
    "authors": "Ao Qu; Yihong Tang; Wei Ma",
    "corresponding_authors": "",
    "abstract": "The rapid advancements of Internet of Things (IoT) and Artificial Intelligence (AI) have catalyzed the development of adaptive traffic control systems (ATCS) for smart cities. In particular, deep reinforcement learning (DRL) models produce state-of-the-art performance and have great potential for practical applications. In the existing DRL-based ATCS, the controlled signals collect traffic state information from nearby vehicles, and then optimal actions (e.g., switching phases) can be determined based on the collected information. The DRL models fully “trust” that vehicles are sending the true information to the traffic signals, making the ATCS vulnerable to adversarial attacks with falsified information. In view of this, this article first time formulates a novel task in which a group of vehicles can cooperatively send falsified information to “cheat” DRL-based ATCS in order to save their total travel time. To solve the proposed task, we develop CollusionVeh , a generic and effective vehicle-colluding framework composed of a road situation encoder, a vehicle interpreter, and a communication mechanism. We employ our framework to attack established DRL-based ATCS and demonstrate that the total travel time for the colluding vehicles can be significantly reduced with a reasonable number of learning episodes, and the colluding effect will decrease if the number of colluding vehicles increases. Additionally, insights and suggestions for the real-world deployment of DRL-based ATCS are provided. The research outcomes could help improve the reliability and robustness of the ATCS and better protect the smart mobility systems.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4386928394",
    "type": "article"
  },
  {
    "title": "Deep Causal Reasoning for Recommendations",
    "doi": "https://doi.org/10.1145/3653985",
    "publication_date": "2024-03-26",
    "publication_year": 2024,
    "authors": "Yaochen Zhu; Jing Yi; Jiayi Xie; Zhenzhong Chen",
    "corresponding_authors": "",
    "abstract": "Traditional recommender systems aim to estimate a user’s rating to an item based on observed ratings from the population. As with all observational studies, hidden confounders, which are factors that affect both item exposures and user ratings, lead to a systematic bias in the estimation. Consequently, causal inference has been introduced in recommendations to address the influence of unobserved confounders. Observing that confounders in recommendations are usually shared among items and are therefore multi-cause confounders, we model the recommendation as a multi-cause multi-outcome (MCMO) inference problem. Specifically, to remedy the confounding bias, we estimate user-specific latent variables that render the item exposures independent Bernoulli trials. The generative distribution is parameterized by a DNN with factorized logistic likelihood and the intractable posteriors are estimated by variational inference. Controlling these factors as substitute confounders, under mild assumptions, can eliminate the bias incurred by multi-cause confounders. Furthermore, we show that MCMO modeling may lead to high variance due to scarce observations associated with the high-dimensional treatment space. Therefore, we theoretically demonstrate that controlling user features as pre-treatment variables can substantially improve sample efficiency and alleviate overfitting. Empirical studies on both simulated and real-world datasets demonstrate that the proposed deep causal recommender shows more robustness to unobserved confounders than state-of-the-art causal recommenders. Codes and datasets are released at https://github.com/yaochenzhu/Deep-Deconf.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4393191443",
    "type": "article"
  },
  {
    "title": "DNSRF: Deep Network-based Semi-NMF Representation Framework",
    "doi": "https://doi.org/10.1145/3670408",
    "publication_date": "2024-06-03",
    "publication_year": 2024,
    "authors": "Dexian Wang; Tianrui Li; Ping Deng; Zhipeng Luo; Pengfei Zhang; Keyu Liu; Wei Huang",
    "corresponding_authors": "",
    "abstract": "Representation learning is an important topic in machine learning, pattern recognition, and data mining research. Among many representation learning approaches, semi-nonnegative matrix factorization (SNMF) is a frequently-used one. However, a typical problem of SNMF is that usually there is no learning rate guidance during the optimization process, which often leads to a poor representation ability. To overcome this limitation, we propose a very general representation learning framework (DNSRF) that is based on deep neural net. Essentially, the parameters of the deep net used to construct the DNSRF algorithms are obtained by matrix element update. In combination with different activation functions, DNSRF can be implemented in various ways. In our experiments, we tested nine instances of our DNSRF framework on six benchmark datasets. In comparison with other state-of-the-art methods, the results demonstrate superior performance of our framework, which is thus shown to have a great representation ability.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4399287622",
    "type": "article"
  },
  {
    "title": "Analysing Utterances in LLM-Based User Simulation for Conversational Search",
    "doi": "https://doi.org/10.1145/3650041",
    "publication_date": "2024-03-05",
    "publication_year": 2024,
    "authors": "Ivan Sekulić; Mohammad Alinannejadi; Fábio Crestani",
    "corresponding_authors": "",
    "abstract": "Clarifying underlying user information needs by asking clarifying questions is an important feature of modern conversational search systems. However, evaluation of such systems through answering prompted clarifying questions requires significant human effort, which can be time-consuming and expensive. In our recent work, we proposed an approach to tackle these issues with a user simulator, USi . Given a description of an information need, USi is capable of automatically answering clarifying questions about the topic throughout the search session. However, while the answers generated by USi are both in line with the underlying information need and in natural language, a deeper understanding of such utterances is lacking. Thus, in this work, we explore utterance formulation of large language model (LLM)–based user simulators. To this end, we first analyze the differences between USi , based on GPT-2, and the next generation of generative LLMs, such as GPT-3. Then, to gain a deeper understanding of LLM-based utterance generation, we compare the generated answers to the recently proposed set of patterns of human-based query reformulations. Finally, we discuss potential applications as well as limitations of LLM-based user simulators and outline promising directions for future work on the topic.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4392471527",
    "type": "article"
  },
  {
    "title": "Federated Momentum Contrastive Clustering",
    "doi": "https://doi.org/10.1145/3653981",
    "publication_date": "2024-03-26",
    "publication_year": 2024,
    "authors": "Runxuan Miao; Erdem Koyuncu",
    "corresponding_authors": "",
    "abstract": "Self-supervised representation learning and deep clustering are mutually beneficial to learn high-quality representations and cluster data simultaneously in centralized settings. However, it is not always feasible to gather large amounts of data at a central entity, considering data privacy requirements and computational resources. Federated Learning (FL) has been developed successfully to aggregate a global model while training on distributed local data, respecting the data privacy of edge devices. However, most FL research effort focuses on supervised learning algorithms. A fully unsupervised federated clustering scheme has not been considered in the existing literature. We present federated momentum contrastive clustering (FedMCC), a generic federated clustering framework that can not only cluster data automatically but also extract discriminative representations training from distributed local data over multiple users. In FedMCC, we demonstrate a two-stage federated learning paradigm where the first stage aims to learn differentiable instance embeddings and the second stage accounts for clustering data automatically. The experimental results show that FedMCC not only achieves superior clustering performance but also outperforms several existing federated self-supervised methods for linear evaluation and semi-supervised learning tasks. Additionally, FedMCC can easily be adapted to ordinary centralized clustering through what we call momentum contrastive clustering (MCC). We show that MCC achieves state-of-the-art clustering accuracy results in certain datasets such as STL-10 and ImageNet-10. We also present a method to reduce the memory footprint of our clustering schemes.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4393191392",
    "type": "article"
  },
  {
    "title": "Cross-Domain HAR: Few Shot Transfer Learning for Human Activity Recognition",
    "doi": "https://doi.org/10.1145/3704921",
    "publication_date": "2024-11-21",
    "publication_year": 2024,
    "authors": "Megha Thukral; Harish Haresamudram; Thomas Ploetz",
    "corresponding_authors": "",
    "abstract": "The ubiquitous availability of smartphones and smartwatches with integrated inertial measurement units (IMUs) enables straightforward capturing of human activities through collecting movement data. For specific applications of sensor based human activity recognition (HAR), however, logistical challenges and burgeoning costs render especially the ground truth annotation of such data a difficult endeavor, resulting in limited scale and diversity of datasets available for deriving effective HAR systems and less than ideal recognition capabilities. Transfer learning, i.e., leveraging publicly available labeled datasets to first learn useful representations that can then be fine-tuned using limited amounts of labeled data from a target domain, can alleviate some of the performance issues of contemporary HAR systems. Yet they can fail when the differences between source and target conditions are too large and / or only few samples from a target application domain are available – each of which are typical challenges in real-world human activity recognition scenarios. In this paper, we present an approach for economic use of publicly available labeled HAR datasets for effective transfer learning. We introduce a novel transfer learning framework–Cross-Domain HAR–which follows the teacher-student self-training paradigm to more effectively recognize activities with very limited label information. It bridges conceptual gaps between source and target domains, including sensor locations and type of activities. Cross-Domain HAR enables substantial performance improvements over the state-of-the-art in sensor-based HAR scenarios. Through our extensive experimental evaluation on a range of benchmark datasets we specifically demonstrate the effectiveness of our approach for practically relevant few shot activity recognition scenarios. We also present a detailed analysis into how the individual components of our framework affect downstream performance and provide practical suggestions for using the framework in real-world applications.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4404572660",
    "type": "article"
  },
  {
    "title": "Scalable Affiliation Recommendation using Auxiliary Networks",
    "doi": "https://doi.org/10.1145/2036264.2036267",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Vishvas Vasuki; Nagarajan Natarajan; Zhengdong Lu; Berkant Savas; Inderjit S. Dhillon",
    "corresponding_authors": "",
    "abstract": "Social network analysis has attracted increasing attention in recent years. In many social networks, besides friendship links among users, the phenomenon of users associating themselves with groups or communities is common. Thus, two networks exist simultaneously: the friendship network among users, and the affiliation network between users and groups. In this article, we tackle the affiliation recommendation problem, where the task is to predict or suggest new affiliations between users and communities, given the current state of the friendship and affiliation networks. More generally, affiliations need not be community affiliations---they can be a user’s taste, so affiliation recommendation algorithms have applications beyond community recommendation. In this article, we show that information from the friendship network can indeed be fruitfully exploited in making affiliation recommendations. Using a simple way of combining these networks, we suggest two models of user-community affinity for the purpose of making affiliation recommendations: one based on graph proximity, and another using latent factors to model users and communities. We explore the affiliation recommendation algorithms suggested by these models and evaluate these algorithms on two real-world networks, Orkut and Youtube. In doing so, we motivate and propose a way of evaluating recommenders, by measuring how good the top 50 recommendations are for the average user, and demonstrate the importance of choosing the right evaluation strategy. The algorithms suggested by the graph proximity model turn out to be the most effective. We also introduce scalable versions of these algorithms, and demonstrate their effectiveness. This use of link prediction techniques for the purpose of affiliation recommendation is, to our knowledge, novel.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W1986211117",
    "type": "article"
  },
  {
    "title": "A Case Study of Collaboration and Reputation in Social Web Search",
    "doi": "https://doi.org/10.1145/2036264.2036268",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Kevin McNally; Michael P. O’Mahony; Maurice Coyle; Peter Briggs; Barry Smyth",
    "corresponding_authors": "",
    "abstract": "Although collaborative searching is not supported by mainstream search engines, recent research has highlighted the inherently collaborative nature of many Web search tasks. In this article, we describe HeyStaks, a collaborative Web search framework that is designed to complement mainstream search engines. At search time, HeyStaks learns from the search activities of other users and leverages this information to generate recommendations based on results that others have found relevant for similar searches. The key contribution of this article is to extend the HeyStaks social search model by considering the search expertise, or reputation, of HeyStaks users and using this information to enhance the result recommendation process. In particular, we propose a reputation model for HeyStaks users that utilise the implicit collaboration events that take place between users as recommendations are made and selected. We describe a live-user trial of HeyStaks that demonstrates the relevance of its core recommendations and the ability of the reputation model to further improve recommendation quality. Our findings indicate that incorporating reputation into the recommendation process further improves the relevance of HeyStaks recommendations by up to 40%.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2002858145",
    "type": "article"
  },
  {
    "title": "Opinion formation under costly expression",
    "doi": "https://doi.org/10.1145/1858948.1858953",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Fang Wu; Bernardo A. Huberman",
    "corresponding_authors": "",
    "abstract": "Opinions play an important role in trust building and the creation of consensus about issues and products and a number of studies have focused on the design, evaluation, and utilization of online opinion systems. However, little effort has been spent on the dynamic aspects of online opinion formation. In this article, we study the dynamics of online opinion expression by analyzing the temporal evolution of vey large sets of user views and determine that in the course of time, later opinions tend to show a big difference with earlier opinions, which moderates the average opinion to the less extreme. Online posters also tend to disagree with previous opinions when the cost of expression is high.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2135455985",
    "type": "article"
  },
  {
    "title": "Intelligent systems and technology for integrative and predictive medicine",
    "doi": "https://doi.org/10.1145/2438653.2438667",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Fei‐Yue Wang; Pak Kin Wong",
    "corresponding_authors": "",
    "abstract": "One of the principal goals in medicine is to determine and implement the best treatment for patients through fastidious estimation of the effects and benefits of therapeutic procedures. The inherent complexities of physiological and pathological networks that span across orders of magnitude in time and length scales, however, represent fundamental hurdles in determining effective treatments for patients. Here we argue for a new approach, called ACP-based approach that combines artificial (societies), computational (experiments) and parallel (execution)methods in intelligent systems and technology for integrative and predictive medicine, or more general, precision medicine and smart health management. The advent of artificial societies that collect the clinically relevant information in prognostics and therapeutics provides a promising platform for organizing and experimenting complex physiological systems toward integrative medicine. The ability of computational experiments to analyze distinct, interactive systems such as the host mechanisms, pathological pathways, therapeutic strategies as well as other factors using the artificial systems will enable control and management through parallel execution of real and arficial systems concurrently within the integrative medicine context. The development of this framework in integrative medicine fueled by close collaborations between physicians, engineers, and scientists will result in preventive and predictive practices of personal, proactive, and precision nature, including rational combinatorial treatments, adaptive therapeutics, and patient-oriented disease management.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2135635648",
    "type": "article"
  },
  {
    "title": "Evaluation of Folksonomy Induction Algorithms",
    "doi": "https://doi.org/10.1145/2337542.2337559",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Markus Strohmaier; Denis Helić; Dominik C. Benz; Christian Körner; Roman Kern",
    "corresponding_authors": "",
    "abstract": "Algorithms for constructing hierarchical structures from user-generated metadata have caught the interest of the academic community in recent years. In social tagging systems, the output of these algorithms is usually referred to as folksonomies (from folk-generated taxonomies). Evaluation of folksonomies and folksonomy induction algorithms is a challenging issue complicated by the lack of golden standards, lack of comprehensive methods and tools as well as a lack of research and empirical/simulation studies applying these methods. In this article, we report results from a broad comparative study of state-of-the-art folksonomy induction algorithms that we have applied and evaluated in the context of five social tagging systems. In addition to adopting semantic evaluation techniques, we present and adopt a new technique that can be used to evaluate the usefulness of folksonomies for navigation . Our work sheds new light on the properties and characteristics of state-of-the-art folksonomy induction algorithms and introduces a new pragmatic approach to folksonomy evaluation, while at the same time identifying some important limitations and challenges of folksonomy evaluation. Our results show that folksonomy induction algorithms specifically developed to capture intuitions of social tagging systems outperform traditional hierarchical clustering techniques. To the best of our knowledge, this work represents the largest and most comprehensive evaluation study of state-of-the-art folksonomy induction algorithms to date.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2083412755",
    "type": "article"
  },
  {
    "title": "Batch Mode Active Learning for Networked Data",
    "doi": "https://doi.org/10.1145/2089094.2089109",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Lixin Shi; Yuhang Zhao; Jie Tang",
    "corresponding_authors": "",
    "abstract": "We study a novel problem of batch mode active learning for networked data. In this problem, data instances are connected with links and their labels are correlated with each other, and the goal of batch mode active learning is to exploit the link-based dependencies and node-specific content information to actively select a batch of instances to query the user for learning an accurate model to label unknown instances in the network. We present three criteria (i.e., minimum redundancy, maximum uncertainty, and maximum impact) to quantify the informativeness of a set of instances, and formalize the batch mode active learning problem as selecting a set of instances by maximizing an objective function which combines both link and content information. As solving the objective function is NP-hard, we present an efficient algorithm to optimize the objective function with a bounded approximation rate. To scale to real large networks, we develop a parallel implementation of the algorithm. Experimental results on both synthetic datasets and real-world datasets demonstrate the effectiveness and efficiency of our approach.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W1982973280",
    "type": "article"
  },
  {
    "title": "Pervasive social context",
    "doi": "https://doi.org/10.1145/2483669.2483679",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Daniel Schuster; Alberto Rosi; Marco Mamei; Thomas Springer; Markus Endler; Franco Zambonelli",
    "corresponding_authors": "",
    "abstract": "As pervasive computing meets social networks, there is a fast growing research field called pervasive social computing. Applications in this area exploit the richness of information arising out of people using sensor-equipped pervasive devices in their everyday life combined with intense use of different social networking services. We call this set of information pervasive social context. We provide a taxonomy to classify pervasive social context along the dimensions space, time, people, and information source (STiPI) as well as commenting on the type and reason for creating such context. A survey of recent research shows the applicability and usefulness of the taxonomy in classifying and assessing applications and systems in the area of pervasive social computing. Finally, we present some research challenges in this area and illustrate how they affect the systems being surveyed.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2025430214",
    "type": "article"
  },
  {
    "title": "An Adaptive Agent for Negotiating with People in Different Cultures",
    "doi": "https://doi.org/10.1145/2036264.2036272",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Kobi Gal; Sarit Kraus; Michele J. Gelfand; Hilal Khashan; Elizabeth Salmón",
    "corresponding_authors": "",
    "abstract": "The rapid dissemination of technology such as the Internet across geographical and ethnic lines is opening up opportunities for computer agents to negotiate with people of diverse cultural and organizational affiliations. To negotiate proficiently with people in different cultures, agents need to be able to adapt to the way behavioral traits of other participants change over time. This article describes a new agent for repeated bilateral negotiation that was designed to model and adapt its behavior to the individual traits exhibited by its negotiation partner. The agent’s decision-making model combined a social utility function that represented the behavioral traits of the other participant, as well as a rule-based mechanism that used the utility function to make decisions in the negotiation process. The agent was deployed in a strategic setting in which both participants needed to complete their individual tasks by reaching agreements and exchanging resources, the number of negotiation rounds was not fixed in advance and agreements were not binding. The agent negotiated with human subjects in the United States and Lebanon in situations that varied the dependency relationships between participants at the onset of negotiation. There was no prior data available about the way people would respond to different negotiation strategies in these two countries. Results showed that the agent was able to adopt a different negotiation strategy to each country. Its average performance across both countries was equal to that of people. However, the agent outperformed people in the United States, because it learned to make offers that were likely to be accepted by people, while being more beneficial to the agent than to people. In contrast, the agent was outperformed by people in Lebanon, because it adopted a high reliability measure which allowed people to take advantage of it. These results provide insight for human-computer agent designers in the types of multicultural settings that we considered, showing that adaptation is a viable approach towards the design of computer agents to negotiate with people when there is no prior data of their behavior.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2109252727",
    "type": "article"
  },
  {
    "title": "Mining Concept Sequences from Large-Scale Search Logs for Context-Aware Query Suggestion",
    "doi": "https://doi.org/10.1145/2036264.2036281",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Zhen Liao; Daxin Jiang; Enhong Chen; Jian Pei; Huanhuan Cao; Hang Li",
    "corresponding_authors": "",
    "abstract": "Query suggestion plays an important role in improving usability of search engines. Although some recently proposed methods provide query suggestions by mining query patterns from search logs, none of them models the immediately preceding queries as context systematically, and uses context information effectively in query suggestions. Context-aware query suggestion is challenging in both modeling context and scaling up query suggestion using context. In this article, we propose a novel context-aware query suggestion approach. To tackle the challenges, our approach consists of two stages. In the first, offline model-learning stage , to address data sparseness, queries are summarized into concepts by clustering a click-through bipartite. A concept sequence suffix tree is then constructed from session data as a context-aware query suggestion model. In the second, online query suggestion stage , a user’s search context is captured by mapping the query sequence submitted by the user to a sequence of concepts. By looking up the context in the concept sequence suffix tree, we suggest to the user context-aware queries. We test our approach on large-scale search logs of a commercial search engine containing 4.0 billion Web queries, 5.9 billion clicks, and 1.87 billion search sessions. The experimental results clearly show that our approach outperforms three baseline methods in both coverage and quality of suggestions.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2171045163",
    "type": "article"
  },
  {
    "title": "Feature-Based Visual Sentiment Analysis of Text Document Streams",
    "doi": "https://doi.org/10.1145/2089094.2089102",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Christian Rohrdantz; Ming Hao; Umeshwar Dayal; Lars-Erik Haug; Daniel A. Keim",
    "corresponding_authors": "",
    "abstract": "This article describes automatic methods and interactive visualizations that are tightly coupled with the goal to enable users to detect interesting portions of text document streams. In this scenario the interestingness is derived from the sentiment, temporal density, and context coherence that comments about features for different targets (e.g., persons, institutions, product attributes, topics, etc.) have. Contributions are made at different stages of the visual analytics pipeline, including novel ways to visualize salient temporal accumulations for further exploration. Moreover, based on the visualization, an automatic algorithm aims to detect and preselect interesting time interval patterns for different features in order to guide analysts. The main target group for the suggested methods are business analysts who want to explore time-stamped customer feedback to detect critical issues. Finally, application case studies on two different datasets and scenarios are conducted and an extensive evaluation is provided for the presented intelligent visual interface for feature-based sentiment exploration over time.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2149310982",
    "type": "article"
  },
  {
    "title": "Using Health-Consumer-Contributed Data to Detect Adverse Drug Reactions by Association Mining with Temporal Analysis",
    "doi": "https://doi.org/10.1145/2700482",
    "publication_date": "2015-07-13",
    "publication_year": 2015,
    "authors": "Haodong Yang; Christopher C. Yang",
    "corresponding_authors": "",
    "abstract": "Since adverse drug reactions (ADRs) represent a significant health problem all over the world, ADR detection has become an important research topic in drug safety surveillance. As many potential ADRs cannot be detected though premarketing review, drug safety currently depends heavily on postmarketing surveillance. Particularly, current postmarketing surveillance in the United States primarily relies on the FDA Adverse Event Reporting System (FAERS). However, the effectiveness of such spontaneous reporting systems for ADR detection is not as good as expected because of the extremely high underreporting ratio of ADRs. Moreover, it often takes the FDA years to complete the whole process of collecting reports, investigating cases, and releasing alerts. Given the prosperity of social media, many online health communities are publicly available for health consumers to share and discuss any healthcare experience such as ADRs they are suffering. Such health-consumer-contributed content is timely and informative, but this data source still remains untapped for postmarketing drug safety surveillance. In this study, we propose to use (1) association mining to identify the relations between a drug and an ADR and (2) temporal analysis to detect drug safety signals at the early stage. We collect data from MedHelp and use the FDA's alerts and information of drug labeling revision as the gold standard to evaluate the effectiveness of our approach. The experiment results show that health-related social media is a promising source for ADR detection, and our proposed techniques are effective to identify early ADR signals.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2248914217",
    "type": "article"
  },
  {
    "title": "On-Device Mobile Landmark Recognition Using Binarized Descriptor with Multifeature Fusion",
    "doi": "https://doi.org/10.1145/2795234",
    "publication_date": "2015-10-07",
    "publication_year": 2015,
    "authors": "Tao Guan; Yuesong Wang; Liya Duan; Rongrong Ji",
    "corresponding_authors": "",
    "abstract": "Along with the exponential growth of high-performance mobile devices, on-device Mobile Landmark Recognition (MLR) has recently attracted increasing research attention. However, the latency and accuracy of automatic recognition remain as bottlenecks against its real-world usage. In this article, we introduce a novel framework that combines interactive image segmentation with multifeature fusion to achieve improved MLR with high accuracy. First, we propose an effective vector binarization method to reduce the memory usage of image descriptors extracted on-device, which maintains comparable recognition accuracy to the original descriptors. Second, we design a location-aware fusion algorithm that can fuse multiple visual features into a compact yet discriminative image descriptor to improve on-device efficiency. Third, a user-friendly interaction scheme is developed that enables interactive foreground/background segmentation to largely improve recognition accuracy. Experimental results demonstrate the effectiveness of the proposed algorithms for on-device MLR applications.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2047978359",
    "type": "article"
  },
  {
    "title": "Effective Social Graph Deanonymization Based on Graph Structure and Descriptive Information",
    "doi": "https://doi.org/10.1145/2700836",
    "publication_date": "2015-07-13",
    "publication_year": 2015,
    "authors": "Hao Fu; Aston Zhang; Xing Xie",
    "corresponding_authors": "",
    "abstract": "The study of online social networks has attracted increasing interest. However, concerns are raised for the privacy risks of user data since they have been frequently shared among researchers, advertisers, and application developers. To solve this problem, a number of anonymization algorithms have been recently developed for protecting the privacy of social graphs. In this article, we proposed a graph node similarity measurement in consideration with both graph structure and descriptive information, and a deanonymization algorithm based on the measurement. Using the proposed algorithm, we evaluated the privacy risks of several typical anonymization algorithms on social graphs with thousands of nodes from Microsoft Academic Search, LiveJournal, and the Enron email dataset, and a social graph with millions of nodes from Tencent Weibo. Our results showed that the proposed algorithm was efficient and effective to deanonymize social graphs without any initial seed mappings. Based on the experiments, we also pointed out suggestions on how to better maintain the data utility while preserving privacy.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2258577634",
    "type": "article"
  },
  {
    "title": "A Hybrid Multigroup Coclustering Recommendation Framework Based on Information Fusion",
    "doi": "https://doi.org/10.1145/2700465",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Shanshan Huang; Jun Ma; Peizhe Cheng; Shuaiqiang Wang",
    "corresponding_authors": "",
    "abstract": "Collaborative Filtering (CF) is one of the most successful algorithms in recommender systems. However, it suffers from data sparsity and scalability problems. Although many clustering techniques have been incorporated to alleviate these two problems, most of them fail to achieve further significant improvement in recommendation accuracy. First of all, most of them assume each user or item belongs to a single cluster. Since usually users can hold multiple interests and items may belong to multiple categories, it is more reasonable to assume that users and items can join multiple clusters (groups), where each cluster is a subset of like-minded users and items they prefer. Furthermore, most of the clustering-based CF models only utilize historical rating information in the clustering procedure but ignore other data resources in recommender systems such as the social connections of users and the correlations between items. In this article, we propose HMCoC, a Hybrid Multigroup CoClustering recommendation framework, which can cluster users and items into multiple groups simultaneously with different information resources. In our framework, we first integrate information of user--item rating records, user social networks, and item features extracted from the DBpedia knowledge base. We then use an optimization method to mine meaningful user--item groups with all the information. Finally, we apply the conventional CF method in each cluster to make predictions. By merging the predictions from each cluster, we generate the top-n recommendations to the target users for return. Extensive experimental results demonstrate the superior performance of our approach in top-n recommendation in terms of MAP, NDCG, and F1 compared with other clustering-based CF models.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W1990897852",
    "type": "article"
  },
  {
    "title": "Traffic Information Publication with Privacy Preservation",
    "doi": "https://doi.org/10.1145/2542666",
    "publication_date": "2014-09-18",
    "publication_year": 2014,
    "authors": "Sashi Gurung; Dan Lin; Wei Jiang; Ali R. Hurson; Rui Zhang",
    "corresponding_authors": "",
    "abstract": "We are experiencing the expanding use of location-based services such as AT&amp;T’s TeleNav GPS Navigator and Intel’s Thing Finder. Existing location-based services have collected a large amount of location data, which has great potential for statistical usage in applications like traffic flow analysis, infrastructure planning, and advertisement dissemination. The key challenge is how to wisely use the data without violating each user’s location privacy concerns. In this article, we first identify a new privacy problem, namely, the inference-route problem, and then present our anonymization algorithms for privacy-preserving trajectory publishing. The experimental results have demonstrated that our approach outperforms the latest related work in terms of both efficiency and effectiveness.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2039049533",
    "type": "article"
  },
  {
    "title": "Constitutive and regulative specifications of commitment protocols",
    "doi": "https://doi.org/10.1145/2438653.2438657",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Matteo Baldoni; Cristina Baroglio; Elisa Marengo; Viviana Patti",
    "corresponding_authors": "",
    "abstract": "Interaction protocols play a fundamental role in multiagent systems. In this work, after analyzing the trends that are emerging not only from research on multiagent interaction protocols but also from neighboring fields, like research on workflows and business processes, we propose a novel definition of commitment-based interaction protocols, that is characterized by the decoupling of the constitutive and the regulative specifications and that explicitly foresees a representation of the latter based on constraints among commitments. A clear distinction between the two representations has many advantages, mainly residing in a greater openness of multiagent systems, and an easier reuse of protocols and of action definitions. A language, named 2CL, for writing regulative specifications is also given together with a designer-oriented graphical notation.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2055419109",
    "type": "article"
  },
  {
    "title": "VSRank",
    "doi": "https://doi.org/10.1145/2542048",
    "publication_date": "2014-07-17",
    "publication_year": 2014,
    "authors": "Shuaiqiang Wang; Jiankai Sun; Byron J. Gao; Jun Ma",
    "corresponding_authors": "",
    "abstract": "Collaborative filtering (CF) is an effective technique addressing the information overload problem. CF approaches generally fall into two categories: rating based and ranking based. The former makes recommendations based on historical rating scores of items and the latter based on their rankings. Ranking-based CF has demonstrated advantages in recommendation accuracy, being able to capture the preference similarity between users even if their rating scores differ significantly. In this study, we propose VSRank, a novel framework that seeks accuracy improvement of ranking-based CF through adaptation of the vector space model. In VSRank, we consider each user as a document and his or her pairwise relative preferences as terms. We then use a novel degree-specialty weighting scheme resembling TF-IDF to weight the terms. Extensive experiments on benchmarks in comparison with the state-of-the-art approaches demonstrate the promise of our approach.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2068029998",
    "type": "article"
  },
  {
    "title": "Online Planning for Large Markov Decision Processes with Hierarchical Decomposition",
    "doi": "https://doi.org/10.1145/2717316",
    "publication_date": "2015-07-15",
    "publication_year": 2015,
    "authors": "Aijun Bai; Feng Wu; Xiaoping Chen",
    "corresponding_authors": "",
    "abstract": "Markov decision processes (MDPs) provide a rich framework for planning under uncertainty. However, exactly solving a large MDP is usually intractable due to the “curse of dimensionality”— the state space grows exponentially with the number of state variables. Online algorithms tackle this problem by avoiding computing a policy for the entire state space. On the other hand, since online algorithm has to find a near-optimal action online in almost real time, the computation time is often very limited. In the context of reinforcement learning, MAXQ is a value function decomposition method that exploits the underlying structure of the original MDP and decomposes it into a combination of smaller subproblems arranged over a task hierarchy. In this article, we present MAXQ-OP—a novel online planning algorithm for large MDPs that utilizes MAXQ hierarchical decomposition in online settings. Compared to traditional online planning algorithms, MAXQ-OP is able to reach much more deeper states in the search tree with relatively less computation time by exploiting MAXQ hierarchical decomposition online. We empirically evaluate our algorithm in the standard Taxi domain—a common benchmark for MDPs—to show the effectiveness of our approach. We have also conducted a long-term case study in a highly complex simulated soccer domain and developed a team named WrightEagle that has won five world champions and five runners-up in the recent 10 years of RoboCup Soccer Simulation 2D annual competitions. The results in the RoboCup domain confirm the scalability of MAXQ-OP to very large domains.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W1921016406",
    "type": "article"
  },
  {
    "title": "Sponsored Search Auctions",
    "doi": "https://doi.org/10.1145/2668108",
    "publication_date": "2015-01-23",
    "publication_year": 2015,
    "authors": "Tao Qin; Wei Chen; Tie‐Yan Liu",
    "corresponding_authors": "",
    "abstract": "Sponsored search has been proven to be a successful business model, and sponsored search auctions have become a hot research direction. There have been many exciting advances in this field, especially in recent years, while at the same time, there are also many open problems waiting for us to resolve. In this article, we provide a comprehensive review of sponsored search auctions in hopes of helping both industry practitioners and academic researchers to become familiar with this field, to know the state of the art, and to identify future research topics. Specifically, we organize the article into two parts. In the first part, we review research works on sponsored search auctions with basic settings, where fully rational advertisers without budget constraints, preknown click-through rates (CTRs) without interdependence, and exact match between queries and keywords are assumed. Under these assumptions, we first introduce the generalized second price (GSP) auction, which is the most popularly used auction mechanism in the industry. Then we give the definitions of several well-studied equilibria and review the latest results on GSP’s efficiency and revenue in these equilibria. In the second part, we introduce some advanced topics on sponsored search auctions. In these advanced topics, one or more assumptions made in the basic settings are relaxed. For example, the CTR of an ad could be unknown and dependent on other ads; keywords could be broadly matched to queries before auctions are executed; and advertisers are not necessarily fully rational, could have budget constraints, and may prefer rich bidding languages. Given that the research on these advanced topics is still immature, in each section of the second part, we provide our opinions on how to make further advances, in addition to describing what has been done by researchers in the corresponding direction.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2036920264",
    "type": "article"
  },
  {
    "title": "Personalized emerging topic detection based on a term aging model",
    "doi": "https://doi.org/10.1145/2542182.2542189",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Mario Cataldi; Luigi Di; Claudio Schifanella",
    "corresponding_authors": "",
    "abstract": "Twitter is a popular microblogging service that acts as a ground-level information news flashes portal where people with different background, age, and social condition provide information about what is happening in front of their eyes. This characteristic makes Twitter probably the fastest information service in the world. In this article, we recognize this role of Twitter and propose a novel, user-aware topic detection technique that permits to retrieve, in real time, the most emerging topics of discussion expressed by the community within the interests of specific users. First, we analyze the topology of Twitter looking at how the information spreads over the network, taking into account the authority/influence of each active user. Then, we make use of a novel term aging model to compute the burstiness of each term, and provide a graph-based method to retrieve the minimal set of terms that can represent the corresponding topic. Finally, since any user can have topic preferences inferable from the shared content, we leverage such knowledge to highlight the most emerging topics within her foci of interest. As evaluation we then provide several experiments together with a user study proving the validity and reliability of the proposed approach.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2064298023",
    "type": "article"
  },
  {
    "title": "Event Classification in Microblogs via Social Tracking",
    "doi": "https://doi.org/10.1145/2967502",
    "publication_date": "2017-02-08",
    "publication_year": 2017,
    "authors": "Yue Gao; Hanwang Zhang; Xibin Zhao; Shuicheng Yan",
    "corresponding_authors": "",
    "abstract": "Social media websites have become important information sharing platforms. The rapid development of social media platforms has led to increasingly large-scale social media data, which has shown remarkable societal and marketing values. There are needs to extract important events in live social media streams. However, microblogs event classification is challenging due to two facts, i.e., the short/conversational nature and the incompatible meanings between the text and the corresponding image in social posts, and the rapidly evolving contents. In this article, we propose to conduct event classification via deep learning and social tracking. First, we introduce a Multi-modal Multi-instance Deep Network (M 2 DN) for microblogs classification, which is able to handle the weakly labeled microblogs data oriented from the incompatible meanings inside microblogs. Besides predicting each microblogs as predefined events, we propose to employ social tracking to extract social-related auxiliary information to enrich the testing samples. We extract a set of candidate-relevant microblogs in a short time window by using social connections, such as related users and geographical locations. All these selected microblogs and the testing data are formulated in a Markov Random Field model. The inference on the Markov Random Field is conducted to update the classification results of the testing microblogs. This method is evaluated on the Brand-Social-Net dataset for classification of 20 events. Experimental results and comparison with the state of the arts show that the proposed method can achieve better performance for the event classification task.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2587648059",
    "type": "article"
  },
  {
    "title": "A Multiagent-Based Approach for Vehicle Routing by Considering Both Arriving on Time and Total Travel Time",
    "doi": "https://doi.org/10.1145/3078847",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Zhiguang Cao; Hongliang Guo; Jie Zhang",
    "corresponding_authors": "",
    "abstract": "Arriving on time and total travel time are two important properties for vehicle routing. Existing route guidance approaches always consider them independently, because they may conflict with each other. In this article, we develop a semi-decentralized multiagent-based vehicle routing approach where vehicle agents follow the local route guidance by infrastructure agents at each intersection, and infrastructure agents perform the route guidance by solving a route assignment problem. It integrates the two properties by expressing them as two objective terms of the route assignment problem. Regarding arriving on time, it is formulated based on the probability tail model, which aims to maximize the probability of reaching destination before deadline. Regarding total travel time, it is formulated as a weighted quadratic term, which aims to minimize the expected travel time from the current location to the destination based on the potential route assignment. The weight for total travel time is designed to be comparatively large if the deadline is loose. Additionally, we improve the proposed approach in two aspects, including travel time prediction and computational efficiency. Experimental results on real road networks justify its ability to increase the average probability of arriving on time, reduce total travel time, and enhance the overall routing performance.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2775249832",
    "type": "article"
  },
  {
    "title": "Cyber Security and the Role of Intelligent Systems in Addressing its Challenges",
    "doi": "https://doi.org/10.1145/3057729",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Yaniv Harel; Irad Ben Gal; Yuval Elovici",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Cyber Security and the Role of Intelligent Systems in Addressing its Challenges Authors: Yaniv Harel Tel Aviv University Tel Aviv UniversityView Profile , Irad Ben Gal Tel Aviv University Tel Aviv UniversityView Profile , Yuval Elovici Ben-Gurion University of the Negev Ben-Gurion University of the NegevView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 8Issue 4July 2017 Article No.: 49pp 1–12https://doi.org/10.1145/3057729Published:11 May 2017Publication History 12citation4,139DownloadsMetricsTotal Citations12Total Downloads4,139Last 12 Months544Last 6 weeks64 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2612932631",
    "type": "article"
  },
  {
    "title": "Reconstruction of Hidden Representation for Robust Feature Extraction",
    "doi": "https://doi.org/10.1145/3284174",
    "publication_date": "2019-01-12",
    "publication_year": 2019,
    "authors": "Yu Zeng; Tianrui Li; Ning Yu; Yi Pan; Hongmei Chen; Bing Liu",
    "corresponding_authors": "",
    "abstract": "This article aims to develop a new and robust approach to feature representation. Motivated by the success of Auto-Encoders, we first theoretically analyze and summarize the general properties of all algorithms that are based on traditional Auto-Encoders: (1) The reconstruction error of the input cannot be lower than a lower bound, which can be viewed as a guiding principle for reconstructing the input. Additionally, when the input is corrupted with noises, the reconstruction error of the corrupted input also cannot be lower than a lower bound. (2) The reconstruction of a hidden representation achieving its ideal situation is the necessary condition for the reconstruction of the input to reach the ideal state. (3) Minimizing the Frobenius norm of the Jacobian matrix of the hidden representation has a deficiency and may result in a much worse local optimum value. We believe that minimizing the reconstruction error of the hidden representation is more robust than minimizing the Frobenius norm of the Jacobian matrix of the hidden representation. Based on the above analysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs), which uses corruption and reconstruction on both the input and the hidden representation. We demonstrate that the proposed model is highly flexible and extensible and has a potentially better capability to learn invariant and robust feature representations. We also show that our model is more robust than Denoising Auto-Encoders (DAEs) for dealing with noises or inessential features. Furthermore, we detail how to train DDAEs with two different pretraining methods by optimizing the objective function in a combined and separate manner, respectively. Comparative experiments illustrate that the proposed model is significantly better for representation learning than the state-of-the-art models.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W3125079666",
    "type": "article"
  },
  {
    "title": "On Learning Prediction Models for Tourists Paths",
    "doi": "https://doi.org/10.1145/2766459",
    "publication_date": "2015-10-09",
    "publication_year": 2015,
    "authors": "Cristina Ioana Muntean; Franco Maria Nardini; Fabrizio Silvestri; Ranieri Baraglia",
    "corresponding_authors": "",
    "abstract": "In this article, we tackle the problem of predicting the “next” geographical position of a tourist, given her history (i.e., the prediction is done accordingly to the tourist’s current trail) by means of supervised learning techniques, namely Gradient Boosted Regression Trees and Ranking SVM. The learning is done on the basis of an object space represented by a 68-dimension feature vector specifically designed for tourism-related data. Furthermore, we propose a thorough comparison of several methods that are considered state-of-the-art in recommender and trail prediction systems for tourism, as well as a popularity baseline. Experiments show that the methods we propose consistently outperform the baselines and provide strong evidence of the performance and robustness of our solutions.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1963661512",
    "type": "article"
  },
  {
    "title": "Multimodular Text Normalization of Dutch User-Generated Content",
    "doi": "https://doi.org/10.1145/2850422",
    "publication_date": "2016-07-07",
    "publication_year": 2016,
    "authors": "Sarah Schulz; Guy De Pauw; Orphée De Clercq; Bart Desmet; Véronique Hoste; Walter Daelemans; Lieve Macken",
    "corresponding_authors": "",
    "abstract": "As social media constitutes a valuable source for data analysis for a wide range of applications, the need for handling such data arises. However, the nonstandard language used on social media poses problems for natural language processing (NLP) tools, as these are typically trained on standard language material. We propose a text normalization approach to tackle this problem. More specifically, we investigate the usefulness of a multimodular approach to account for the diversity of normalization issues encountered in user-generated content (UGC). We consider three different types of UGC written in Dutch (SNS, SMS, and tweets) and provide a detailed analysis of the performance of the different modules and the overall system. We also apply an extrinsic evaluation by evaluating the performance of a part-of-speech tagger, lemmatizer, and named-entity recognizer before and after normalization.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2371227879",
    "type": "article"
  },
  {
    "title": "A Traffic Flow Approach to Early Detection of Gathering Events",
    "doi": "https://doi.org/10.1145/3078850",
    "publication_date": "2017-07-24",
    "publication_year": 2017,
    "authors": "Amin Vahedian Khezerlou; Xun Zhou; Lufan Li; Zubair Shafiq; Alex X. Liu; Fan Zhang",
    "corresponding_authors": "",
    "abstract": "Given a spatial field and the traffic flow between neighboring locations, the early detection of gathering events ( edge ) problem aims to discover and localize a set of most likely gathering events. It is important for city planners to identify emerging gathering events that might cause public safety or sustainability concerns. However, it is challenging to solve the edge problem due to numerous candidate gathering footprints in a spatial field and the nontrivial task of balancing pattern quality and computational efficiency. Prior solutions to model the edge problem lack the ability to describe the dynamic flow of traffic and the potential gathering destinations because they rely on static or undirected footprints. In our recent work, we modeled the footprint of a gathering event as a Gathering Graph (G-Graph), where the root of the directed acyclic G-Graph is the potential destination and the directed edges represent the most likely paths traffic takes to move toward the destination. We also proposed an efficient algorithm called SmartEdge to discover the most likely nonoverlapping G-Graphs in the given spatial field. However, it is challenging to perform a systematic performance study of the proposed algorithm, due to unavailability of the ground truth of gathering events. In this article, we introduce an event simulation mechanism, which makes it possible to conduct a comprehensive performance study of the SmartEdge algorithm. We measure the quality of the detected patterns, in a systematic way, in terms of timeliness and location accuracy. The results show that, on average, the SmartEdge algorithm is able to detect patterns within a grid cell away (less than 500 meters) of the simulated events and detect patterns of the simulated events as early as 10 minutes prior to the first arrival to the gathering event.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2739060064",
    "type": "article"
  },
  {
    "title": "Augmented Collaborative Filtering for Sparseness Reduction in Personalized POI Recommendation",
    "doi": "https://doi.org/10.1145/3086635",
    "publication_date": "2017-09-12",
    "publication_year": 2017,
    "authors": "Chaoran Cui; Jialie Shen; Liqiang Nie; Richang Hong; Jun Ma",
    "corresponding_authors": "",
    "abstract": "As mobile device penetration increases, it has become pervasive for images to be associated with locations in the form of geotags. Geotags bridge the gap between the physical world and the cyberspace, giving rise to new opportunities to extract further insights into user preferences and behaviors. In this article, we aim to exploit geotagged photos from online photo-sharing sites for the purpose of personalized Point-of-Interest (POI) recommendation. Owing to the fact that most users have only very limited travel experiences, data sparseness poses a formidable challenge to personalized POI recommendation. To alleviate data sparseness, we propose to augment current collaborative filtering algorithms along from multiple perspectives. Specifically, hybrid preference cues comprising user-uploaded and user-favored photos are harvested to study users’ tastes. Moreover, heterogeneous high-order relationship information is jointly captured from user social networks and POI multimodal contents with hypergraph models. We also build upon the matrix factorization algorithm to integrate the disparate sources of preference and relationship information, and apply our approach to directly optimize user preference rankings. Extensive experiments on a large and publicly accessible dataset well verified the potential of our approach for addressing data sparseness and offering quality recommendations to users, especially for those who have only limited travel experiences.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2755570041",
    "type": "article"
  },
  {
    "title": "Integrate and Conquer",
    "doi": "https://doi.org/10.1145/3200488",
    "publication_date": "2018-06-01",
    "publication_year": 2018,
    "authors": "Chong Peng; Zhao Kang; Shuting Cai; Qiang Cheng",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce a novel, general methodology, called integrate and conquer, for simultaneously accomplishing the tasks of feature extraction, manifold construction, and clustering, which is taken to be superior to building a clustering method as a single task. When the proposed novel methodology is used on two-dimensional (2D) data, it naturally induces a new clustering method highly effective on 2D data. Existing clustering algorithms usually need to convert 2D data to vectors in a preprocessing step, which, unfortunately, severely damages 2D spatial information and omits inherent structures and correlations in the original data. The induced new clustering method can overcome the matrix-vectorization-related issues to enhance the clustering performance on 2D matrices. More specifically, the proposed methodology mutually enhances three tasks of finding subspaces, learning manifolds, and constructing data representation in a seamlessly integrated fashion. When used on 2D data, we seek two projection matrices with optimal numbers of directions to project the data into low-rank, noise-mitigated, and the most expressive subspaces, in which manifolds are adaptively updated according to the projections, and new data representation is built with respect to the projected data by accounting for nonlinearity via adaptive manifolds. Consequently, the learned subspaces and manifolds are clean and intrinsic, and the new data representation is discriminative and robust. Extensive experiments have been conducted and the results confirm the effectiveness of the proposed methodology and algorithm.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2807603574",
    "type": "article"
  },
  {
    "title": "Random-Forest-Inspired Neural Networks",
    "doi": "https://doi.org/10.1145/3232230",
    "publication_date": "2018-10-29",
    "publication_year": 2018,
    "authors": "Suhang Wang; Charų C. Aggarwal; Huan Liu",
    "corresponding_authors": "",
    "abstract": "Neural networks have become very popular in recent years, because of the astonishing success of deep learning in various domains such as image and speech recognition. In many of these domains, specific architectures of neural networks, such as convolutional networks, seem to fit the particular structure of the problem domain very well and can therefore perform in an astonishingly effective way. However, the success of neural networks is not universal across all domains. Indeed, for learning problems without any special structure, or in cases where the data are somewhat limited, neural networks are known not to perform well with respect to traditional machine-learning methods such as random forests. In this article, we show that a carefully designed neural network with random forest structure can have better generalization ability. In fact, this architecture is more powerful than random forests, because the back-propagation algorithm reduces to a more powerful and generalized way of constructing a decision tree. Furthermore, the approach is efficient to train and requires a small constant factor of the number of training examples. This efficiency allows the training of multiple neural networks to improve the generalization accuracy. Experimental results on real-world benchmark datasets demonstrate the effectiveness of the proposed enhancements for classification and regression.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2898886170",
    "type": "article"
  },
  {
    "title": "A Trust Computing-based Security Routing Scheme for Cyber Physical Systems",
    "doi": "https://doi.org/10.1145/3321694",
    "publication_date": "2019-11-13",
    "publication_year": 2019,
    "authors": "Yuxin Liu; Xiao Liu; Anfeng Liu; Naixue Xiong; Fang Liu",
    "corresponding_authors": "",
    "abstract": "Security is a pivotal issue for the development of Cyber Physical Systems (CPS). The trusted computing of CPS includes the complete protection mechanisms, such as hardware, firmware, and software, the combination of which is responsible for enforcing a system security policy. A Trust Detection-based Secured Routing (TDSR) scheme is proposed to establish security routes from source nodes to the data center under malicious environment to ensure network security. In the TDSR scheme, sensor nodes in the routing path send detection routing to identify relay nodes’ trust. And then, data packets are routed through trustworthy nodes to sink securely. In the TDSR scheme, the detection routing is executed in those nodes that have abundant energy; thus, the network lifetime cannot be affected. Performance evaluation through simulation is carried out for success of routing ratio, compromised node detection ratio, and detection routing overhead. The experiment results show that the performance can be improved in the TDSR scheme compared to previous schemes.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2988551807",
    "type": "article"
  },
  {
    "title": "On Incremental High Utility Sequential Pattern Mining",
    "doi": "https://doi.org/10.1145/3178114",
    "publication_date": "2018-06-01",
    "publication_year": 2018,
    "authors": "Jun-Zhe Wang; Jiun‐Long Huang",
    "corresponding_authors": "",
    "abstract": "High utility sequential pattern (HUSP) mining is an emerging topic in pattern mining, and only a few algorithms have been proposed to address it. In practice, most sequence databases usually grow over time, and it is inefficient for existing algorithms to mine HUSPs from scratch when databases grow with a small portion of updates. In view of this, we propose the IncUSP-Miner + algorithm to mine HUSPs incrementally. Specifically, to avoid redundant re-computations, we propose a tighter upper bound of the utility of a sequence, called Tight Sequence Utility (TSU), and then we design a novel data structure, called the candidate pattern tree, to buffer the sequences whose TSU values are greater than or equal to the minimum utility threshold in the original database. Accordingly, to avoid keeping a huge amount of utility information for each sequence, a set of concise utility information is designed to be stored in each tree node. To improve the mining efficiency, several strategies are proposed to reduce the amount of computation for utility update and the scopes of database scans. Moreover, several strategies are also proposed to properly adjust the candidate pattern tree for the support of multiple database updates. Experimental results on some real and synthetic datasets show that IncUSP-Miner + is able to efficiently mine HUSPs incrementally.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2805697508",
    "type": "article"
  },
  {
    "title": "A Semi-Boosted Nested Model With Sensitivity-Based Weighted Binarization for Multi-Domain Network Intrusion Detection",
    "doi": "https://doi.org/10.1145/3313778",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Joseph W. Mikhail; John M. Fossaceca; Ronald Iammartino",
    "corresponding_authors": "",
    "abstract": "Effective network intrusion detection techniques are required to thwart evolving cybersecurity threats. Historically, traditional enterprise networks have been researched extensively in this regard. However, the cyber threat landscape has grown to include wireless networks. In this article, the authors present a novel model that can be trained on completely different feature sets and applied to two distinct intrusion detection applications: traditional enterprise networks and 802.11 wireless networks. This is the first method that demonstrates superior performance in both aforementioned applications. The model is based on a one-versus-all binary framework comprising multiple nested sub-ensembles. To provide good generalization ability, each sub-ensemble contains a collection of sub-learners, and only a portion of the sub-learners implement boosting. A class weight based on the sensitivity metric (true-positive rate), learned from the training data only, is assigned to the sub-ensembles of each class. The use of pruning to remove sub-learners that do not contribute to or have an adverse effect on overall system performance is investigated as well. The results demonstrate that the proposed system can achieve exceptional performance in applications to both traditional enterprise intrusion detection and 802.11 wireless intrusion detection.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3026559324",
    "type": "article"
  },
  {
    "title": "Enhanced Knowledge-Leverage-Based TSK Fuzzy System Modeling for Inductive Transfer Learning",
    "doi": "https://doi.org/10.1145/2903725",
    "publication_date": "2016-07-25",
    "publication_year": 2016,
    "authors": "Zhaohong Deng; Yizhang Jiang; Hisao Ishibuchi; Kup‐Sze Choi; Shitong Wang",
    "corresponding_authors": "",
    "abstract": "The knowledge-leverage-based Takagi--Sugeno--Kang fuzzy system (KL-TSK-FS) modeling method has shown promising performance for fuzzy modeling tasks where transfer learning is required. However, the knowledge-leverage mechanism of the KL-TSK-FS can be further improved. This is because available training data in the target domain are not utilized for the learning of antecedents and the knowledge transfer mechanism from a source domain to the target domain is still too simple for the learning of consequents when a Takagi--Sugeno--Kang fuzzy system (TSK-FS) model is trained in the target domain. The proposed method, that is, the enhanced KL-TSK-FS (EKL-TSK-FS), has two knowledge-leverage strategies for enhancing the parameter learning of the TSK-FS model for the target domain using available information from the source domain. One strategy is used for the learning of antecedent parameters, while the other is for consequent parameters. It is demonstrated that the proposed EKL-TSK-FS has higher transfer learning abilities than the KL-TSK-FS. In addition, the EKL-TSK-FS has been further extended for the scene of the multisource domain.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2488269320",
    "type": "article"
  },
  {
    "title": "Soft Confidence-Weighted Learning",
    "doi": "https://doi.org/10.1145/2932193",
    "publication_date": "2016-09-20",
    "publication_year": 2016,
    "authors": "Jialei Wang; Peilin Zhao; Steven C. H. Hoi",
    "corresponding_authors": "",
    "abstract": "Online learning plays an important role in many big data mining problems because of its high efficiency and scalability. In the literature, many online learning algorithms using gradient information have been applied to solve online classification problems. Recently, more effective second-order algorithms have been proposed, where the correlation between the features is utilized to improve the learning efficiency. Among them, Confidence-Weighted (CW) learning algorithms are very effective, which assume that the classification model is drawn from a Gaussian distribution, which enables the model to be effectively updated with the second-order information of the data stream. Despite being studied actively, these CW algorithms cannot handle nonseparable datasets and noisy datasets very well. In this article, we propose a family of Soft Confidence-Weighted (SCW) learning algorithms for both binary classification and multiclass classification tasks, which is the first family of online classification algorithms that enjoys four salient properties simultaneously: (1) large margin training, (2) confidence weighting, (3) capability to handle nonseparable data, and (4) adaptive margin. Our experimental results show that the proposed SCW algorithms significantly outperform the original CW algorithm. When comparing with a variety of state-of-the-art algorithms (including AROW, NAROW, and NHERD), we found that SCW in general achieves better or at least comparable predictive performance, but enjoys considerably better efficiency advantage (i.e., using a smaller number of updates and lower time cost). To facilitate future research, we release all the datasets and source code to the public at http://libol.stevenhoi.org/.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2521689864",
    "type": "article"
  },
  {
    "title": "Online Heterogeneous Transfer Learning by Knowledge Transition",
    "doi": "https://doi.org/10.1145/3309537",
    "publication_date": "2019-05-30",
    "publication_year": 2019,
    "authors": "Hanrui Wu; Yuguang Yan; Yuzhong Ye; Huaqing Min; Michael K. Ng; Qingyao Wu",
    "corresponding_authors": "",
    "abstract": "In this article, we study the problem of online heterogeneous transfer learning, where the objective is to make predictions for a target data sequence arriving in an online fashion, and some offline labeled instances from a heterogeneous source domain are provided as auxiliary data. The feature spaces of the source and target domains are completely different, thus the source data cannot be used directly to assist the learning task in the target domain. To address this issue, we take advantage of unlabeled co-occurrence instances as intermediate supplementary data to connect the source and target domains, and perform knowledge transition from the source domain into the target domain. We propose a novel online heterogeneous transfer learning algorithm called O nline H eterogeneous K nowledge T ransition (OHKT) for this purpose. In OHKT, we first seek to generate pseudo labels for the co-occurrence data based on the labeled source data, and then develop an online learning algorithm to classify the target sequence by leveraging the co-occurrence data with pseudo labels. Experimental results on real-world data sets demonstrate the effectiveness and efficiency of the proposed algorithm.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2947733970",
    "type": "article"
  },
  {
    "title": "WiSign",
    "doi": "https://doi.org/10.1145/3377553",
    "publication_date": "2020-04-23",
    "publication_year": 2020,
    "authors": "Lei Zhang; Yixiang Zhang; Xiaolong Zheng",
    "corresponding_authors": "",
    "abstract": "In this article, we propose WiSign that recognizes the continuous sentences of American Sign Language (ASL) with existing WiFi infrastructure. Instead of identifying the individual ASL words from the manually segmented ASL sentence in existing works, WiSign can automatically segment the original channel state information (CSI) based on the power spectral density (PSD) segmentation method. WiSign constructs a five-layer Deep Belief Network (DBN) to automatically extract the features of isolated fragments, and then uses the Hidden Markov Model (HMM) with Gaussian mixture and Forward-Backward algorithm to recognize sign words. In order to further improve the accuracy, WiSign also integrates the language model N-gram, which uses the grammar rules of ASL to calibrate the recognized results of sign words. We implement a prototype of WiSign with commercial WiFi devices and evaluate its performance in real indoor environments. The results show that WiSign achieves satisfactory accuracy when recognizing ASL sentences that involve the movements of the head, arms, hands, and fingers.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3022461327",
    "type": "article"
  },
  {
    "title": "Pricing-aware Real-time Charging Scheduling and Charging Station Expansion for Large-scale Electric Buses",
    "doi": "https://doi.org/10.1145/3428080",
    "publication_date": "2020-11-25",
    "publication_year": 2020,
    "authors": "Guang Wang; Zhihan Fang; Xiaoyang Xie; Shuai Wang; Huijun Sun; Fan Zhang; Yunhuai Liu; Desheng Zhang",
    "corresponding_authors": "",
    "abstract": "We are witnessing a rapid growth of electrified vehicles due to the ever-increasing concerns on urban air quality and energy security. Compared to other types of electric vehicles, electric buses have not yet been prevailingly adopted worldwide due to their high owning and operating costs, long charging time, and the uneven spatial distribution of charging facilities. Moreover, the highly dynamic environment factors such as unpredictable traffic congestion, different passenger demands, and even the changing weather can significantly affect electric bus charging efficiency and potentially hinder the further promotion of large-scale electric bus fleets. To address these issues, in this article, we first analyze a real-world dataset including massive data from 16,359 electric buses, 1,400 bus lines, and 5,562 bus stops. Then, we investigate the electric bus network to understand its operating and charging patterns, and further verify the necessity and feasibility of a real-time charging scheduling. With such understanding, we design busCharging , a pricing-aware real-time charging scheduling system based on Markov Decision Process to reduce the overall charging and operating costs for city-scale electric bus fleets, taking the time-variant electricity pricing into account. To show the effectiveness of busCharging , we implement it with the real-world data from Shenzhen, which includes GPS data of electric buses, the metadata of all bus lines and bus stops, combined with data of 376 charging stations for electric buses. The evaluation results show that busCharging dramatically reduces the charging cost by 23.7% and 12.8% of electricity usage simultaneously. Finally, we design a scheduling-based charging station expansion strategy to verify our busCharging is also effective during the charging station expansion process.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3107249032",
    "type": "article"
  },
  {
    "title": "Multi-Stage Fusion and Multi-Source Attention Network for Multi-Modal Remote Sensing Image Segmentation",
    "doi": "https://doi.org/10.1145/3484440",
    "publication_date": "2021-12-20",
    "publication_year": 2021,
    "authors": "Jiaqi Zhao; Yong Zhou; Boyu Shi; Jingsong Yang; Di Zhang; Rui Yao",
    "corresponding_authors": "",
    "abstract": "With the rapid development of sensor technology, lots of remote sensing data have been collected. It effectively obtains good semantic segmentation performance by extracting feature maps based on multi-modal remote sensing images since extra modal data provides more information. How to make full use of multi-model remote sensing data for semantic segmentation is challenging. Toward this end, we propose a new network called Multi-Stage Fusion and Multi-Source Attention Network ((MS) 2 -Net) for multi-modal remote sensing data segmentation. The multi-stage fusion module fuses complementary information after calibrating the deviation information by filtering the noise from the multi-modal data. Besides, similar feature points are aggregated by the proposed multi-source attention for enhancing the discriminability of features with different modalities. The proposed model is evaluated on publicly available multi-modal remote sensing data sets, and results demonstrate the effectiveness of the proposed method.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W4200174151",
    "type": "article"
  },
  {
    "title": "Spatial Variability Aware Deep Neural Networks (SVANN): A General Approach",
    "doi": "https://doi.org/10.1145/3466688",
    "publication_date": "2021-11-30",
    "publication_year": 2021,
    "authors": "Jayant Gupta; Carl Molnar; Yiqun Xie; Joe Knight; Shashi Shekhar",
    "corresponding_authors": "",
    "abstract": "Spatial variability is a prominent feature of various geographic phenomena such as climatic zones, USDA plant hardiness zones, and terrestrial habitat types (e.g., forest, grasslands, wetlands, and deserts). However, current deep learning methods follow a spatial-one-size-fits-all (OSFA) approach to train single deep neural network models that do not account for spatial variability. Quantification of spatial variability can be challenging due to the influence of many geophysical factors. In preliminary work, we proposed a spatial variability aware neural network (SVANN-I, formerly called SVANN ) approach where weights are a function of location but the neural network architecture is location independent. In this work, we explore a more flexible SVANN-E approach where neural network architecture varies across geographic locations. In addition, we provide a taxonomy of SVANN types and a physics inspired interpretation model. Experiments with aerial imagery based wetland mapping show that SVANN-I outperforms OSFA and SVANN-E performs the best of all.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3214805245",
    "type": "article"
  },
  {
    "title": "A Dynamic Convolutional Neural Network Based Shared-Bike Demand Forecasting Model",
    "doi": "https://doi.org/10.1145/3447988",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Shaojie Qiao; Nan Han; Jianbin Huang; Kun Yue; Rui Mao; Hongping Shu; Qiang He; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "Bike-sharing systems are becoming popular and generate a large volume of trajectory data. In a bike-sharing system, users can borrow and return bikes at different stations. In particular, a bike-sharing system will be affected by weather, the time period, and other dynamic factors, which challenges the scheduling of shared bikes. In this article, a new shared-bike demand forecasting model based on dynamic convolutional neural networks, called SDF , is proposed to predict the demand of shared bikes. SDF chooses the most relevant weather features from real weather data by using the Pearson correlation coefficient and transforms them into a two-dimensional dynamic feature matrix, taking into account the states of stations from historical data. The feature information in the matrix is extracted, learned, and trained with a newly proposed dynamic convolutional neural network to predict the demand of shared bikes in a dynamical and intelligent fashion. The phase of parameter update is optimized from three aspects: the loss function, optimization algorithm, and learning rate. Then, an accurate shared-bike demand forecasting model is designed based on the basic idea of minimizing the loss value. By comparing with classical machine learning models, the weight sharing strategy employed by SDF reduces the complexity of the network. It allows a high prediction accuracy to be achieved within a relatively short period of time. Extensive experiments are conducted on real-world bike-sharing datasets to evaluate SDF. The results show that SDF significantly outperforms classical machine learning models in prediction accuracy and efficiency.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3217402958",
    "type": "article"
  },
  {
    "title": "Urban Traffic Dynamics Prediction—A Continuous Spatial-temporal Meta-learning Approach",
    "doi": "https://doi.org/10.1145/3474837",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Yingxue Zhang; Yanhua Li; Xun Zhou; Jun Luo; Zhi-Li Zhang",
    "corresponding_authors": "",
    "abstract": "Urban traffic status (e.g., traffic speed and volume) is highly dynamic in nature, namely, varying across space and evolving over time. Thus, predicting such traffic dynamics is of great importance to urban development and transportation management. However, it is very challenging to solve this problem due to spatial-temporal dependencies and traffic uncertainties. In this article, we solve the traffic dynamics prediction problem from Bayesian meta-learning perspective and propose a novel continuous spatial-temporal meta-learner (cST-ML), which is trained on a distribution of traffic prediction tasks segmented by historical traffic data with the goal of learning a strategy that can be quickly adapted to related but unseen traffic prediction tasks. cST-ML tackles the traffic dynamics prediction challenges by advancing the Bayesian black-box meta-learning framework through the following new points: (1) cST-ML captures the dynamics of traffic prediction tasks using variational inference, and to better capture the temporal uncertainties within tasks, cST-ML performs as a rolling window within each task; (2) cST-ML has novel designs in architecture, where CNN and LSTM are embedded to capture the spatial-temporal dependencies between traffic status and traffic-related features; (3) novel training and testing algorithms for cST-ML are designed. We also conduct experiments on two real-world traffic datasets (taxi inflow and traffic speed) to evaluate our proposed cST-ML. The experimental results verify that cST-ML can significantly improve the urban traffic prediction performance and outperform all baseline models especially when obvious traffic dynamics and temporal uncertainties are presented.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4206788904",
    "type": "article"
  },
  {
    "title": "CLC: A Consensus-based Label Correction Approach in Federated Learning",
    "doi": "https://doi.org/10.1145/3519311",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Bixiao Zeng; Xiaodong Yang; Yiqiang Chen; Hanchao Yu; Yingwei Zhang",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) is a novel distributed learning framework where multiple participants collaboratively train a global model without sharing any raw data to preserve privacy. However, data quality may vary among the participants, the most typical of which is label noise. The incorrect label would significantly damage the performance of the global model. In FL, the inaccessibility of raw data makes this issue more challenging. Previously published studies are limited to using a task-specific benchmark-trained model to evaluate the relevance between the benchmark dataset in the server and the local one on the participants’ side. However, such approaches have failed to exploit the cooperative nature of FL itself and are not practical. This paper proposes a Consensus-based Label Correction approach (CLC) in FL, which tries to correct the noisy labels using the developed consensus method among the FL participants. The consensus-defined class-wise information is used to identify the noisy labels and correct them with pseudo-labels. Extensive experiments are conducted on several public datasets in various settings. The experimental results prove the advantage over the state-of-art methods. The link to the source code is https://github.com/bixiao-zeng/CLC.git .",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4220721049",
    "type": "article"
  },
  {
    "title": "Graph Sequence Neural Network with an Attention Mechanism for Traffic Speed Prediction",
    "doi": "https://doi.org/10.1145/3470889",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Zhilong Lu; Weifeng Lv; Zhipu Xie; Bowen Du; Guixi Xiong; Leilei Sun; Haiquan Wang",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the emerging success of Graph Neural Networks (GNNs) for modeling graphical data. A GNN can model the spatial dependencies of nodes in a graph based on message passing through node aggregation. However, in many application scenarios, these spatial dependencies can change over time, and a basic GNN model cannot capture these changes. In this article, we propose a G raph S eq uence neural network with an A tt ention mechanism (GSeqAtt) for processing graph sequences. More specifically, two attention mechanisms are combined: a horizontal mechanism and a vertical mechanism. GTransformer, which is a horizontal attention mechanism for handling time series, is used to capture the correlations between graphs in the input time sequence. The vertical attention mechanism, a Graph Network (GN) block structure with an attention mechanism (GNAtt), acts within the graph structure in each frame of the time series. Experiments show that our proposed model is able to handle information propagation for graph sequences accurately and efficiently. Moreover, results on real-world data from three road intersections show that our GSeqAtt outperforms state-of-the-art baselines on the traffic speed prediction task.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4214900325",
    "type": "article"
  },
  {
    "title": "FLeet: Online Federated Learning via Staleness Awareness and Performance Prediction",
    "doi": "https://doi.org/10.1145/3527621",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Georgios Damaskinos; Rachid Guerraoui; Anne-Marie Kermarrec; Vlad Nitu; Rhicheek Patra; François Taı̈ani",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) is very appealing for its privacy benefits: essentially, a global model is trained with updates computed on mobile devices while keeping the data of users local. Standard FL infrastructures are however designed to have no energy or performance impact on mobile devices, and are therefore not suitable for applications that require frequent ( online ) model updates, such as news recommenders. This article presents FLeet , the first Online FL system, acting as a middleware between the Android operating system and the machine learning application. FLeet combines the privacy of Standard FL with the precision of online learning thanks to two core components: (1) I-Prof , a new lightweight profiler that predicts and controls the impact of learning tasks on mobile devices, and (2) AdaSGD , a new adaptive learning algorithm that is resilient to delayed updates. Our extensive evaluation shows that Online FL, as implemented by FLeet , can deliver a 2.3× quality boost compared to Standard FL while only consuming 0.036% of the battery per day. I-Prof can accurately control the impact of learning tasks by improving the prediction accuracy by up to 3.6× in terms of computation time, and by up to 19× in terms of energy. AdaSGD outperforms alternative FL approaches by 18.4% in terms of convergence speed on heterogeneous data.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4225724416",
    "type": "article"
  },
  {
    "title": "Supply-Demand-aware Deep Reinforcement Learning for Dynamic Fleet Management",
    "doi": "https://doi.org/10.1145/3467979",
    "publication_date": "2022-01-18",
    "publication_year": 2022,
    "authors": "Bolong Zheng; Lingfeng Ming; Qi Hu; Zhipeng Lü; Guanfeng Liu; Xiaofang Zhou",
    "corresponding_authors": "",
    "abstract": "Online ride-hailing platforms have reduced significantly the amounts of the time that taxis are idle and that passengers spend on waiting. As a key component of these platforms, the fleet management problem can be naturally modeled as a Markov Decision Process, which enables us to use the deep reinforcement learning. However, existing studies are proposed based on simplified problem settings that fail to model the complicated supply-dynamics and restrict the performance in the real traffic environment. In this article, we propose a supply-demand-aware deep reinforcement learning algorithm for taxi dispatching, where we use a deep Q-network with action sampling policy, called AS-DQN, to learn an optimal dispatching policy. Furthermore, we utilize a dueling network architecture, called AS-DDQN, to improve the performance of AS-DQN. Extensive experiments on real-world datasets offer insight into the performance of our model and show that it is capable of outperforming the baseline approaches.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4205893624",
    "type": "article"
  },
  {
    "title": "DeepRoute+: Modeling Couriers’ Spatial-temporal Behaviors and Decision Preferences for Package Pick-up Route Prediction",
    "doi": "https://doi.org/10.1145/3481006",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Haomin Wen; Youfang Lin; Huaiyu Wan; Shengnan Guo; Fan Wu; Lixia Wu; Chao Song; Yinghui Xu",
    "corresponding_authors": "",
    "abstract": "Over 10 billion packages are picked up every day in China. A fundamental task raised in the emerging intelligent logistics systems is the couriers’ package pick-up route prediction, which is beneficial for package dispatching, arrival-time estimation and overdue-risk evaluation, by leveraging the predicted routes to improve those downstream tasks. In the package pick-up scene, the decision-making of a courier is affected by strict spatial-temporal constraints (e.g., package location, promised pick-up time, current time, and courier’s current location). Furthermore, couriers have different decision preferences on various factors (e.g., time factor, distance factor, and balance of both), based on their own perception of the environments and work experience. In this article, we propose a novel model, named DeepRoute+, to predict couriers’ future package pick-up routes according to the couriers’ decision experience and preference learned from the historical behaviors. Specifically, DeepRoute+ consists of three layers: (1) The representation layer produces experience- and preference-aware representations for the unpicked-up packages, in which a decision preference module can dynamically adjust the importance of factors that affects the courier’s decision under the current situation. (2) The transformer encoder layer encodes the representations of packages while considering the spatial-temporal correlations among them. (3) The attention-based decoder layer uses the attention mechanism to generate the whole pick-up route recurrently. Experiments on a real-world logistics dataset demonstrate the state-of-the-art performance of our model.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4206035315",
    "type": "article"
  },
  {
    "title": "What Can Knowledge Bring to Machine Learning?—A Survey of Low-shot Learning for Structured Data",
    "doi": "https://doi.org/10.1145/3510030",
    "publication_date": "2022-03-03",
    "publication_year": 2022,
    "authors": "Yang Hu; Adriane Chapman; Guihua Wen; Dame Wendy Hall",
    "corresponding_authors": "",
    "abstract": "Supervised machine learning has several drawbacks that make it difficult to use in many situations. Drawbacks include heavy reliance on massive training data, limited generalizability, and poor expressiveness of high-level semantics. Low-shot Learning attempts to address these drawbacks. Low-shot learning allows the model to obtain good predictive power with very little or no training data, where structured knowledge plays a key role as a high-level semantic representation of human. This article will review the fundamental factors of low-shot learning technologies, with a focus on the operation of structured knowledge under different low-shot conditions. We also introduce other techniques relevant to low-shot learning. Finally, we point out the limitations of low-shot learning, the prospects and gaps of industrial applications, and future research directions.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4214876417",
    "type": "article"
  },
  {
    "title": "A Review on Source Code Documentation",
    "doi": "https://doi.org/10.1145/3519312",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Sawan Rai; Ramesh Chandra Belwal; Atul Gupta",
    "corresponding_authors": "",
    "abstract": "Context: Coding is an incremental activity where a developer may need to understand a code before making suitable changes in the code. Code documentation is considered one of the best practices in software development but requires significant efforts from developers. Recent advances in natural language processing and machine learning have provided enough motivation to devise automated approaches for source code documentation at multiple levels. Objective: The review aims to study current code documentation practices and analyze the existing literature to provide a perspective on their preparedness to address the stated problem and the challenges that lie ahead. Methodology: We provide a detailed account of the literature in the area of automated source code documentation at different levels and critically analyze the effectiveness of the proposed approaches. This also allows us to infer gaps and challenges to address the problem at different levels. Findings: (1) The research community focused on method-level summarization. (2) Deep learning has dominated the past five years of this research field. (3) Researchers are regularly proposing bigger corpora for source code documentation. (4) Java and Python are the widely used programming languages as corpus. (5) Bilingual Evaluation Understudy is the most favored evaluation metric for the research persons.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4220921499",
    "type": "review"
  },
  {
    "title": "Crowd Flow Prediction for Irregular Regions with Semantic Graph Attention Network",
    "doi": "https://doi.org/10.1145/3501805",
    "publication_date": "2022-04-25",
    "publication_year": 2022,
    "authors": "Fuxian Li; Jie Feng; Huan Yan; Depeng Jin; Yong Li",
    "corresponding_authors": "",
    "abstract": "It is essential to predict crowd flow precisely in a city, which is practically partitioned into irregular regions based on road networks and functionality. However, prior works mainly focus on grid-based crowd flow prediction, where a city is divided into many regular grids. Although Convolutional Neural Netwok (CNN) is powerful to capture spatial dependence from grid-based Euclidean data, it fails to tackle non-Euclidean data, which reflect the correlations among irregular regions. Besides, prior works fail to jointly capture the hierarchical spatio-temporal dependence from both regular and irregular regions. Finally, the correlations among regions are time-varying and functionality-related. However, the combination of dynamic and semantic attributes of regions are ignored by related works. To address the above challenges, in this article, we propose a novel model to tackle the flow prediction task for irregular regions. First, we employ CNN and Graph Neural Network (GNN) to capture micro and macro spatial dependence among grid-based regions and irregular regions, respectively. Further, we think highly of the dynamic inter-region correlations and propose a location-aware and time-aware graph attention mechanism named Semantic Graph Attention Network (Semantic-GAT), based on dynamic node attribute embedding and multi-view graph reconstruction. Extensive experimental results based on two real-life datasets demonstrate that our model outperforms 10 baselines by reducing the prediction error around 8%.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4224439980",
    "type": "article"
  },
  {
    "title": "HiGRN: A Hierarchical Graph Recurrent Network for Global Sea Surface Temperature Prediction",
    "doi": "https://doi.org/10.1145/3597937",
    "publication_date": "2023-05-22",
    "publication_year": 2023,
    "authors": "Hanchen Yang; Wengen Li; Siyun Hou; Jihong Guan; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "Sea surface temperature (SST) is one critical parameter of global climate change, and accurate SST prediction is important to various applications, e.g., weather forecasting, fishing directions, and disaster warnings. The global ocean system is unified and complex, and the SST patterns in different oceanic regions are highly diverse and correlated. However, existing data-driven SST prediction methods mainly consider the local patterns within a certain oceanic region, e.g., El Nino region and the Black sea. It is challenging but necessary to model the global SST correlations rather than that in a specific region to enhance the prediction accuracy of SST. In this work, we proposed a new method called Hierarchical Graph Recurrent Network (HiGRN) to address the issue. First, to learn the dynamic and diverse local SST patterns of specific locations, we design an adaptive node embedding with self-learned parameters to learn various SST patterns. Then we develop a hierarchical cluster generator to aggregate the locations with similar patterns into regional clusters and utilize a graph convolution network to learn the spatial correlations among these clusters. Finally, we introduce a multi-level attention mechanism to fuse the local patterns and regional correlations, and the output is fed into a recurrent network to achieve SST predictions. Extensive experiments on two real-world datasets show that our method largely outperforms the state-of-the-art SST prediction methods. The source code is available at https://github.com/Neoyanghc/HiGRN .",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4377226795",
    "type": "article"
  },
  {
    "title": "A Spatial and Adversarial Representation Learning Approach for Land Use Classification with POIs",
    "doi": "https://doi.org/10.1145/3627824",
    "publication_date": "2023-10-17",
    "publication_year": 2023,
    "authors": "Ronghui Xu; Weiming Huang; Jun Zhao; Meng Chen; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Points-of-interests (POIs) have been proven to be indicative for sensing urban land use in numerous studies. However, recent progress mainly relies on spatial co-occurrence patterns among POI categories, which falls short in utilizing the rich semantic information embodied in POI hierarchical categories and in sensing the spatial distribution patterns of POIs at an individual zonal scale. In this context, we present a spatial and adversarial representation learning approach (SARL) for predicting land use of urban zones with POIs. SARL deeply mines the information from POIs from both spatial and categorical perspectives. Specifically, we first utilize a convolutional neural network to sense the spatial distribution patterns of POIs in each urban zone. We then leverage an autoencoder and an adversarial learning strategy to mine the POI categorical information in all hierarchical levels, which emphasizes the prominent and definitive POIs while preserves the overall POI hierarchical structures in each zone. Finally, we fuse these information from the two perspectives via a Wide &amp; Deep network and carry out land use prediction with the fused embeddings. We conduct comprehensive experiments to validate the effectiveness of SARL in four European cities with real-world data. The results demonstrate that SARL substantially outperforms several competitive baselines.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4387698707",
    "type": "article"
  },
  {
    "title": "TS-Fastformer: Fast Transformer for Time-series Forecasting",
    "doi": "https://doi.org/10.1145/3630637",
    "publication_date": "2023-10-30",
    "publication_year": 2023,
    "authors": "Sangwon Lee; Junho Hong; Ling Liu; Wonik Choi",
    "corresponding_authors": "",
    "abstract": "Many real-world applications require precise and fast time-series forecasting. Recent trends in time-series forecasting models are shifting from LSTM-based models to Transformer-based models. However, the Transformer-based model has a limited ability to represent sequential relationships in time-series data. In addition, the transformer-based model suffers from slow training and inference speed due to the bottleneck incurred by a deep encoder and step-by-step decoder inference. To address these problems, we propose a time-series forecasting optimized Transformer model, called TS-Fastformer. TS-Fastformer introduces three new optimizations: First, we propose a Sub Window Tokenizer for compressing input in a simple manner. The Sub Window Tokenizer reduces the length of input sequences to mitigate the complexity of self-attention and enables both single and multi-sequence learning. Second, we propose Time-series Pre-trained Encoder to extract effective representations through pre-training. This optimization enables TS-Fastformer to capture both seasonal and trend representations as well as to mitigate bottlenecks of conventional transformer models. Third, we propose the Past Attention Decoder to forecast target by incorporating past long short-term dependency patterns. Furthermore, Past Attention Decoder achieves high performance improvement by removing a trend distribution that changes over a long period. We evaluate the efficiency of our model with extensive experiments using seven real-world datasets and compare our model to six representative time-series forecasting approaches. The results show that the proposed TS-Fastformer reduces MSE by 10.1% compared to state-of-the-art model and demonstrates 21.6% faster training time compared to the existing fastest transformer, respectively.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4388016610",
    "type": "article"
  },
  {
    "title": "Evolving Knowledge Graph Representation Learning with Multiple Attention Strategies for Citation Recommendation System",
    "doi": "https://doi.org/10.1145/3635273",
    "publication_date": "2024-01-13",
    "publication_year": 2024,
    "authors": "Jhih-Chen Liu; Chiao-Ting Chen; Chi Lee; Szu-Hao Huang",
    "corresponding_authors": "",
    "abstract": "The growing number of publications in the field of artificial intelligence highlights the need for researchers to enhance their efficiency in searching for relevant articles. Most paper recommendation models either rely on simplistic citation relationships among papers or focus on content-based approaches, both of which overlook interactions within academic networks. To address the aforementioned problem, knowledge graph embedding (KGE) methods have been used for citation recommendations because recent research proves that graph representations can effectively improve recommendation model accuracy. However, academic networks are dynamic, leading to changes in the representations of users and items over time. The majority of KGE-based citation recommendations are primarily designed for static graphs, thus failing to capture the evolution of dynamic knowledge graph (DKG) structures. To address these challenges, we introduced the evolving knowledge graph embedding (EKGE) method. In this methodology, evolving knowledge graphs are input into time-series models to learn the patterns of structural evolution. The model has the capability to generate embeddings for each entity at various time points, thereby overcoming limitation of static models that require retraining to acquire embeddings at each specific time point. To enhance the efficiency of feature extraction, we employed a multiple attention strategy. This helped the model find recommendation lists that are closely related to a user’s needs, leading to improved recommendation accuracy. Various experiments conducted on a citation recommendation dataset revealed that the EKGE model exhibits a 1.13% increase in prediction accuracy compared to other KGE methods. Moreover, the model’s accuracy can be further increased by an additional 0.84% through the incorporation of an attention mechanism.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4390838295",
    "type": "article"
  },
  {
    "title": "Aspect-enhanced Explainable Recommendation with Multi-modal Contrastive Learning",
    "doi": "https://doi.org/10.1145/3673234",
    "publication_date": "2024-06-19",
    "publication_year": 2024,
    "authors": "Hao Liao; Shuo Wang; Hao Cheng; Wei Zhang; Ji-Wei Zhang; Mingyang Zhou; Kezhong Lu; Rui Mao; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Explainable recommender systems ( ERS ) aim to enhance users’ trust in the systems by offering personalized recommendations with transparent explanations. This transparency provides users with a clear understanding of the rationale behind the recommendations, fostering a sense of confidence and reliability in the system’s outputs. Generally, the explanations are presented in a familiar and intuitive way, which is in the form of natural language, thus enhancing their accessibility to users. Recently, there has been an increasing focus on leveraging reviews as a valuable source of rich information in both modeling user-item preferences and generating textual interpretations, which can be performed simultaneously in a multi-task framework. Despite the progress made in these review-based recommendation systems, the integration of implicit feedback derived from user-item interactions and user-written text reviews has yet to be fully explored. To fill this gap, we propose a model named SERMON (A s pect-enhanced E xplainable R ecommendation with M ulti-modal C o ntrast Lear n ing). Our model explores the application of multimodal contrastive learning to facilitate reciprocal learning across two modalities, thereby enhancing the modeling of user preferences. Moreover, our model incorporates the aspect information extracted from the review, which provides two significant enhancements to our tasks. Firstly, the quality of the generated explanations is improved by incorporating the aspect characteristics into the explanations generated by a pre-trained model with controlled textual generation ability. Secondly, the commonly used user-item interactions are transformed into user-item-aspect interactions, which we refer to as interaction triple, resulting in a more nuanced representation of user preference. To validate the effectiveness of our model, we conduct extensive experiments on three real-world datasets. The experimental results show that our model outperforms state-of-the-art baselines, with a 2.0% improvement in prediction accuracy and a substantial 24.5% enhancement in explanation quality for the TripAdvisor dataset.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4399829296",
    "type": "article"
  },
  {
    "title": "Hybrid Prompt Learning for Generating Justifications of Security Risks in Automation Rules",
    "doi": "https://doi.org/10.1145/3675401",
    "publication_date": "2024-06-29",
    "publication_year": 2024,
    "authors": "Bernardo Breve; Gaetano Cimino; Vincenzo Deufemia",
    "corresponding_authors": "",
    "abstract": "Trigger-action platforms (TAPs) enable users without programming experience to personalize the behavior of Internet of Things applications and services through IF-THEN rules. Unfortunately, the arbitrary connection of smart devices and online services, even with simple rules, such as “IF the entrance Netatmo Wheather Station detects a temperature above 30 \\({}^{\\circ}C\\) ( \\(86^{\\circ}F\\) ) THEN open the shutters in the living room,” might expose users to potential security and privacy risks (e.g., the execution of the previous rule might provide an easy entry point for thieves, especially during the summer vacation period). The goal of our research is to make the users capable of understanding and mitigating the threats and risks associated with the execution of IF-THEN rules. To this end, we define a new challenging task, namely generating post hoc justifications of privacy and security risks associated with automation rules, and propose a novel natural language generation strategy based on hybrid prompt learning producing justifications in the form of real-life threat scenarios. The proposed strategy allows for prompt customization with task-specific information, providing contextual details enabling to grasp the nuances and subtleties of the domain language, resulting in more coherent justifications. The experiments conducted on the if-this-then-that (IFTTT) platform show that our method produces effective justifications, improving the explainability of discrete and hybrid prompting methods up to 27% in BLEURT score. The code of the software is publicly available on GitHub 1 .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4400146982",
    "type": "article"
  },
  {
    "title": "AMT-CDR: A Deep Adversarial Multi-Channel Transfer Network for Cross-Domain Recommendation",
    "doi": "https://doi.org/10.1145/3641286",
    "publication_date": "2024-01-27",
    "publication_year": 2024,
    "authors": "Kezhi Lu; Qian Zhang; Danny Hughes; Guangquan Zhang; Jie Lü",
    "corresponding_authors": "",
    "abstract": "Recommender systems are one of the most successful applications of using AI for providing personalized e-services to customers. However, data sparsity is presenting enormous challenges that are hindering the further development of advanced recommender systems. Although cross-domain recommendation partly overcomes data sparsity by transferring knowledge from a source domain with relatively dense data to augment data in the target domain, the current methods do not handle heterogeneous data very well. For example, using today’s cross-domain transfer learning schemes with data comprising clicks, ratings, user reviews, item metadata, and knowledge graphs will likely result in a poorly performing model. User preferences will not be comprehensively profiled, and accurate recommendations will not be generated. To solve these three challenges—handling heterogeneous data, avoiding negative transfer, and dealing with data sparsity—we designed a new end-to-end deep A dversarial M ulti-channel T ransfer network for C ross- D omain R ecommendation named AMT-CDR . Heterogeneous data is handled by constructing a cross-domain graph based on real-world knowledge graphs—we used Freebase and YAGO. Negative transfer is prevented through an adversarial learning strategy that maintains consistency across the different data channels. Data sparsity is addressed with an end-to-end neural network that considers data across multiple channels and generates accurate recommendations by leveraging knowledge from both the source and target domains. Extensive experiments on three dual-target cross-domain recommendation tasks demonstrate the superiority of AMT-CDR compared to eight state-of-the-art methods. All source code is available at https://github.com/bjtu-lucas-nlp/AMT-CDR .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4391277893",
    "type": "article"
  },
  {
    "title": "Optimal Treatment Strategies for Critical Patients with Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3643856",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Simi Job; Xiaohui Tao; Lin Li; Haoran Xie; Taotao Cai; Jianming Yong; Qing Li",
    "corresponding_authors": "",
    "abstract": "Personalized clinical decision support systems are increasingly being adopted due to the emergence of data-driven technologies, with this approach now gaining recognition in critical care. The task of incorporating diverse patient conditions and treatment procedures into critical care decision-making can be challenging due to the heterogeneous nature of medical data. Advances in Artificial Intelligence (AI), particularly Reinforcement Learning (RL) techniques, enables the development of personalized treatment strategies for severe illnesses by using a learning agent to recommend optimal policies. In this study, we propose a Deep Reinforcement Learning (DRL) model with a tailored reward function and an LSTM-GRU-derived state representation to formulate optimal treatment policies for vasopressor administration in stabilizing patient physiological states in critical care settings. Using an ICU dataset and the Medical Information Mart for Intensive Care (MIMIC-III) dataset, we focus on patients with Acute Respiratory Distress Syndrome (ARDS) that has led to Sepsis, to derive optimal policies that can prioritize patient recovery over patient survival. Both the DDQN ( RepDRL-DDQN ) and Dueling DDQN ( RepDRL-DDDQN ) versions of the DRL model surpass the baseline performance, with the proposed model’s learning agent achieving an optimal learning process across our performance measuring schemes. The robust state representation served as the foundation for enhancing the model’s performance, ultimately providing an optimal treatment policy focused on rapid patient recovery.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4391448746",
    "type": "article"
  },
  {
    "title": "MHGCN+: Multiplex Heterogeneous Graph Convolutional Network",
    "doi": "https://doi.org/10.1145/3650046",
    "publication_date": "2024-02-29",
    "publication_year": 2024,
    "authors": "Chaofan Fu; Pengyang Yu; Yanwei Yu; Chao Huang; Zhongying Zhao; Junyu Dong",
    "corresponding_authors": "",
    "abstract": "Heterogeneous graph convolutional networks have gained great popularity in tackling various network analytical tasks on heterogeneous graph data, ranging from link prediction to node classification. However, most existing works ignore the relation heterogeneity with multiplex networks between multi-typed nodes and the different importance of relations in meta-paths for node embedding, which can hardly capture the heterogeneous structure signals across different relations. To tackle this challenge, this work proposes a M ultiplex H eterogeneous G raph C onvolutional N etwork (MHGCN+) for multiplex heterogeneous network embedding. Our MHGCN+ can automatically learn the useful heterogeneous meta-path interactions of different lengths with different importance in multiplex heterogeneous networks through multi-layer convolution aggregation. Additionally, we effectively integrate both multi-relation structural signals and attribute semantics into the learned node embeddings with both unsupervised and semi-supervised learning paradigms. Extensive experiments on seven real-world datasets with various network analytical tasks demonstrate the significant superiority of MHGCN+ against state-of-the-art embedding baselines in terms of all evaluation metrics. The source code of our method is available at: https://github.com/FuChF/MHGCN-plus .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4392341864",
    "type": "article"
  },
  {
    "title": "A Novel Blockchain-based Responsible Recommendation System for Service Process Creation and Recommendation",
    "doi": "https://doi.org/10.1145/3643858",
    "publication_date": "2024-03-02",
    "publication_year": 2024,
    "authors": "Tieliang Gao; Li Duan; Lufeng Feng; Wei Ni; Quan Z. Sheng",
    "corresponding_authors": "",
    "abstract": "Service composition platforms play a crucial role in creating personalized service processes. Challenges, including the risk of tampering with service data during service invocation and the potential single point of failure in centralized service registration centers, hinder the efficient and responsible creation of service processes. This paper presents a novel framework called Context-Aware Responsible Service Process Creation and Recommendation (SPCR-CA), which incorporates blockchain, Recurrent Neural Networks (RNNs), and a Skip-Gram model holistically to enhance the security, efficiency, and quality of service process creation and recommendation. Specifically, the blockchain establishes a trusted service provision environment, ensuring transparent and secure transactions between services and mitigating the risk of tampering. The RNN trains responsible service processes, contextualizing service components and producing coherent recommendations of linkage components. The Skip-Gram model trains responsible user-service process records, generating semantic vectors that facilitate the recommendation of similar service processes to users. Experiments using the Programmable-Web dataset demonstrate the superiority of the SPCR-CA framework to existing benchmarks in precision and recall. The proposed framework enhances the reliability, efficiency, and quality of service process creation and recommendation, enabling users to create responsible and tailored service processes. The SPCR-CA framework offers promising potential to provide users with secure and user-centric service creation and recommendation capabilities.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4392347848",
    "type": "article"
  },
  {
    "title": "A Game-theoretic Framework for Privacy-preserving Federated Learning",
    "doi": "https://doi.org/10.1145/3656049",
    "publication_date": "2024-04-10",
    "publication_year": 2024,
    "authors": "Xiaojin Zhang; Lixin Fan; Siwei Wang; Wenjie Li; Kai Chen; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "In federated learning, benign participants aim to optimize a global model collaboratively. However, the risk of privacy leakage cannot be ignored in the presence of semi-honest adversaries. Existing research has focused either on designing protection mechanisms or on inventing attacking mechanisms. While the battle between defenders and attackers seems never-ending, we are concerned with one critical question: Is it possible to prevent potential attacks in advance? To address this, we propose the first game-theoretic framework that considers both FL defenders and attackers in terms of their respective payoffs, which include computational costs, FL model utilities, and privacy leakage risks. We name this game the federated learning privacy game (FLPG), in which neither defenders nor attackers are aware of all participants’ payoffs. To handle the incomplete information inherent in this situation, we propose associating the FLPG with an oracle that has two primary responsibilities. First, the oracle provides lower and upper bounds of the payoffs for the players. Second, the oracle acts as a correlation device, privately providing suggested actions to each player. With this novel framework, we analyze the optimal strategies of defenders and attackers. Furthermore, we derive and demonstrate conditions under which the attacker, as a rational decision-maker, should always follow the oracle’s suggestion not to attack .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4394678743",
    "type": "article"
  },
  {
    "title": "Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning",
    "doi": "https://doi.org/10.1145/3664931",
    "publication_date": "2024-05-14",
    "publication_year": 2024,
    "authors": "Miaomiao Cai; Min Hou; Lei Chen; Le Wu; Haoyue Bai; Yong Li; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Collaborative Filtering (CF) plays a crucial role in modern recommender systems, leveraging historical user-item interactions to provide personalized suggestions. However, CF-based methods often encounter biases due to imbalances in training data. This phenomenon makes CF-based methods tend to prioritize recommending popular items and performing unsatisfactorily on inactive users. Existing works address this issue by rebalancing training samples, reranking recommendation results, or making the modeling process robust to the bias. Despite their effectiveness, these approaches can compromise accuracy or be sensitive to weighting strategies, making them challenging to train. Therefore, exploring how to mitigate these biases remains in urgent demand. In this article, we deeply analyze the causes and effects of the biases and propose a framework to alleviate biases in recommendation from the perspective of representation distribution, namely Group-Alignment and Global-Uniformity Enhanced Representation Learning for Debiasing Recommendation (AURL). Specifically, we identify two significant problems in the representation distribution of users and items, namely group-discrepancy and global-collapse. These two problems directly lead to biases in the recommendation results. To this end, we propose two simple but effective regularizers in the representation space, respectively named group-alignment and global-uniformity. The goal of group-alignment is to bring the representation distribution of long-tail entities closer to that of popular entities, while global-uniformity aims to preserve the information of entities as much as possible by evenly distributing representations. Our method directly optimizes both the group-alignment and global-uniformity regularization terms to mitigate recommendation biases. Please note that AURL applies to arbitrary CF-based recommendation backbones. Extensive experiments on three real datasets and various recommendation backbones verify the superiority of our proposed framework. The results show that AURL not only outperforms existing debiasing models in mitigating biases but also improves recommendation performance to some extent.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4396894962",
    "type": "article"
  },
  {
    "title": "Beware of Words: Evaluating the Lexical Diversity of Conversational LLMs using ChatGPT as Case Study",
    "doi": "https://doi.org/10.1145/3696459",
    "publication_date": "2024-09-20",
    "publication_year": 2024,
    "authors": "Gonzalo Serrano Martínez; José Alberto Hernández; Javier Conde; Pedro Reviriego; Elena Merino-Gómez",
    "corresponding_authors": "",
    "abstract": "The performance of conversational Large Language Models (LLMs) in general, and of ChatGPT in particular, is currently being evaluated on many different tasks, from logical reasoning or maths to answering questions on a myriad of topics. Instead, much less attention is being devoted to the study of the linguistic features of the texts generated by these LLMs. This is surprising since LLMs are models for language, and understanding how they use the language is important. Indeed, conversational LLMs are poised to have a significant impact on the evolution of languages as they may eventually dominate the creation of new text. This means that for example, if conversational LLMs do not use a word it may become less and less frequent and eventually stop being used altogether. Therefore, evaluating the linguistic features of the text they produce and how those depend on the model parameters is the first step toward understanding the potential impact of conversational LLMs on the evolution of languages. In this paper, we consider the evaluation of the lexical diversity of the text generated by LLMs in English and how it depends on the model parameters. A methodology is presented and used to conduct a comprehensive evaluation of lexical diversity using ChatGPT as a case study. The results show how lexical diversity depends on the version of ChatGPT and some of its parameters, such as the presence penalty, or the role assigned to the model. The dataset and tools used in our analysis are released under open licenses with the goal of drawing much-needed attention to the evaluation of the linguistic features of LLM-generated text.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4402675481",
    "type": "article"
  },
  {
    "title": "Heterogeneous Graph Neural Networks using Self-supervised Reciprocally Contrastive Learning",
    "doi": "https://doi.org/10.1145/3706115",
    "publication_date": "2024-12-05",
    "publication_year": 2024,
    "authors": "Cuiying Huo; Dongxiao He; Yawen Li; Di Jin; Jianwu Dang; Witold Pedrycz; Lingfei Wu; Weixiong Zhang",
    "corresponding_authors": "",
    "abstract": "Heterogeneous graph neural network (HGNN) is a popular technique for modeling and analyzing heterogeneous graphs. Most existing HGNN-based approaches are supervised or semi-supervised learning methods requiring graphs to be annotated, which is costly and time-consuming. Self-supervised contrastive learning has been proposed to address the problem of requiring annotated data by mining intrinsic properties in the given data. However, the existing contrastive learning methods are not suitable for heterogeneous graphs because they construct contrastive views only based on data perturbation or pre-defined structural properties (e.g., meta-path) in graph data while ignoring noises in node attributes and graph topologies. We develop a robust heterogeneous graph contrastive learning approach, namely HGCL, which introduces two views on respective guidances of node attributes and graph topologies and integrates and enhances them by a reciprocally contrastive mechanism to better model heterogeneous graphs. In this new approach, we adopt distinct but suitable attribute and topology fusion mechanisms in the two views, which are conducive to mining relevant information in attributes and topologies separately. We further use both attribute similarity and topological correlation to construct high-quality contrastive samples. Extensive experiments on four large real-world heterogeneous graphs demonstrate the superiority and robustness of HGCL over several state-of-the-art methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4405073635",
    "type": "article"
  },
  {
    "title": "Hire: Hybrid-modal Interaction with Multiple Relational Enhancements for Image-Text Matching",
    "doi": "https://doi.org/10.1145/3714431",
    "publication_date": "2025-01-23",
    "publication_year": 2025,
    "authors": "Xuri Ge; Fuhai Chen; Songpei Xu; Fuxiang Tao; Jie Wang; Joemon M. Jose",
    "corresponding_authors": "",
    "abstract": "Image-text matching (ITM) is a fundamental problem in computer vision. The key issue lies in jointly learning the visual and textual representation to estimate their similarity accurately. Most existing methods focus on feature enhancement within modality or feature interaction across modalities, which, however, neglects the contextual information of the object representation based on the inter-object relationships that match the corresponding sentences with rich contextual semantics. In this paper, we propose a Hybrid-modal Interaction with multiple Relational Enhancements (termed Hire ) for image-text matching, which correlates the intra- and inter-modal semantics between objects and words with implicit and explicit relationship modelling. In particular, the explicit intra-modal spatial-semantic graph-based reasoning network is designed to improve the contextual representation of visual objects with salient spatial and semantic relational connectivities, guided by the explicit relationships of the objects’ spatial positions and their scene graph. We use implicit relationship modelling for potential relationship interactions before explicit modelling to improve the fault tolerance of explicit relationship detection. Then the visual and textual semantic representations are refined jointly via inter-modal interactive attention and cross-modal alignment. To correlate the context of objects with the textual context, we further refine the visual semantic representation via cross-level object-sentence and word-image-based interactive attention. Extensive experiments validate that the proposed hybrid-modal interaction with implicit and explicit modelling is more beneficial for image-text matching. And the proposed Hire obtains new state-of-the-art results on MS-COCO and Flickr30K benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406761700",
    "type": "article"
  },
  {
    "title": "ATE-FS: An Average Treatment Effect-based Feature Selection Technique for Software Fault Prediction",
    "doi": "https://doi.org/10.1145/3716857",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Akshat Mangal; Santosh Singh Rathore",
    "corresponding_authors": "",
    "abstract": "In software development, software fault prediction (SFP) models aim to identify code sections with a high likelihood of faults before the testing process. SFP models achieve this by analyzing data about the structural properties of the software’s previous versions. Consequently, the accuracy and interpretation of SFP models depend heavily on the chosen software metrics and how well they correlate with patterns of fault occurrence. Previous research has explored improving SFP model performance through feature selection (metric selection). Yet inconsistencies in conclusions arose due to the presence of inconsistent and correlated software metrics. Relying solely on correlations between metrics and faults makes it difficult for developers to take actionable steps, as the causal relationships remain unclear. To address this challenge, this work investigates the use of Causal Inference (CI) methods to understand the causal relationships between software project characteristics, development practices, and the fault-proneness of code sections. We propose a CI-based technique called Average Treatment Effect for Feature Selection (ATE-FS). This technique leverages the causal inference concept to quantify the cause-and-effect relationships between software metrics and fault-proneness. ATE-FS utilizes Average Treatment Effect (ATE) features to identify code metrics that are most suitable for building SFP models. These ATE features capture the causal impact of a metric on fault-proneness. Through an experimental analysis involving twenty-seven SFP datasets, we validate the performance of ATE-FS. We further compare its performance with other state-of-the-art feature selection techniques. The results demonstrate that ATE-FS achieves a significant performance for fault prediction. Additionally, ATE-FS improved consistency in feature selection across diverse SFP datasets.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407370258",
    "type": "article"
  },
  {
    "title": "Comparative Evaluation of GPT Models in FHIR Proficiency",
    "doi": "https://doi.org/10.1145/3718095",
    "publication_date": "2025-02-17",
    "publication_year": 2025,
    "authors": "Tia Pope; Ahmad Patooghy",
    "corresponding_authors": "",
    "abstract": "Ensuring interoperability in healthcare data exchange is vital for advancing patient care, and Fast Healthcare Interoperability Resources (FHIR®) has emerged as a cornerstone standard in this effort. As healthcare increasingly integrates AI for managing and interpreting complex data, proficiency in FHIR is essential to ensure seamless and reliable interactions with healthcare systems. This study evaluates the FHIR proficiency of Generative Pre-trained Transformer (GPT) models, which serves as a critical benchmark for applying artificial intelligence (AI) in healthcare. The performance of GPT-3.5, GPT-4.0, and two custom models was assessed in two FHIR examination scenarios using novel metrics, including Token Processing Cost (TPC), Accuracy-Adjusted Token Processing Cost (ATPC), Comprehensive Performance Index (CPI), and Quality-Adjusted Performance Score (QAPS). GPT-4.0 demonstrated superior accuracy and robustness, while custom models such as the “FHIR Interop Expert” showed strengths in domain-specific tasks through effective prompt engineering. Despite these capabilities, none of the models consistently achieved the \\(\\geq 99\\) % accuracy required for high-stakes healthcare applications. The findings underscore the importance of refining domain-specific training and evaluation methods. The proposed metrics provide a replicable framework for assessing AI readiness, offering a foundation for the responsible and effective integration of AI into healthcare workflows.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407626609",
    "type": "article"
  },
  {
    "title": "Denoising structure against adversarial attacks on graph representation learning",
    "doi": "https://doi.org/10.1145/3714428",
    "publication_date": "2025-02-20",
    "publication_year": 2025,
    "authors": "Na Chen; Ping Li; Jincheng Huang; Kai Zhang",
    "corresponding_authors": "",
    "abstract": "Despite their excellent performance in graph representation learning, graph convolutional networks have been proved to be vulnerable to adversarial perturbations on the connectivity between nodes in an unnoticed manner. In this work, by looking into the impacts of adversarial attacks on graph data, we empirically find that the dominant edge-addition attacks generally increase the heterophily between connected nodes, which will fool the transductive inference models on node classification task. To defend against such attacks, we develop a two-stage denoising method (TSD) that aims at removing possible malicious edges so as to mitigate the heterophily issue introduced by attacks. In particular, after a rough removal of the links that have quite low feature similarity, our method further spots the potentially heterophilious links by predicting node labels with a multi-view labeling consensus. This design is based on assumption that if the label predictions for the same node from two different views of a graph data are consistent, then we have a high chance to acquire the reliable labeling. The experiments demonstrate that by denoising a graph this way, the robustness of graph convolutional networks on node classification task is remarkably improved, compared to several strong competitive robust graph neural network models.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407762172",
    "type": "article"
  },
  {
    "title": "PIN: Application-level Consensus for Blockchain-based Artificial Intelligence Frameworks",
    "doi": "https://doi.org/10.1145/3721845",
    "publication_date": "2025-03-04",
    "publication_year": 2025,
    "authors": "Tannishtha Devgun; Rahul Saha; Gulshan Kumar; Mauro Conti",
    "corresponding_authors": "",
    "abstract": "Integrating Artificial Intelligence (AI) into blockchain consensus, such as Proof-of-Learning and Proof of Useful Work, necessitates AI enablers. However, current consensus protocols cannot ensure AI enabler quality, crucial for AI-powered distributed blockchain and federated learning. Traditional consensus middleware between network and application layers proves inadequate for AI-focused blockchain and federated learning. Thus, an AI-driven application-level consensus with quality-assured enablers is imperative. We propose Proof-of-INtelligence (PIN), an application-level consensus for AI-based blockchain and federated learning, ensuring AI enabler quality. To the best of our knowledge, PIN pioneers the first AI-centric application-level consensus for distributed environments. Employing enablers like accuracy and training quality, PIN is showcased in the federated learning setup “PIN in BlOckchAin-based fedeRateD learning (PIN-BOARD),” the first AI-specific consensus application in blockchain-based federated learning. Both PIN and PIN-BOARD are the highlights of our contributions to the presented work and emphasize the novelty. PIN is the first AI-centric application-level consensus for blockchain and pioneers decentralized AI assurance; PIN addresses the limitations of existing consensus protocols and advances blockchain-based federated learning through the novel framework called PIN-BOARD. Experimental evaluation involves PIN’s accuracy, confirmation time, and a new AI-assurance factor metric. PIN-BOARD’s assessment includes testing accuracy and reward accuracy. A thorough security analysis ensures the strength of PIN and PIN-BOARD. The comparative evaluation highlights PIN’s 20% throughput enhancement and efficient artificial index. PIN-BOARD reduces epochs by 28.5% for peak federated learning accuracy as compared to existing federated models. Thus, PIN emerges as an efficient AI-driven application-level consensus with AI assurance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408155588",
    "type": "article"
  },
  {
    "title": "Transformer-Enhanced Adaptive Graph Convolutional Network for Traffic Flow Prediction",
    "doi": "https://doi.org/10.1145/3729244",
    "publication_date": "2025-04-11",
    "publication_year": 2025,
    "authors": "Elgan Huang; Zhanshan Zhao; Jiao Yin; Jinli Cao; Hua Wang",
    "corresponding_authors": "",
    "abstract": "Traffic flow prediction is vital in urban traffic management, planning, and development. With the continuous advancement of urbanization, there is an increasing demand for traffic flow prediction models to achieve higher accuracy and long-range forecasting capabilities. Against this backdrop, traditional methods that rely on local feature extraction and static spatial graph construction often fall short of expectations. This highlights the urgent need for advanced approaches to dynamically model spatio-temporal features while capturing global dependencies, effectively meeting the demands of complex traffic flow prediction tasks. To achieve this, we propose the Transformer-enhanced Adaptive Graph Convolutional Network (T-AGCN), a novel model designed to capture global temporal relationships and dynamically extract rich spatial information. T-AGCN incorporates an Adaptive Graph Learner module to model dynamic relationships among traffic nodes and a Transformer-based Spatio-Temporal (T-ST) graph convolutional module to capture long-range temporal dependencies in historical traffic data effectively. These innovations enable T-AGCN to jointly learn dynamic spatial interactions and complex temporal patterns, offering a comprehensive representation of traffic network dynamics. We evaluate T-AGCN on two real-world datasets, PeMSD7(M), PeMS08, and METR-LA. The experimental results demonstrate that T-AGCN, inspired by the baseline model Spatial-Temporal Graph Convolutional Network (STGCN), significantly enhances its design. Moreover, T-AGCN consistently outperforms state-of-the-art models, including the Transformer-based Interactive Temporal and Adaptive Network (TITAN) and the Spatial-Temporal Decoupled Masked Autoencoder (STD-MAE). The implementation is available on GitHub at https://github.com/time1722/T-AGCN .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409348972",
    "type": "article"
  },
  {
    "title": "Learning on Missing Tabular Data: Attention with Self-Supervision, Not Imputation, is All You Need",
    "doi": "https://doi.org/10.1145/3729241",
    "publication_date": "2025-04-11",
    "publication_year": 2025,
    "authors": "Li-Wei Chang; Cheng–Te Li; Caijuan Yang; Shou-De Lin",
    "corresponding_authors": "",
    "abstract": "Learning from data with missing values is a common challenge in real-world applications. Existing approaches for handling data incompleteness often involve imputation, which can introduce errors that propagate into downstream tasks or impose assumptions that limit the support for heterogeneous feature types. To address these issues, we propose Missing Feature Attention Network ( MFAN ), an end-to-end label prediction model that directly consumes incomplete data without requiring imputation. MFAN flexibly accommodates both continuous and categorical features through learnable embeddings, and leverages a transformer encoder with self-attention to capture the correlation among features as well as the correlation between features and missingness . This attention-based mechanism allows missing features to benefit from relationships learned among observed features, leading to enhanced hidden representations and robust prediction performance. Additionally, we introduce auxiliary self-supervised pre-training tasks that further guide the attention mechanism in modeling missingness. Experimental results on eight regression and seven classification datasets demonstrate MFAN ’s superiority over state-of-the-art end-to-end methods and imputation-based approaches. Comprehensive ablation studies confirm the effectiveness of each MFAN component, underscoring the importance of explicitly modeling correlations among observed and missing features.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409349068",
    "type": "article"
  },
  {
    "title": "Understanding User Preferences in Explainable Artificial Intelligence: A Mapping Function Proposal",
    "doi": "https://doi.org/10.1145/3733837",
    "publication_date": "2025-05-05",
    "publication_year": 2025,
    "authors": "Maryam Hashemi; Ali Darejeh; Francisco Cruz",
    "corresponding_authors": "",
    "abstract": "The increasing complexity of AI systems has led to the growth of the field of Explainable Artificial Intelligence (XAI), which aims to provide explanations and justifications for the outputs of AI algorithms. While there is considerable demand for XAI, there remains a scarcity of studies aimed at comprehensively understanding the practical distinctions among different methods and effectively aligning each method with users’ individual needs, and ideally, offer a mapping function which can map each user with its specific needs to a method of explainability. This study endeavors to bridge this gap by conducting a review of the relevant works in XAI, with a specific focus on Explainable Machine Learning (XML), and a keen eye on user needs to provide an observational study. Our main objective is to offer a classification of XAI methods within the realm of XML, categorizing current works into three distinct domains: philosophy, theory, and practice. Moreover, our study seeks to facilitate the connection between XAI users and the most suitable methods for them and tailor explanations to meet their specific needs by proposing a mapping function that take to account users and their desired properties and suggest an XAI method to them. This entails an examination of prevalent XAI approaches and an evaluation of their properties. The primary outcome of this study is the formulation of a clear and concise strategy for selecting the optimal XAI method to achieve a given goal, all while delivering personalized explanations tailored to individual users.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410091168",
    "type": "article"
  },
  {
    "title": "Improving Knowledge Tracing through Multi-Source Scaling with Decoder-Only Transformers",
    "doi": "https://doi.org/10.1145/3735652",
    "publication_date": "2025-05-20",
    "publication_year": 2025,
    "authors": "Teng Guo; Bojun Zhan; Shuyan Huang; Jiahao Chen; Xiangyu Zhao; Mingliang Hou; Zitao Liu",
    "corresponding_authors": "",
    "abstract": "Knowledge tracing (KT) is a problem of modeling students’ knowledge states to predict their future performance by observing their historical learning interactions. The collection of educational data presents significant challenges, as students’ limited learning engagement restricts the generation of large-scale interaction data, while stringent privacy regulations further limit the availability of student learning sequences from online platforms. Hence, it is crucial to enhance the capabilities of deep learning based KT (DLKT) models by constructing large-scale datasets through the integration of student interaction data across multiple subjects and sources. The success of ChatGPT demonstrates that the decoder-only Transformer architecture is highly effective in capturing complex information from large-scale sequential data. Against this background, we propose a novel decoder-only Transformer architecture based model, named Unified DLKT ( UniKT ), to learn coherent and unified representations across a wide range of data sources. Specifically, we combine student learning sequences from six educational scenarios and utilize a multi-source encoding to learn unified representations of interactions from mixed data. UniKT is a stack of Transformer decoder layers for handling long-term dependencies among students’ historical interactions and future performance. We evaluate UniKT on six publicly available real-world educational datasets, and experimental results demonstrate that our method outperforms the majority of existing DLKT models in terms of AUC and accuracy. Furthermore, the empirical analysis shows the strong transferability and adaptability of UniKT in learning from multiple sources. To encourage reproducible research, we make our data and code publicly available at https://pykt.org/ .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410515601",
    "type": "article"
  },
  {
    "title": "Knowledge Enhancement and Temporal Aware for Multi-Behavior Contrastive Recommendation",
    "doi": "https://doi.org/10.1145/3735512",
    "publication_date": "2025-05-20",
    "publication_year": 2025,
    "authors": "Hongrui Xuan; Bohan Li; Wenlong Wu; Yi Liu; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "A well-designed recommender system can accurately learn the embeddings of users and items, reflecting the unique preferences of users. Traditional recommendation techniques usually focus on modeling the singular type of behaviors between users and items. However, in many practical recommendation scenarios (e.g., social media, e-commerce), there exist multi-typed interactive behaviors in user-item relationships, such as click, tag-as-favorite, and purchase in online shopping platforms. Thus, how to make full use of multi-behavior information for recommendation is of great importance to the existing system, which presents challenges in two aspects that need to be explored: (1) Utilizing users’ personalized preferences to capture multi-behavioral dependencies; (2) Dealing with the insufficient recommendation caused by sparse supervision signal for target behavior. In this work, we propose the Knowledge Enhancement Multi-Behavior Contrastive Learning framework (KMCLR)[54], including two Contrastive Learning tasks and three functional modules to tackle the above challenges, respectively. In particular, we design the multi-behavior learning module to extract users’ personalized behavior information for user-embedding enhancement, and utilize knowledge graph in the knowledge enhancement module to derive more robust knowledge-aware representations for items. In addition, in the optimization stage, we also model the coarse-grained commonalities and the fine-grained differences between multi-behavior of users to further improve the recommendation effect, and propose a joint training paradigm to enhance the learning effect of KMCLR in the joint learning module. Besides, we also considered how to make full use of temporal signals to enhance the effectiveness of multi-behavior recommendations in scenarios with time information and designed a novel encoder to address this issue. Extensive experiments and ablation tests on the three real-world datasets indicate our KMCLR outperforms various state-of-the-art recommendation methods and verify the effectiveness of our method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410543547",
    "type": "article"
  },
  {
    "title": "Personalized Learning Path Recommendation with Time-Aware Attention Based Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3747594",
    "publication_date": "2025-07-09",
    "publication_year": 2025,
    "authors": "Shengjun Jiang; Yiping Wen; Jun Shen; Gaoxian Peng; Guosheng Kang; Jianxun Liu",
    "corresponding_authors": "",
    "abstract": "Learning resources in online learning systems typically adhere to uniform formats and settings, lacking flexibility and personalization to meet diverse learning needs and preferences. This inability to meet individualized learning needs and preferences has spurred research interest in personalized learning path recommendations. Many researchers have explored recommending learning path by leveraging user historical learning resource sequence to model personalized characteristics. However, these methods overlook the time information in the learning process, and fail to interpret the dynamic shifts in learning preferences during recommendation. Therefore, we propose a method, termed TA-RL, for learning path recommendation, based on time-aware attention mechanism and reinforcement learning. First, we propose a novel time-aware attention mechanism to trace the evolving learning preferences of user, in which attention weights are computed using a context-aware time distance measure and the similarity between history learning resources. Then, we employ a Monte Carlo policy gradient reinforcement learning method to generate learning path recommendation based on learning preferences. We validate the effectiveness of our proposed method by comprehensive experiments on two real-world datasets.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412119959",
    "type": "article"
  },
  {
    "title": "Tabular Transformers Meet Relational Databases",
    "doi": "https://doi.org/10.1145/3749991",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Jakub Peleška; Gustav Šír",
    "corresponding_authors": "",
    "abstract": "Transformer models have continuously expanded into all machine learning domains convertible to the underlying sequence-to-sequence representation, including tabular data. However, while ubiquitous, this representation restricts their extension to the more general case of relational databases . In this paper, we introduce a modular neural message-passing scheme that closely adheres to the formal relational model, enabling direct end-to-end learning of tabular transformers from database storage systems. We address the associated challenges of appropriate learning data representation and loading, which are critical in the database setting, and compare our approach against a number of representative models from various related fields across a significantly wide range of datasets. Our results then demonstrate superior performance of this newly proposed class of neural architectures.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412565305",
    "type": "article"
  },
  {
    "title": "Inherent Bias in Electronic Health Records: A Scoping Review of Sources of Bias",
    "doi": "https://doi.org/10.1145/3757924",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Oriel Perets; Emanuela Stagno; Eyal Ben Yehuda; Megan McNichol; Leo Anthony Celi; Nadav Rappoport; Matilda Dorotić",
    "corresponding_authors": "",
    "abstract": "1 Abstract 1.1 Objectives Biases inherent in electronic health records (EHRs), which are often used as a data source to train medical AI models, may significantly exacerbate health inequities and challenge the adoption of ethical and responsible AI in healthcare. Biases arise from multiple sources, some of which are not as documented in the literature (e.g., bias in medical devices measurement). Biases are encoded in how the data has been collected and labeled, by implicit and unconscious biases of clinicians, or by the tools used for data processing. These biases and their encoding in healthcare records can potentially undermine the reliability of such data and bias clinical judgments and medical outcomes. Moreover, when healthcare records are used to build data-driven solutions, the biases can be further exacerbated, resulting in systems that can perpetuate biases and induce healthcare disparities. This literature scoping review aims to categorize the main sources of biases inherent in EHRs. 1.2 Methods We queried PubMed and Web of Science on January 19th, 2023, for peer-reviewed sources in English, published between 2016 and 2023, using the PRISMA approach to stepwise scoping of the literature. To select the papers that empirically analyze bias in EHR, from the initial yield of 430 papers, 27 duplicates were removed, and 403 studies were screened for eligibility. 196 articles were removed after the title and abstract screening, and 96 articles were excluded after the full-text review resulting in a final selection of 116 articles. 1.3 Results Existing studies often focus on individual biases in EHR data, but a comprehensive review categorizing these biases is largely absent. To address this gap, we propose a systematic taxonomy to classify and better understand the multiplicity of biases in EHR data. Our framework identifies six primary sources: a) bias from past clinical trials ; b) data-related biases , such as missing or incomplete information; human-related biases , including c) implicit clinician bias, d) referral and admission bias, and e) diagnosis or risk disparities bias; and f) biases in devices and algorithms. This taxonomy, illustrated in Table 1, provides a valuable tool for systematically evaluating and addressing these issues. 1.4 Conclusions Machine learning and data-driven solutions can potentially transform healthcare delivery, but not without limitations. The core inputs in the systems (data and human factors) currently contain several sources of bias that are poorly documented and analyzed for remedies. The current evidence heavily focuses on data-related biases, while other sources are less often analyzed or anecdotal. However, these different sources of bias can compound each other, leading to a cumulative effect. Therefore, to understand the issues holistically we need to explore these diverse sources of bias. While racial biases in EHR have been often documented, other sources of biases have been less frequently investigated and documented (e.g. gender-related biases, sexual orientation discrimination, socially induced biases, and implicit, often unconscious, human-related cognitive biases). Moreover, some existing studies lack concrete evidence of the effects of the bias, but rather illustrate the different prevalence of disease across groups, which does not per se prove the effect of the bias. Our review shows that data-, human- and machine biases are prevalent in healthcare and can significantly affect treatment decisions and outcomes and amplify healthcare disparities. Understanding how diverse biases affect AI systems and recommendations is critical. We recommend that researchers and medical personnel develop safeguards and adopt data-driven solutions with a “bias-in-mind” approach. More empirical evidence is needed to tease out the effects of different sources of bias on health outcomes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412991710",
    "type": "review"
  },
  {
    "title": "Intelligent Social Media Indexing and Sharing Using an Adaptive Indexing Search Engine",
    "doi": "https://doi.org/10.1145/2168752.2168761",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Clement Leung; Alice W. S. Chan; Alfredo Milani; Jiming Liu; Yuanxi Li",
    "corresponding_authors": "",
    "abstract": "Effective sharing of diverse social media is often inhibited by limitations in their search and discovery mechanisms, which are particularly restrictive for media that do not lend themselves to automatic processing or indexing. Here, we present the structure and mechanism of an adaptive search engine which is designed to overcome such limitations. The basic framework of the adaptive search engine is to capture human judgment in the course of normal usage from user queries in order to develop semantic indexes which link search terms to media objects semantics. This approach is particularly effective for the retrieval of multimedia objects, such as images, sounds, and videos, where a direct analysis of the object features does not allow them to be linked to search terms, for example, nontextual/icon-based search, deep semantic search, or when search terms are unknown at the time the media repository is built. An adaptive search architecture is presented to enable the index to evolve with respect to user feedback, while a randomized query-processing technique guarantees avoiding local minima and allows the meaningful indexing of new media objects and new terms. The present adaptive search engine allows for the efficient community creation and updating of social media indexes, which is able to instill and propagate deep knowledge into social media concerning the advanced search and usage of media resources. Experiments with various relevance distribution settings have shown efficient convergence of such indexes, which enable intelligent search and sharing of social media resources that are otherwise hard to discover.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2005496291",
    "type": "article"
  },
  {
    "title": "Using Stochastic Models to Describe and Predict Social Dynamics of Web Users",
    "doi": "https://doi.org/10.1145/2337542.2337547",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Kristina Lerman; Tad Hogg",
    "corresponding_authors": "",
    "abstract": "The popularity of content in social media is unequally distributed, with some items receiving a disproportionate share of attention from users. Predicting which newly-submitted items will become popular is critically important for both the hosts of social media content and its consumers. Accurate and timely prediction would enable hosts to maximize revenue through differential pricing for access to content or ad placement. Prediction would also give consumers an important tool for filtering the content. Predicting the popularity of content in social media is challenging due to the complex interactions between content quality and how the social media site highlights its content. Moreover, most social media sites selectively present content that has been highly rated by similar users, whose similarity is indicated implicitly by their behavior or explicitly by links in a social network. While these factors make it difficult to predict popularity a priori , stochastic models of user behavior on these sites can allow predicting popularity based on early user reactions to new content. By incorporating the various mechanisms through which web sites display content, such models improve on predictions that are based on simply extrapolating from the early votes. Specifically, for one such site, the news aggregator Digg, we show how a stochastic model distinguishes the effect of the increased visibility due to the network from how interested users are in the content. We find a wide range of interest, distinguishing stories primarily of interest to users in the network (“niche interests”) from those of more general interest to the user community. This distinction is useful for predicting a story’s eventual popularity from users’ early reactions to the story.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2042740312",
    "type": "article"
  },
  {
    "title": "Advertising Keywords Recommendation for Short-Text Web Pages Using Wikipedia",
    "doi": "https://doi.org/10.1145/2089094.2089112",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Weinan Zhang; Dingquan Wang; Gui-Rong Xue; Hongyuan Zha",
    "corresponding_authors": "",
    "abstract": "Advertising keywords recommendation is an indispensable component for online advertising with the keywords selected from the target Web pages used for contextual advertising or sponsored search. Several ranking-based algorithms have been proposed for recommending advertising keywords. However, for most of them performance is still lacking, especially when dealing with short-text target Web pages, that is, those containing insufficient textual information for ranking. In some cases, short-text Web pages may not even contain enough keywords for selection. A natural alternative is then to recommend relevant keywords not present in the target Web pages. In this article, we propose a novel algorithm for advertising keywords recommendation for short-text Web pages by leveraging the contents of Wikipedia, a user-contributed online encyclopedia. Wikipedia contains numerous entities with related entities on a topic linked to each other. Given a target Web page, we propose to use a content-biased PageRank on the Wikipedia graph to rank the related entities. Furthermore, in order to recommend high-quality advertising keywords, we also add an advertisement-biased factor into our model. With these two biases, advertising keywords that are both relevant to a target Web page and valuable for advertising are recommended. In our experiments, several state-of-the-art approaches for keyword recommendation are compared. The experimental results demonstrate that our proposed approach produces substantial improvement in the precision of the top 20 recommended keywords on short-text Web pages over existing approaches.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2101587558",
    "type": "article"
  },
  {
    "title": "Robust Visual Tracking Using an Effective Appearance Model Based on Sparse Coding",
    "doi": "https://doi.org/10.1145/2168752.2168757",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Shengping Zhang; Hongxun Yao; Xin Sun; Shaohui Liu",
    "corresponding_authors": "",
    "abstract": "Intelligent video surveillance is currently one of the most active research topics in computer vision, especially when facing the explosion of video data captured by a large number of surveillance cameras. As a key step of an intelligent surveillance system, robust visual tracking is very challenging for computer vision. However, it is a basic functionality of the human visual system (HVS). Psychophysical findings have shown that the receptive fields of simple cells in the visual cortex can be characterized as being spatially localized, oriented, and bandpass, and it forms a sparse, distributed representation of natural images. In this article, motivated by these findings, we propose an effective appearance model based on sparse coding and apply it in visual tracking. Specifically, we consider the responses of general basis functions extracted by independent component analysis on a large set of natural image patches as features and model the appearance of the tracked target as the probability distribution of these features. In order to make the tracker more robust to partial occlusion, camouflage environments, pose changes, and illumination changes, we further select features that are related to the target based on an entropy-gain criterion and ignore those that are not. The target is finally represented by the probability distribution of those related features. The target search is performed by minimizing the Matusita distance between the distributions of the target model and a candidate using Newton-style iterations. The experimental results validate that the proposed method is more robust and effective than three state-of-the-art methods.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2014710242",
    "type": "article"
  },
  {
    "title": "Introduction to ACM TIST",
    "doi": "https://doi.org/10.1145/1858948.1858949",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Qiang Yang",
    "corresponding_authors": "Qiang Yang",
    "abstract": "No abstract available.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2016002042",
    "type": "article"
  },
  {
    "title": "From manifesta to krypta",
    "doi": "https://doi.org/10.1145/2438653.2438662",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Rino Falcone; Michele Piunti; Matteo Venanzi; Cristiano Castelfranchi",
    "corresponding_authors": "",
    "abstract": "In this article we consider the special abilities needed by agents for assessing trust based on inference and reasoning. We analyze the case in which it is possible to infer trust towards unknown counterparts by reasoning on abstract classes or categories of agents shaped in a concrete application domain. We present a scenario of interacting agents providing a computational model implementing different strategies to assess trust. Assuming a medical domain, categories, including both competencies and dispositions of possible trustees, are exploited to infer trust towards possibly unknown counterparts. The proposed approach for the cognitive assessment of trust relies on agents' abilities to analyze heterogeneous information sources along different dimensions. Trust is inferred based on specific observable properties (manifesta), namely explicitly readable signals indicating internal features (krypta) regulating agents' behavior and effectiveness on specific tasks. Simulative experiments evaluate the performance of trusting agents adopting different strategies to delegate tasks to possibly unknown trustees, while experimental results show the relevance of this kind of cognitive ability in the case of open multiagent systems.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1983416421",
    "type": "article"
  },
  {
    "title": "Nontrivial landmark recommendation using geotagged photos",
    "doi": "https://doi.org/10.1145/2483669.2483680",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Yue Shi; Pavel Serdyukov; Alan Hanjalić; Martha Larson",
    "corresponding_authors": "",
    "abstract": "Online photo-sharing sites provide a wealth of information about user behavior and their potential is increasing as it becomes ever-more common for images to be associated with location information in the form of geotags. In this article, we propose a novel approach that exploits geotagged images from an online community for the purpose of personalized landmark recommendation. Under our formulation of the task, recommended landmarks should be relevant to user interests and additionally they should constitute nontrivial recommendations. In other words, recommendations of landmarks that are highly popular and frequently visited and can be easily discovered through other information sources such as travel guides should be avoided in favor of recommendations that relate to users' personal interests. We propose a collaborative filtering approach to the personalized landmark recommendation task within a matrix factorization framework. Our approach, WMF-CR, combines weighted matrix factorization and category-based regularization. The integrated weights emphasize the contribution of nontrivial landmarks in order to focus the recommendation model specifically on the generation of nontrivial recommendations. They support the judicious elimination of trivial landmarks from consideration without also discarding information valuable for recommendation. Category-based regularization addresses the sparse data problem, which is arguably even greater in the case of our landmark recommendation task than in other recommendation scenarios due to the limited amount of travel experience recorded in the online image set of any given user. We use category information extracted from Wikipedia in order to provide the system with a method to generalize the semantics of landmarks and allow the model to relate them not only on the basis of identity, but also on the basis of topical commonality. The proposed approach is computational scalable, that is, its complexity is linear with the number of observed preferences in the user-landmark preference matrix and the number of nonzero similarities in the category-based landmark similarity matrix. We evaluate the approach on a large collection of geotagged photos gathered from Flickr. Our experimental results demonstrate that WMF-CR outperforms several state-of-the-art baseline approaches in recommending nontrivial landmarks. Additionally, they demonstrate that the approach is well suited for addressing data sparseness and provides particular performance improvement in the case of users who have limited travel experience, that is, have visited only few cities or few landmarks.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1970830946",
    "type": "article"
  },
  {
    "title": "Monitoring global forest cover using data mining",
    "doi": "https://doi.org/10.1145/1989734.1989740",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Varun Mithal; Ashish Garg; Shyam Boriah; Michael Steinbach; Vipin Kumar; Christopher Potter; Steven Klooster; Carlos Rubio‐Terres",
    "corresponding_authors": "",
    "abstract": "Forests are a critical component of the planet's ecosystem. Unfortunately, there has been significant degradation in forest cover over recent decades as a result of logging, conversion to crop, plantation, and pasture land, or disasters (natural or man made) such as forest fires, floods, and hurricanes. As a result, significant attention is being given to the sustainable use of forests. A key to effective forest management is quantifiable knowledge about changes in forest cover. This requires identification and characterization of changes and the discovery of the relationship between these changes and natural and anthropogenic variables. In this article, we present our preliminary efforts and achievements in addressing some of these tasks along with the challenges and opportunities that need to be addressed in the future. At a higher level, our goal is to provide an overview of the exciting opportunities and challenges in developing and applying data mining approaches to provide critical information for forest and land use management.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2020087467",
    "type": "article"
  },
  {
    "title": "Measuring and Recommending Time-Sensitive Routes from Location-Based Data",
    "doi": "https://doi.org/10.1145/2542668",
    "publication_date": "2014-07-28",
    "publication_year": 2014,
    "authors": "Hsun-Ping Hsieh; Cheng–Te Li; Shou-De Lin",
    "corresponding_authors": "",
    "abstract": "Location-based services allow users to perform geospatial recording actions, which facilitates the mining of the moving activities of human beings. This article proposes to recommend time-sensitive trip routes consisting of a sequence of locations with associated timestamps based on knowledge extracted from large-scale timestamped location sequence data (e.g., check-ins and GPS traces). We argue that a good route should consider (a) the popularity of places, (b) the visiting order of places, (c) the proper visiting time of each place, and (d) the proper transit time from one place to another. By devising a statistical model, we integrate these four factors into a route goodness function that aims to measure the quality of a route. Equipped with the route goodness, we recommend time-sensitive routes for two scenarios. The first is about constructing the route based on the user-specified source location with the starting time. The second is about composing the route between the specified source location and the destination location given a starting time. To handle these queries, we propose a search method, Guidance Search , which consists of a novel heuristic satisfaction function that guides the search toward the destination location and a backward checking mechanism to boost the effectiveness of the constructed route. Experiments on the Gowalla check-in datasets demonstrate the effectiveness of our model on detecting real routes and performing cloze test of routes, comparing with other baseline methods. We also develop a system TripRouter as a real-time demo platform.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W1990176501",
    "type": "article"
  },
  {
    "title": "Ensembles of Restricted Hoeffding Trees",
    "doi": "https://doi.org/10.1145/2089094.2089106",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Albert Bifet; Eibe Frank; Geoffrey Holmes; Bernhard Pfahringer",
    "corresponding_authors": "",
    "abstract": "The success of simple methods for classification shows that is is often not necessary to model complex attribute interactions to obtain good classification accuracy on practical problems. In this article, we propose to exploit this phenomenon in the data stream context by building an ensemble of Hoeffding trees that are each limited to a small subset of attributes. In this way, each tree is restricted to model interactions between attributes in its corresponding subset. Because it is not known a priori which attribute subsets are relevant for prediction, we build exhaustive ensembles that consider all possible attribute subsets of a given size. As the resulting Hoeffding trees are not all equally important, we weigh them in a suitable manner to obtain accurate classifications. This is done by combining the log-odds of their probability estimates using sigmoid perceptrons, with one perceptron per class. We propose a mechanism for setting the perceptrons’ learning rate using the change detection method for data streams, and also use to reset ensemble members (i.e., Hoeffding trees) when they no longer perform well. Our experiments show that the resulting ensemble classifier outperforms bagging for data streams in terms of accuracy when both are used in conjunction with adaptive naive Bayes Hoeffding trees, at the expense of runtime and memory consumption. We also show that our stacking method can improve the performance of a bagged ensemble.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2032196926",
    "type": "article"
  },
  {
    "title": "An Event-Driven QoI-Aware Participatory Sensing Framework with Energy and Budget Constraints",
    "doi": "https://doi.org/10.1145/2630074",
    "publication_date": "2015-04-24",
    "publication_year": 2015,
    "authors": "Bo Zhang; Zheng Song; Chi Harold Liu; Jian Ma; Wendong Wang",
    "corresponding_authors": "",
    "abstract": "Participatory sensing systems can be used for concurrent event monitoring applications, like noise levels, fire, and pollutant concentrations. However, they are facing new challenges as to how to accurately detect the exact boundaries of these events, and further, to select the most appropriate participants to collect the sensing data. On the one hand, participants’ handheld smart devices are constrained with different energy conditions and sensing capabilities, and they move around with uncontrollable mobility patterns in their daily life. On the other hand, these sensing tasks are within time-varying quality-of-information (QoI) requirements and budget to afford the users’ incentive expectations. Toward this end, this article proposes an event-driven QoI-aware participatory sensing framework with energy and budget constraints. The main method of this framework is event boundary detection. For the former, a two-step heuristic solution is proposed where the coarse-grained detection step finds its approximation and the fine-grained detection step identifies the exact location. Participants are selected by explicitly considering their mobility pattern, required QoI of multiple tasks, and users’ incentive requirements, under the constraint of an aggregated task budget. Extensive experimental results, based on a real trace in Beijing, show the effectiveness and robustness of our approach, while comparing with existing schemes.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2054702422",
    "type": "article"
  },
  {
    "title": "Gaussian Processes for Independence Tests with Non-iid Data in Causal Inference",
    "doi": "https://doi.org/10.1145/2806892",
    "publication_date": "2015-11-26",
    "publication_year": 2015,
    "authors": "Seth Flaxman; Daniel B. Neill; Alexander J. Smola",
    "corresponding_authors": "",
    "abstract": "In applied fields, practitioners hoping to apply causal structure learning or causal orientation algorithms face an important question: which independence test is appropriate for my data? In the case of real-valued iid data, linear dependencies, and Gaussian error terms, partial correlation is sufficient. But once any of these assumptions is modified, the situation becomes more complex. Kernel-based tests of independence have gained popularity to deal with nonlinear dependencies in recent years, but testing for conditional independence remains a challenging problem. We highlight the important issue of non-iid observations: when data are observed in space, time, or on a network, “nearby” observations are likely to be similar. This fact biases estimates of dependence between variables. Inspired by the success of Gaussian process regression for handling non-iid observations in a wide variety of areas and by the usefulness of the Hilbert-Schmidt Independence Criterion (HSIC), a kernel-based independence test, we propose a simple framework to address all of these issues: first, use Gaussian process regression to control for certain variables and to obtain residuals. Second, use HSIC to test for independence. We illustrate this on two classic datasets, one spatial, the other temporal, that are usually treated as iid. We show how properly accounting for spatial and temporal variation can lead to more reasonable causal graphs. We also show how highly structured data, like images and text, can be used in a causal inference framework using a novel structured input/output Gaussian process formulation. We demonstrate this idea on a dataset of translated sentences, trying to predict the source language.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2273081434",
    "type": "article"
  },
  {
    "title": "Rating Effects on Social News Posts and Comments",
    "doi": "https://doi.org/10.1145/2963104",
    "publication_date": "2017-07-24",
    "publication_year": 2017,
    "authors": "Maria Glenski; Tim Weninger",
    "corresponding_authors": "",
    "abstract": "At a time when information seekers first turn to digital sources for news and opinion, it is critical that we understand the role that social media plays in human behavior. This is especially true when information consumers also act as information producers and editors through their online activity. In order to better understand the effects that editorial ratings have on online human behavior, we report the results of a two large-scale in vivo experiments in social media. We find that small, random rating manipulations on social media posts and comments created significant changes in downstream ratings, resulting in significantly different final outcomes. We found positive herding effects for positive treatments on posts, increasing the final rating by 11.02% on average, but not for positive treatments on comments. Contrary to the results of related work, we found negative herding effects for negative treatments on posts and comments, decreasing the final ratings, on average, of posts by 5.15% and of comments by 37.4%. Compared to the control group, the probability of reaching a high rating ( ⩾ 2,000) for posts is increased by 24.6% when posts receive the positive treatment and for comments it is decreased by 46.6% when comments receive the negative treatment.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2963046391",
    "type": "article"
  },
  {
    "title": "A framework for trust modeling in multiagent electronic marketplaces with buying advisors to consider varying seller behavior and the limiting of seller bids",
    "doi": "https://doi.org/10.1145/2438653.2438659",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jie Zhang; Robin Cohen",
    "corresponding_authors": "",
    "abstract": "In this article, we present a framework of use in electronic marketplaces that allows buying agents to model the trustworthiness of selling agents in an effective way, making use of seller ratings provided by other buying agents known as advisors. The trustworthiness of the advisors is also modeled, using an approach that combines both personal and public knowledge and allows the relative weighting to be adjusted over time. Through a series of experiments that simulate e-marketplaces, including ones where sellers may vary their behavior over time, we are able to demonstrate that our proposed framework delivers effective seller recommendations to buyers, resulting in important buyer profit. We also propose limiting seller bids as a method for promoting seller honesty, thus facilitating successful selection of sellers by buyers, and demonstrate the value of this approach through experimental results. Overall, this research is focused on the technological aspects of electronic commerce and specifically on technology that would be used to manage trust.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2156354968",
    "type": "article"
  },
  {
    "title": "On Optimizing Airline Ticket Purchase Timing",
    "doi": "https://doi.org/10.1145/2733384",
    "publication_date": "2015-10-01",
    "publication_year": 2015,
    "authors": "William Groves; Maria Gini",
    "corresponding_authors": "",
    "abstract": "Proper timing of the purchase of airline tickets is difficult even when historical ticket prices and some domain knowledge are available. To address this problem, we introduce an algorithm that optimizes purchase timing on behalf of customers and provides performance estimates of its computed action policy. Given a desired flight route and travel date, the algorithm uses machine-learning methods on recent ticket price quotes from many competing airlines to predict the future expected minimum price of all available flights. The main novelty of our algorithm lies in using a systematic feature-selection technique, which captures time dependencies in the data by using time-delayed features, and reduces the number of features by imposing a class hierarchy among the raw features and pruning the features based on in-situ performance. Our algorithm achieves much closer to the optimal purchase policy than other existing decision theoretic approaches for this domain, and meets or exceeds the performance of existing feature-selection methods from the literature. Applications of our feature-selection process to other domains are also discussed.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2026621533",
    "type": "article"
  },
  {
    "title": "Object-Oriented Travel Package Recommendation",
    "doi": "https://doi.org/10.1145/2542665",
    "publication_date": "2014-09-18",
    "publication_year": 2014,
    "authors": "Chang Wei Tan; Qi Liu; Enhong Chen; Hui Xiong; Xiang Wu",
    "corresponding_authors": "",
    "abstract": "Providing better travel services for tourists is one of the important applications in urban computing. Though many recommender systems have been developed for enhancing the quality of travel service, most of them lack a systematic and open framework to dynamically incorporate multiple types of additional context information existing in the tourism domain, such as the travel area, season, and price of travel packages. To that end, in this article, we propose an open framework, the Objected-Oriented Recommender System (ORS), for the developers performing personalized travel package recommendations to tourists. This framework has the ability to import all the available additional context information to the travel package recommendation process in a cost-effective way. Specifically, the different types of additional information are extracted and uniformly represented as feature--value pairs. Then, we define the Object, which is the collection of the feature--value pairs. We propose two models that can be used in the ORS framework for extracting the implicit relationships among Objects. The Objected-Oriented Topic Model (OTM) can extract the topics conditioned on the intrinsic feature--value pairs of the Objects. The Objected-Oriented Bayesian Network (OBN) can effectively infer the cotravel probability of two tourists by calculating the co-occurrence time of feature--value pairs belonging to different kinds of Objects. Based on the relationships mined by OTM or OBN, the recommendation list is generated by the collaborative filtering method. Finally, we evaluate these two models and the ORS framework on real-world travel package data, and the experimental results show that the ORS framework is more flexible in terms of incorporating additional context information, and thus leads to better performances for travel package recommendations. Meanwhile, for feature selection in ORS, we define the feature information entropy, and the experimental results demonstrate that using features with lower entropies usually leads to better recommendation results.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2028910316",
    "type": "article"
  },
  {
    "title": "Nonnegative Multiresolution Representation-Based Texture Image Classification",
    "doi": "https://doi.org/10.1145/2738050",
    "publication_date": "2015-10-07",
    "publication_year": 2015,
    "authors": "Yongsheng Dong; Dacheng Tao; Xuelong Li",
    "corresponding_authors": "",
    "abstract": "Effective representation of image texture is important for an image-classification task. Statistical modelling in wavelet domains has been widely used to image texture representation. However, due to the intraclass complexity and interclass diversity of textures, it is hard to use a predefined probability distribution function to fit adaptively all wavelet subband coefficients of different textures. In this article, we propose a novel modelling approach, Heterogeneous and Incrementally Generated Histogram (HIGH), to indirectly model the wavelet coefficients by use of four local features in wavelet subbands. By concatenating all the HIGHs in all wavelet subbands of a texture, we can construct a nonnegative multiresolution vector (NMV) to represent a texture image. Considering the NMV’s high dimensionality and nonnegativity, we further propose a Hessian regularized discriminative nonnegative matrix factorization to compute a low-dimensional basis of the linear subspace of NMVs. Finally, we present a texture classification approach by projecting NMVs on the low-dimensional basis. Experimental results show that our proposed texture classification method outperforms seven representative approaches.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2094100186",
    "type": "article"
  },
  {
    "title": "Data Mining of Online Genealogy Datasets for Revealing Lifespan Patterns in Human Population",
    "doi": "https://doi.org/10.1145/2700464",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Michael Fire; Yuval Elovici",
    "corresponding_authors": "",
    "abstract": "Online genealogy datasets contain extensive information about millions of people and their past and present family connections. This vast amount of data can help identify various patterns in the human population. In this study, we present methods and algorithms that can assist in identifying variations in lifespan distributions of the human population in the past centuries, in detecting social and genetic features that correlate with the human lifespan, and in constructing predictive models of human lifespan based on various features that can easily be extracted from genealogy datasets. We have evaluated the presented methods and algorithms on a large online genealogy dataset with over a million profiles and over 9 million connections, all of which were collected from the WikiTree website. Our findings indicate that significant but small positive correlations exist between the parents’ lifespan and their children’s lifespan. Additionally, we found slightly higher and significant correlations between the lifespans of spouses. We also discovered a very small positive and significant correlation between longevity and reproductive success in males, and a small and significant negative correlation between longevity and reproductive success in females. Moreover, our predictive models presented results with a Mean Absolute Error as low as 13.18 in predicting the lifespans of individuals who outlived the age of 10, and our classification models presented better than random classification results in predicting which people who outlive the age of 50 will also outlive the age of 80. We believe that this study will be the first of many studies to utilize the wealth of data on human populations, existing in online genealogy datasets, to better understand factors that influence the human lifespan. Understanding these factors can assist scientists in providing solutions for successful aging.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2964182980",
    "type": "article"
  },
  {
    "title": "A Game-Theory Approach for Effective Crowdsource-Based Relevance Assessment",
    "doi": "https://doi.org/10.1145/2873063",
    "publication_date": "2016-03-31",
    "publication_year": 2016,
    "authors": "Yashar Moshfeghi; Alvaro Francisco Huertas Rosero; Joemon M. Jose",
    "corresponding_authors": "",
    "abstract": "Despite the ever-increasing popularity of crowdsourcing (CS) in both industry and academia, procedures that ensure quality in its results are still elusive. We hypothesise that a CS design based on game theory can persuade workers to perform their tasks as quickly as possible with the highest quality. In order to do so, in this article we propose a CS framework inspired by the n -person Chicken game. Our aim is to address the problem of CS quality without compromising on CS benefits such as low monetary cost and high task completion speed. With that goal in mind, we study the effects of knowledge updates as well as incentives for good workers to continue playing. We define a general task with the characteristics of relevance assessment as a case study, because it has been widely explored in the past with CS due to its potential cost and complexity. In order to investigate our hypotheses, we conduct a simulation where we study the effect of the proposed framework on data accuracy, task completion time, and total monetary rewards. Based on a game-theoretical analysis, we study how different types of individuals would behave under a particular game scenario. In particular, we simulate a population comprised of different types of workers with varying ability to formulate optimal strategies and learn from their experiences. A simulation of the proposed framework produced results that support our hypothesis.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2312443980",
    "type": "article"
  },
  {
    "title": "ST-SAGE",
    "doi": "https://doi.org/10.1145/3011019",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Weiqing Wang; Hongzhi Yin; Ling Chen; Yizhou Sun; Shazia Sadiq; Xiaofang Zhou",
    "corresponding_authors": "",
    "abstract": "With the rapid development of location-based social networks (LBSNs), spatial item recommendation has become an important mobile application, especially when users travel away from home. However, this type of recommendation is very challenging compared to traditional recommender systems. A user may visit only a limited number of spatial items, leading to a very sparse user-item matrix. This matrix becomes even sparser when the user travels to a distant place, as most of the items visited by a user are usually located within a short distance from the user’s home. Moreover, user interests and behavior patterns may vary dramatically across different time and geographical regions. In light of this, we propose ST-SAGE, a spatial-temporal sparse additive generative model for spatial item recommendation in this article. ST-SAGE considers both personal interests of the users and the preferences of the crowd in the target region at the given time by exploiting both the co-occurrence patterns and content of spatial items. To further alleviate the data-sparsity issue, ST-SAGE exploits the geographical correlation by smoothing the crowd’s preferences over a well-designed spatial index structure called the spatial pyramid . To speed up the training process of ST-SAGE, we implement a parallel version of the model inference algorithm on the GraphLab framework. We conduct extensive experiments; the experimental results clearly demonstrate that ST-SAGE outperforms the state-of-the-art recommender systems in terms of recommendation effectiveness, model training efficiency, and online recommendation efficiency.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2606241408",
    "type": "article"
  },
  {
    "title": "Robust Spammer Detection in Microblogs",
    "doi": "https://doi.org/10.1145/3086637",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Hao Fu; Xing Xie; Rui Yong; Neil Zhenqiang Gong; Guangzhong Sun; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Microblogging Web sites, such as Twitter and Sina Weibo, have become popular platforms for socializing and sharing information in recent years. Spammers have also discovered this new opportunity to unfairly overpower normal users with unsolicited content, namely social spams. Although it is intuitive for everyone to follow legitimate users, recent studies show that both legitimate users and spammers follow spammers for different reasons. Evidence of users seeking spammers on purpose is also observed. We regard this behavior as useful information for spammer detection. In this article, we approach the problem of spammer detection by leveraging the “carefulness” of users, which indicates how careful a user is when she is about to follow a potential spammer. We propose a framework to measure the carefulness and develop a supervised learning algorithm to estimate it based on known spammers and legitimate users. We illustrate how the robustness of the detection algorithms can be improved with aid of the proposed measure. Evaluation on two real datasets from Sina Weibo and Twitter with millions of users are performed, as well as an online test on Sina Weibo. The results show that our approach indeed captures the carefulness, and it is effective for detecting spammers. In addition, we find that our measure is also beneficial for other applications, such as link prediction.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2749421715",
    "type": "article"
  },
  {
    "title": "TPM",
    "doi": "https://doi.org/10.1145/3230706",
    "publication_date": "2018-11-01",
    "publication_year": 2018,
    "authors": "Weiqing Wang; Hongzhi Yin; Xingzhong Du; Quoc Viet Hung Nguyen; Xiaofang Zhou",
    "corresponding_authors": "",
    "abstract": "With the rapid development of location-based social networks (LBSNs), spatial item recommendation has become an important way of helping users discover interesting locations to increase their engagement with location-based services. The availability of spatial, temporal, and social information in LBSNs offers an unprecedented opportunity to enhance the spatial item recommendation. Many previous works studied spatial and social influences on spatial item recommendation in LBSNs. Due to the strong correlations between a user’s check-in time and the corresponding check-in location, which include the sequential influence and temporal cyclic effect, it is essential for spatial item recommender system to exploit the temporal effect to improve the recommendation accuracy. Leveraging temporal information in spatial item recommendation is, however, very challenging, considering (1) when integrating sequential influences, users’ check-in data in LBSNs has a low sampling rate in both space and time, which renders existing location prediction techniques on GPS trajectories ineffective, and the prediction space is extremely large, with millions of distinct locations as the next prediction target, which impedes the application of classical Markov chain models; (2) there are various temporal cyclic patterns (i.e., daily, weekly, and monthly) in LBSNs, but existing work is limited to one specific pattern; and (3) there is no existing framework that unifies users’ personal interests, temporal cyclic patterns, and the sequential influence of recently visited locations in a principled manner. In light of the above challenges, we propose a Temporal Personalized Model ( TPM ), which introduces a novel latent variable topic-region to model and fuse sequential influence, cyclic patterns with personal interests in the latent and exponential space. The advantages of modeling the temporal effect at the topic-region level include a significantly reduced prediction space, an effective alleviation of data sparsity, and a direct expression of the semantic meaning of users’ spatial activities. Moreover, we introduce two methods to model the effect of various cyclic patterns. The first method is a time indexing scheme that encodes the effect of various cyclic patterns into a binary code. However, the indexing scheme faces the data sparsity problem in each time slice. To deal with this data sparsity problem, the second method slices the time according to each cyclic pattern separately and explores these patterns in a joint additive model. Furthermore, we design an asymmetric Locality Sensitive Hashing (ALSH) technique to speed up the online top- k recommendation process by extending the traditional LSH. We evaluate the performance of TPM on two real datasets and one large-scale synthetic dataset. The performance of TPM in recommending cold-start items is also evaluated. The results demonstrate a significant improvement in TPM’s ability to recommend spatial items, in terms of both effectiveness and efficiency, compared with the state-of-the-art methods.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2898621004",
    "type": "article"
  },
  {
    "title": "A Hybrid Background Subtraction Method with Background and Foreground Candidates Detection",
    "doi": "https://doi.org/10.1145/2746409",
    "publication_date": "2015-10-01",
    "publication_year": 2015,
    "authors": "Fan‐Chieh Cheng; Bo‐Hao Chen; Shih‐Chia Huang",
    "corresponding_authors": "",
    "abstract": "Background subtraction for motion detection is often used in video surveillance systems. However, difficulties in bootstrapping restrict its development. This article proposes a novel hybrid background subtraction technique to solve this problem. For performance improvement of background subtraction, the proposed technique not only quickly initializes the background model but also eliminates unnecessary regions containing only background pixels in the object detection process. Furthermore, an embodiment based on the proposed technique is also presented. Experimental results verify that the proposed technique allows for reduced execution time as well as improvement of performance as evaluated by Recall, Precision, F1, and Similarity metrics when used with state-of-the-art background subtraction methods.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2007722825",
    "type": "article"
  },
  {
    "title": "Activity Sensor",
    "doi": "https://doi.org/10.1145/2700468",
    "publication_date": "2015-04-24",
    "publication_year": 2015,
    "authors": "Jitao Sang; Tao Mei; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "While on the go, people are using their phones as a personal concierge discovering what is around and deciding what to do. Mobile phone has become a recommendation terminal customized for individuals—capable of recommending activities and simplifying the accomplishment of related tasks. In this article, we conduct usage mining on the check-in data, with summarized statistics identifying the local recommendation challenges of huge solution space, sparse available data, and complicated user intent, and discovered observations to motivate the hierarchical, contextual, and sequential solution. We present a point-of-interest (POI) category-transition--based approach, with a goal of estimating the visiting probability of a series of successive POIs conditioned on current user context and sensor context. A mobile local recommendation demo application is deployed. The objective and subjective evaluations validate the effectiveness in providing mobile users both accurate recommendation and favorable user experience.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2090423500",
    "type": "article"
  },
  {
    "title": "Automatic Construction of Statechart-Based Anomaly Detection Models for Multi-Threaded Industrial Control Systems",
    "doi": "https://doi.org/10.1145/3011018",
    "publication_date": "2017-02-24",
    "publication_year": 2017,
    "authors": "Amit Kleinmann; Avishai Wool",
    "corresponding_authors": "",
    "abstract": "Traffic of Industrial Control System (ICS) between the Human Machine Interface (HMI) and the Programmable Logic Controller (PLC) is known to be highly periodic. However, it is sometimes multiplexed, due to asynchronous scheduling. Modeling the network traffic patterns of multiplexed ICS streams using Deterministic Finite Automata (DFA) for anomaly detection typically produces a very large DFA and a high false-alarm rate. In this article, we introduce a new modeling approach that addresses this gap. Our Statechart DFA modeling includes multiple DFAs, one per cyclic pattern, together with a DFA-selector that de-multiplexes the incoming traffic into sub-channels and sends them to their respective DFAs. We demonstrate how to automatically construct the statechart from a captured traffic stream. Our unsupervised learning algorithms first build a Discrete-Time Markov Chain (DTMC) from the stream. Next, we split the symbols into sets, one per multiplexed cycle, based on symbol frequencies and node degrees in the DTMC graph. Then, we create a sub-graph for each cycle and extract Euler cycles for each sub-graph. The final statechart is comprised of one DFA per Euler cycle. The algorithms allow for non-unique symbols, which appear in more than one cycle, and also for symbols that appear more than once in a cycle. We evaluated our solution on traces from a production ICS using the Siemens S7-0x72 protocol. We also stress-tested our algorithms on a collection of synthetically-generated traces that simulated multiplexed ICS traces with varying levels of symbol uniqueness and time overlap. The algorithms were able to split the symbols into sets with 99.6% accuracy. The resulting statechart modeled the traces with a median false-alarm rate of as low as 0.483%. In all but the most extreme scenarios, the Statechart model drastically reduced both the false-alarm rate and the learned model size in comparison with the naive single-DFA model.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2501509689",
    "type": "article"
  },
  {
    "title": "Measuring Similarity Similarly",
    "doi": "https://doi.org/10.1145/2890510",
    "publication_date": "2016-09-26",
    "publication_year": 2016,
    "authors": "W. Ben Towne; Carolyn Penstein Rosé; James D. Herbsleb",
    "corresponding_authors": "",
    "abstract": "Several intelligent technologies designed to improve navigability in and digestibility of text corpora use topic modeling such as the state-of-the-art Latent Dirichlet Allocation (LDA). This model and variants on it provide lower-dimensional document representations used in visualizations and in computing similarity between documents. This article contributes a method for validating such algorithms against human perceptions of similarity, especially applicable to contexts in which the algorithm is intended to support navigability between similar documents via dynamically generated hyperlinks. Such validation enables researchers to ground their methods in context of intended use instead of relying on assumptions of fit. In addition to the methodology, this article presents the results of an evaluation using a corpus of short documents and the LDA algorithm. We also present some analysis of potential causes of differences between cases in which this model matches human perceptions of similarity more or less well.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2527655278",
    "type": "article"
  },
  {
    "title": "Social Bridges in Urban Purchase Behavior",
    "doi": "https://doi.org/10.1145/3149409",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Xiaowen Dong; Yoshihiko Suhara; Burçin Bozkaya; Vivek K. Singh; Bruno Lepri; Alex Pentland",
    "corresponding_authors": "",
    "abstract": "The understanding and modeling of human purchase behavior in city environment can have important implications in the study of urban economy and in the design and organization of cities. In this article, we study human purchase behavior at the community level and argue that people who live in different communities but work at close-by locations could act as “social bridges” between the respective communities and that they are correlated with similarity in community purchase behavior. We provide empirical evidence by studying millions of credit card transaction records for tens of thousands of individuals in a city environment during a period of three months. More specifically, we show that the number of social bridges between communities is a much stronger indicator of similarity in their purchase behavior than traditionally considered factors such as income and sociodemographic variables. Our findings also suggest that such an effect varies across different merchant categories, that the presence of female customers in social bridges is a stronger indicator compared to that of their male counterparts, and that there seems to be a geographical constraint for this effect, all of which may have implications in the studies of urban economy and data-driven urban planning.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2780588353",
    "type": "article"
  },
  {
    "title": "RecRules",
    "doi": "https://doi.org/10.1145/3344211",
    "publication_date": "2019-09-05",
    "publication_year": 2019,
    "authors": "Fulvio Corno; Luigi De Russis; Alberto Monge Roffarello",
    "corresponding_authors": "",
    "abstract": "Nowadays, end users can personalize their smart devices and web applications by defining or reusing IF-THEN rules through dedicated End-User Development (EUD) tools. Despite apparent simplicity, such tools present their own set of issues. The emerging and increasing complexity of the Internet of Things, for example, is barely taken into account, and the number of possible combinations between triggers and actions of different smart devices and web applications is continuously growing. Such a large design space makes end-user personalization a complex task for non-programmers, and motivates the need of assisting users in easily discovering and managing rules and functionality, e.g., through recommendation techniques. In this article, we tackle the emerging problem of recommending IF-THEN rules to end users by presenting RecRules , a hybrid and semantic recommendation system. Through a mixed content and collaborative approach, the goal of RecRules is to recommend by functionality : it suggests rules based on their final purposes, thus overcoming details like manufacturers and brands. The algorithm uses a semantic reasoning process to enrich rules with semantic information, with the aim of uncovering hidden connections between rules in terms of shared functionality. Then, it builds a collaborative semantic graph, and it exploits different types of path-based features to train a learning to rank algorithm and compute top-N recommendations. We evaluate RecRules through different experiments on real user data extracted from IFTTT, one of the most popular EUD tools. Results are promising: they show the effectiveness of our approach with respect to other state-of-the-art algorithms and open the way for a new class of recommender systems for EUD that take into account the actual functionality needed by end users.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2972151630",
    "type": "article"
  },
  {
    "title": "STCAPLRS",
    "doi": "https://doi.org/10.1145/2842631",
    "publication_date": "2016-03-31",
    "publication_year": 2016,
    "authors": "Quan Fang; Changsheng Xu; M. Shamim Hossain; Ghulam Muhammad",
    "corresponding_authors": "",
    "abstract": "Newly emerging location-based social media network services (LBSMNS) provide valuable resources to understand users’ behaviors based on their location histories. The location-based behaviors of a user are generally influenced by both user intrinsic interest and the location preference, and moreover are spatial-temporal context dependent. In this article, we propose a spatial-temporal context-aware personalized location recommendation system (STCAPLRS), which offers a particular user a set of location items such as points of interest or venues (e.g., restaurants and shopping malls) within a geospatial range by considering personal interest, local preference, and spatial-temporal context influence. STCAPLRS can make accurate recommendation and facilitate people’s local visiting and new location exploration by exploiting the context information of user behavior, associations between users and location items, and the location and content information of location items. Specifically, STCAPLRS consists of two components: offline modeling and online recommendation. The core module of the offline modeling part is a context-aware regression mixture model that is designed to model the location-based user behaviors in LBSMNS to learn the interest of each individual user, the local preference of each individual location, and the context-aware influence factors. The online recommendation part takes a querying user along with the corresponding querying spatial-temporal context as input and automatically combines the learned interest of the querying user, the local preference of the querying location, and the context-aware influence factor to produce the top- k recommendations. We evaluate the performance of STCAPLRS on two real-world datasets: Dianping and Foursquare. The results demonstrate the superiority of STCAPLRS in recommending location items for users in terms of both effectiveness and efficiency. Moreover, the experimental analysis results also illustrate the excellent interpretability of STCAPLRS.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2320402896",
    "type": "article"
  },
  {
    "title": "Efficient Generalized Fused Lasso and Its Applications",
    "doi": "https://doi.org/10.1145/2847421",
    "publication_date": "2016-05-05",
    "publication_year": 2016,
    "authors": "Bo Xin; Yoshinobu Kawahara; Yizhou Wang; Lingjing Hu; Wen Gao",
    "corresponding_authors": "",
    "abstract": "Generalized fused lasso (GFL) penalizes variables with l 1 norms based both on the variables and their pairwise differences. GFL is useful when applied to data where prior information is expressed using a graph over the variables. However, the existing GFL algorithms incur high computational costs and do not scale to high-dimensional problems. In this study, we propose a fast and scalable algorithm for GFL. Based on the fact that fusion penalty is the Lovász extension of a cut function, we show that the key building block of the optimization is equivalent to recursively solving graph-cut problems. Thus, we use a parametric flow algorithm to solve GFL in an efficient manner. Runtime comparisons demonstrate a significant speedup compared to existing GFL algorithms. Moreover, the proposed optimization framework is very general; by designing different cut functions, we also discuss the extension of GFL to directed graphs. Exploiting the scalability of the proposed algorithm, we demonstrate the applications of our algorithm to the diagnosis of Alzheimer’s disease (AD) and video background subtraction (BS). In the AD problem, we formulated the diagnosis of AD as a GFL regularized classification. Our experimental evaluations demonstrated that the diagnosis performance was promising. We observed that the selected critical voxels were well structured, i.e., connected, consistent according to cross validation, and in agreement with prior pathological knowledge. In the BS problem, GFL naturally models arbitrary foregrounds without predefined grouping of the pixels. Even by applying simple background models, e.g., a sparse linear combination of former frames, we achieved state-of-the-art performance on several public datasets.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2346552878",
    "type": "article"
  },
  {
    "title": "A Visual Analysis Approach for Understanding Durability Test Data of Automotive Products",
    "doi": "https://doi.org/10.1145/3345640",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Ying Zhao; Lei Wang; Shijie Li; Fangfang Zhou; Xiaoru Lin; Qiang Lü; Lei Ren",
    "corresponding_authors": "",
    "abstract": "People face data-rich manufacturing environments in Industry 4.0. As an important technology for explaining and understanding complex data, visual analytics has been increasingly introduced into industrial data analysis scenarios. With the durability test of automotive starters as background, this study proposes a visual analysis approach for understanding large-scale and long-term durability test data. Guided by detailed scenario and requirement analyses, we first propose a migration-adapted clustering algorithm that utilizes a segmentation strategy and a group of matching-updating operations to achieve an efficient and accurate clustering analysis of the data for starting mode identification and abnormal test detection. We then design and implement a visual analysis system that provides a set of user-friendly visual designs and lightweight interactions to help people gain data insights into the test process overview, test data patterns, and durability performance dynamics. Finally, we conduct a quantitative algorithm evaluation, case study, and user interview by using real-world starter durability test datasets. The results demonstrate the effectiveness of the approach and its possible inspiration for the durability test data analysis of other similar industrial products.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2996086865",
    "type": "article"
  },
  {
    "title": "Travel Recommendation via Fusing Multi-Auxiliary Information into Matrix Factorization",
    "doi": "https://doi.org/10.1145/3372118",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Lei Chen; Zhiang Wu; Jie Cao; Guixiang Zhu; Yong Ge",
    "corresponding_authors": "",
    "abstract": "As an e-commerce feature, the personalized recommendation is invariably highly-valued by both consumers and merchants. The e-tourism has become one of the hottest industries with the adoption of recommendation systems. Several lines of evidence have confirmed the travel-product recommendation is quite different from traditional recommendations. Travel products are usually browsed and purchased relatively infrequently compared with other traditional products (e.g., books and food), which gives rise to the extreme sparsity of travel data. Meanwhile, the choice of a suitable travel product is affected by an army of factors such as departure, destination, and financial and time budgets. To address these challenging problems, in this article, we propose a Probabilistic Matrix Factorization with Multi-Auxiliary Information (PMF-MAI) model in the context of the travel-product recommendation. In particular, PMF-MAI is able to fuse the probabilistic matrix factorization on the user-item interaction matrix with the linear regression on a suite of features constructed by the multiple auxiliary information. In order to fit the sparse data, PMF-MAI is built by a whole-data based learning approach that utilizes unobserved data to increase the coupling between probabilistic matrix factorization and linear regression. Extensive experiments are conducted on a real-world dataset provided by a large tourism e-commerce company. PMF-MAI shows an overwhelming superiority over all competitive baselines on the recommendation performance. Also, the importance of features is examined to reveal the crucial auxiliary information having a great impact on the adoption of travel products.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3011518473",
    "type": "article"
  },
  {
    "title": "DeepKey",
    "doi": "https://doi.org/10.1145/3393619",
    "publication_date": "2020-05-31",
    "publication_year": 2020,
    "authors": "Xiang Zhang; Lina Yao; Chaoran Huang; Tao Gu; Zheng Yang; Yunhao Liu",
    "corresponding_authors": "",
    "abstract": "Biometric authentication involves various technologies to identify individuals by exploiting their unique, measurable physiological and behavioral characteristics. However, traditional biometric authentication systems (e.g., face recognition, iris, retina, voice, and fingerprint) are at increasing risks of being tricked by biometric tools such as anti-surveillance masks, contact lenses, vocoder, or fingerprint films. In this article, we design a multimodal biometric authentication system named DeepKey, which uses both Electroencephalography (EEG) and gait signals to better protect against such risk. DeepKey consists of two key components: an Invalid ID Filter Model to block unauthorized subjects, and an identification model based on attention-based Recurrent Neural Network (RNN) to identify a subject’s EEG IDs and gait IDs in parallel. The subject can only be granted access while all the components produce consistent affirmations to match the user’s proclaimed identity. We implement DeepKey with a live deployment in our university and conduct extensive empirical experiments to study its technical feasibility in practice. DeepKey achieves the False Acceptance Rate (FAR) and the False Rejection Rate (FRR) of 0 and 1.0%, respectively. The preliminary results demonstrate that DeepKey is feasible, shows consistent superior performance compared to a set of methods, and has the potential to be applied to the authentication deployment in real-world settings.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3033368137",
    "type": "article"
  },
  {
    "title": "Domain-attention Conditional Wasserstein Distance for Multi-source Domain Adaptation",
    "doi": "https://doi.org/10.1145/3391229",
    "publication_date": "2020-05-31",
    "publication_year": 2020,
    "authors": "Hanrui Wu; Yuguang Yan; Michael K. Ng; Qingyao Wu",
    "corresponding_authors": "",
    "abstract": "Multi-source domain adaptation has received considerable attention due to its effectiveness of leveraging the knowledge from multiple related sources with different distributions to enhance the learning performance. One of the fundamental challenges in multi-source domain adaptation is how to determine the amount of knowledge transferred from each source domain to the target domain. To address this issue, we propose a new algorithm, called Domain-attention Conditional Wasserstein Distance (DCWD), to learn transferred weights for evaluating the relatedness across the source and target domains. In DCWD, we design a new conditional Wasserstein distance objective function by taking the label information into consideration to measure the distance between a given source domain and the target domain. We also develop an attention scheme to compute the transferred weights of different source domains based on their conditional Wasserstein distances to the target domain. After that, the transferred weights can be used to reweight the source data to determine their importance in knowledge transfer. We conduct comprehensive experiments on several real-world data sets, and the results demonstrate the effectiveness and efficiency of the proposed method.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3046682702",
    "type": "article"
  },
  {
    "title": "Is Rank Aggregation Effective in Recommender Systems? An Experimental Analysis",
    "doi": "https://doi.org/10.1145/3365375",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Samuel E. L. Oliveira; Victor Diniz; Anísio Lacerda; Luiz Merschmanm; Gisele L. Pappa",
    "corresponding_authors": "",
    "abstract": "Recommender Systems are tools designed to help users find relevant information from the myriad of content available online. They work by actively suggesting items that are relevant to users according to their historical preferences or observed actions. Among recommender systems, top- N recommenders work by suggesting a ranking of N items that can be of interest to a user. Although a significant number of top- N recommenders have been proposed in the literature, they often disagree in their returned rankings, offering an opportunity for improving the final recommendation ranking by aggregating the outputs of different algorithms. Rank aggregation was successfully used in a significant number of areas, but only a few rank aggregation methods have been proposed in the recommender systems literature. Furthermore, there is a lack of studies regarding rankings’ characteristics and their possible impacts on the improvements achieved through rank aggregation. This work presents an extensive two-phase experimental analysis of rank aggregation in recommender systems. In the first phase, we investigate the characteristics of rankings recommended by 15 different top- N recommender algorithms regarding agreement and diversity. In the second phase, we look at the results of 19 rank aggregation methods and identify different scenarios where they perform best or worst according to the input rankings’ characteristics. Our results show that supervised rank aggregation methods provide improvements in the results of the recommended rankings in six out of seven datasets. These methods provide robustness even in the presence of a big set of weak recommendation rankings. However, in cases where there was a set of non-diverse high-quality input rankings, supervised and unsupervised algorithms produced similar results. In these cases, we can avoid the cost of the former in favor of the latter.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3006895932",
    "type": "article"
  },
  {
    "title": "Superpixel Region Merging Based on Deep Network for Medical Image Segmentation",
    "doi": "https://doi.org/10.1145/3386090",
    "publication_date": "2020-05-31",
    "publication_year": 2020,
    "authors": "Hui Liu; Haiou Wang; Yan Wu; Lei Xing",
    "corresponding_authors": "",
    "abstract": "Automatic and accurate semantic segmentation of pathological structures in medical images is challenging because of noisy disturbance, deformable shapes of pathology, and low contrast between soft tissues. Classical superpixel-based classification algorithms suffer from edge leakage due to complexity and heterogeneity inherent in medical images. Therefore, we propose a deep U-Net with superpixel region merging processing incorporated for edge enhancement to facilitate and optimize segmentation. Our approach combines three innovations: (1) different from deep learning--based image segmentation, the segmentation evolved from superpixel region merging via U-Net training getting rich semantic information, in addition to gray similarity; (2) a bilateral filtering module was adopted at the beginning of the network to eliminate external noise and enhance soft tissue contrast at edges of pathogy; and (3) a normalization layer was inserted after the convolutional layer at each feature scale, to prevent overfitting and increase the sensitivity to model parameters. This model was validated on lung CT, brain MR, and coronary CT datasets, respectively. Different superpixel methods and cross validation show the effectiveness of this architecture. The hyperparameter settings were empirically explored to achieve a good trade-off between the performance and efficiency, where a four-layer network achieves the best result in precision, recall, F-measure, and running speed. It was demonstrated that our method outperformed state-of-the-art networks, including FCN-16s, SegNet, PSPNet, DeepLabv3, and traditional U-Net, both quantitatively and qualitatively. Source code for the complete method is available at https://github.com/Leahnawho/Superpixel-network.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3048255638",
    "type": "article"
  },
  {
    "title": "On Representation Learning for Road Networks",
    "doi": "https://doi.org/10.1145/3424346",
    "publication_date": "2020-12-22",
    "publication_year": 2020,
    "authors": "Meng-Xiang Wang; Wang-Chien Lee; Tao-Yang Fu; Ge Yu",
    "corresponding_authors": "",
    "abstract": "Informative representation of road networks is essential to a wide variety of applications on intelligent transportation systems. In this article, we design a new learning framework, called Representation Learning for Road Networks (RLRN), which explores various intrinsic properties of road networks to learn embeddings of intersections and road segments in road networks. To implement the RLRN framework, we propose a new neural network model, namely Road Network to Vector (RN2Vec), to learn embeddings of intersections and road segments jointly by exploring geo-locality and homogeneity of them, topological structure of the road networks, and moving behaviors of road users. In addition to model design, issues involving data preparation for model training are examined. We evaluate the learned embeddings via extensive experiments on several real-world datasets using different downstream test cases, including node/edge classification and travel time estimation. Experimental results show that the proposed RN2Vec robustly outperforms existing methods, including (i) Feature-based methods : raw features and principal components analysis (PCA); (ii) Network embedding methods : DeepWalk, LINE, and Node2vec; and (iii) Features + Network structure-based methods : network embeddings and PCA, graph convolutional networks, and graph attention networks. RN2Vec significantly outperforms all of them in terms of F1-score in classifying traffic signals (11.96% to 16.86%) and crossings (11.36% to 16.67%) on intersections and in classifying avenue (10.56% to 15.43%) and street (11.54% to 16.07%) on road segments, as well as in terms of Mean Absolute Error in travel time estimation (17.01% to 23.58%).",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3113491032",
    "type": "article"
  },
  {
    "title": "Conditional Text Generation for Harmonious Human-Machine Interaction",
    "doi": "https://doi.org/10.1145/3439816",
    "publication_date": "2021-02-26",
    "publication_year": 2021,
    "authors": "Bin Guo; Hao Wang; Yasan Ding; Wei Wu; Shaoyang Hao; Yueqi Sun; Zhiwen Yu",
    "corresponding_authors": "",
    "abstract": "In recent years, with the development of deep learning, text-generation technology has undergone great changes and provided many kinds of services for human beings, such as restaurant reservation and daily communication. The automatically generated text is becoming more and more fluent so researchers begin to consider more anthropomorphic text-generation technology, that is, the conditional text generation, including emotional text generation, personalized text generation, and so on. Conditional Text Generation (CTG) has thus become a research hotspot. As a promising research field, we find that much attention has been paid to exploring it. Therefore, we aim to give a comprehensive review of the new research trends of CTG. We first summarize several key techniques and illustrate the technical evolution route in the field of neural text generation, based on the concept model of CTG. We further make an investigation of existing CTG fields and propose several general learning models for CTG. Finally, we discuss the open issues and promising research directions of CTG.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3135797089",
    "type": "article"
  },
  {
    "title": "Dynamic Probabilistic Graphical Model for Progressive Fake News Detection on Social Media Platform",
    "doi": "https://doi.org/10.1145/3523060",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Li Ke; Bin Guo; Jiaqi Liu; Jiangtao Wang; Haoyang Ren; Fei Yi; Zhiwen Yu",
    "corresponding_authors": "",
    "abstract": "Recently, fake news has been readily spread by massive amounts of users in social media, and automatic fake news detection has become necessary. The existing works need to prepare the overall data to perform detection, losing important information about the dynamic evolution of crowd opinions, and usually neglect the issue of uneven arrival of data in the real world. To address these issues, in this article, we focus on a kind of approach for fake news detection, namely progressive detection , which can be achieved by the dynamic Probabilistic Graphical Model . Based on the observation on real-world datasets, we adaptively improve the Kalman Filter to the Labeled Variable Dimension Kalman Filter (LVDKF) that learns two universal patterns from true and fake news, respectively, which can capture the temporal information of time-series data that arrive unevenly. It can take sequential data as input, distill the dynamic evolution knowledge regarding a post, and utilize crowd wisdom from users’ responses to achieve progressive detection. Then we derive the formulas using the Forward, Backward, and EM Algorithm, and we design a dynamic detection algorithm using Bayes’ theorem. Finally, we design experimental scenarios simulating progressive detection and evaluate LVDKF on two public datasets. It outperforms the baseline methods in these experimental scenarios, which indicates that it is adequate for progressive detection.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4220715345",
    "type": "article"
  },
  {
    "title": "Privacy Preservation for Trajectory Publication Based on Differential Privacy",
    "doi": "https://doi.org/10.1145/3474839",
    "publication_date": "2022-04-12",
    "publication_year": 2022,
    "authors": "Lin Yao; Zhenyu Chen; Haibo Hu; Guowei Wu; Bin Wu",
    "corresponding_authors": "",
    "abstract": "With the proliferation of location-aware devices, trajectory data have been used widely in real-life applications. However, trajectory data are often associated with sensitive labels, such as users’ purchase transactions and planned activities. As such, inappropriate sharing or publishing of these data could threaten users’ privacy, especially when an adversary has sufficient background knowledge about a trajectory through other data sources, such as social media (check-in tags). Though differential privacy has been used to address the privacy of trajectory data, no existing method can protect the privacy of both trajectory data and sensitive labels. In this article, we propose a comprehensive trajectory publishing algorithm with three effective procedures. First, we apply density-based clustering to determine hotspots and outliers and then blur their locations by generalization. Second, we propose a graph-based model to efficiently capture the relationship among sensitive labels and trajectory points in all records and leverage Laplace noise to achieve differential privacy. Finally, we generate and publish trajectories by traversing and updating this graph until we travel all vertexes. Our experiments on synthetic and real-life datasets demonstrate that our algorithm effectively protects the privacy of both sensitive labels and location data in trajectory publication. Compared with existing works on trajectory publishing, our algorithm can also achieve higher data utility.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4223549164",
    "type": "article"
  },
  {
    "title": "Efficient Federated Matrix Factorization Against Inference Attacks",
    "doi": "https://doi.org/10.1145/3501812",
    "publication_date": "2022-05-17",
    "publication_year": 2022,
    "authors": "Di Chai; Leye Wang; Kai Chen; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Recommender systems typically require the revelation of users’ ratings to the recommender server, which will subsequently use these ratings to provide personalized services. However, such revelations make users vulnerable to a broader set of inference attacks, allowing the recommender server to learn users’ private attributes, e.g., age and gender. Therefore, in this paper, we propose an efficient federated matrix factorization method that protects users against inference attacks. The key idea is that we obfuscate one user’s rating to another such that the private attribute leakage is minimized under the given distortion budget, which bounds the recommending loss and overhead of system efficiency. During the obfuscation, we apply differential privacy to control the information leakage between the users. We also adopt homomorphic encryption to protect the intermediate results during training. Our framework is implemented and tested on real-world datasets. The result shows that our method can reduce up to 16.7% of inference attack accuracy compared to using no privacy protections.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4280588960",
    "type": "article"
  },
  {
    "title": "Enough Waiting for the Couriers: Learning to Estimate Package Pick-up Arrival Time from Couriers’ Spatial-Temporal Behaviors",
    "doi": "https://doi.org/10.1145/3582561",
    "publication_date": "2023-02-08",
    "publication_year": 2023,
    "authors": "Haomin Wen; Youfang Lin; Fan Wu; Huaiyu Wan; Zhongxiang Sun; Tianyue Cai; Hongyu Liu; Shengnan Guo; Jianbin Zheng; Chao Song; Lixia Wu",
    "corresponding_authors": "",
    "abstract": "In intelligent logistics systems, predicting the Estimated Time of Pick-up Arrival (ETPA) of packages is a crucial task, which aims to predict the courier’s arrival time to all the unpicked-up packages at any time. Accurate prediction of ETPA can help systems alleviate customers’ waiting anxiety and improve their experience. We identify three main challenges of this problem. First, unlike the travel time estimation problem in other fields like ride-hailing, the ETPA task is distinctively a multi-destination and path-free prediction problem. Second, an intuitive idea for solving ETPA is to predict the pick-up route and then the time in two stages. However, it is difficult to accurately and efficiently predict couriers’ future routes in the route prediction step since their behaviors are affected by multiple complex factors. Third, furthermore, in the time prediction step, the requirement for providing a courier’s all unpicked-up packages’ ETPA at once in real time makes the problem even more challenging. To tackle the preceding challenges, we propose RankETPA, which integrates the route inference into the ETPA prediction. First, a learning-based pick-up route predictor is designed to learn the route-ranking strategies of couriers from their massive spatial-temporal behaviors. Then, a spatial-temporal attention-based arrival time predictor is designed for real-time ETPA inference via capturing the spatial-temporal correlations between the unpicked-up packages. Extensive experiments on two real-world datasets and a synthetic dataset demonstrate that RankETPA achieves significant performance improvement against the baseline models.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4319594638",
    "type": "article"
  },
  {
    "title": "Watermarking in Secure Federated Learning: A Verification Framework Based on Client-Side Backdooring",
    "doi": "https://doi.org/10.1145/3630636",
    "publication_date": "2023-10-30",
    "publication_year": 2023,
    "authors": "Wenyuan Yang; Shuo Shao; Yue Yang; Xiyao Liu; Ximeng Liu; Zhihua Xia; Gerald Schaefer; Hui Fang",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) allows multiple participants to collaboratively build deep learning (DL) models without directly sharing data. Consequently, the issue of copyright protection in FL becomes important since unreliable participants may gain access to the jointly trained model. Application of homomorphic encryption (HE) in a secure FL framework prevents the central server from accessing plaintext models. Thus, it is no longer feasible to embed the watermark at the central server using existing watermarking schemes. In this article, we propose a novel client-side FL watermarking scheme to tackle the copyright protection issue in secure FL with HE. To the best of our knowledge, it is the first scheme to embed the watermark to models under a secure FL environment. We design a black-box watermarking scheme based on client-side backdooring to embed a pre-designed trigger set into an FL model by a gradient-enhanced embedding method. Additionally, we propose a trigger set construction mechanism to ensure that the watermark cannot be forged. Experimental results demonstrate that our proposed scheme delivers outstanding protection performance and robustness against various watermark removal attacks and ambiguity attack.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4388016531",
    "type": "article"
  },
  {
    "title": "Robust Dimensionality Reduction via Low-rank Laplacian Graph Learning",
    "doi": "https://doi.org/10.1145/3582698",
    "publication_date": "2023-02-02",
    "publication_year": 2023,
    "authors": "Mingjian Cai; Xiang‐Jun Shen; Stanley Ebhohimhen Abhadiomhen; Yingfeng Cai; Sirui Tian",
    "corresponding_authors": "",
    "abstract": "Manifold learning is a widely used technique for dimensionality reduction as it can reveal the intrinsic geometric structure of data. However, its performance decreases drastically when data samples are contaminated by heavy noise or occlusions, which leads to unsatisfying data processing performance. We propose a novel robust dimensionality reduction method via low-rank Laplacian graph learning for classification and clustering tasks to solve the above problem. First, we construct a low-rank Laplacian graph by combining manifold learning and subspace learning. This graph can capture both global and local structural information of the data. And we introduce rank constraints for the Laplacian graph to make it more discriminative. Second, we put the learning of projection matrix and sample affinity graph into a unified framework. The projection matrix is embedded into a robust low-rank Laplacian graph so that the low-dimensional mapping of data can maintain the structural information in the graph well. Finally, we add a regularization term to the projection matrix to make it have the ability of both feature extraction and feature selection. Therefore, the proposed model can resist the interference of noise or data damage to learn the optimal projection to achieve better performance in dimensionality reduction through such a data dimensionality reduction joint framework. Comprehensive experiments on various benchmark datasets with varying degrees of occlusions or corruptions are carried out to evaluate the performance of the proposed method. Compared with the state-of-the-art dimensionality reduction methods in the literature, the experimental results are inspiring, showing our method’s effectiveness and robustness in classification and clustering, especially in object recognition scenarios with noise or occlusions.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4319034492",
    "type": "article"
  },
  {
    "title": "<scp>MaNIACS</scp> : Approximate Mining of Frequent Subgraph Patterns through Sampling",
    "doi": "https://doi.org/10.1145/3587254",
    "publication_date": "2023-03-10",
    "publication_year": 2023,
    "authors": "Giulia Preti; Gianmarco De Francisci Morales; Matteo Riondato",
    "corresponding_authors": "",
    "abstract": "We present MaNIACS , a sampling-based randomized algorithm for computing high-quality approximations of the collection of the subgraph patterns that are frequent in a single, large, vertex-labeled graph, according to the Minimum Node Image-based (MNI) frequency measure. The output of MaNIACS comes with strong probabilistic guarantees, obtained by using the empirical Vapnik–Chervonenkis (VC) dimension, a key concept from statistical learning theory, together with strong probabilistic tail bounds on the difference between the frequency of a pattern in the sample and its exact frequency. MaNIACS leverages properties of the MNI-frequency to aggressively prune the pattern search space, and thus to reduce the time spent in exploring subspaces that contain no frequent patterns. In turn, this pruning leads to better bounds to the maximum frequency estimation error, which leads to increased pruning, resulting in a beneficial feedback effect. The results of our experimental evaluation of MaNIACS on real graphs show that it returns high-quality collections of frequent patterns in large graphs up to two orders of magnitude faster than the exact algorithm.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4323864059",
    "type": "article"
  },
  {
    "title": "Hyper-Laplacian Regularized Multi-View Clustering with Exclusive L21 Regularization and Tensor Log-Determinant Minimization Approach",
    "doi": "https://doi.org/10.1145/3587034",
    "publication_date": "2023-03-16",
    "publication_year": 2023,
    "authors": "Qilun Luo; Ming Yang; Wen Li; Mingqing Xiao",
    "corresponding_authors": "",
    "abstract": "Multi-view clustering aims to capture the multiple views inherent information by identifying the data clustering that reflects distinct features of datasets. Since there is a consensus in literature that different views of a dataset share a common latent structure, most existing multi-view subspace learning methods rely on the nuclear norm to seek the low-rank representation of the underlying subspace. However, the nuclear norm often fails to distinguish the variance of features for each cluster due to its convex nature and data tends to fall in multiple non-linear subspaces for multi-dimensional datasets. To address these problems, we propose a new and novel multi-view clustering method (HL-L21-TLD-MSC) that unifies the Hyper-Laplacian (HL) and exclusive ℓ 2,1 (L21) regularization with the Tensor Log-Determinant Rank Minimization (TLD) setting. Specifically, the hyper-Laplacian regularization maintains the local geometrical structure that makes the estimation prune to nonlinearities, and the mixed ℓ 2,1 and ℓ 1,2 regularization provides the joint sparsity within-cluster as well as the exclusive sparsity between-cluster. Furthermore, a log-determinant function is used as a tighter tensor rank approximation to discriminate the dimension of features. An efficient alternating algorithm is then derived to optimize the proposed model, and the construction of a convergent sequence to the Karush-Kuhn-Tucker (KKT) critical point solution is mathematically validated in detail. Extensive experiments are conducted on ten well-known datasets to demonstrate that the proposed approach outperforms the existing state-of-the-art approaches with various scenarios, in which, six of them achieve perfect results under our framework developed in this article, demonstrating highl effectiveness for the proposed approach.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4327590988",
    "type": "article"
  },
  {
    "title": "Automatic player labeling, tracking and field registration and trajectory mapping in broadcast soccer video",
    "doi": "https://doi.org/10.1145/1899412.1899419",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Xiaofeng Tong; Jia Liu; Tao Wang; Yimin Zhang",
    "corresponding_authors": "",
    "abstract": "In this article, we present a method to perform automatic player trajectories mapping based on player detection, unsupervised labeling, efficient multi-object tracking, and playfield registration in broadcast soccer videos. Player detector determines the players' positions and scales by combining the ability of dominant color based background subtraction and a boosting detector with Haar features. We first learn the dominant color with accumulate color histogram at the beginning of processing, then use the player detector to collect hundreds of player samples, and learn player appearance codebook by unsupervised clustering. In a soccer game, a player can be labeled as one of four categories: two teams, referee or outlier. The learning capability enables the method to be generalized well to different videos without any manual initialization. With the dominant color and player appearance model, we can locate and label each player. After that, we perform multi-object tracking by using Markov Chain Monte Carlo (MCMC) data association to generate player trajectories. Some data driven dynamics are proposed to improve the Markov chain's efficiency, such as label consistency, motion consistency, and track length, etc. Finally, we extract key-points and find the mapping from an image plane to the standard field model, and then map players' position and trajectories to the field. A large quantity of experimental results on FIFA World Cup 2006 videos demonstrate that this method can reach high detection and labeling precision, reliably tracking in scenes of player occlusion, moderate camera motion and pose variation, and yield promising field registration results.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2171314781",
    "type": "article"
  },
  {
    "title": "A fully online and unsupervised system for large and high-density area surveillance",
    "doi": "https://doi.org/10.1145/2438653.2438670",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Xuan Song; Xiaowei Shao; Quanshi Zhang; Ryosuke Shibasaki; Huijing Zhao; Jinshi Cui; Hongbin Zha",
    "corresponding_authors": "",
    "abstract": "For reasons of public security, an intelligent surveillance system that can cover a large, crowded public area has become an urgent need. In this article, we propose a novel laser-based system that can simultaneously perform tracking, semantic scene learning, and abnormality detection in a fully online and unsupervised way. Furthermore, these three tasks cooperate with each other in one framework to improve their respective performances. The proposed system has the following key advantages over previous ones: (1) It can cover quite a large area (more than 60×35m), and simultaneously perform robust tracking, semantic scene learning, and abnormality detection in a high-density situation. (2) The overall system can vary with time, incrementally learn the structure of the scene, and perform fully online abnormal activity detection and tracking. This feature makes our system suitable for real-time applications. (3) The surveillance tasks are carried out in a fully unsupervised manner, so that there is no need for manual labeling and the construction of huge training datasets. We successfully apply the proposed system to the JR subway station in Tokyo, and demonstrate that it can cover an area of 60×35m, robustly track more than 150 targets at the same time, and simultaneously perform online semantic scene learning and abnormality detection with no human intervention.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1968149994",
    "type": "article"
  },
  {
    "title": "Exploring pattern-aware travel routes for trajectory search",
    "doi": "https://doi.org/10.1145/2483669.2483681",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Ling-Yin Wei; Wen-Chih Peng; Wang-Chien Lee",
    "corresponding_authors": "",
    "abstract": "With the popularity of positioning devices, Web 2.0 technology, and trip sharing services, many users are willing to log and share their trips on the Web. Thus, trip planning Web sites are able to provide some new services by inferring Regions-Of-Interest (ROIs) and recommending popular travel routes from trip trajectories. We argue that simply providing some travel routes consisting of popular ROIs to users is not sufficient. To tour around a wide geographical area, for example, a city, some users may prefer a trip to visit as many ROIs as possible, while others may like to stop by only a few ROIs for an in-depth visit. We refer to a trip fitting the former user group as an in-breadth trip and a trip suitable for the latter user group as an in-depth trip . Prior studies on trip planning have focused on mining ROIs and travel routes without considering these different preferences. In this article, given a spatial range and a user preference of depth/breadth specified by a user, we develop a Pattern-Aware Trajectory Search (PATS) framework to retrieve the top K trajectories passing through popular ROIs. PATS is novel because the returned travel trajectories, discovered from travel patterns hidden in trip trajectories, may represent the most valuable travel experiences of other travelers fitting the user's trip preference in terms of depth or breadth. The PATS framework comprises two components: travel behavior exploration and trajectory search . The travel behavior exploration component determines a set of ROIs along with their attractive scores by considering not only the popularity of the ROIs but also the travel sequential relationships among the ROIs. To capture the travel sequential relationships among ROIs and to derive their attractive scores, a user movement graph is constructed. For the trajectory search component of PATS, we formulate two trajectory score functions, the depth-trip score function and the breadth-trip score function, by taking into account the number of ROIs in a trajectory and their attractive scores. Accordingly, we propose an algorithm, namely, Bounded Trajectory Search (BTS), to efficiently retrieve the top K trajectories based on the two trajectory scores. The PATS framework is evaluated by experiments and user studies using a real dataset. The experimental results demonstrate the effectiveness and the efficiency of the proposed PATS framework.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2000910707",
    "type": "article"
  },
  {
    "title": "A machine learning approach to college drinking prediction and risk factor identification",
    "doi": "https://doi.org/10.1145/2508037.2508053",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Jinbo Bi; Jiangwen Sun; Yu‐Wei Wu; Howard Tennen; Stephen Armeli",
    "corresponding_authors": "",
    "abstract": "Alcohol misuse is one of the most serious public health problems facing adolescents and young adults in the United States. National statistics shows that nearly 90% of alcohol consumed by youth under 21 years of age involves binge drinking and 44% of college students engage in high-risk drinking activities. Conventional alcohol intervention programs, which aim at installing either an alcohol reduction norm or prohibition against underage drinking, have yielded little progress in controlling college binge drinking over the years. Existing alcohol studies are deductive where data are collected to investigate a psychological/behavioral hypothesis, and statistical analysis is applied to the data to confirm the hypothesis. Due to this confirmatory manner of analysis, the resulting statistical models are cohort-specific and typically fail to replicate on a different sample. This article presents two machine learning approaches for a secondary analysis of longitudinal data collected in college alcohol studies sponsored by the National Institute on Alcohol Abuse and Alcoholism. Our approach aims to discover knowledge, from multiwave cohort-sequential daily data, which may or may not align with the original hypothesis but quantifies predictive models with higher likelihood to generalize to new samples. We first propose a so-called temporally-correlated support vector machine to construct a classifier as a function of daily moods, stress, and drinking expectancies to distinguish days with nighttime binge drinking from days without for individual students. We then propose a combination of cluster analysis and feature selection, where cluster analysis is used to identify drinking patterns based on averaged daily drinking behavior and feature selection is used to identify risk factors associated with each pattern. We evaluate our methods on two cohorts of 530 total college students recruited during the Spring and Fall semesters, respectively. Cross validation on these two cohorts and further on 100 random partitions of the total students demonstrate that our methods improve the model generalizability in comparison with traditional multilevel logistic regression. The discovered risk factors and the interaction of these factors delineated in our models can set a potential basis and offer insights to a new design of more effective college alcohol interventions.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2035318406",
    "type": "article"
  },
  {
    "title": "Community detection and visualization in social networks",
    "doi": "https://doi.org/10.1145/2542182.2542193",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Juan David Cruz Gomez; Cécile Bothorel; F. Poulet",
    "corresponding_authors": "",
    "abstract": "Due to the explosion of social networking and the information sharing among their users, the interest in analyzing social networks has increased over the recent years. Two general interests in this kind of studies are community detection and visualization. In the first case, most of the classic algorithms for community detection use only the structural information to identify groups, that is, how clusters are formed according to the topology of the relationships. However, these methods do not take into account any semantic information which could guide the clustering process, and which may add elements to conduct further analyses. In the second case most of the layout algorithms for clustered graphs have been designed to differentiate the groups within the graph, but they are not designed to analyze the interactions between such groups. Identifying these interactions gives an insight into the way different communities exchange messages or information, and allows the social network researcher to identify key actors, roles, and paths from one community to another. This article presents a novel model to use, in a conjoint way, the semantic information from the social network and its structural information to, first, find structurally and semantically related groups of nodes, and second, a layout algorithm for clustered graphs which divides the nodes into two types, one for nodes with edges connecting other communities and another with nodes connecting nodes only within their own community. With this division the visualization tool focuses on the connections between groups facilitating deep studies of augmented social networks.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2054116241",
    "type": "article"
  },
  {
    "title": "Effective and efficient microprocessor design space exploration using unlabeled design configurations",
    "doi": "https://doi.org/10.1145/2542182.2542202",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Tianshi Chen; Yunji Chen; Qi Guo; Zhi‐Hua Zhou; Ling Li; Zhiwei Xu",
    "corresponding_authors": "",
    "abstract": "Ever-increasing design complexity and advances of technology impose great challenges on the design of modern microprocessors. One such challenge is to determine promising microprocessor configurations to meet specific design constraints, which is called Design Space Exploration (DSE). In the computer architecture community, supervised learning techniques have been applied to DSE to build regression models for predicting the qualities of design configurations. For supervised learning, however, considerable simulation costs are required for attaining the labeled design configurations. Given limited resources, it is difficult to achieve high accuracy. In this article, inspired by recent advances in semisupervised learning and active learning, we propose the COAL approach which can exploit unlabeled design configurations to significantly improve the models. Empirical study demonstrates that COAL significantly outperforms a state-of-the-art DSE technique by reducing mean squared error by 35% to 95%, and thus, promising architectures can be attained more efficiently.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2131609469",
    "type": "article"
  },
  {
    "title": "Detecting Social Media Hidden Communities Using Dynamic Stochastic Blockmodel with Temporal Dirichlet Process",
    "doi": "https://doi.org/10.1145/2517085",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Xuning Tang; Christopher C. Yang",
    "corresponding_authors": "",
    "abstract": "Detecting evolving hidden communities within dynamic social networks has attracted significant attention recently due to its broad applications in e-commerce, online social media, security intelligence, public health, and other areas. Many community network detection techniques employ a two-stage approach to identify and detect evolutionary relationships between communities of two adjacent time epochs. These techniques often identify communities with high temporal variation, since the two-stage approach detects communities of each epoch independently without considering the continuity of communities across two time epochs. Other techniques require identification of a predefined number of hidden communities which is not realistic in many applications. To overcome these limitations, we propose the Dynamic Stochastic Blockmodel with Temporal Dirichlet Process, which enables the detection of hidden communities and tracks their evolution simultaneously from a network stream. The number of hidden communities is automatically determined by a temporal Dirichlet process without human intervention. We tested our proposed technique on three different testbeds with results identifying a high performance level when compared to the baseline algorithm.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1977660912",
    "type": "article"
  },
  {
    "title": "Transfer Metric Learning with Semi-Supervised Extension",
    "doi": "https://doi.org/10.1145/2168752.2168768",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Yu Zhang; Dit‐Yan Yeung",
    "corresponding_authors": "",
    "abstract": "Distance metric learning plays a very crucial role in many data mining algorithms because the performance of an algorithm relies heavily on choosing a good metric. However, the labeled data available in many applications is scarce, and hence the metrics learned are often unsatisfactory. In this article, we consider a transfer-learning setting in which some related source tasks with labeled data are available to help the learning of the target task. We first propose a convex formulation for multitask metric learning by modeling the task relationships in the form of a task covariance matrix. Then we regard transfer learning as a special case of multitask learning and adapt the formulation of multitask metric learning to the transfer-learning setting for our method, called transfer metric learning (TML). In TML, we learn the metric and the task covariances between the source tasks and the target task under a unified convex formulation. To solve the convex optimization problem, we use an alternating method in which each subproblem has an efficient solution. Moreover, in many applications, some unlabeled data is also available in the target task, and so we propose a semi-supervised extension of TML called STML to further improve the generalization performance by exploiting the unlabeled data based on the manifold assumption. Experimental results on some commonly used transfer-learning applications demonstrate the effectiveness of our method.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1984608801",
    "type": "article"
  },
  {
    "title": "Tractable POMDP representations for intelligent tutoring systems",
    "doi": "https://doi.org/10.1145/2438653.2438664",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jeremiah T. Folsom-Kovarik; Gita Sukthankar; Sae Schatz",
    "corresponding_authors": "",
    "abstract": "With Partially Observable Markov Decision Processes (POMDPs), Intelligent Tutoring Systems (ITSs) can model individual learners from limited evidence and plan ahead despite uncertainty. However, POMDPs need appropriate representations to become tractable in ITSs that model many learner features, such as mastery of individual skills or the presence of specific misconceptions. This article describes two POMDP representations— state queues and observation chains —that take advantage of ITS task properties and let POMDPs scale to represent over 100 independent learner features. A real-world military training problem is given as one example. A human study ( n = 14) provides initial validation for the model construction. Finally, evaluating the experimental representations with simulated students helps predict their impact on ITS performance. The compressed representations can model a wide range of simulated problems with instructional efficacy equal to lossless representations. With improved tractability, POMDP ITSs can accommodate more numerous or more detailed learner states and inputs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2069713201",
    "type": "article"
  },
  {
    "title": "Real-Time System for Driver Fatigue Detection by RGB-D Camera",
    "doi": "https://doi.org/10.1145/2629482",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Liyan Zhang; Fan Liu; Jinhui Tang",
    "corresponding_authors": "",
    "abstract": "Drowsy driving is one of the major causes of fatal traffic accidents. In this article, we propose a real-time system that utilizes RGB-D cameras to automatically detect driver fatigue and generate alerts to drivers. By introducing RGB-D cameras, the depth data can be obtained, which provides extra evidence to benefit the task of head detection and head pose estimation. In this system, two important visual cues (head pose and eye state) for driver fatigue detection are extracted and leveraged simultaneously. We first present a real-time 3D head pose estimation method by leveraging RGB and depth data. Then we introduce a novel method to predict eye states employing the WLBP feature, which is a powerful local image descriptor that is robust to noise and illumination variations. Finally, we integrate the results from both head pose and eye states to generate the overall conclusion. The combination and collaboration of the two types of visual cues can reduce the uncertainties and resolve the ambiguity that a single cue may induce. The experiments were performed using an inside-car environment during the day and night, and theyfully demonstrate the effectiveness and robustness of our system as well as the proposed methods of predicting head pose and eye states.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2071669314",
    "type": "article"
  },
  {
    "title": "On the Relationship between Novelty and Popularity of User-Generated Content",
    "doi": "https://doi.org/10.1145/2337542.2337554",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "David Carmel; Haggai Roitman; Elad Yom‐Tov",
    "corresponding_authors": "",
    "abstract": "This work deals with the task of predicting the popularity of user-generated content. We demonstrate how the novelty of newly published content plays an important role in affecting its popularity. More specifically, we study three dimensions of novelty. The first one, termed contemporaneous novelty , models the relative novelty embedded in a new post with respect to contemporary content that was generated by others. The second type of novelty, termed self novelty , models the relative novelty with respect to the user’s own contribution history. The third type of novelty, termed discussion novelty , relates to the novelty of the comments associated by readers with respect to the post content. We demonstrate the contribution of the new novelty measures to estimating blog-post popularity by predicting the number of comments expected for a fresh post. We further demonstrate how novelty based measures can be utilized for predicting the citation volume of academic papers.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2078456932",
    "type": "article"
  },
  {
    "title": "Infer User Interests via Link Structure Regularization",
    "doi": "https://doi.org/10.1145/2499380",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Jinpeng Wang; Wayne Xin Zhao; Yulan He; Xiaoming Li",
    "corresponding_authors": "",
    "abstract": "Learning user interests from online social networks helps to better understand user behaviors and provides useful guidance to design user-centric applications. Apart from analyzing users' online content, it is also important to consider users' social connections in the social Web. Graph regularization methods have been widely used in various text mining tasks, which can leverage the graph structure information extracted from data. Previously, graph regularization methods operate under the cluster assumption that nearby nodes are more similar and nodes on the same structure (typically referred to as a cluster or a manifold) are likely to be similar. We argue that learning user interests from complex, sparse, and dynamic social networks should be based on the link structure assumption under which node similarities are evaluated based on the local link structures instead of explicit links between two nodes. We propose a regularization framework based on the relation bipartite graph, which can be constructed from any type of relations. Using Twitter as our case study, we evaluate our proposed framework from social networks built from retweet relations. Both quantitative and qualitative experiments show that our proposed method outperforms a few competitive baselines in learning user interests over a set of predefined topics. It also gives superior results compared to the baselines on retweet prediction and topical authority identification.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2085826953",
    "type": "article"
  },
  {
    "title": "DUCT",
    "doi": "https://doi.org/10.1145/3066156",
    "publication_date": "2017-07-12",
    "publication_year": 2017,
    "authors": "Brammert Ottens; Christos Dimitrakakis; Boi Faltings",
    "corresponding_authors": "",
    "abstract": "We propose a distributed upper confidence bound approach, DUCT, for solving distributed constraint optimization problems. We compare four variants of this approach with a baseline random sampling algorithm, as well as other complete and incomplete algorithms for DCOPs. Under general assumptions, we theoretically show that the solution found by DUCT after T steps is approximately T −1 -close to the optimal. Experimentally, we show that DUCT matches the optimal solution found by the well-known DPOP and O-DPOP algorithms on moderate-size problems, while always requiring less agent communication. For larger problems, where DPOP fails, we show that DUCT produces significantly better solutions than local, incomplete algorithms. Overall, we believe that DUCT is a practical, scalable algorithm for complex DCOPs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2735020746",
    "type": "article"
  },
  {
    "title": "Information Retrieval in the Commentsphere",
    "doi": "https://doi.org/10.1145/2337542.2337553",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Martin Potthast; Benno Stein; Fabian Loose; Steffen Becker",
    "corresponding_authors": "",
    "abstract": "This article studies information retrieval tasks related to Web comments. Prerequisite of such a study and a main contribution of the article is a unifying survey of the research field. We identify the most important retrieval tasks related to comments, namely filtering, ranking, and summarization. Within these tasks, we distinguish two paradigms according to which comments are utilized and which we designate as comment-targeting and comment-exploiting . Within the first paradigm, the comments themselves form the retrieval targets. Within the second paradigm, the commented items form the retrieval targets (i.e., comments are used as an additional information source to improve the retrieval performance for the commented items). We report on four case studies to demonstrate the exploration of the commentsphere under information retrieval aspects: comment filtering, comment ranking, comment summarization and cross-media retrieval. The first three studies deal primarily with comment-targeting retrieval, while the last one deals with comment-exploiting retrieval. Throughout the article, connections to information retrieval research are pointed out.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2020345959",
    "type": "article"
  },
  {
    "title": "Local Structure-Based Sparse Representation for Face Recognition",
    "doi": "https://doi.org/10.1145/2733383",
    "publication_date": "2015-10-07",
    "publication_year": 2015,
    "authors": "Fan Liu; Jinhui Tang; Yan Song; Liyan Zhang; Zhenmin Tang",
    "corresponding_authors": "",
    "abstract": "This article presents a simple yet effective face recognition method, called local structure-based sparse representation classification (LS_SRC). Motivated by the “divide-and-conquer” strategy, we first divide the face into local blocks and classify each local block, then integrate all the classification results to make the final decision. To classify each local block, we further divide each block into several overlapped local patches and assume that these local patches lie in a linear subspace. This subspace assumption reflects the local structure relationship of the overlapped patches, making sparse representation-based classification (SRC) feasible even when encountering the single-sample-per-person (SSPP) problem. To lighten the computing burden of LS_SRC, we further propose the local structure-based collaborative representation classification (LS_CRC). Moreover, the performance of LS_SRC and LS_CRC can be further improved by using the confusion matrix of the classifier. Experimental results on four public face databases show that our methods not only generalize well to SSPP problem but also have strong robustness to occlusion; little pose variation; and the variations of expression, illumination, and time.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2040925620",
    "type": "article"
  },
  {
    "title": "An abstractive approach to sentence compression",
    "doi": "https://doi.org/10.1145/2483669.2483674",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Trevor Cohn; Mirella Lapata",
    "corresponding_authors": "",
    "abstract": "In this article we generalize the sentence compression task. Rather than simply shorten a sentence by deleting words or constituents, as in previous work, we rewrite it using additional operations such as substitution, reordering, and insertion. We present an experimental study showing that humans can naturally create abstractive sentences using a variety of rewrite operations, not just deletion. We next create a new corpus that is suited to the abstractive compression task and formulate a discriminative tree-to-tree transduction model that can account for structural and lexical mismatches. The model incorporates a grammar extraction method, uses a language model for coherent output, and can be easily tuned to a wide range of compression-specific loss functions.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2104944827",
    "type": "article"
  },
  {
    "title": "Combination Forecasting Reversion Strategy for Online Portfolio Selection",
    "doi": "https://doi.org/10.1145/3200692",
    "publication_date": "2018-06-22",
    "publication_year": 2018,
    "authors": "Ding-jiang Huang; Shunchang Yu; Bin Li; Steven C. H. Hoi; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "Machine learning and artificial intelligence techniques have been applied to construct online portfolio selection strategies recently. A popular and state-of-the-art family of strategies is to explore the reversion phenomenon through online learning algorithms and statistical prediction models. Despite gaining promising results on some benchmark datasets, these strategies often adopt a single model based on a selection criterion (e.g., breakdown point) for predicting future price. However, such model selection is often unstable and may cause unnecessarily high variability in the final estimation, leading to poor prediction performance in real datasets and thus non-optimal portfolios. To overcome the drawbacks, in this article, we propose to exploit the reversion phenomenon by using combination forecasting estimators and design a novel online portfolio selection strategy, named Combination Forecasting Reversion (CFR), which outputs optimal portfolios based on the improved reversion estimator. We further present two efficient CFR implementations based on online Newton step (ONS) and online gradient descent (OGD) algorithms, respectively, and theoretically analyze their regret bounds, which guarantee that the online CFR model performs as well as the best CFR model in hindsight. We evaluate the proposed algorithms on various real markets with extensive experiments. Empirical results show that CFR can effectively overcome the drawbacks of existing reversion strategies and achieve the state-of-the-art performance.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2809119175",
    "type": "article"
  },
  {
    "title": "Multitask Low-Rank Affinity Graph for Image Segmentation and Image Annotation",
    "doi": "https://doi.org/10.1145/2856058",
    "publication_date": "2016-03-31",
    "publication_year": 2016,
    "authors": "Teng Li; Bin Cheng; Bingbing Ni; Guangchan Liu; Shuicheng Yan",
    "corresponding_authors": "",
    "abstract": "This article investigates a low-rank representation--based graph, which can used in graph-based vision tasks including image segmentation and image annotation. It naturally fuses multiple types of image features in a framework named multitask low-rank affinity pursuit. Given the image patches described with multiple types of features, we aim at inferring a unified affinity matrix that implicitly encodes the relations among these patches. This is achieved by seeking the sparsity-consistent low-rank affinities from the joint decompositions of multiple feature matrices into pairs of sparse and low-rank matrices, the latter of which is expressed as the production of the image feature matrix and its corresponding image affinity matrix. The inference process is formulated as a minimization problem and solved efficiently with the augmented Lagrange multiplier method. Considering image patches as vertices, a graph can be built based on the resulted affinity matrix. Compared to previous methods, which are usually based on a single type of feature, the proposed method seamlessly integrates multiple types of features to jointly produce the affinity matrix in a single inference step. The proposed method is applied to graph-based image segmentation and graph-based image annotation. Experiments on benchmark datasets well validate the superiority of using multiple features over single feature and also the superiority of our method over conventional methods for feature fusion.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2325658686",
    "type": "article"
  },
  {
    "title": "Coranking the Future Influence of Multiobjects in Bibliographic Network Through Mutual Reinforcement",
    "doi": "https://doi.org/10.1145/2897371",
    "publication_date": "2016-05-02",
    "publication_year": 2016,
    "authors": "Senzhang Wang; Sihong Xie; Xiaoming Zhang; Zhoujun Li; Philip S. Yu; Yueying He",
    "corresponding_authors": "",
    "abstract": "Scientific literature ranking is essential to help researchers find valuable publications from a large literature collection. Recently, with the prevalence of webpage ranking algorithms such as PageRank and HITS, graph-based algorithms have been widely used to iteratively rank papers and researchers through the networks formed by citation and coauthor relationships. However, existing graph-based ranking algorithms mostly focus on ranking the current importance of literature. For researchers who enter an emerging research area, they might be more interested in new papers and young researchers that are likely to become influential in the future, since such papers and researchers are more helpful in letting them quickly catch up on the most recent advances and find valuable research directions. Meanwhile, although some works have been proposed to rank the prestige of a certain type of objects with the help of multiple networks formed of multiobjects, there still lacks a unified framework to rank multiple types of objects in the bibliographic network simultaneously. In this article, we propose a unified ranking framework MRCoRank to corank the future popularity of four types of objects: papers, authors, terms, and venues through mutual reinforcement. Specifically, because the citation data of new publications are sparse and not efficient to characterize their innovativeness, we make the first attempt to extract the text features to help characterize innovative papers and authors. With the observation that the current trend is more indicative of the future trend of citation and coauthor relationships, we then construct time-aware weighted graphs to quantify the importance of links established at different times on both citation and coauthor graphs. By leveraging both the constructed text features and time-aware graphs, we finally fuse the rich information in a mutual reinforcement ranking framework to rank the future importance of multiobjects simultaneously. We evaluate the proposed model through extensive experiments on the ArnetMiner dataset containing more than 1,500,000 papers. Experimental results verify the effectiveness of MRCoRank in coranking the future influence of multiobjects in a bibliographic network.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2346028821",
    "type": "article"
  },
  {
    "title": "Exploiting Social-Mobile Information for Location Visualization",
    "doi": "https://doi.org/10.1145/3001594",
    "publication_date": "2017-01-12",
    "publication_year": 2017,
    "authors": "Jitao Sang; Quan Fang; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "With a smart phone at hand, it becomes easy now to snap pictures and publish them online with few lines of texts. The GPS coordinates and User-Generated Content (UGC) data embedded in the shared photos provide opportunities to exploit important knowledge to tackle interesting tasks like geographically organizing photos and location visualization. In this work, we propose to organize photos both geographically and semantically, and investigate the problem of location visualization from multiple semantic themes. The novel visualization scheme provides a rich display landscape for geographical exploration from versatile views. A two-level solution is presented, where we first identify the highly photographed places of interest (POI) and discover their focused themes, and then aggregate the lower-level POI themes to generate the higher-level city themes for location visualization. We have conducted experiments on crawled Flickr and Instagram data and exhibited the visualization for the cities of Singapore and Sydney. The experimental results have validated the proposed method and demonstrated the potentials of location visualization from multiple themes.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2574240456",
    "type": "article"
  },
  {
    "title": "Unveiling Correlations via Mining Human-Thing Interactions in the Web of Things",
    "doi": "https://doi.org/10.1145/3035967",
    "publication_date": "2017-06-30",
    "publication_year": 2017,
    "authors": "Lina Yao; Quan Z. Sheng; Anne H. H. Ngu; Xue Li; Boualem Benattalah",
    "corresponding_authors": "",
    "abstract": "With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web services, physical things are becoming an integral part of the emerging ubiquitous Web. Finding correlations among ubiquitous things is a crucial prerequisite for many important applications such as things search, discovery, classification, recommendation, and composition. This article presents DisCor-T , a novel graph-based approach for discovering underlying connections of things via mining the rich content embodied in the human-thing interactions in terms of user, temporal, and spatial information. We model this various information using two graphs, namely a spatio-temporal graph and a social graph. Then, random walk with restart (RWR) is applied to find proximities among things, and a relational graph of things (RGT) indicating implicit correlations of things is learned. The correlation analysis lays a solid foundation contributing to improved effectiveness in things management and analytics. To demonstrate the utility of the proposed approach, we develop a flexible feature-based classification framework on top of RGT and perform a systematic case study. Our evaluation exhibits the strength and feasibility of the proposed approach.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2726400417",
    "type": "article"
  },
  {
    "title": "Visual Classification of Furniture Styles",
    "doi": "https://doi.org/10.1145/3065951",
    "publication_date": "2017-06-30",
    "publication_year": 2017,
    "authors": "Zhenhen Hu; Yonggang Wen; Luoqi Liu; Jianguo Jiang; Richang Hong; Meng Wang; Shuicheng Yan",
    "corresponding_authors": "",
    "abstract": "Furniture style describes the discriminative appearance characteristics of furniture. It plays an important role in real-world indoor decoration. In this article, we explore the furniture style features and study the problem of furniture style classification. Differing from traditional object classification, furniture style classification aims at classifying different furniture in terms of the “style” that describes its appearance (e.g., American style, Gothic style, Rococo style, etc.) rather than the “kind” that is more related to its functional structure (e.g., bed, desk, etc.). To pursue efficient furniture style features, we construct a novel dataset of furniture styles that contains 16 common style categories and implement three strategies with respect to two categories of classification, that is, handcrafted classification and learning-based classification. First, we follow the typical image classification pipeline to extract the handcrafted features and train the classifier by support vector machine. Then we use the convolutional neural network to extract learning-based features from training images. To obtain comprehensive furniture style features, we finally combine the handcrafted image classification pipeline and the learning-based network. We experimentally evaluate the performances of handcrafted features and learning-based features of each strategy, and the results show the superiority of learning-based features and also the comprehensiveness of handcrafted features.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2734103229",
    "type": "article"
  },
  {
    "title": "Strategic Information Disclosure to People with Multiple Alternatives",
    "doi": "https://doi.org/10.1145/2558397",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Amos Azaria; Zinovi Rabinovich; Claudia V. Goldman; Sarit Kraus",
    "corresponding_authors": "",
    "abstract": "In this article, we study automated agents that are designed to encourage humans to take some actions over others by strategically disclosing key pieces of information. To this end, we utilize the framework of persuasion games—a branch of game theory that deals with asymmetric interactions where one player (Sender) possesses more information about the world, but it is only the other player (Receiver) who can take an action. In particular, we use an extended persuasion model, where the Sender’s information is imperfect and the Receiver has more than two alternative actions available. We design a computational algorithm that, from the Sender’s standpoint, calculates the optimal information disclosure rule. The algorithm is parameterized by the Receiver’s decision model (i.e., what choice he will make based on the information disclosed by the Sender) and can be retuned accordingly. We then provide an extensive experimental study of the algorithm’s performance in interactions with human Receivers. First, we consider a fully rational (in the Bayesian sense) Receiver decision model and experimentally show the efficacy of the resulting Sender’s solution in a routing domain. Despite the discrepancy in the Sender’s and the Receiver’s utilities from each of the Receiver’s choices, our Sender agent successfully persuaded human Receivers to select an option more beneficial for the agent. Dropping the Receiver’s rationality assumption, we introduce a machine learning procedure that generates a more realistic human Receiver model. We then show its significant benefit to the Sender solution by repeating our routing experiment. To complete our study, we introduce a second (supply--demand) experimental domain and, by contrasting it with the routing domain, obtain general guidelines for a Sender on how to construct a Receiver model.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2045350176",
    "type": "article"
  },
  {
    "title": "CITY FEED",
    "doi": "https://doi.org/10.1145/2873064",
    "publication_date": "2016-03-31",
    "publication_year": 2016,
    "authors": "Linlin You; Gianmario Motta; Kaixu Liu; Tianyi Ma",
    "corresponding_authors": "",
    "abstract": "Crowdsourcing implies user collaboration and engagement, which fosters a renewal of city governance processes. In this article, we address a subset of crowdsourcing, named citizen-sourcing, where citizens interact with authorities collaboratively and actively. Many systems have experimented citizen-sourcing in city governance processes; however, their maturity levels are mixed. In order to focus on the service maturity, we introduce a city service maturity framework that contains five levels of service support and two levels of information integration. As an example, we introduce CITY FEED, which implements citizen-sourcing in city issue management process. In order to support such process, CITY FEED supports all levels of the maturity framework (publishing, transacting, interacting, collaborating, and evaluating) and integrates related information relationally and heterogeneously. In order to integrate heterogeneous information, it implements a threefold feed deduplication mechanism based on the geographic, text semantic, and image similarities of feeds. Currently, CITY FEED is in a pilot stage.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2332605193",
    "type": "article"
  },
  {
    "title": "Crowdsourcing Without a Crowd",
    "doi": "https://doi.org/10.1145/2776896",
    "publication_date": "2016-05-05",
    "publication_year": 2016,
    "authors": "Advaith Siddharthan; Christopher Lambin; Anne-Marie Robinson; Nirwan Sharma; Richard Comont; Elaine M. O'Mahony; Chris Mellish; René van der Wal",
    "corresponding_authors": "",
    "abstract": "We present an incremental Bayesian model that resolves key issues of crowd size and data quality for consensus labeling. We evaluate our method using data collected from a real-world citizen science program, B ee W atch , which invites members of the public in the United Kingdom to classify (label) photographs of bumblebees as one of 22 possible species. The biological recording domain poses two key and hitherto unaddressed challenges for consensus models of crowdsourcing: (1) the large number of potential species makes classification difficult, and (2) this is compounded by limited crowd availability, stemming from both the inherent difficulty of the task and the lack of relevant skills among the general public. We demonstrate that consensus labels can be reliably found in such circumstances with very small crowd sizes of around three to five users (i.e., through group sourcing). Our incremental Bayesian model, which minimizes crowd size by re-evaluating the quality of the consensus label following each species identification solicited from the crowd, is competitive with a Bayesian approach that uses a larger but fixed crowd size and outperforms majority voting. These results have important ecological applicability: biological recording programs such as B ee W atch can sustain themselves when resources such as taxonomic experts to confirm identifications by photo submitters are scarce (as is typically the case), and feedback can be provided to submitters in a timely fashion. More generally, our model provides benefits to any crowdsourced consensus labeling task where there is a cost (financial or otherwise) associated with soliciting a label.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2346616636",
    "type": "article"
  },
  {
    "title": "Learning User Attributes via Mobile Social Multimedia Analytics",
    "doi": "https://doi.org/10.1145/2963105",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Liqiang Nie; Luming Zhang; Meng Wang; Richang Hong; Aleksandr Farseev; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Learning user attributes from mobile social media is a fundamental basis for many applications, such as personalized and targeting services. A large and growing body of literature has investigated the user attributes learning problem. However, far too little attention has been paid to jointly consider the dual heterogeneities of user attributes learning by harvesting multiple social media sources. In particular, user attributes are complementarily and comprehensively characterized by multiple social media sources, including footprints from Foursqare, daily updates from Twitter, professional careers from Linkedin, and photo posts from Instagram. On the other hand, attributes are inter-correlated in a complex way rather than independent to each other, and highly related attributes may share similar feature sets. Towards this end, we proposed a unified model to jointly regularize the source consistency and graph-constrained relatedness among tasks. As a byproduct, it is able to learn the attribute-specific and attribute-sharing features via graph-guided fused lasso penalty. Besides, we have theoretically demonstrated its optimization. Extensive evaluations on a real-world dataset thoroughly demonstrated the effectiveness of our proposed model.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2605531266",
    "type": "article"
  },
  {
    "title": "Mining Significant Microblogs for Misinformation Identification",
    "doi": "https://doi.org/10.1145/3173458",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Qiang Liu; Feng Yu; Shu Wu; Liang Wang",
    "corresponding_authors": "",
    "abstract": "With the rapid growth of social media, massive misinformation is also spreading widely on social media, e.g., Weibo and Twitter, and brings negative effects to human life. Today, automatic misinformation identification has drawn attention from academic and industrial communities. Whereas an event on social media usually consists of multiple microblogs, current methods are mainly constructed based on global statistical features. However, information on social media is full of noise, which should be alleviated. Moreover, most of the microblogs about an event have little contribution to the identification of misinformation, where useful information can be easily overwhelmed by useless information. Thus, it is important to mine significant microblogs for constructing a reliable misinformation identification method. In this article, we propose an attention-based approach for identification of misinformation (AIM). Based on the attention mechanism, AIM can select microblogs with the largest attention values for misinformation identification. The attention mechanism in AIM contains two parts: content attention and dynamic attention. Content attention is the calculated-based textual features of each microblog. Dynamic attention is related to the time interval between the posting time of a microblog and the beginning of the event. To evaluate AIM, we conduct a series of experiments on the Weibo and Twitter datasets, and the experimental results show that the proposed AIM model outperforms the state-of-the-art methods.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2962981892",
    "type": "article"
  },
  {
    "title": "Edge-enabled Disaster Rescue",
    "doi": "https://doi.org/10.1145/3331146",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Fang Liu; Yeting Guo; Zhiping Cai; Nong Xiao; Ziming Zhao",
    "corresponding_authors": "",
    "abstract": "In the aftermath of earthquakes, floods, and other disasters, photos are increasingly playing more significant roles, such as finding missing people and assessing disasters, in rescue and recovery efforts. These disaster photos are taken in real time by the crowd, unmanned aerial vehicles, and wireless sensors. However, communications equipment is often damaged in disasters, and the very limited communication bandwidth restricts the upload of photos to the cloud center, seriously impeding disaster rescue endeavors. Based on edge computing, we propose Echo, a highly time-efficient disaster rescue framework. By utilizing the computing, storage, and communication abilities of edge servers, disaster photos are preprocessed and analyzed in real time, and more specific visuals are immensely helpful for conducting emergency response and rescue. This article takes the search for missing people as a case study to show that Echo can be more advantageous in terms of disaster rescue. To greatly conserve valuable communication bandwidth, only significantly associated images are extracted and uploaded to the cloud center for subsequent facial recognition. Furthermore, an adaptive photo detector is designed to utilize the precious and unstable communication bandwidth effectively, as well as ensure the photo detection precision and recall rate. The effectiveness and efficiency of the proposed method are demonstrated by simulation experiments.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2995410453",
    "type": "article"
  },
  {
    "title": "Robust Decentralized Low-Rank Matrix Decomposition",
    "doi": "https://doi.org/10.1145/2854157",
    "publication_date": "2016-05-02",
    "publication_year": 2016,
    "authors": "István Hegedűs; Árpád Berta; Levente Kocsis; András A. Benczúr; Márk Jelasity",
    "corresponding_authors": "",
    "abstract": "Low-rank matrix approximation is an important tool in data mining with a wide range of applications, including recommender systems, clustering, and identifying topics in documents. When the matrix to be approximated originates from a large distributed system, such as a network of mobile phones or smart meters, a challenging problem arises due to the strongly conflicting yet essential requirements of efficiency, robustness, and privacy preservation. We argue that although collecting sensitive data in a centralized fashion may be efficient, it is not an option when considering privacy and efficiency at the same time. Thus, we do not allow any sensitive data to leave the nodes of the network. The local information at each node (personal attributes, documents, media ratings, etc.) defines one row in the matrix. This means that all computations have to be performed at the edge of the network. Known parallel methods that respect the locality constraint, such as synchronized parallel gradient search or distributed iterative methods, require synchronized rounds or have inherent issues with load balancing, and thus they are not robust to failure. Our distributed stochastic gradient descent algorithm overcomes these limitations. During the execution, any sensitive information remains local, whereas the global features (e.g., the factor model of movies) converge to the correct value at all nodes. We present a theoretical derivation and a thorough experimental evaluation of our algorithm. We demonstrate that the convergence speed of our method is competitive while not relying on synchronization and being robust to extreme and realistic failure scenarios. To demonstrate the feasibility of our approach, we present trace-based simulations, real smartphone user behavior analysis, and tests over real movie recommender system data.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2346406435",
    "type": "article"
  },
  {
    "title": "Joint Structured Sparsity Regularized Multiview Dimension Reduction for Video-Based Facial Expression Recognition",
    "doi": "https://doi.org/10.1145/2956556",
    "publication_date": "2016-10-25",
    "publication_year": 2016,
    "authors": "Liping Xie; Dacheng Tao; Haikun Wei",
    "corresponding_authors": "",
    "abstract": "Video-based facial expression recognition (FER) has recently received increased attention as a result of its widespread application. Using only one type of feature to describe facial expression in video sequences is often inadequate, because the information available is very complex. With the emergence of different features to represent different properties of facial expressions in videos, an appropriate combination of these features becomes an important, yet challenging, problem. Considering that the dimensionality of these features is usually high, we thus introduce multiview dimension reduction (MVDR) into video-based FER. In MVDR, it is critical to explore the relationships between and within different feature views. To achieve this goal, we propose a novel framework of MVDR by enforcing joint structured sparsity at both inter- and intraview levels. In this way, correlations on and between the feature spaces of different views tend to be well-exploited. In addition, a transformation matrix is learned for each view to discover the patterns contained in the original features, so that the different views are comparable in finding a common representation. The model can be not only performed in an unsupervised manner, but also easily extended to a semisupervised setting by incorporating some domain knowledge. An alternating algorithm is developed for problem optimization, and each subproblem can be efficiently solved. Experiments on two challenging video-based FER datasets demonstrate the effectiveness of the proposed framework.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2534029181",
    "type": "article"
  },
  {
    "title": "Harnessing Music-Related Visual Stereotypes for Music Information Retrieval",
    "doi": "https://doi.org/10.1145/2926719",
    "publication_date": "2016-10-25",
    "publication_year": 2016,
    "authors": "Alexander Schindler; Andreas Rauber",
    "corresponding_authors": "",
    "abstract": "Over decades, music labels have shaped easily identifiable genres to improve recognition value and subsequently market sales of new music acts. Referring to print magazines and later to music television as important distribution channels, the visual representation thus played and still plays a significant role in music marketing. Visual stereotypes developed over decades that enable us to quickly identify referenced music only by sight without listening. Despite the richness of music-related visual information provided by music videos and album covers as well as T-shirts, advertisements, and magazines, research towards harnessing this information to advance existing or approach new problems of music retrieval or recommendation is scarce or missing. In this article, we present our research on visual music computing that aims to extract stereotypical music-related visual information from music videos. To provide comprehensive and reproducible results, we present the Music Video Dataset, a thoroughly assembled suite of datasets with dedicated evaluation tasks that are aligned to current Music Information Retrieval tasks. Based on this dataset, we provide evaluations of conventional low-level image processing and affect-related features to provide an overview of the expressiveness of fundamental visual properties such as color, illumination, and contrasts. Further, we introduce a high-level approach based on visual concept detection to facilitate visual stereotypes. This approach decomposes the semantic content of music video frames into concrete concepts such as vehicles, tools, and so on, defined in a wide visual vocabulary. Concepts are detected using convolutional neural networks and their frequency distributions as semantic descriptions for a music video. Evaluations showed that these descriptions show good performance in predicting the music genre of a video and even outperform audio-content descriptors on cross-genre thematic tags. Further, highly significant performance improvements were observed by augmenting audio-based approaches through the introduced visual approach.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2535046761",
    "type": "article"
  },
  {
    "title": "Spatial Ensemble Learning for Heterogeneous Geographic Data with Class Ambiguity",
    "doi": "https://doi.org/10.1145/3337798",
    "publication_date": "2019-07-31",
    "publication_year": 2019,
    "authors": "Zhe Jiang; Arpan Man Sainju; Yan Li; Shashi Shekhar; Joseph Knight",
    "corresponding_authors": "",
    "abstract": "Class ambiguity refers to the phenomenon whereby similar features correspond to different classes at different locations. Given heterogeneous geographic data with class ambiguity, the spatial ensemble learning (SEL) problem aims to find a decomposition of the geographic area into disjoint zones such that class ambiguity is minimized and a local classifier can be learned in each zone. The problem is important for applications such as land cover mapping from heterogeneous earth observation data with spectral confusion. However, the problem is challenging due to its high computational cost. Related work in ensemble learning either assumes an identical sample distribution (e.g., bagging, boosting, random forest) or decomposes multi-modular input data in the feature vector space (e.g., mixture of experts, multimodal ensemble) and thus cannot effectively minimize class ambiguity. In contrast, we propose a spatial ensemble framework that explicitly partitions input data in geographic space. Our approach first preprocesses data into homogeneous spatial patches and uses a greedy heuristic to allocate pairs of patches with high class ambiguity into different zones. We further extend our spatial ensemble learning framework with spatial dependency between nearby zones based on the spatial autocorrelation effect. Both theoretical analysis and experimental evaluations on two real world wetland mapping datasets show the feasibility of the proposed approach.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2968079289",
    "type": "article"
  },
  {
    "title": "Location Prediction",
    "doi": "https://doi.org/10.1145/2816824",
    "publication_date": "2016-02-11",
    "publication_year": 2016,
    "authors": "Yantao Jia; Yuanzhuo Wang; Xiaolong Jin; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "In social networks, predicting a user’s location mainly depends on those of his/her friends, where the key lies in how to select his/her most influential friends. In this article, we analyze the theoretically maximal accuracy of location prediction based on friends’ locations and compare it with the practical accuracy obtained by the state-of-the-art location prediction methods. Upon observing a big gap between the theoretical and practical accuracy, we propose a new strategy for selecting influential friends in order to improve the practical location prediction accuracy. Specifically, several features are defined to measure the influence of the friends on a user’s location, based on which we put forth a sequential random-walk-with-restart procedure to rank the friends of the user in terms of their influence. By dynamically selecting the top N most influential friends of the user per time slice, we develop a temporal-spatial Bayesian model to characterize the dynamics of friends’ influence for location prediction. Finally, extensive experimental results on datasets of real social networks demonstrate that the proposed influential friend selection method and temporal-spatial Bayesian model can significantly improve the accuracy of location prediction.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2287191753",
    "type": "article"
  },
  {
    "title": "Correlated Multi-label Classification with Incomplete Label Space and Class Imbalance",
    "doi": "https://doi.org/10.1145/3342512",
    "publication_date": "2019-09-05",
    "publication_year": 2019,
    "authors": "Ali Braytee; Wei Liu; Ali Anaissi; Paul Kennedy",
    "corresponding_authors": "",
    "abstract": "Multi-label classification is defined as the problem of identifying the multiple labels or categories of new observations based on labeled training data. Multi-labeled data has several challenges, including class imbalance, label correlation, incomplete multi-label matrices, and noisy and irrelevant features. In this article, we propose an integrated multi-label classification approach with incomplete label space and class imbalance (ML-CIB) for simultaneously training the multi-label classification model and addressing the aforementioned challenges. The model learns a new label matrix and captures new label correlations, because it is difficult to find a complete label vector for each instance in real-world data. We also propose a label regularization to handle the imbalanced multi-labeled issue in the new label, and l 1 regularization norm is incorporated in the objective function to select the relevant sparse features. A multi-label feature selection (ML-CIB-FS) method is presented as a variant of the proposed ML-CIB to show the efficacy of the proposed method in selecting the relevant features. ML-CIB is formulated as a constrained objective function. We use the accelerated proximal gradient method to solve the proposed optimisation problem. Last, extensive experiments are conducted on 19 regular-scale and large-scale imbalanced multi-labeled datasets. The promising results show that our method significantly outperforms the state-of-the-art.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2971553865",
    "type": "article"
  },
  {
    "title": "Bayesian Nonparametric Unsupervised Concept Drift Detection for Data Stream Mining",
    "doi": "https://doi.org/10.1145/3420034",
    "publication_date": "2020-11-13",
    "publication_year": 2020,
    "authors": "Junyu Xuan; Jie Lü; Guangquan Zhang",
    "corresponding_authors": "",
    "abstract": "Online data stream mining is of great significance in practice because of its ubiquity in many real-world scenarios, especially in the big data era. Traditional data mining algorithms cannot be directly applied to data streams due to (1) the possible change of underlying data distribution over time (i.e., concept drift ) and (2) delayed, short, or even no labels for streaming data in practice. A new research area, named unsupervised concept drift detection , has emerged to tackle this difficulty mainly based on two-sample hypothesis tests, such as the Kolmogorov–Smirnov test. However, it is surprising that none of the existing methods in this area exploit the Bayesian nonparametric hypothesis test, which has clear interpretability and straightforward prior knowledge encoding ability and no strict or unrealistic requirement of prefixing the form for the underlying data distribution. In this article, we present a Bayesian nonparametric unsupervised concept drift detection method based on the Polya tree hypothesis test. The basic idea is to decompose the underlying data distribution into a multi-resolution representation that transforms the whole distribution hypothesis test into recursive and simple binomial tests. Also, an incremental mechanism is especially designed to improve its efficiency in the stream setting. The method effectively detect drifts, and it also locates where a drift happens and the posteriors of hypotheses. The experiments on synthetic data verify the desired properties of the proposed method, and the experiments on real-world data show the better performance of the method for data stream mining compared with its frequentist counterpart in the literature.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3099492174",
    "type": "article"
  },
  {
    "title": "Passenger Mobility Prediction via Representation Learning for Dynamic Directed and Weighted Graphs",
    "doi": "https://doi.org/10.1145/3446344",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Yuandong Wang; Hongzhi Yin; Tong Chen; Chunyang Liu; Ben Wang; Tianyu Wo; Jie Xu",
    "corresponding_authors": "",
    "abstract": "In recent years, ride-hailing services have been increasingly prevalent, as they provide huge convenience for passengers. As a fundamental problem, the timely prediction of passenger demands in different regions is vital for effective traffic flow control and route planning. As both spatial and temporal patterns are indispensable passenger demand prediction, relevant research has evolved from pure time series to graph-structured data for modeling historical passenger demand data, where a snapshot graph is constructed for each time slot by connecting region nodes via different relational edges (origin-destination relationship, geographical distance, etc.). Consequently, the spatiotemporal passenger demand records naturally carry dynamic patterns in the constructed graphs, where the edges also encode important information about the directions and volume (i.e., weights) of passenger demands between two connected regions. aspects in the graph-structure data. representation for DDW is the key to solve the prediction problem. However, existing graph-based solutions fail to simultaneously consider those three crucial aspects of dynamic, directed, and weighted graphs, leading to limited expressiveness when learning graph representations for passenger demand prediction. Therefore, we propose a novel spatiotemporal graph attention network, namely Gallat ( G raph prediction with all at tention) as a solution. In Gallat, by comprehensively incorporating those three intrinsic properties of dynamic directed and weighted graphs, we build three attention layers to fully capture the spatiotemporal dependencies among different regions across all historical time slots. Moreover, the model employs a subtask to conduct pretraining so that it can obtain accurate results more quickly. We evaluate the proposed model on real-world datasets, and our experimental results demonstrate that Gallat outperforms the state-of-the-art approaches.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3214882838",
    "type": "article"
  },
  {
    "title": "Route Optimization via Environment-Aware Deep Network and Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3461645",
    "publication_date": "2021-12-16",
    "publication_year": 2021,
    "authors": "Pengzhan Guo; Keli Xiao; Zeyang Ye; Wei Zhu",
    "corresponding_authors": "",
    "abstract": "Vehicle mobility optimization in urban areas is a long-standing problem in smart city and spatial data analysis. Given the complex urban scenario and unpredictable social events, our work focuses on developing a mobile sequential recommendation system to maximize the profitability of vehicle service providers (e.g., taxi drivers). In particular, we treat the dynamic route optimization problem as a long-term sequential decision-making task. A reinforcement-learning framework is proposed to tackle this problem, by integrating a self-check mechanism and a deep neural network for customer pick-up point monitoring. To account for unexpected situations (e.g., the COVID-19 outbreak), our method is designed to be capable of handling related environment changes with a self-adaptive parameter determination mechanism. Based on the yellow taxi data in New York City and vicinity before and after the COVID-19 outbreak, we have conducted comprehensive experiments to evaluate the effectiveness of our method. The results show consistently excellent performance, from hourly to weekly measures, to support the superiority of our method over the state-of-the-art methods (i.e., with more than 98% improvement in terms of the profitability for taxi drivers).",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3213401008",
    "type": "article"
  },
  {
    "title": "Selecting and Composing Learning Rate Policies for Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3570508",
    "publication_date": "2022-11-03",
    "publication_year": 2022,
    "authors": "Yanzhao Wu; Ling Liu",
    "corresponding_authors": "",
    "abstract": "The choice of learning rate (LR) functions and policies has evolved from a simple fixed LR to the decaying LR and the cyclic LR, aiming to improve the accuracy and reduce the training time of Deep Neural Networks (DNNs). This article presents a systematic approach to selecting and composing an LR policy for effective DNN training to meet desired target accuracy and reduce training time within the pre-defined training iterations. It makes three original contributions. First, we develop an LR tuning mechanism for auto-verification of a given LR policy with respect to the desired accuracy goal under the pre-defined training time constraint. Second, we develop an LR policy recommendation system (LRBench) to select and compose good LR policies from the same and/or different LR functions through dynamic tuning, and avoid bad choices, for a given learning task, DNN model, and dataset. Third, we extend LRBench by supporting different DNN optimizers and show the significant mutual impact of different LR policies and different optimizers. Evaluated using popular benchmark datasets and different DNN models (LeNet, CNN3, ResNet), we show that our approach can effectively deliver high DNN test accuracy, outperform the existing recommended default LR policies, and reduce the DNN training time by 1.6-6.7× to meet a targeted model accuracy.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4308437157",
    "type": "article"
  },
  {
    "title": "MetaDetector: Meta Event Knowledge Transfer for Fake News Detection",
    "doi": "https://doi.org/10.1145/3532851",
    "publication_date": "2022-07-04",
    "publication_year": 2022,
    "authors": "Yasan Ding; Bin Guo; Yan Liu; Yunji Liang; Haocheng Shen; Zhiwen Yu",
    "corresponding_authors": "",
    "abstract": "The blooming of fake news on social networks has devastating impacts on society, the economy, and public security. Although numerous studies are conducted for the automatic detection of fake news, the majority tend to utilize deep neural networks to learn event-specific features for superior detection performance on specific datasets. However, the trained models heavily rely on the training datasets and are infeasible to apply to upcoming events due to the discrepancy between event distributions. Inspired by domain adaptation theories, we propose an end-to-end adversarial adaptation network, dubbed as MetaDetector , to transfer meta knowledge (event-shared features) between different events. Specifically, MetaDetector pushes the feature extractor and event discriminator to eliminate event-specific features and preserve required meta knowledge by adversarial training. Furthermore, the pseudo-event discriminator is utilized to evaluate the importance of news records in historical events to obtain partial knowledge that are discriminative for detecting fake news. Under the coordinated optimization among all the submodules, MetaDetector accurately transfers the meta knowledge of historical events to the upcoming event for fact checking. We conduct extensive experiments on two real-world datasets collected from Sina Weibo and Twitter. The experimental results demonstrate that MetaDetector outperforms the state-of-the-art methods, especially when the distribution discrepancy between events is significant.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3175916155",
    "type": "article"
  },
  {
    "title": "Dynamic-Aware Federated Learning for Face Forgery Video Detection",
    "doi": "https://doi.org/10.1145/3501814",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Ziheng Hu; Hongtao Xie; Lingyun Yu; Xingyu Gao; Zhihua Shang; Yongdong Zhang",
    "corresponding_authors": "",
    "abstract": "The spread of face forgery videos is a serious threat to information credibility, calling for effective detection algorithms to identify them. Most existing methods have assumed a shared or centralized training set. However, in practice, data may be distributed on devices of different enterprises that cannot be centralized to share due to security and privacy restrictions. In this article, we propose a Federated Learning face forgery detection framework to train a global model collaboratively while keeping data on local devices. In order to make the detection model more robust, we propose a novel Inconsistency-Capture module (ICM) to capture the dynamic inconsistencies between adjacent frames of face forgery videos. The ICM contains two parallel branches. The first branch takes the whole face of adjacent frames as input to calculate a global inconsistency representation. The second branch focuses only on the inter-frame variation of critical regions to capture the local inconsistency. To the best of our knowledge, this is the first work to apply federated learning to face forgery video detection, which is trained with decentralized data. Extensive experiments show that the proposed framework achieves competitive performance compared with existing methods that are trained with centralized data, with higher-level security and privacy guarantee.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4214661097",
    "type": "article"
  },
  {
    "title": "SignDS-FL: Local Differentially Private Federated Learning with Sign-based Dimension Selection",
    "doi": "https://doi.org/10.1145/3517820",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Xue Jiang; Xuebing Zhou; Jens Großklags",
    "corresponding_authors": "",
    "abstract": "Federated Learning (FL) [ 31 ] is a decentralized learning mechanism that has attracted increasing attention due to its achievements in computational efficiency and privacy preservation. However, recent research highlights that the original FL framework may still reveal sensitive information of clients’ local data from the exchanged local updates and the global model parameters. Local Differential Privacy (LDP), as a rigorous definition of privacy, has been applied to Federated Learning to provide formal privacy guarantees and prevent potential privacy leakage. However, previous LDP-FL solutions suffer from considerable utility loss with an increase of model dimensionality. Recent work [ 29 ] proposed a two-stage framework that mitigates the dimension-dependency problem by first selecting one “important” dimension for each local update and then perturbing the dimension value to construct the sparse privatized update. However, the framework may still suffer from utility loss because of the insufficient per-stage privacy budget and slow model convergence. In this article, we propose an improved framework, SignDS-FL , which shares the concept of dimension selection with Reference [ 29 ], but saves the privacy cost for the value perturbation stage by assigning random sign values to the selected dimensions. Besides using the single-dimension selection algorithms in Reference [ 29 ], we propose an Exponential Mechanism-based Multi-Dimension Selection algorithm that further improves model convergence and accuracy. We evaluate the framework on a number of real-world datasets with both simple logistic regression models and deep neural networks. For training logistic regression models on structured datasets, our framework yields only a \\( \\sim \\) 1%–2% accuracy loss in comparison to a \\( \\sim \\) 5%–15% decrease of accuracy for the baseline methods. For training deep neural networks on image datasets, the accuracy loss of our framework is less than \\( 8\\% \\) and at best only \\( 2\\% \\) . Extensive experimental results show that our framework significantly outperforms the previous LDP-FL solutions and enjoys an advanced utility-privacy balance.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4221104046",
    "type": "article"
  },
  {
    "title": "FLEE: A Hierarchical Federated Learning Framework for Distributed Deep Neural Network over Cloud, Edge, and End Device",
    "doi": "https://doi.org/10.1145/3514501",
    "publication_date": "2022-05-17",
    "publication_year": 2022,
    "authors": "Zhengyi Zhong; Weidong Bao; Ji Wang; Xiaomin Zhu; Xiongtao Zhang",
    "corresponding_authors": "",
    "abstract": "With the development of smart devices, the computing capabilities of portable end devices such as mobile phones have been greatly enhanced. Meanwhile, traditional cloud computing faces great challenges caused by privacy-leakage and time-delay problems, there is a trend to push models down to edges and end devices. However, due to the limitation of computing resource, it is difficult for end devices to complete complex computing tasks alone. Therefore, this article divides the model into two parts and deploys them on multiple end devices and edges, respectively. Meanwhile, an early exit is set to reduce computing resource overhead, forming a hierarchical distributed architecture. In order to enable the distributed model to continuously evolve by using new data generated by end devices, we comprehensively consider various data distributions on end devices and edges, proposing a hierarchical federated learning framework FLEE , which can realize dynamical updates of models without redeploying them. Through image and sentence classification experiments, we verify that it can improve model performances under all kinds of data distributions, and prove that compared with other frameworks, the models trained by FLEE consume less global computing resource in the inference stage.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4280654234",
    "type": "article"
  },
  {
    "title": "Adversarial Learning for Cross Domain Recommendations",
    "doi": "https://doi.org/10.1145/3548776",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Pan Li; Brian Brost; Alexander Tuzhilin",
    "corresponding_authors": "",
    "abstract": "Existing cross domain recommender systems typically assume homogeneous user preferences across multiple domains to capture similarities of user-item interactions and to provide cross domain recommendations accordingly. Meanwhile, the heterogeneity of user behaviors is usually not well studied and captured during the recommendation process, where users might have vastly different interests in different domains. In addition, previous models focus primarily on recommendation tasks between domain pairs, and cannot be naturally extended to serve for multiple domain recommendation applications. To address these challenges, we propose to utilize the idea of adversarial learning to intelligently incorporate global user preferences and domain-specific user preferences for providing satisfying cross domain recommendations. In particular, our proposed Adversarial Cross Domain Recommendation (ACDR) model first obtains the latent representations of global user preferences from their explicit feature information, and then transforms them into domain-specific user embeddings, where we take into account user behaviors and their heterogeneous preferences among different domains. By doing so, we address the differences among user representations in the domain-specific latent space while also preserving global user preferences, as we effectively segment the distributions of domain-specific user embeddings in the shared latent space. The convergence of our proposed model is theoretically guaranteed. The proposed ACDR model leads to significant and consistent improvements in cross domain recommendation performance over the state-of-the-art baseline models, which we demonstrate through extensive experiments on three real-world datasets. In addition, we show that the improvements are greater on those datasets that are smaller and more sparse, on those users that have fewer interaction records in the dataset, and when user interactions from more product domains are included in the cross domain recommendation model.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4285727734",
    "type": "article"
  },
  {
    "title": "VesNet: A Vessel Network for Jointly Learning Route Pattern and Future Trajectory",
    "doi": "https://doi.org/10.1145/3639370",
    "publication_date": "2024-01-18",
    "publication_year": 2024,
    "authors": "Fenyu Jiang; Huandong Wang; Yong Li",
    "corresponding_authors": "",
    "abstract": "Vessel trajectory prediction is the key to maritime applications such as traffic surveillance, collision avoidance, anomaly detection, and so on. Making predictions more precisely requires a better understanding of the moving trend for a particular vessel since the movement is affected by multiple factors like marine environment, vessel type, and vessel behavior. In this paper, we propose a model named VesNet, based on the attentional seq2seq framework, to predict vessel future movement sequence by observing the current trajectory. Firstly, we extract the route patterns from the raw AIS data during preprocessing. Then, we design a multi-task learning structure to learn how to implement route pattern classification and vessel trajectory prediction simultaneously. By comparing with representative baseline models, we find that our VesNet has the best performance in terms of long-term prediction precision. Additionally, VesNet can recognize the route pattern by capturing the implicit moving characteristics. The experimental results prove that the proposed multi-task learning assists the vessel trajectory prediction mission.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4390984762",
    "type": "article"
  },
  {
    "title": "RANGO: A Novel Deep Learning Approach to Detect Drones Disguising from Video Surveillance Systems",
    "doi": "https://doi.org/10.1145/3641282",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "Jin Han; Yun-Feng Ren; Alessandro Brighente; Mauro Conti",
    "corresponding_authors": "",
    "abstract": "Video surveillance systems provide means to detect the presence of potentially malicious drones in the surroundings of critical infrastructures. In particular, these systems collect images and feed them to a deep-learning classifier able to detect the presence of a drone in the input image. However, current classifiers are not efficient in identifying drones that disguise themselves with the image background, e.g., hiding in front of a tree. Furthermore, video-based detection systems heavily rely on the image’s brightness, where darkness imposes significant challenges in detecting drones. Both these phenomena increase the possibilities for attackers to get close to critical infrastructures without being spotted and hence be able to gather sensitive information or cause physical damages, possibly leading to safety threats. In this article, we propose RANGO, a drone detection arithmetic able to detect drones in challenging images where the target is difficult to distinguish from the background. RANGO is based on a deep learning architecture that exploits a Preconditioning Operation (PREP) that highlights the target by the difference between the target gradient and the background gradient. The idea is to highlight features that will be useful for classification. After PREP, RANGO uses multiple convolution kernels to make the final decision on the presence of the drone. We test RANGO on a drone image dataset composed of multiple already-existing datasets to which we add samples of birds and planes. We then compare RANGO with multiple currently existing approaches to show its superiority. When tested on images with disguising drones, RANGO attains an increase of 6.6% mean Average Precision (mAP) compared to YOLOv5 solution. When tested on the conventional dataset, RANGO improves the mAP by approximately 2.2%, thus confirming its effectiveness also in the general scenario.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4391145681",
    "type": "article"
  },
  {
    "title": "SiG: A Siamese-Based Graph Convolutional Network to Align Knowledge in Autonomous Transportation Systems",
    "doi": "https://doi.org/10.1145/3643861",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Mai HAO; Ming Cai; Minghui Fang; Linlin You",
    "corresponding_authors": "",
    "abstract": "Domain knowledge is gradually renovating its attributes to exhibit distinct features in autonomy, propelled by the shift of modern transportation systems (TS) toward autonomous TS (ATS) comprising three progressive generations. The knowledge graph (KG) and its corresponding versions can help depict the evolving TS. Given that KG versions exhibit asymmetry primarily due to variations in evolved knowledge, it is imperative to harmonize the evolved knowledge embodied by the entity across disparate KG versions. Hence, this article proposes a siamese-based graph convolutional network (GCN) model, namely SiG , to address unresolved issues of low accuracy, efficiency, and effectiveness in aligning asymmetric KGs. SiG can optimize entity alignment in ATS and support the analysis of future-stage ATS development. Such a goal is attained through (a) generating unified KGs to enhance data quality, (b) defining graph split to facilitate entire-graph computation, (c) enhancing a GCN to extract intrinsic features, and (d) designing a siamese network to train asymmetric KGs. The evaluation results suggest that SiG surpasses other commonly employed models, resulting in average improvements of 23.90% and 37.89% in accuracy and efficiency, respectively. These findings have significant implications for TS evolution analysis and offer a novel perspective for research on complex systems limited by continuously updated knowledge.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4391436390",
    "type": "article"
  },
  {
    "title": "MGRR-Net: Multi-level Graph Relational Reasoning Network for Facial Action Unit Detection",
    "doi": "https://doi.org/10.1145/3643863",
    "publication_date": "2024-02-09",
    "publication_year": 2024,
    "authors": "Xuri Ge; Joemon M. Jose; Songpei Xu; Xiao Liu; Hu Han",
    "corresponding_authors": "",
    "abstract": "The Facial Action Coding System (FACS) encodes the action units (AUs) in facial images, which has attracted extensive research attention due to its wide use in facial expression analysis. Many methods that perform well on automatic facial action unit (AU) detection primarily focus on modeling various AU relations between corresponding local muscle areas or mining global attention–aware facial features; however, they neglect the dynamic interactions among local-global features. We argue that encoding AU features just from one perspective may not capture the rich contextual information between regional and global face features, as well as the detailed variability across AUs, because of the diversity in expression and individual characteristics. In this article, we propose a novel Multi-level Graph Relational Reasoning Network (termed MGRR-Net ) for facial AU detection. Each layer of MGRR-Net performs a multi-level (i.e., region-level, pixel-wise, and channel-wise level) feature learning. On the one hand, the region-level feature learning from the local face patch features via graph neural network can encode the correlation across different AUs. On the other hand, pixel-wise and channel-wise feature learning via graph attention networks (GAT) enhance the discrimination ability of AU features by adaptively recalibrating feature responses of pixels and channels from global face features. The hierarchical fusion strategy combines features from the three levels with gated fusion cells to improve AU discriminative ability. Extensive experiments on DISFA and BP4D AU datasets show that the proposed approach achieves superior performance than the state-of-the-art methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4391681622",
    "type": "article"
  },
  {
    "title": "FedCMD: A Federated Cross-modal Knowledge Distillation for Drivers’ Emotion Recognition",
    "doi": "https://doi.org/10.1145/3650040",
    "publication_date": "2024-03-01",
    "publication_year": 2024,
    "authors": "Saira Bano; Nicola Tonellotto; Pietro Cassará; Alberto Gotta",
    "corresponding_authors": "",
    "abstract": "Emotion recognition has attracted a lot of interest in recent years in various application areas such as healthcare and autonomous driving. Existing approaches to emotion recognition are based on visual, speech, or psychophysiological signals. However, recent studies are looking at multimodal techniques that combine different modalities for emotion recognition. In this work, we address the problem of recognizing the user’s emotion as a driver from unlabeled videos using multimodal techniques. We propose a collaborative training method based on cross-modal distillation, i.e., “FedCMD” (Federated Cross-Modal Distillation). Federated Learning (FL) is an emerging collaborative decentralized learning technique that allows each participant to train their model locally to build a better generalized global model without sharing their data. The main advantage of FL is that only local data is used for training, thus maintaining privacy and providing a secure and efficient emotion recognition system. The local model in FL is trained for each vehicle device with unlabeled video data by using sensor data as a proxy. Specifically, for each local model, we show how driver emotional annotations can be transferred from the sensor domain to the visual domain by using cross-modal distillation. The key idea is based on the observation that a driver’s emotional state indicated by a sensor correlates with facial expressions shown in videos. The proposed “FedCMD” approach is tested on the multimodal dataset “BioVid Emo DB” and achieves state-of-the-art performance. Experimental results show that our approach is robust to non-identically distributed data, achieving 96.67% and 90.83% accuracy in classifying five different emotions with IID (independently and identically distributed) and non-IID data, respectively. Moreover, our model is much more robust to overfitting, resulting in better generalization than the other existing methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4392356983",
    "type": "article"
  },
  {
    "title": "Balanced Quality Score: Measuring Popularity Debiasing in Recommendation",
    "doi": "https://doi.org/10.1145/3650043",
    "publication_date": "2024-03-01",
    "publication_year": 2024,
    "authors": "Erica Coppolillo; Marco Minici; Ettore Ritacco; Luciano Caroprese; Francesco Sergio Pisani; Giuseppe Manco",
    "corresponding_authors": "",
    "abstract": "Popularity bias is the tendency of recommender systems to further suggest popular items while disregarding niche ones, hence giving no chance for items with low popularity to emerge. Although the literature is rich in debiasing techniques, it still lacks quality measures that effectively enable their analyses and comparisons. In this article, we first introduce a formal, data-driven, and parameter-free strategy for classifying items into low, medium, and high popularity categories. Then we introduce Balanced Quality Score (BQS) , a quality measure that rewards the debiasing techniques that successfully push a recommender system to suggest niche items, without losing points in its predictive capability in terms of global accuracy. We conduct tests of BQS on three distinct baseline collaborative filtering frameworks: one based on history-embedding and two on user/item-embedding modeling. These evaluations are performed on multiple benchmark datasets and against various state-of-the-art competitors, demonstrating the effectiveness of BQS.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4392357097",
    "type": "article"
  },
  {
    "title": "HydraGAN: A Cooperative Agent Model for Multi-Objective Data Generation",
    "doi": "https://doi.org/10.1145/3653982",
    "publication_date": "2024-04-05",
    "publication_year": 2024,
    "authors": "Chance DeSmet; Diane J. Cook",
    "corresponding_authors": "",
    "abstract": "Generative adversarial networks have become a de facto approach to generate synthetic data points that resemble their real counterparts. We tackle the situation where the realism of individual samples is not the sole criterion for synthetic data generation. Additional constraints such as privacy preservation, distribution realism, and diversity promotion may also be essential to optimize. To address this challenge, we introduce HydraGAN , a multi-agent network that performs multi-objective synthetic data generation. We theoretically verify that training the HydraGAN system, containing a single generator and an arbitrary number of discriminators, leads to a Nash equilibrium. Experimental results for six datasets indicate that HydraGAN consistently outperforms prior methods in maximizing the Area under the Radar Chart, balancing a combination of cooperative or competitive data generation goals.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4393992298",
    "type": "article"
  },
  {
    "title": "Self-supervised Text Style Transfer using Cycle-Consistent Adversarial Networks",
    "doi": "https://doi.org/10.1145/3678179",
    "publication_date": "2024-07-18",
    "publication_year": 2024,
    "authors": "Moreno La Quatra; Giuseppe Gallipoli; Luca Cagliero",
    "corresponding_authors": "",
    "abstract": "Text Style Transfer (TST) is a relevant branch of natural language processing that aims to control the style attributes of a piece of text while preserving its original content. To address TST in the absence of parallel data, Cycle-consistent Generative Adversarial Networks (CycleGANs) have recently emerged as promising solutions. Existing CycleGAN-based TST approaches suffer from the following limitations: (1) They apply self-supervision, based on the cycle-consistency principle, in the latent space. This approach turns out to be less robust to mixed-style inputs, i.e., when the source text is partly in the original and partly in the target style; (2) Generators and discriminators rely on recurrent networks, which are exposed to known issues with long-term text dependencies; (3) The target style is weakly enforced, as the discriminator distinguishes real from fake sentences without explicitly accounting for the generated text's style. We propose a new CycleGAN-based TST approach that applies self-supervision directly at the sequence level to effectively handle mixed-style inputs and employs Transformers to leverage the attention mechanism for both text encoding and decoding. We also employ a pre-trained style classifier to guide the generation of text in the target style while maintaining the original content's meaning. The experimental results achieved on the formality and sentiment transfer tasks show that our approach outperforms existing ones, both CycleGAN-based and not (including an open-source Large Language Model), on benchmark data and shows better robustness to mixed-style inputs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4400777800",
    "type": "article"
  },
  {
    "title": "Efficiently Gluing Pre-trained Language and Vision Models for Image Captioning",
    "doi": "https://doi.org/10.1145/3682067",
    "publication_date": "2024-07-29",
    "publication_year": 2024,
    "authors": "Peipei Song; Yuanen Zhou; Xun Yang; Daqing Liu; Zhenzhen Hu; Depeng Wang; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Vision-and-language pre-training models have achieved impressive performance for image captioning. But most of them are trained with millions of paired image-text data and require huge memory and computing overhead. To alleviate this, we try to stand on the shoulders of large-scale pre-trained language models (PLM) and pre-trained vision models (PVM) and efficiently connect them for image captioning. There are two major challenges: one is that language and vision modalities have different semantic granularity (e.g., a noun may cover many pixels), and the other is that the semantic gap still exists between the pre-trained language and vision models. To this end, we design a lightweight and efficient connector to glue PVM and PLM, which holds a criterion of selection-then-transformation . Specifically, in the selection phase, we treat each image as a set of patches instead of pixels. We select salient image patches and cluster them into visual regions to align with text. Then, to effectively reduce the semantic gap, we propose to map the selected image patches into text space through spatial and channel transformations. With training on image captioning datasets, the connector learns to bridge the semantic granularity and semantic gap via backpropagation, preparing for the PLM to generate descriptions. Experimental results on the MSCOCO and Flickr30k datasets demonstrate that our method yields comparable performance to existing works. By solely training the small connector, we achieve a CIDEr performance of 132.2% on the MSCOCO Karpathy test split. Moreover, our findings reveal that fine-tuning the PLM can further enhance performance potential, resulting in a CIDEr score of 140.6%. Code and models are available at https://github.com/YuanEZhou/PrefixCap .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4401075326",
    "type": "article"
  },
  {
    "title": "Efficient Federated Learning Using Dynamic Update and Adaptive Pruning with Momentum on Shared Server Data",
    "doi": "https://doi.org/10.1145/3690648",
    "publication_date": "2024-09-02",
    "publication_year": 2024,
    "authors": "Ji Liu; Juncheng Jia; Hong Zhang; Yuhui Yun; Leye Wang; Yang Zhou; Huaiyu Dai; Dejing Dou",
    "corresponding_authors": "",
    "abstract": "Despite achieving remarkable performance, Federated Learning (FL) encounters two important problems, i.e., low training efficiency and limited computational resources. In this paper, we propose a new FL framework, i.e., FedDUMAP, with three original contributions, to leverage the shared insensitive data on the server in addition to the distributed data in edge devices so as to efficiently train a global model. First, we propose a simple dynamic server update algorithm, which takes advantage of the shared insensitive data on the server while dynamically adjusting the update steps on the server in order to speed up the convergence and improve the accuracy. Second, we propose an adaptive optimization method with the dynamic server update algorithm to exploit the global momentum on the server and each local device for superior accuracy. Third, we develop a layer-adaptive model pruning method to carry out specific pruning operations, which is adapted to the diverse features of each layer so as to attain an excellent trade-off between effectiveness and efficiency. Our proposed FL model, FedDUMAP, combines the three original techniques and has a significantly better performance compared with baseline approaches in terms of efficiency (up to 16.9 times faster), accuracy (up to 20.4% higher), and computational cost (up to 62.6% smaller).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4402128566",
    "type": "article"
  },
  {
    "title": "Optimizing Privacy, Utility, and Efficiency in A Constrained Multi-Objective Federated Learning Framework",
    "doi": "https://doi.org/10.1145/3701039",
    "publication_date": "2024-10-24",
    "publication_year": 2024,
    "authors": "Yan Kang; Hanlin Gu; Xingxing Tang; Yuanqin He; Yuzhu Zhang; Jinnan He; Yuxing Han; Lixin Fan; Kai Chen; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Conventionally, federated learning aims to optimize a single objective, typically the utility. However, for a federated learning system to be trustworthy, it needs to simultaneously satisfy multiple objectives, such as maximizing model performance, minimizing privacy leakage and training costs, and being robust to malicious attacks. Multi-Objective Optimization (MOO) aiming to optimize multiple conflicting objectives simultaneously is quite suitable for solving the optimization problem of Trustworthy Federated Learning (TFL). In this paper, we unify MOO and TFL by formulating the problem of constrained multi-objective federated learning (CMOFL). Under this formulation, existing MOO algorithms can be adapted to TFL straightforwardly. Different from existing CMOFL algorithms focusing on utility, efficiency, fairness, and robustness, we consider optimizing privacy leakage along with utility loss and training cost, the three primary objectives of a TFL system. We develop two improved CMOFL algorithms based on NSGA-II and PSL, respectively, to effectively and efficiently find Pareto optimal solutions and provide theoretical analysis on their convergence. We design quantitative measurements of privacy leakage, utility loss, and training cost for three privacy protection mechanisms: Randomization, BatchCrypt (an efficient homomorphic encryption), and Sparsification. Empirical experiments conducted under the three protection mechanisms demonstrate the effectiveness of our proposed algorithms.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4403730615",
    "type": "article"
  },
  {
    "title": "Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation",
    "doi": "https://doi.org/10.1145/3709011",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Nanxu Gong; Wangyang Ying; Dongjie Wang; Yanjie Fu",
    "corresponding_authors": "",
    "abstract": "Feature selection aims to identify the optimal feature subset for enhancing downstream models. Effective feature selection can remove redundant features, save computational resources, accelerate the model learning process, and improve the model overall performance. However, existing works are often time-intensive to identify the effective feature subset within high-dimensional feature spaces. Meanwhile, these methods mainly utilize a single downstream task performance as the selection criterion, leading to the selected subsets that are not only redundant but also lack generalizability. To bridge these gaps, we reformulate feature selection through a neuro-symbolic lens and introduce a novel generative framework aimed at identifying short and effective feature subsets. More specifically, we found that feature ID tokens of the selected subset can be formulated as symbols to reflect the intricate correlations among features. Thus, in this framework, we first create a data collector to automatically collect numerous feature selection samples consisting of feature ID tokens, model performance, and the measurement of feature subset redundancy. Building on the collected data, an encoder-decoder-evaluator learning paradigm is developed to preserve the intelligence of feature selection into a continuous embedding space for efficient search. Within the learned embedding space, we leverage a multi-gradient search algorithm to find more robust and generalized embeddings with the objective of improving model performance and reducing feature subset redundancy. These embeddings are then utilized to reconstruct the feature ID tokens for executing the final feature selection. Ultimately, comprehensive experiments and case studies are conducted to validate the effectiveness of the proposed framework. The associated data and code are publicly available 1 .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4405638186",
    "type": "article"
  },
  {
    "title": "Group Profiling for Understanding Social Structures",
    "doi": "https://doi.org/10.1145/2036264.2036279",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Lei Tang; Xufei Wang; Huan Liu",
    "corresponding_authors": "",
    "abstract": "The prolific use of participatory Web and social networking sites is reshaping the ways in which people interact with one another. It has become a vital part of human social life in both the developed and developing world. People sharing certain similarities or affiliates tend to form communities within social media. At the same time, they participate in various online activities: content sharing, tagging, posting status updates, etc. These diverse activities leave behind traces of their social life, providing clues to understand changing social structures. A large body of existing work focuses on extracting cohesive groups based on network topology. But little attention is paid to understanding the changing social structures. In order to help explain the formation of a group, we explore different group-profiling strategies to construct descriptions of a group. This research can assist network navigation, visualization, and analysis, as well as monitoring and tracking the ebbs and tides of different groups in evolving networks. By exploiting information collected from real-world social media sites, extensive experiments are conducted to evaluate group-profiling results. The pros and cons of different group-profiling strategies are analyzed with concrete examples. We also show some potential applications based on group profiling. Interesting findings with discussions are reported.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1986433916",
    "type": "article"
  },
  {
    "title": "Fair Seeding in Knockout Tournaments",
    "doi": "https://doi.org/10.1145/2036264.2036273",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Thuc Vu; Yoav Shoham",
    "corresponding_authors": "",
    "abstract": "We investigated the existence of fair seeding in knockout tournaments. We define two fairness criteria, both adapted from the literature: envy-freeness and order preservation. We show how to achieve the first criterion in tournaments whose structure is unconstrained, and prove an impossibility result for balanced tournaments. For the second criterion we have a similar result for unconstrained tournaments, but not for the balanced case. We provide instead a heuristic algorithm which we show through experiments to be efficient and effective. This suggests that the criterion is achievable also in balanced tournaments. However, we prove that it again becomes impossible to achieve when we add a weak condition guarding against the phenomenon of tournament dropout.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2003916001",
    "type": "article"
  },
  {
    "title": "Batch and online learning algorithms for nonconvex neyman-pearson classification",
    "doi": "https://doi.org/10.1145/1961189.1961200",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Gilles Gasso; Aristidis Pappaioannou; M. A. Spivak; Léon Bottou",
    "corresponding_authors": "",
    "abstract": "We describe and evaluate two algorithms for Neyman-Pearson (NP) classification problem which has been recently shown to be of a particular importance for bipartite ranking problems. NP classification is a nonconvex problem involving a constraint on false negatives rate. We investigated batch algorithm based on DC programming and stochastic gradient method well suited for large-scale datasets. Empirical evidences illustrate the potential of the proposed methods.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2057816915",
    "type": "article"
  },
  {
    "title": "Efficient Tag Recommendation for Real-Life Data",
    "doi": "https://doi.org/10.1145/2036264.2036266",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Marek Lipczak; Evangelos Milios",
    "corresponding_authors": "",
    "abstract": "Despite all of the advantages of tags as an easy and flexible information management approach, tagging is a cumbersome task. A set of descriptive tags has to be manually entered by users whenever they post a resource. This process can be simplified by the use of tag recommendation systems. Their objective is to suggest potentially useful tags to the user. We present a hybrid tag recommendation system together with a scalable, highly efficient system architecture. The system is able to utilize user feedback to tune its parameters to specific characteristics of the underlying tagging system and adapt the recommendation models to newly added content. The evaluation of the system on six real-life datasets demonstrated the system’s ability to combine tags from various sources (e.g., resource content or tags previously used by the user) to achieve the best quality of recommended tags. It also confirmed the importance of parameter tuning and content adaptation. A series of additional experiments allowed us to better understand the characteristics of the system and tagging datasets and to determine the potential areas for further system development.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2139420544",
    "type": "article"
  },
  {
    "title": "Trust and matching algorithms for selecting suitable agents",
    "doi": "https://doi.org/10.1145/2542182.2542198",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Nardine Osman; Carles Sierra; Fiona McNeill; Juan Pane; John Debenham",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of finding suitable agents to collaborate with for a given interaction in distributed open systems, such as multiagent and P2P systems. The agent in question is given the chance to describe its confidence in its own capabilities. However, since agents may be malicious, misinformed, suffer from miscommunication, and so on, one also needs to calculate how much trusted is that agent. This article proposes a novel trust model that calculates the expectation about an agent's future performance in a given context by assessing both the agent's willingness and capability through the semantic comparison of the current context in question with the agent's performance in past similar experiences. The proposed mechanism for assessing trust may be applied to any real world application where past commitments are recorded and observations are made that assess these commitments, and the model can then calculate one's trust in another with respect to a future commitment by assessing the other's past performance.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2001508443",
    "type": "article"
  },
  {
    "title": "Accurate and Novel Recommendations",
    "doi": "https://doi.org/10.1145/2668107",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Amin Javari; Mahdi Jalili",
    "corresponding_authors": "",
    "abstract": "Recommender systems are in the center of network science, and they are becoming increasingly important in individual businesses for providing efficient, personalized services and products to users. Previous research in the field of recommendation systems focused on improving the precision of the system through designing more accurate recommendation lists. Recently, the community has been paying attention to diversity and novelty of recommendation lists as key characteristics of modern recommender systems. In many cases, novelty and precision do not go hand in hand, and the accuracy--novelty dilemma is one of the challenging problems in recommender systems, which needs efforts in making a trade-off between them. In this work, we propose an algorithm for providing novel and accurate recommendation to users. We consider the standard definition of accuracy and an effective self-information--based measure to assess novelty of the recommendation list. The proposed algorithm is based on item popularity, which is defined as the number of votes received in a certain time interval. Wavelet transform is used for analyzing popularity time series and forecasting their trend in future timesteps. We introduce two filtering algorithms based on the information extracted from analyzing popularity time series of the items. The popularity-based filtering algorithm gives a higher chance to items that are predicted to be popular in future timesteps. The other algorithm, denoted as a novelty and population-based filtering algorithm, is to move toward items with low popularity in past timesteps that are predicted to become popular in the future. The introduced filters can be applied as adds-on to any recommendation algorithm. In this article, we use the proposed algorithms to improve the performance of classic recommenders, including item-based collaborative filtering and Markov-based recommender systems. The experiments show that the algorithms could significantly improve both the accuracy and effective novelty of the classic recommenders.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2089505397",
    "type": "article"
  },
  {
    "title": "CRADLE",
    "doi": "https://doi.org/10.1145/2996200",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Reuth Mirsky; Kobi Gal; Stuart M. Shieber",
    "corresponding_authors": "",
    "abstract": "In exploratory domains, agents’ behaviors include switching between activities, extraneous actions, and mistakes. Such settings are prevalent in real world applications such as interaction with open-ended software, collaborative office assistants, and integrated development environments. Despite the prevalence of such settings in the real world, there is scarce work in formalizing the connection between high-level goals and low-level behavior and inferring the former from the latter in these settings. We present a formal grammar for describing users’ activities in such domains. We describe a new top-down plan recognition algorithm called CRADLE (Cumulative Recognition of Activities and Decreasing Load of Explanations) that uses this grammar to recognize agents’ interactions in exploratory domains. We compare the performance of CRADLE with state-of-the-art plan recognition algorithms in several experimental settings consisting of real and simulated data. Our results show that CRADLE was able to output plans exponentially more quickly than the state-of-the-art without compromising its correctness, as determined by domain experts. Our approach can form the basis of future systems that use plan recognition to provide real-time support to users in a growing class of interesting and challenging domains.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2605785924",
    "type": "article"
  },
  {
    "title": "Refined-Graph Regularization-Based Nonnegative Matrix Factorization",
    "doi": "https://doi.org/10.1145/3090312",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Xuelong Li; Guosheng Cui; Yongsheng Dong",
    "corresponding_authors": "",
    "abstract": "Nonnegative matrix factorization (NMF) is one of the most popular data representation methods in the field of computer vision and pattern recognition. High-dimension data are usually assumed to be sampled from the submanifold embedded in the original high-dimension space. To preserve the locality geometric structure of the data, k -nearest neighbor ( k -NN) graph is often constructed to encode the near-neighbor layout structure. However, k -NN graph is based on Euclidean distance, which is sensitive to noise and outliers. In this article, we propose a refined-graph regularized nonnegative matrix factorization by employing a manifold regularized least-squares regression (MRLSR) method to compute the refined graph. In particular, each sample is represented by the whole dataset regularized with ℓ 2 -norm and Laplacian regularizer. Then a MRLSR graph is constructed based on the representative coefficients of each sample. Moreover, we present two optimization schemes to generate refined-graphs by employing a hard-thresholding technique. We further propose two refined-graph regularized nonnegative matrix factorization methods and use them to perform image clustering. Experimental results on several image datasets reveal that they outperform 11 representative methods.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2749238013",
    "type": "article"
  },
  {
    "title": "Knowledge Representations and Inference Techniques for Medical Question Answering",
    "doi": "https://doi.org/10.1145/3106745",
    "publication_date": "2017-10-23",
    "publication_year": 2017,
    "authors": "Travis R. Goodwin; Sanda M. Harabagiu",
    "corresponding_authors": "",
    "abstract": "Answering medical questions related to complex medical cases, as required in modern Clinical Decision Support (CDS) systems, imposes (1) access to vast medical knowledge and (2) sophisticated inference techniques. In this article, we examine the representation and role of combining medical knowledge automatically derived from (a) clinical practice and (b) research findings for inferring answers to medical questions. Knowledge from medical practice was distilled from a vast Electronic Medical Record (EMR) system, while research knowledge was processed from biomedical articles available in PubMed Central. The knowledge automatically acquired from the EMR system took into account the clinical picture and therapy recognized from each medical record to generate a probabilistic Markov network denoted as a Clinical Picture and Therapy Graph (CPTG). Moreover, we represented the background of medical questions available from the description of each complex medical case as a medical knowledge sketch. We considered three possible representations of medical knowledge sketches that were used by four different probabilistic inference methods to pinpoint the answers from the CPTG. In addition, several answer-informed relevance models were developed to provide a ranked list of biomedical articles containing the answers. Evaluations on the TREC-CDS data show which of the medical knowledge representations and inference methods perform optimally. The experiments indicate an improvement of biomedical article ranking by 49% over state-of-the-art results.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2766696615",
    "type": "article"
  },
  {
    "title": "Learning Probabilistic Hierarchical Task Networks as Probabilistic Context-Free Grammars to Capture User Preferences",
    "doi": "https://doi.org/10.1145/2589481",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Nan Li; William Cushing; Subbarao Kambhampati; Sung‐Wook Yoon",
    "corresponding_authors": "",
    "abstract": "We introduce an algorithm to automatically learn probabilistic hierarchical task networks (pHTNs) that capture a user's preferences on plans by observing only the user's behavior. HTNs are a common choice of representation for a variety of purposes in planning, including work on learning in planning. Our contributions are twofold. First, in contrast with prior work, which employs HTNs to represent domain physics or search control knowledge, we use HTNs to model user preferences. Second, while most prior work on HTN learning requires additional information (e.g., annotated traces or tasks) to assist the learning process, our system only takes plan traces as input. Initially, we will assume that users carry out preferred plans more frequently, and thus the observed distribution of plans is an accurate representation of user preference. We then generalize to the situation where feasibility constraints frequently prevent the execution of preferred plans. Taking the prevalent perspective of viewing HTNs as grammars over primitive actions, we adapt an expectation-maximization (EM) technique from the discipline of probabilistic grammar induction to acquire probabilistic context-free grammars (pCFG) that capture the distribution on plans. To account for the difference between the distributions of possible and preferred plans, we subsequently modify this core EM technique by rescaling its input. We empirically demonstrate that the proposed approaches are able to learn HTNs representing user preferences better than the inside-outside algorithm. Furthermore, when feasibility constraints are obfuscated, the algorithm with rescaled input performs better than the algorithm with the original input.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2017174110",
    "type": "article"
  },
  {
    "title": "Improving recency ranking using twitter data",
    "doi": "https://doi.org/10.1145/2414425.2414429",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Yi Chang; Anlei Dong; Pranam Kolari; Ruiqiang Zhang; Yoshiyuki Inagaki; Fernanodo Diaz; Hongyuan Zha; Yan Liu",
    "corresponding_authors": "",
    "abstract": "In Web search and vertical search, recency ranking refers to retrieving and ranking documents by both relevance and freshness. As impoverished in-links and click information is the the biggest challenge for recency ranking, we advocate the use of Twitter data to address the challenge in this article. We propose a method to utilize Twitter TinyURL to detect fresh and high-quality documents, and leverage Twitter data to generate novel and effective features for ranking. The empirical experiments demonstrate that the proposed approach effectively improves a commercial search engine for both Web search ranking and tweet vertical ranking.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2026069639",
    "type": "article"
  },
  {
    "title": "Folksonomy-Based Term Extraction for Word Cloud Generation",
    "doi": "https://doi.org/10.1145/2337542.2337545",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "David Carmel; Erel Uziel; Ido Guy; Yosi Mass; Haggai Roitman",
    "corresponding_authors": "",
    "abstract": "In this work we study the task of term extraction for word cloud generation in sparsely tagged domains, in which manual tags are scarce. We present a folksonomy-based term extraction method, called tag-boost , which boosts terms that are frequently used by the public to tag content. Our experiments with tag-boost based term extraction over different domains demonstrate tremendous improvement in word cloud quality, as reflected by the agreement between manual tags of the testing items and the cloud’s terms extracted from the items’ content. Moreover, our results demonstrate the high robustness of this approach, as compared to alternative cloud generation methods that exhibit a high sensitivity to data sparseness. Additionally, we show that tag-boost can be effectively applied even in nontagged domains, by using an external rich folksonomy borrowed from a well-tagged domain.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2094242017",
    "type": "article"
  },
  {
    "title": "Towards Topic Modeling for Big Data",
    "doi": null,
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Yi Wang; Xuemin Zhao; Zhenlong Sun; Hao Yan; Lifeng Wang; Zhihui Jin; Liubin Wang; Yang Gao; Jia Zeng; Qiang Yang; Ching Law",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W27929844",
    "type": "article"
  },
  {
    "title": "A Cross-Domain Recommendation Mechanism for Cold-Start Users Based on Partial Least Squares Regression",
    "doi": "https://doi.org/10.1145/3231601",
    "publication_date": "2018-11-01",
    "publication_year": 2018,
    "authors": "Cheng–Te Li; Chia-Tai Hsu; Man-Kwan Shan",
    "corresponding_authors": "",
    "abstract": "Recommender systems are common in e-commerce platforms in recent years. Recommender systems are able to help users find preferential items among a large amount of products so that users’ time is saved and sellers’ profits are increased. Cross-domain recommender systems aim to recommend items based on users’ different tastes across domains. While recommender systems usually suffer from the user cold-start problem that leads to unsatisfying recommendation performance, cross-domain recommendation can remedy such a problem. This article proposes a novel cross-domain recommendation model based on regression analysis, partial least squares regression (PLSR). The proposed recommendation models, PLSR-CrossRec and PLSR-Latent, are able to purely use source-domain ratings to predict the ratings for cold-start users who never rated items in the target domains. Experiments conducted on the Epinions dataset with ten various domains’ rating records demonstrate that PLSR-Latent can outperform several matrix factorization-based competing methods under a variety of cross-domain settings. The time efficiency of PLSR-Latent is also satisfactory.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2898653164",
    "type": "article"
  },
  {
    "title": "Traffic Simulation and Visual Verification in Smog",
    "doi": "https://doi.org/10.1145/3200491",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Mingliang Xu; Hua Wang; Shili Chu; Yong Gan; Xiaoheng Jiang; Yafei Li; Bing Zhou",
    "corresponding_authors": "",
    "abstract": "Smog causes low visibility on the road and it can impact the safety of traffic. Modeling traffic in smog will have a significant impact on realistic traffic simulations. Most existing traffic models assume that drivers have optimal vision in the simulations, making these simulations are not suitable for modeling smog weather conditions. In this article, we introduce the Smog Full Velocity Difference Model (SMOG-FVDM) for a realistic simulation of traffic in smog weather conditions. In this model, we present a stadia model for drivers in smog conditions. We introduce it into a car-following traffic model using both psychological force and body force concepts, and then we introduce the SMOG-FVDM. Considering that there are lots of parameters in the SMOG-FVDM, we design a visual verification system based on SMOG-FVDM to arrive at an adequate solution which can show visual simulation results under different road scenarios and different degrees of smog by reconciling the parameters. Experimental results show that our model can give a realistic and efficient traffic simulation of smog weather conditions.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2903312941",
    "type": "article"
  },
  {
    "title": "Resources Sequencing Using Automatic Prerequisite--Outcome Annotation",
    "doi": "https://doi.org/10.1145/2505349",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Sahar Changuel; Nicolas Labroche; Bernadette Bouchon‐Meunier",
    "corresponding_authors": "",
    "abstract": "The objective of any tutoring system is to provide resources to learners that are adapted to their current state of knowledge. With the availability of a large variety of online content and the disjunctive nature of results provided by traditional search engines, it becomes crucial to provide learners with adapted learning paths that propose a sequence of resources that match their learning objectives. In an ideal case, the sequence of documents provided to the learner should be such that each new document relies on concepts that have been already defined in previous documents. Thus, the problem of determining an effective learning path from a corpus of web documents depends on the accurate identification of outcome and prerequisite concepts in these documents and on their ordering according to this information. Until now, only a few works have been proposed to distinguish between prerequisite and outcome concepts, and to the best of our knowledge, no method has been introduced so far to benefit from this information to produce a meaningful learning path. To this aim, this article first describes a concept annotation method that relies on machine-learning techniques to predict the class of each concept—prerequisite or outcome—on the basis of contextual and local features. Then, this categorization is exploited to produce an automatic resource sequencing on the basis of different representations and scoring functions that transcribe the precedence relation between learning resources. Experiments conducted on a real dataset built from online resources show that our concept annotation approach outperforms the baseline method and that the learning paths automatically generated are consistent with the ground truth provided by the author of the online content.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2129713874",
    "type": "article"
  },
  {
    "title": "Beyond Relevance",
    "doi": "https://doi.org/10.1145/2801130",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Fabiano Belém; Carolina S. Batista; Rodrygo L. T. Santos; Jussara M. Almeida; Marcos André Gonçalves",
    "corresponding_authors": "",
    "abstract": "The design and evaluation of tag recommendation methods has historically focused on maximizing the relevance of the suggested tags for a given object, such as a movie or a song. However, relevance by itself may not be enough to guarantee recommendation usefulness. Promoting novelty and diversity in tag recommendation not only increases the chances that the user will select “some” of the recommended tags but also promotes complementary information (i.e., tags), which helps to cover multiple aspects or topics related to the target object. Previous work has addressed the tag recommendation problem by exploiting at most two of the following aspects: (1) relevance, (2) explicit topic diversity, and (3) novelty. In contrast, here we tackle these three aspects conjointly, by introducing two new tag recommendation methods that cover all three aspects of the problem at different levels. Our first method, called Random Forest with topic-related attributes , or RF t , extends a relevance-driven tag recommender based on the Random Forest ( RF ) learning-to-rank method by including new tag attributes to capture the extent to which a candidate tag is related to the topics of the target object. This solution captures topic diversity as well as novelty at the attribute level while aiming at maximizing relevance in its objective function. Our second method, called Explicit Tag Recommendation Diversifier with Novelty Promotion , or xTReND , reranks the recommendations provided by any tag recommender to jointly promote relevance, novelty, and topic diversity. We use RF t as a basic recommender applied before the reranking, thus building a solution that addresses the problem at both attribute and objective levels. Furthermore, to enable the use of our solutions on applications in which category information is unavailable, we investigate the suitability of using latent Dirichlet allocation (LDA) to automatically generate topics for objects. We evaluate all tag recommendation approaches using real data from five popular Web 2.0 applications. Our results show that RF t greatly outperforms the relevance-driven RF baseline in diversity while producing gains in relevance as well. We also find that our new xTReND reranker obtains considerable gains in both novelty and relevance when compared to that same baseline while keeping the same relevance levels. Furthermore, compared to our previous reranker method, xTReD , which does not consider novelty, xTReND is also quite effective, improving the novelty of the recommended tags while keeping similar relevance and diversity levels in most datasets and scenarios. Comparing our two new proposals, we find that xTReND considerably outperforms RF t in terms of novelty and diversity with only small losses (under 4%) in relevance. Overall, considering the trade-off among relevance, novelty, and diversity, our results demonstrate the superiority of xTReND over the baselines and the proposed alternative, RF t . Finally, the use of automatically generated latent topics as an alternative to manually labeled categories also provides significant improvements, which greatly enhances the applicability of our solutions to applications where the latter is not available.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2270188535",
    "type": "article"
  },
  {
    "title": "A Supervised Learning Model for High-Dimensional and Large-Scale Data",
    "doi": "https://doi.org/10.1145/2972957",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "Chong Peng; Jie Cheng; Qiang Cheng",
    "corresponding_authors": "",
    "abstract": "We introduce a new supervised learning model using a discriminative regression approach. This new model estimates a regression vector to represent the similarity between a test example and training examples while seamlessly integrating the class information in the similarity estimation. This distinguishes our model from usual regression models and locally linear embedding approaches, rendering our method suitable for supervised learning problems in high-dimensional settings. Our model is easily extensible to account for nonlinear relationship and applicable to general data, including both high- and low-dimensional data. The objective function of the model is convex, for which two optimization algorithms are provided. These two optimization approaches induce two scalable solvers that are of mathematically provable, linear time complexity. Experimental results verify the effectiveness of the proposed method on various kinds of data. For example, our method shows comparable performance on low-dimensional data and superior performance on high-dimensional data to several widely used classifiers; also, the linear solvers obtain promising performance on large-scale classification.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2548608220",
    "type": "article"
  },
  {
    "title": "Modeling the Thermal Dynamics of Buildings",
    "doi": "https://doi.org/10.1145/2629674",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Siddhartha Ghosh; Steve Reece; Alex Rogers; Stephen Roberts; Areej Malibari; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "Minimizing the energy consumed by heating, ventilation, and air conditioning (HVAC) systems of residential buildings without impacting occupants’ comfort has been highlighted as an important artificial intelligence (AI) challenge. Typically, approaches that seek to address this challenge use a model that captures the thermal dynamics within a building, also referred to as a thermal model. Among thermal models, gray-box models are a popular choice for modeling the thermal dynamics of buildings. They combine knowledge of the physical structure of a building with various data-driven inputs and are accurate estimators of the state (internal temperature). However, existing gray-box models require a detailed specification of all the physical elements that can affect the thermal dynamics of a building a priori. This limits their applicability, particularly in residential buildings, where additional dynamics can be induced by human activities such as cooking, which contributes additional heat, or opening of windows, which leads to additional leakage of heat. Since the incidence of these additional dynamics is rarely known, their combined effects cannot readily be accommodated within existing models. To overcome this limitation and improve the general applicability of gray-box models, we introduce a novel model, which we refer to as a latent force thermal model of the thermal dynamics of a building, or LFM-TM. Our model is derived from an existing gray-box thermal model, which is augmented with an extra term referred to as the learned residual. This term is capable of modeling the effect of any a priori unknown additional dynamic, which, if not captured, appears as a structure in a thermal model’s residual (the error induced by the model). More importantly, the learned residual can also capture the effects of physical elements such as a building’s envelope or the lags in a heating system, leading to a significant reduction in complexity compared to existing models. To evaluate the performance of LFM-TM, we apply it to two independent data sources. The first is an established dataset, referred to as the FlexHouse data, which was previously used for evaluating the efficacy of existing gray-box models [Bacher and Madsen 2011]. The second dataset consists of heating data logged within homes located on the University of Southampton campus, which were specifically instrumented to collect data for our thermal modeling experiments. On both datasets, we show that LFM-TM outperforms existing models in its ability to accurately fit the observed data, generate accurate day-ahead internal temperature predictions, and explain a large amount of the variability in the future observations. This, along with the fact that we also use a corresponding efficient sequential inference scheme for LFM-TM, makes it an ideal candidate for model-based predictive control, where having accurate online predictions of internal temperatures is essential for high-quality solutions.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1988685575",
    "type": "article"
  },
  {
    "title": "A Sparse Projection and Low-Rank Recovery Framework for Handwriting Representation and Salient Stroke Feature Extraction",
    "doi": "https://doi.org/10.1145/2601408",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Zhao Zhang; Cheng‐Lin Liu; Mingbo Zhao",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the problem of simultaneous low-rank recovery and sparse projection. More specifically, a new Robust Principal Component Analysis (RPCA)-based framework called Sparse Projection and Low-Rank Recovery (SPLRR) is proposed for handwriting representation and salient stroke feature extraction. In addition to achieving a low-rank component encoding principal features and identify errors or missing values from a given data matrix as RPCA, SPLRR also learns a similarity-preserving sparse projection for extracting salient stroke features and embedding new inputs for classification. These properties make SPLRR applicable for handwriting recognition and stroke correction and enable online computation. A cosine-similarity-style regularization term is incorporated into the SPLRR formulation for encoding the similarities of local handwriting features. The sparse projection and low-rank recovery are calculated from a convex minimization problem that can be efficiently solved in polynomial time. Besides, the supervised extension of SPLRR is also elaborated. The effectiveness of our SPLRR is examined by extensive handwritten digital repairing, stroke correction, and recognition based on benchmark problems. Compared with other related techniques, SPLRR delivers strong generalization capability and state-of-the-art performance for handwriting representation and recognition.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1995711748",
    "type": "article"
  },
  {
    "title": "Using Digital Footprints for a City-Scale Traffic Simulation",
    "doi": "https://doi.org/10.1145/2517028",
    "publication_date": "2014-07-28",
    "publication_year": 2014,
    "authors": "Gavin McArdle; Eoghan Furey; Aonghus Lawlor; Alexei Pozdnoukhov",
    "corresponding_authors": "",
    "abstract": "This article introduces a microsimulation of urban traffic flows within a large-scale scenario implemented for the Greater Dublin region in Ireland. Traditionally, the data available for traffic simulations come from a population census and dedicated road surveys that only partly cover shopping, leisure, or recreational trips. To account for the latter, the presented traffic modeling framework exploits the digital footprints of city inhabitants on services such as Twitter and Foursquare. We enriched the model with findings from our previous studies on geographical layout of communities in a country-wide mobile phone network to account for socially related journeys. These datasets were used to calibrate a variant of a radiation model of spatial choice, which we introduced in order to drive individuals’ decisions on trip destinations within an assigned daily activity plan. We observed that given the distribution of population, the workplace locations, a comprehensive set of urban facilities, and a list of typical activity sequences of city dwellers collected within a national travel survey, the developed microsimulation reproduces not only the journey statistics such as peak travel periods but also the traffic volumes at main road segments with surprising accuracy.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2032216089",
    "type": "article"
  },
  {
    "title": "A Framework for Dataset Benchmarking and Its Application to a New Movie Rating Dataset",
    "doi": "https://doi.org/10.1145/2751565",
    "publication_date": "2016-02-11",
    "publication_year": 2016,
    "authors": "Simon Dooms; Alejandro Bellogín; Toon De Pessemier; Luc Martens",
    "corresponding_authors": "",
    "abstract": "Rating datasets are of paramount importance in recommender systems research. They serve as input for recommendation algorithms, as simulation data, or for evaluation purposes. In the past, public accessible rating datasets were not abundantly available, leaving researchers no choice but to work with old and static datasets like MovieLens and Netflix. More recently, however, emerging trends as social media and smartphones are found to provide rich data sources which can be turned into valuable research datasets. While dataset availability is growing, a structured way for introducing and comparing new datasets is currently still lacking. In this work, we propose a five-step framework to introduce and benchmark new datasets in the recommender systems domain. We illustrate our framework on a new movie rating dataset—called MovieTweetings—collected from Twitter. Following our framework, we detail the origin of the dataset, provide basic descriptive statistics, investigate external validity, report the results of a number of reproducible benchmarks, and conclude by discussing some interesting advantages and appropriate research use cases.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2284074706",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Crowd in Intelligent Systems",
    "doi": "https://doi.org/10.1145/2920522",
    "publication_date": "2016-07-12",
    "publication_year": 2016,
    "authors": "Kuan-Ta Chen; Omar Alonso; Martha Larson; Irwin King",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2471730112",
    "type": "article"
  },
  {
    "title": "Concept and Attention-Based CNN for Question Retrieval in Multi-View Learning",
    "doi": "https://doi.org/10.1145/3151957",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Pengwei Wang; Lei Ji; Jun Yan; Dejing Dou; Nisansa de Silva; Yong Zhang; Lianwen Jin",
    "corresponding_authors": "",
    "abstract": "Question retrieval, which aims to find similar versions of a given question, is playing a pivotal role in various question answering (QA) systems. This task is quite challenging, mainly in regard to five aspects: synonymy, polysemy, word order, question length, and data sparsity. In this article, we propose a unified framework to simultaneously handle these five problems. We use the word combined with corresponding concept information to handle the synonymy problem and the polysemous problem. Concept embedding and word embedding are learned at the same time from both the context-dependent and context-independent views. To handle the word-order problem, we propose a high-level feature-embedded convolutional semantic model to learn question embedding by inputting concept embedding and word embedding. Due to the fact that the lengths of some questions are long, we propose a value-based convolutional attentional method to enhance the proposed high-level feature-embedded convolutional semantic model in learning the key parts of the question and the answer. The proposed high-level feature-embedded convolutional semantic model nicely represents the hierarchical structures of word information and concept information in sentences with their layer-by-layer convolution and pooling. Finally, to resolve data sparsity, we propose using the multi-view learning method to train the attention-based convolutional semantic model on question–answer pairs. To the best of our knowledge, we are the first to propose simultaneously handling the above five problems in question retrieval using one framework. Experiments on three real question-answering datasets show that the proposed framework significantly outperforms the state-of-the-art solutions.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2786109915",
    "type": "article"
  },
  {
    "title": "CNNs Based Viewpoint Estimation for Volume Visualization",
    "doi": "https://doi.org/10.1145/3309993",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Neng Shi; Yubo Tao",
    "corresponding_authors": "",
    "abstract": "Viewpoint estimation from 2D rendered images is helpful in understanding how users select viewpoints for volume visualization and guiding users to select better viewpoints based on previous visualizations. In this article, we propose a viewpoint estimation method based on Convolutional Neural Networks (CNNs) for volume visualization. We first design an overfit-resistant image rendering pipeline to generate the training images with accurate viewpoint annotations, and then train a category-specific viewpoint classification network to estimate the viewpoint for the given rendered image. Our method can achieve good performance on images rendered with different transfer functions and rendering parameters in several categories. We apply our model to recover the viewpoints of the rendered images in publications, and show how experts look at volumes. We also introduce a CNN feature-based image similarity measure for similarity voting based viewpoint selection, which can suggest semantically meaningful optimal viewpoints for different volumes and transfer functions.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2964256275",
    "type": "article"
  },
  {
    "title": "Using Sparse Representation to Detect Anomalies in Complex WSNs",
    "doi": "https://doi.org/10.1145/3331147",
    "publication_date": "2019-10-30",
    "publication_year": 2019,
    "authors": "Xiaoming Li; Guangquan Xu; Xi Zheng; Kaitai Liang; Emmanouil Panaousis; Tao Li; Wei Wang; Chao Shen",
    "corresponding_authors": "",
    "abstract": "In recent years, wireless sensor networks (WSNs) have become an active area of research for monitoring physical and environmental conditions. Due to the interdependence of sensors, a functional anomaly in one sensor can cause a functional anomaly in another sensor, which can further lead to the malfunctioning of the entire sensor network. Existing research work has analysed faulty sensor anomalies but fails to show the effectiveness throughout the entire interdependent network system. In this article, a dictionary learning algorithm based on a non-negative constraint is developed, and a sparse representation anomaly node detection method for sensor networks is proposed based on the dictionary learning. Through experiment on a specific thermal power plant in China, we verify the robustness of our proposed method in detecting abnormal nodes against four state of the art approaches and proved our method is more robust. Furthermore, the experiments are conducted on the obtained abnormal nodes to prove the interdependence of multi-layer sensor networks and reveal the conditions and causes of a system crash.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2984694572",
    "type": "article"
  },
  {
    "title": "Dystemo",
    "doi": "https://doi.org/10.1145/2912147",
    "publication_date": "2016-08-23",
    "publication_year": 2016,
    "authors": "Valentina Sintsova; Pearl Pu",
    "corresponding_authors": "",
    "abstract": "Emotion recognition in text has become an important research objective. It involves building classifiers capable of detecting human emotions for a specific application, for example, analyzing reactions to product launches, monitoring emotions at sports events, or discerning opinions in political debates. Most successful approaches rely heavily on costly manual annotation. To alleviate this burden, we propose a distant supervision method—Dystemo—for automatically producing emotion classifiers from tweets labeled using existing or easy-to-produce emotion lexicons. The goal is to obtain emotion classifiers that work more accurately for specific applications than available emotion lexicons. The success of this method depends mainly on a novel classifier—Balanced Weighted Voting (BWV)—designed to overcome the imbalance in emotion distribution in the initial dataset, and on novel heuristics for detecting neutral tweets. We demonstrate how Dystemo works using Twitter data about sports events, a fine-grained 20-category emotion model, and three different initial emotion lexicons. Through a series of carefully designed experiments, we confirm that Dystemo is effective both in extending initial emotion lexicons of small coverage to find correctly more emotional tweets and in correcting emotion lexicons of low accuracy to perform more accurately.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2507366876",
    "type": "article"
  },
  {
    "title": "Multi-Modal Curriculum Learning over Graphs",
    "doi": "https://doi.org/10.1145/3322122",
    "publication_date": "2019-07-20",
    "publication_year": 2019,
    "authors": "Chen Gong; Jian Yang; Dacheng Tao",
    "corresponding_authors": "",
    "abstract": "Curriculum Learning (CL) is a recently proposed learning paradigm that aims to achieve satisfactory performance by properly organizing the learning sequence from simple curriculum examples to more difficult ones. Up to now, few works have been done to explore CL for the data with graph structure. Therefore, this article proposes a novel CL algorithm that can be utilized to guide the Label Propagation (LP) over graphs, of which the target is to “learn” the labels of unlabeled examples on the graphs. Specifically, we assume that different unlabeled examples have different levels of difficulty for propagation, and their label learning should follow a simple-to-difficult sequence with the updated curricula. Furthermore, considering that the practical data are often characterized by multiple modalities, every modality in our method is associated with a “teacher” that not only evaluates the difficulties of examples from its own viewpoint, but also cooperates with other teachers to generate the overall simplest curriculum examples for propagation. By taking the curriculums suggested by the teachers as a whole, the common preference (i.e., commonality) of teachers on selecting the simplest examples can be discovered by a row-sparse matrix, and their distinct opinions (i.e., individuality) are captured by a sparse noise matrix. As a result, an accurate curriculum sequence can be established and the propagation quality can thus be improved. Theoretically, we prove that the propagation risk bound is closely related to the examples’ difficulty information, and empirically, we show that our method can generate higher accuracy than the state-of-the-art CL approach and LP algorithms on various multi-modal tasks.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2963102641",
    "type": "article"
  },
  {
    "title": "Market Clearing–based Dynamic Multi-agent Task Allocation",
    "doi": "https://doi.org/10.1145/3356467",
    "publication_date": "2020-01-21",
    "publication_year": 2020,
    "authors": "Sofia Amador Nelke; Steven Okamoto; Roie Zivan",
    "corresponding_authors": "",
    "abstract": "Realistic multi-agent team applications often feature dynamic environments with soft deadlines that penalize late execution of tasks. This puts a premium on quickly allocating tasks to agents. However, when such problems include temporal and spatial constraints that require tasks to be executed sequentially by agents, they are NP-hard, and thus are commonly solved using general and specifically designed incomplete heuristic algorithms. We propose FMC_TA, a novel such incomplete task allocation algorithm that allows tasks to be easily sequenced to yield high-quality solutions. FMC_TA first finds allocations that are fair (envy-free), balancing the load and sharing important tasks among agents, and efficient (Pareto optimal) in a simplified version of the problem. It computes such allocations in polynomial or pseudo-polynomial time (centrally or distributedly, respectively) using a Fisher market with agents as buyers and tasks as goods. It then heuristically schedules the allocations, taking into account inter-agent constraints on shared tasks. We empirically compare our algorithm to state-of-the-art incomplete methods, both centralized and distributed, on law enforcement problems inspired by real police logs. We present a novel formalization of the law enforcement problem, which we use to perform our empirical study. The results show a clear advantage for FMC_TA in total utility and in measures in which law enforcement authorities measure their own performance. Besides problems with realistic properties, the algorithms were compared on synthetic problems in which we increased the size of different elements of the problem to investigate the algorithm’s behavior when the problem scales. The domination of the proposed algorithm was found to be consistent.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3015770683",
    "type": "article"
  },
  {
    "title": "A Joint Neural Model for User Behavior Prediction on Social Networking Platforms",
    "doi": "https://doi.org/10.1145/3406540",
    "publication_date": "2020-09-25",
    "publication_year": 2020,
    "authors": "Junwei Li; Le Wu; Richang Hong; Kun Zhang; Yong Ge; Yan Li",
    "corresponding_authors": "",
    "abstract": "Social networking services provide platforms for users to perform two kinds of behaviors: consumption behavior (e.g., recommending items of interest) and social link behavior (e.g., recommending potential social links). Accurately modeling and predicting users’ two kinds of behaviors are two core tasks in these platforms with various applications. Recently, with the advance of neural networks, many neural-based models have been designed to predict a single users’ behavior, i.e., social link behavior or consumption behavior. Compared to the classical shallow models, these neural-based models show better performance to drive a user’s behavior by modeling the complex patterns. However, there are few works exploiting whether it is possible to design a neural-based model to jointly predict users’ two kinds of behaviors to further enhance the prediction performance. In fact, social scientists have already shown that users’ two kinds of behaviors are not isolated; people trend to the consumption recommendation of friends on social platforms and would like to make new friends with like-minded users. While some previous works jointly model users’ two kinds of behaviors with shallow models, we argue that the correlation between users’ two kinds of behaviors are complex, which could not be well-designed with shallow linear models. To this end, in this article, we propose a neural joint behavior prediction model named Neural Joint Behavior Prediction Model (NJBP) to mutually enhance the prediction performance of these two tasks on social networking platforms. Specifically, there are two key characteristics of our proposed model: First, to model the correlation of users’ two kinds of behaviors, we design a fusion layer in the neural network to model the positive correlation of users’ two kinds of behaviors. Second, as the observed links in the social network are often very sparse, we design a new link-based loss function that could preserve the social network topology. After that, we design a joint optimization function to allow the two behaviors modeling tasks to be trained to mutually enhance each other. Finally, extensive experimental results on two real-world datasets show that our proposed method is on average 7.14% better than the best baseline on social link behavior while 6.21% on consumption behavior prediction. Compared with the pair-wise loss function on two datasets, our proposed link-based loss function improves at least 4.69% on the social link behavior prediction and 4.72% on the consumption behavior prediction.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3090813943",
    "type": "article"
  },
  {
    "title": "DeepApp",
    "doi": "https://doi.org/10.1145/3408325",
    "publication_date": "2020-10-29",
    "publication_year": 2020,
    "authors": "Xia Tong; Yong Li; Jie Feng; Depeng Jin; Qing Zhang; Hengliang Luo; Qingmin Liao",
    "corresponding_authors": "",
    "abstract": "Smartphone mobile application (App) usage prediction, i.e., which Apps will be used next, is beneficial for user experience improvement. Through an in-depth analysis on a real-world dataset, we find that App usage is highly spatio-temporally correlated and personalized. Given the ability to model complex spatio-temporal contexts, we aim to apply deep learning to achieve high prediction accuracy. However, the personalization yields a problem: training one network for each individual suffers from data scarcity, yet training one deep neural network for all users often fails to uncover user preference. In this article, we propose a novel App usage prediction framework, named DeepApp , to achieve context-aware prediction via multi-task learning. To tackle the challenge of data scarcity, we train one general network for multiple users to share common patterns. To better utilize the spatio-temporal contexts, we supplement a location prediction task in the multi-task learning framework to learn spatio-temporal relations. As for the personalization, we add a user identification task to capture user preference. We evaluate DeepApp on the large-scale dataset by extensive experiments. Results demonstrate that DeepApp outperforms the start-of-the-art baseline by 6.44%.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3095268172",
    "type": "article"
  },
  {
    "title": "Multiview Common Subspace Clustering via Coupled Low Rank Representation",
    "doi": "https://doi.org/10.1145/3465056",
    "publication_date": "2021-08-01",
    "publication_year": 2021,
    "authors": "Stanley Ebhohimhen Abhadiomhen; Zhiyang Wang; Xiang‐Jun Shen; Jianping Fan",
    "corresponding_authors": "",
    "abstract": "Multi-view subspace clustering (MVSC) finds a shared structure in latent low-dimensional subspaces of multi-view data to enhance clustering performance. Nonetheless, we observe that most existing MVSC methods neglect the diversity in multi-view data by considering only the common knowledge to find a shared structure either directly or by merging different similarity matrices learned for each view. In the presence of noise, this predefined shared structure becomes a biased representation of the different views. Thus, in this article, we propose a MVSC method based on coupled low-rank representation to address the above limitation. Our method first obtains a low-rank representation for each view, constrained to be a linear combination of the view-specific representation and the shared representation by simultaneously encouraging the sparsity of view-specific one. Then, it uses the k -block diagonal regularizer to learn a manifold recovery matrix for each view through respective low-rank matrices to recover more manifold structures from them. In this way, the proposed method can find an ideal similarity matrix by approximating clustering projection matrices obtained from the recovery structures. Hence, this similarity matrix denotes our clustering structure with exactly k connected components by applying a rank constraint on the similarity matrix’s relaxed Laplacian matrix to avoid spectral post-processing of the low-dimensional embedding matrix. The core of our idea is such that we introduce dynamic approximation into the low-rank representation to allow the clustering structure and the shared representation to guide each other to learn cleaner low-rank matrices that would lead to a better clustering structure. Therefore, our approach is notably different from existing methods in which the local manifold structure of data is captured in advance. Extensive experiments on six benchmark datasets show that our method outperforms 10 similar state-of-the-art compared methods in six evaluation metrics.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3193347070",
    "type": "article"
  },
  {
    "title": "Multitask Balanced and Recalibrated Network for Medical Code Prediction",
    "doi": "https://doi.org/10.1145/3563041",
    "publication_date": "2022-09-08",
    "publication_year": 2022,
    "authors": "Wei Sun; Shaoxiong Ji; Erik Cambria; Pekka Marttinen",
    "corresponding_authors": "",
    "abstract": "Human coders assign standardized medical codes to clinical documents generated during patients' hospitalization, which is error-prone and labor-intensive. Automated medical coding approaches have been developed using machine learning methods such as deep neural networks. Nevertheless, automated medical coding is still challenging because of the imbalanced class problem, complex code association, and noise in lengthy documents. To solve these issues, we propose a novel neural network called Multitask Balanced and Recalibrated Neural Network. Significantly, the multitask learning scheme shares the relationship knowledge between different code branches to capture the code association. A recalibrated aggregation module is developed by cascading convolutional blocks to extract high-level semantic features that mitigate the impact of noise in documents. Also, the cascaded structure of the recalibrated module can benefit the learning from lengthy notes. To solve the class imbalanced problem, we deploy the focal loss to redistribute the attention of low and high-frequency medical codes. Experimental results show that our proposed model outperforms competitive baselines on a real-world clinical dataset MIMIC-III.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3198841974",
    "type": "article"
  },
  {
    "title": "COVID-GAN+: Estimating Human Mobility Responses to COVID-19 through Spatio-temporal Generative Adversarial Networks with Enhanced Features",
    "doi": "https://doi.org/10.1145/3481617",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Han Bao; Xun Zhou; Yiqun Xie; Yingxue Zhang; Yanhua Li",
    "corresponding_authors": "",
    "abstract": "Estimating human mobility responses to the large-scale spreading of the COVID-19 pandemic is crucial, since its significance guides policymakers to give Non-pharmaceutical Interventions, such as closure or reopening of businesses. It is challenging to model due to complex social contexts and limited training data. Recently, we proposed a conditional generative adversarial network (COVID-GAN) to estimate human mobility response under a set of social and policy conditions integrated from multiple data sources. Although COVID-GAN achieves a good average estimation accuracy under real-world conditions, it produces higher errors in certain regions due to the presence of spatial heterogeneity and outliers. To address these issues, in this article, we extend our prior work by introducing a new spatio-temporal deep generative model, namely, COVID-GAN+. COVID-GAN+ deals with the spatial heterogeneity issue by introducing a new spatial feature layer that utilizes the local Moran statistic to model the spatial heterogeneity strength in the data. In addition, we redesign the training objective to learn the estimated mobility changes from historical average levels to mitigate the effects of spatial outliers. We perform comprehensive evaluations using urban mobility data derived from cell phone records and census data. Results show that COVID-GAN+ can better approximate real-world human mobility responses than prior methods, including COVID-GAN.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4205320585",
    "type": "article"
  },
  {
    "title": "Weakly Supervised Spatial Deep Learning for Earth Image Segmentation Based on Imperfect Polyline Labels",
    "doi": "https://doi.org/10.1145/3480970",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Zhe Jiang; Wenchong He; Marcus Stephen Kirby; Arpan Man Sainju; Shaowen Wang; Lawrence V. Stanislawski; Ethan Shavers; E. Lynn Usery",
    "corresponding_authors": "",
    "abstract": "In recent years, deep learning has achieved tremendous success in image segmentation for computer vision applications. The performance of these models heavily relies on the availability of large-scale high-quality training labels (e.g., PASCAL VOC 2012). Unfortunately, such large-scale high-quality training data are often unavailable in many real-world spatial or spatiotemporal problems in earth science and remote sensing (e.g., mapping the nationwide river streams for water resource management). Although extensive efforts have been made to reduce the reliance on labeled data (e.g., semi-supervised or unsupervised learning, few-shot learning), the complex nature of geographic data such as spatial heterogeneity still requires sufficient training labels when transferring a pre-trained model from one region to another. On the other hand, it is often much easier to collect lower-quality training labels with imperfect alignment with earth imagery pixels (e.g., through interpreting coarse imagery by non-expert volunteers). However, directly training a deep neural network on imperfect labels with geometric annotation errors could significantly impact model performance. Existing research that overcomes imperfect training labels either focuses on errors in label class semantics or characterizes label location errors at the pixel level. These methods do not fully incorporate the geometric properties of label location errors in the vector representation. To fill the gap, this article proposes a weakly supervised learning framework to simultaneously update deep learning model parameters and infer hidden true vector label locations. Specifically, we model label location errors in the vector representation to partially reserve geometric properties (e.g., spatial contiguity within line segments). Evaluations on real-world datasets in the National Hydrography Dataset (NHD) refinement application illustrate that the proposed framework outperforms baseline methods in classification accuracy.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4205586741",
    "type": "article"
  },
  {
    "title": "Detecting Extreme Traffic Events Via a Context Augmented Graph Autoencoder",
    "doi": "https://doi.org/10.1145/3539735",
    "publication_date": "2022-05-31",
    "publication_year": 2022,
    "authors": "Yue Hu; Ao Qu; Daniel B. Work",
    "corresponding_authors": "",
    "abstract": "Accurate and timely detection of large events on urban transportation networks enables informed mobility management. This work tackles the problem of extreme event detection on large-scale transportation networks using origin-destination mobility data, which is now widely available. Such data is highly structured in time and space, but high dimensional and sparse. Current multivariate time series anomaly detection methods cannot fully address these challenges. To exploit the structure of mobility data, we formulate the event detection problem in a novel way, as detecting anomalies in a set of time-dependent directed weighted graphs. We further propose a Context augmented Graph Autoencoder (Con-GAE) model to solve the problem, which leverages graph embedding and context embedding techniques to capture the spatial and temporal patterns. Con-GAE adopts an autoencoder framework and detects anomalies via semi-supervised learning. The performance of the method is assessed on several city-scale travel-time datasets from Uber Movement, New York taxis, and Chicago taxis and compared to state-of-the-art approaches. The proposed Con-GAE can achieve an improvement in the area under the curve score as large as 0.15 over the second best method. We also discuss real-world traffic anomalies detected by Con-GAE.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4282003570",
    "type": "article"
  },
  {
    "title": "Data-driven Targeted Advertising Recommendation System for Outdoor Billboard",
    "doi": "https://doi.org/10.1145/3495159",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Liang Wang; Zhiwen Yu; Bin Guo; Dingqi Yang; Lianbo Ma; Zhidan Liu; Fei Xiong",
    "corresponding_authors": "",
    "abstract": "In this article, we propose and study a novel data-driven framework for Targeted Outdoor Advertising Recommendation (TOAR) with a special consideration of user profiles and advertisement topics. Given an advertisement query and a set of outdoor billboards with different spatial locations and rental prices, our goal is to find a subset of billboards, such that the total targeted influence is maximum under a limited budget constraint. To achieve this goal, we are facing two challenges: (1) it is difficult to estimate targeted advertising influence in physical world; (2) due to NP hardness, many common search techniques fail to provide a satisfied solution with an acceptable time, especially for large-scale problem settings. Taking into account the exposure strength, advertisement matching degree, and advertising repetition effect, we first build a targeted influence model that can characterize that the advertising influence spreads along with users mobility. Subsequently, based on a divide-and-conquer strategy, we develop two effective approaches, i.e., a master–slave-based sequential optimization method, TOAR-MSS, and a cooperative co-evolution-based optimization method, TOAR-CC, to solve our studied problem. Extensive experiments on two real-world datasets clearly validate the effectiveness and efficiency of our proposed approaches.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4206245354",
    "type": "article"
  },
  {
    "title": "Predicting Future Locations with Semantic Trajectories",
    "doi": "https://doi.org/10.1145/3465060",
    "publication_date": "2022-01-27",
    "publication_year": 2022,
    "authors": "Heli Sun; Xianglan Guo; Zhou Yang; Xuguang Chu; Xinwang Liu; Liang He",
    "corresponding_authors": "",
    "abstract": "Location prediction has attracted much attention due to its important role in many location-based services, including taxi services, route navigation, traffic planning, and location-based advertisements. Traditional methods only use spatial-temporal trajectory data to predict where a user will go next. The divorce of semantic knowledge from the spatial-temporal one inhibits our better understanding of users’ activities. Inspired by the architecture of Long Short Term Memory (LSTM), we design ST-LSTM, which draws on semantic trajectories to predict future locations. Semantic data add a new dimension to our study, increasing the accuracy of prediction. Since semantic trajectories are sparser than the spatial-temporal ones, we propose a strategic filling algorithm to solve this problem. In addition, as the prediction is based on the historical trajectories of users, the cold-start problem arises. We build a new virtual social network for users to resolve the issue. Experiments on two real-world datasets show that the performance of our method is superior to those of the baselines.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4210786613",
    "type": "article"
  },
  {
    "title": "Gray-Box Shilling Attack: An Adversarial Learning Approach",
    "doi": "https://doi.org/10.1145/3512352",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Zongwei Wang; Min Gao; Jundong Li; Junwei Zhang; Jiang Zhong",
    "corresponding_authors": "",
    "abstract": "Recommender systems are essential components of many information services, which aim to find relevant items that match user preferences. Several studies have shown that shilling attacks can significantly weaken the robustness of recommender systems by injecting fake user profiles. Traditional shilling attacks focus on creating hand-engineered fake user profiles, but these profiles can be detected effortlessly by advanced detection methods. Adversarial learning, which has emerged in recent years, can be leveraged to generate powerful and intelligent attack models. To this end, in this article we explore potential risks of recommender systems and shed light on a gray-box shilling attack model based on generative adversarial networks, named GSA-GANs . Specifically, we aim to generate fake user profiles that can achieve two goals: unnoticeable and offensive. Toward these goals, there are several challenges that we need to address: (1) learning complex user behaviors from user-item rating data, and (2) adversely influencing the recommendation results without knowing the underlying recommendation algorithms. To tackle these challenges, two essential GAN modules are respectively designed to make generated fake profiles more similar to real ones and harmful to recommendation results. Experimental results on three public datasets demonstrate that the proposed GSA-GANs framework outperforms baseline models in attack effectiveness, transferability, and camouflage. In the end, we also provide several possible defensive strategies against GSA-GANs. The exploration and analysis in our work will contribute to the defense research of recommender systems.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4220897279",
    "type": "article"
  },
  {
    "title": "Doing More with Less: Overcoming Data Scarcity for POI Recommendation via Cross-Region Transfer",
    "doi": "https://doi.org/10.1145/3511711",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Vinayak Gupta; Srikanta Bedathur",
    "corresponding_authors": "",
    "abstract": "Variability in social app usage across regions results in a high skew of the quantity and the quality of check-in data collected, which in turn is a challenge for effective location recommender systems. In this article, we present Axolotl ( Automated cross Location-network Transfer Learning ), a novel method aimed at transferring location preference models learned in a data-rich region to significantly boost the quality of recommendations in a data-scarce region. Axolotl predominantly deploys two channels for information transfer: (1) a meta-learning based procedure learned using location recommendation as well as social predictions, and (2) a lightweight unsupervised cluster-based transfer across users and locations with similar preferences. Both of these work together synergistically to achieve improved accuracy of recommendations in data-scarce regions without any prerequisite of overlapping users and with minimal fine-tuning. We build Axolotl on top of a twin graph-attention neural network model used for capturing the user- and location-conditioned influences in a user-mobility graph for each region. We conduct extensive experiments on 12 user mobility datasets across the US, Japan, and Germany, using three as source regions and nine of them (that have much sparsely recorded mobility data) as target regions. Empirically, we show that Axolotl achieves up to 18% better recommendation performance than the existing state-of-the-art methods across all metrics.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4221019432",
    "type": "article"
  },
  {
    "title": "Relation-aware Graph Convolutional Networks for Multi-relational Network Alignment",
    "doi": "https://doi.org/10.1145/3579827",
    "publication_date": "2023-01-09",
    "publication_year": 2023,
    "authors": "Yujie Fang; Xin Li; Rui Ye; Xiaoyan Tan; Peiyao Zhao; Mingzhong Wang",
    "corresponding_authors": "",
    "abstract": "The alignment of multiple multi-relational networks, such as knowledge graphs, is vital for many AI applications. In comparison with existing GCNs which cannot fully utilize relational information of multiple types, we propose a relation-aware graph convolutional network (ERGCN), which is equipped with both entity convolution and relation convolution to learn the entity embeddings and relation embeddings simultaneously. The role discrimination and translation property of knowledge graphs are adopted in the entity convolutional process to incorporate the relation information. To facilitate the relation convolution, we construct quadruples to model the connection between a pair of relations thus to determine their neighborhood, which also enables the relation convolution to be conducted in an efficient way. Thereafter, AERGCN, the alignment framework based on ERGCN, is developed for multi-relational network alignment tasks. Anchors are used to supervise the objective function, which aims at minimizing the distances between anchors and to generate new cross-network triplets to build a bridge between different knowledge graphs at the level of triplet to improve the performance of alignment. Experiments on real-world datasets show that the proposed solutions outperform the competitive baselines in terms of link prediction, entity alignment, and relation alignment.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4313889511",
    "type": "article"
  },
  {
    "title": "Hybrid Representation and Decision Fusion towards Visual-textual Sentiment",
    "doi": "https://doi.org/10.1145/3583076",
    "publication_date": "2023-02-06",
    "publication_year": 2023,
    "authors": "Chunyong Yin; Sun Zhang; Qingkui Zeng",
    "corresponding_authors": "",
    "abstract": "The rising use of online media has changed social customs of the public. Users have become gradually accustomed to sharing daily experiences and publishing personal opinions on social networks. Social data carrying with emotions and attitudes have provided significant decision support for numerous tasks in sentiment analysis. Conventional sentiment analysis methods only concern about textual modality and are vulnerable to the multimodal scenario, while common multimodal approaches only focus on the interactive relationship between modalities without considering unique intra-modal information. A hybrid fusion network is proposed in this work to capture both the inter-modal and intra-modal features. First, in the intermediate fusion stage, a multi-head visual attention is proposed to extract accurate semantic and sentimental information from textual embedding representations with the assistance of visual features. Then, multiple base classifiers are trained to learn independent and diverse discriminative information from different modal representations in the late fusion stage. The final decision is determined based on fusing the decision supports from base classifiers via a decision fusion method. To improve the generalization of our hybrid fusion network, a similarity loss is employed to inject decision diversity into the whole model. Empirical results on multimodal datasets have demonstrated the proposed model achieves a higher accuracy and better generalization compared with baselines for multimodal sentiment analysis.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4319317266",
    "type": "article"
  },
  {
    "title": "Reinforced PU-learning with Hybrid Negative Sampling Strategies for Recommendation",
    "doi": "https://doi.org/10.1145/3582562",
    "publication_date": "2023-02-07",
    "publication_year": 2023,
    "authors": "Wun-Ting Yang; Chiao-Ting Chen; Chuan-Yun Sang; Szu-Hao Huang",
    "corresponding_authors": "",
    "abstract": "The data of recommendation systems typically only contain the purchased item as positive data and other un-purchased items as unlabeled data. To train a good recommendation model, in addition to the known positive information, we also need high-quality negative information. Capturing negative signals in positive and unlabeled data is challenging for recommendation systems. Most studies have used specific data and proposed negative sampling methods suitable to the data characteristics. Existing negative sampling strategies cannot automatically select suitable approaches for different data. However, this one-size-fits-all strategy often makes potential positive samples considered as negative, or truly negative samples considered as potential positive samples and recommend to users. In this way, it will not only turn down the recommendation result, but even also have an adverse effect. Accordingly, we propose a novel negative sampling model, Reinforced PU-learning with Hybrid Negative Sampling Strategies for Recommendation (RHNSR), which can combine multiple sampling strategies and dynamically adjust the proportions used by different sampling strategies. In addition, ensemble learning, which integrates various model sampling strategies for obtaining an improved solution, was applied to RHNSR. Extensive experiments were conducted on three real-world recommendation datasets, and the experimental results indicated that the proposed model significantly outperformed state-of-the-art baseline models and revealed significant improvements in precision and hit ratio (49.02% and 37.41%, respectively).",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4319349004",
    "type": "article"
  },
  {
    "title": "Configure Your Federation: Hierarchical Attention-enhanced Meta-Learning Network for Personalized Federated Learning",
    "doi": "https://doi.org/10.1145/3591362",
    "publication_date": "2023-04-21",
    "publication_year": 2023,
    "authors": "Yujia Gao; Pengfei Wang; Liang Liu; Chi Zhang; Huadóng Ma",
    "corresponding_authors": "",
    "abstract": "Federated learning, as a distributed machine learning framework, enables clients to conduct model training without transmitting their data to the server, which is used to solve the dilemma of data silos and data privacy. It can work well on clients having similar data characteristics and distribution. However, it has some limitations where the dataset of clients may be different in distribution, quantity, and concept in many application scenarios. Personalized federated learning is a new federated learning paradigm that aims to guarantee client personalized models’ effectiveness when collaborating with the cloud server. Intuitively, providing further facilitated collaborations for the clients with similar data characteristics and distribution can benefit personalized model building. However, due to the invisibility of client data, it is challenging to extract client characteristics and define collaborative relationships among them from a fine-grained view. Moreover, a reasonable collaborative training approach needs to be designed for a distributed server–client framework. In this article, we design a Hierarchical Attention-enhanced Meta-learning Network (HAM) to address this issue. The main advantage of HAM is that it utilizes the meta-learning approach of taking model parameters as features and learns to learn an extra model for each client to analyze similarities according to their local dataset automatically. According to its two-layers framework, HAM can reasonably achieve a tradeoff between clients’ personality and commonality and provides a hybrid model with useful information from all clients. Considering there are two networks (HAM and base network) that need to learn for each client during the federated training process, we then provide an alternative learning approach to train them in an end-to-end fashion. To further clarify the approach, we describe the personalized federated learning settings framework as FedHAM where the HAM network is distributed deployed in each client. Extensive experiments based on two datasets prove that our method outperforms state-of-the-art baselines under different evaluation metrics.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4366683281",
    "type": "article"
  },
  {
    "title": "Qrowdsmith: Enhancing Paid Microtask Crowdsourcing with Gamification and Furtherance Incentives",
    "doi": "https://doi.org/10.1145/3604940",
    "publication_date": "2023-06-22",
    "publication_year": 2023,
    "authors": "Eddy Maddalena; Luis Ibáñez; Neal Reeves; Elena Simperl",
    "corresponding_authors": "",
    "abstract": "Microtask crowdsourcing platforms are social intelligence systems in which volunteers, called crowdworkers, complete small, repetitive tasks in return for a small fee. Beyond payments, task requesters are considering non-monetary incentives such as points, badges, and other gamified elements to increase performance and improve crowdworker experience. In this article, we present Qrowdsmith, a platform for gamifying microtask crowdsourcing. To design the system, we explore empirically a range of gamified and financial incentives and analyse their impact on how efficient, effective, and reliable the results are. To maintain participation over time and save costs, we propose furtherance incentives, which are offered to crowdworkers to encourage additional contributions in addition to the fee agreed upfront. In a series of controlled experiments, we find that while gamification can work as furtherance incentives, it impacts negatively on crowdworkers’ performance, both in terms of the quantity and quality of work, as compared to a baseline where they can continue to contribute voluntarily. Gamified incentives are also less effective than paid bonus equivalents. Our results contribute to the understanding of how best to encourage engagement in microtask crowdsourcing activities and design better crowd intelligence systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4381486056",
    "type": "article"
  },
  {
    "title": "The Privacy Issue of Counterfactual Explanations: Explanation Linkage Attacks",
    "doi": "https://doi.org/10.1145/3608482",
    "publication_date": "2023-07-11",
    "publication_year": 2023,
    "authors": "Sofie Goethals; Kenneth Sörensen; David Martens",
    "corresponding_authors": "",
    "abstract": "Black-box machine learning models are used in an increasing number of high-stakes domains, and this creates a growing need for Explainable AI (XAI). However, the use of XAI in machine learning introduces privacy risks, which currently remain largely unnoticed. Therefore, we explore the possibility of an explanation linkage attack , which can occur when deploying instance-based strategies to find counterfactual explanations. To counter such an attack, we propose k -anonymous counterfactual explanations and introduce pureness as a metric to evaluate the validity of these k -anonymous counterfactual explanations. Our results show that making the explanations, rather than the whole dataset, k -anonymous, is beneficial for the quality of the explanations.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4383906905",
    "type": "article"
  },
  {
    "title": "Labeling Chaos to Learning Harmony: Federated Learning with Noisy Labels",
    "doi": "https://doi.org/10.1145/3626242",
    "publication_date": "2023-10-09",
    "publication_year": 2023,
    "authors": "Vasileios Tsouvalas; Aaqib Saeed; Tanır Özçelebi; Nirvana Meratnia",
    "corresponding_authors": "",
    "abstract": "Federated Learning (FL) is a distributed machine learning paradigm that enables learning models from decentralized private datasets where the labeling effort is entrusted to the clients. While most existing FL approaches assume high-quality labels are readily available on users’ devices, in reality, label noise can naturally occur in FL and is closely related to clients’ characteristics. Due to scarcity of available data and significant label noise variations among clients in FL, existing state-of-the-art centralized approaches exhibit unsatisfactory performance, whereas prior FL studies rely on excessive on-device computational schemes or additional clean data available on the server. We propose FedLN , a framework to deal with label noise across different FL training stages, namely FL initialization, on-device model training, and server model aggregation, able to accommodate the diverse computational capabilities of devices in an FL system. Specifically, FedLN computes per-client noise level estimation in a single federated round and improves the models’ performance by either correcting or mitigating the effect of noisy samples. Our evaluation on various publicly available vision and audio datasets demonstrates a 22% improvement on average compared to other existing methods for a label noise level of 60%. We further validate the efficiency of FedLN in human-annotated real-world noisy datasets and report a 4.8% increase on average in models’ recognition performance, highlighting that FedLN can be useful for improving FL services provided to everyday users.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4387460392",
    "type": "article"
  },
  {
    "title": "Fairness-Driven Private Collaborative Machine Learning",
    "doi": "https://doi.org/10.1145/3639368",
    "publication_date": "2024-01-02",
    "publication_year": 2024,
    "authors": "Dana Pessach; Tamir Tassa; Erez Shmueli",
    "corresponding_authors": "",
    "abstract": "The performance of machine learning algorithms can be considerably improved when trained over larger datasets. In many domains, such as medicine and finance, larger datasets can be obtained if several parties, each having access to limited amounts of data, collaborate and share their data. However, such data sharing introduces significant privacy challenges. While multiple recent studies have investigated methods for private collaborative machine learning, the fairness of such collaborative algorithms was overlooked. In this work we suggest a feasible privacy-preserving pre-process mechanism for enhancing fairness of collaborative machine learning algorithms. Our experimentation with the proposed method shows that it is able to enhance fairness considerably with only a minor compromise in accuracy.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3201690998",
    "type": "article"
  },
  {
    "title": "Overcoming Diverse Undesired Effects in Recommender Systems: A Deontological Approach",
    "doi": "https://doi.org/10.1145/3643857",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Paula Gómez Duran; Pere Gilabert; Santi Seguí; Jordi Vitrià",
    "corresponding_authors": "",
    "abstract": "In today’s digital landscape, recommender systems have gained ubiquity as a means of directing users toward personalized products, services, and content. However, despite their widespread adoption and a long track of research, these systems are not immune to shortcomings. A significant challenge faced by recommender systems is the presence of biases, which produces various undesirable effects, prominently the popularity bias. This bias hampers the diversity of recommended items, thus restricting users’ exposure to less popular or niche content. Furthermore, this issue is compounded when multiple stakeholders are considered, requiring the balance of multiple, potentially conflicting objectives. In this article, we present a new approach to address a wide range of undesired consequences in recommender systems that involve various stakeholders. Instead of adopting a consequentialist perspective that aims to mitigate the repercussions of a recommendation policy, we propose a deontological approach centered around a minimal set of ethical principles. More precisely, we introduce two distinct principles aimed at avoiding overconfidence in predictions and accurately modeling the genuine interests of users. The proposed approach circumvents the need for defining a multi-objective system, which has been identified as one of the main limitations when developing complex recommenders. Through extensive experimentation, we show the efficacy of our approach in mitigating the adverse impact of the recommender from both user and item perspectives, ultimately enhancing various beyond accuracy metrics. This study underscores the significance of responsible and equitable recommendations and proposes a strategy that can be easily deployed in real-world scenarios.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4391448911",
    "type": "article"
  },
  {
    "title": "CACTUS: A Comprehensive Abstraction and Classification Tool for Uncovering Structures",
    "doi": "https://doi.org/10.1145/3649459",
    "publication_date": "2024-02-27",
    "publication_year": 2024,
    "authors": "Luca Gherardini; Varun Ravi Varma; Karol Capała; Roger Woods; José Sousa",
    "corresponding_authors": "",
    "abstract": "The availability of large datasets is providing the impetus for driving many current artificial intelligent developments. However, specific challenges arise in developing solutions that exploit small datasets, mainly due to practical and cost-effective deployment issues, as well as the opacity of deep learning models. To address this, the Comprehensive Abstraction and Classification Tool for Uncovering Structures (CACTUS) is presented as a means of improving secure analytics by effectively employing explainable artificial intelligence. CACTUS achieves this by providing additional support for categorical attributes, preserving their original meaning, optimising memory usage, and speeding up the computation through parallelisation. It exposes to the user the frequency of the attributes in each class and ranks them by their discriminative power. Performance is assessed by applying it to various domains, including Wisconsin Diagnostic Breast Cancer, Thyroid0387, Mushroom, Cleveland Heart Disease, and Adult Income datasets.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4392198876",
    "type": "article"
  },
  {
    "title": "Score-based Graph Learning for Urban Flow Prediction",
    "doi": "https://doi.org/10.1145/3655629",
    "publication_date": "2024-04-01",
    "publication_year": 2024,
    "authors": "Pengyu Wang; Xuechen Luo; Wenxin Tai; Kunpeng Zhang; Goce Trajcevsky; Fan Zhou",
    "corresponding_authors": "",
    "abstract": "Accurate urban flow prediction (UFP) is crucial for a range of smart city applications such as traffic management, urban planning, and risk assessment. To capture the intrinsic characteristics of urban flow, recent efforts have utilized spatial and temporal graph neural networks to deal with the complex dependence between the traffic in adjacent areas. However, existing graph neural network based approaches suffer from several critical drawbacks, including improper graph representation of urban traffic data, lack of semantic correlation modeling among graph nodes, and coarse-grained exploitation of external factors. To address these issues, we propose DiffUFP , a novel probabilistic graph-based framework for UFP. DiffUFP consists of two key designs: (1) a semantic region dynamic extraction method that effectively captures the underlying traffic network topology, and (2) a conditional denoising score-based adjacency matrix generator that takes spatial, temporal, and external factors into account when constructing the adjacency matrix rather than simply concatenation in existing studies. Extensive experiments conducted on real-world datasets demonstrate the superiority of DiffUFP over the state-of-the-art UFP models and the effect of the two specific modules.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4393387678",
    "type": "article"
  },
  {
    "title": "A Federated Social Recommendation Approach with Enhanced Hypergraph Neural Network",
    "doi": "https://doi.org/10.1145/3665931",
    "publication_date": "2024-05-25",
    "publication_year": 2024,
    "authors": "Hongliang Sun; Zhiying Tu; Dianbo Sui; Bolin Zhang; Xiaofei Xu",
    "corresponding_authors": "",
    "abstract": "In recent years, the development of online social network platforms has led to increased research efforts in social recommendation systems. Unlike traditional recommendation systems, social recommendation systems utilize both user-item interactions and user-user social relations to recommend relevant items, taking into account social homophily and social influence. Graph neural network (GNN)-based social recommendation methods have been proposed to model these item interactions and social relations effectively. However, existing GNN-based methods rely on centralized training, which raises privacy concerns and faces challenges in data collection due to regulations and privacy restrictions. Federated learning has emerged as a privacy-preserving alternative. Combining federated learning with GNN-based methods for social recommendation can leverage their respective advantages, but it also introduces new challenges: (1) existing federated recommendation systems often lack the capability to process heterogeneous data, such as user-item interactions and social relations; (2) due to the sparsity of data distributed across different clients, capturing the higher-order relationship information among users becomes challenging and is often overlooked by most federated recommendation systems. To overcome these challenges, we propose a federated social recommendation approach with enhanced hypergraph neural network (HGNN). We introduce HGNN to learn user and item embeddings in federated recommendation systems, leveraging the hypergraph structure to address the heterogeneity of data. Based on carefully crafted triangular motifs, we merge user and item nodes to construct hypergraphs on local clients, capturing specific triangular relations. Multiple HGNN channels are used to encode different categories of high-order relations, and an attention mechanism is applied to aggregate the embedded information from these channels. Our experiments on real-world social recommendation datasets demonstrate the effectiveness of the proposed approach. Extensive experiment results on three publicly available datasets validate the effectiveness of the proposed method.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399019044",
    "type": "article"
  },
  {
    "title": "Beyond Text: Multimodal Credibility Assessment Approaches for Online User-Generated Content",
    "doi": "https://doi.org/10.1145/3673236",
    "publication_date": "2024-06-14",
    "publication_year": 2024,
    "authors": "Monika Choudhary; Satyendra Singh Chouhan; Santosh Singh Rathore",
    "corresponding_authors": "",
    "abstract": "User-Generated Content (UGC) is increasingly becoming prevalent on various digital platforms. The content generated on social media, review forums, and question-answer platforms impacts a larger audience and influences their political, social, and other cognitive abilities. Traditional credibility assessment mechanisms involve assessing the credibility of the source and the text. However, with the increase in how user content can be generated and shared (audio, video, images), multimodal representation of User-Generated Content has become increasingly popular. This paper reviews the credibility assessment of UGC in various domains, particularly identifying fake news, suspicious profiles, and fake reviews and testimonials, focusing on both textual content and the source of the content creator. Next, the concept of multimodal credibility assessment is presented, which also includes audio, video, and images in addition to text. After that, the paper presents a systematic review and comprehensive analysis of work done in the credibility assessment of UGC considering multimodal features. Additionally, the paper provides extensive details on the publicly available multimodal datasets for the credibility assessment of UGC. In the end, the research gaps, challenges, and future directions in assessing the credibility of multimodal user-generated content are presented.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399671515",
    "type": "article"
  },
  {
    "title": "DESIGN: Online Device Selection and Edge Association for Federated Synergy Learning-enabled AIoT",
    "doi": "https://doi.org/10.1145/3673237",
    "publication_date": "2024-06-15",
    "publication_year": 2024,
    "authors": "Shucun Fu; Fang Dong; Dian Shen; Runze Chen; Jiangshan Hao",
    "corresponding_authors": "",
    "abstract": "The Artificial Intelligence of Things (AIoT) is an emerging technology that enables numerous AIoT devices to participate in big data analytics and machine learning (ML) model training, providing various customized intelligent services for industry manufacturing. Federated Learning (FL) empowers AIoT applications with privacy-preserving distributed model training without sharing raw data. However, due to IoT devices’ limited computing and memory resources, existing FL approaches for AIoT applications cannot support efficient large-scale model training. Federated synergy learning (FSyL) is a promising collaborative paradigm that alleviates the computation and communication overhead on resource-constrained AIoT devices via offloading part of the ML model to the edge server for end-to-edge collaborative training. Existing FSyL works neither efficiently address the inter-round device selection to improve model diversity nor determine the intra-round edge association to reduce the training cost, which hinders the applications of FSyL-enable AIoT. Motivated by this issue, this paper first investigates the bottlenecks of executing FSyL in AIoT. It builds an optimization model of joint inter-round device selection and intra-round edge association for balancing model diversity and training cost. To tackle the intractable coupling problem, we present a framework named Online DE vice S elect I on and Ed G e Associatio N for Cost-Diversity Trade-offs FSyL (DESIGN). First, the edge association subproblem is extracted from the original problem, and game theory determines the optimal association decision for an arbitrary device selection. Then, based on the optimal association decision, device selection is modeled as a combinatorial multi-armed bandit (CMAB) problem. Finally, we propose an online mechanism to obtain joint device selection and edge association decisions. The performance of DESIGN is theoretically analyzed and experimentally evaluated on real-world datasets. The results show that DESIGN can achieve up to \\(84.3\\%\\) in cost-saving with an accuracy improvement of \\(23.6\\%\\) compared with the state-of-the-art.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399701987",
    "type": "article"
  },
  {
    "title": "A Unified Framework for Analyzing Textual Context and Intent in Social Media",
    "doi": "https://doi.org/10.1145/3682064",
    "publication_date": "2024-07-29",
    "publication_year": 2024,
    "authors": "Jothi Prakash; S. Arul Antran Vijay",
    "corresponding_authors": "",
    "abstract": "In the realm of natural language processing, tasks like emotion recognition, irony detection, hate speech detection, offensive language identification, and stance detection are pivotal for understanding user-generated content. While several task-specific and multitask learning models have been proposed, there remains a need for a unified framework that can effectively address these tasks simultaneously. This research introduces a novel unified framework designed to tackle multiple NLP tasks concurrently, aiming to outperform existing task-specific and multitask models in terms of accuracy, F1-score, and AUC-ROC. We compared our proposed framework against several baseline models, including task-specific models like SVM, RF, LSTM, CNN, and BERT, as well as multitask learning frameworks such as Hard Parameter Sharing, Soft Parameter Sharing, Cross-stitch Networks, MMoE, and T5. The performance was evaluated across various tasks, and statistical significance was assessed using the Wilcoxon signed-rank test. Additionally, an ablation study was conducted to determine the contribution of individual components within our proposed method. The proposed framework consistently outperformed other models across all tasks. For instance, in emotion recognition, our model achieved an accuracy of 0.899, F1-score of 0.883, and AUC-ROC of 0.971, surpassing all baseline models. The Wilcoxon signed-rank test further confirmed the statistical superiority of our model over the baselines across all datasets.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4401079252",
    "type": "article"
  },
  {
    "title": "Exploring Dataset Bias and Scaling Techniques in Multi-Source Gait Biomechanics: An Explainable Machine Learning Approach",
    "doi": "https://doi.org/10.1145/3702646",
    "publication_date": "2024-11-11",
    "publication_year": 2024,
    "authors": "Sophie Fleischmann; Severine Dietz; Julian Shanbhag; Annika Wuensch; Marlies Nitschke; Jörg Miehling; Sandro Wartzack; Sigrid Leyendecker; Bjoern M. Eskofier; Anne D. Koelewijn",
    "corresponding_authors": "",
    "abstract": "Machine learning has become increasingly important in biomechanics. It allows to unveil hidden patterns from large and complex data, which leads to a more comprehensive understanding of biomechanical processes and deeper insights into human movement. However, machine learning models are often trained on a single dataset with a limited number of participants, which negatively affects their robustness and generalizability. Combining data from multiple existing sources provides an opportunity to overcome these limitations without spending more time on recruiting participants and recording new data. It is furthermore an opportunity for researchers who lack the financial requirements or laboratory equipment to conduct expensive motion capture studies themselves. At the same time, subtle interlaboratory differences can be problematic in an analysis, due to the bias that they introduce. In our study, we investigated differences in motion capture datasets in the context of machine learning, for which we combined overground walking trials from four existing studies. Specifically, our goal was to examine whether a machine learning model was able to predict the original data source based on marker and GRF trajectories of single strides, and how different scaling methods and pooling procedures affected the outcome. Layer-wise relevance propagation was applied to understand which factors were influential to distinguish the original data sources. We found that the model could predict the original data source with a very high accuracy (up to &gt;99%), which decreased by about 15 percentage points when we scaled every dataset individually prior to pooling. However, none of the proposed scaling methods could fully remove the dataset bias. Layer-wise relevance propagation revealed that there was not only one single factor that differed between all datasets. Instead, every dataset had its unique characteristics that were picked up by the model. These variables differed between the scaling and pooling approaches but were mostly consistent between trials belonging to the same dataset. Our results show that motion capture data is sensitive even to small deviations in marker placement and experimental setup and that small inter-group differences should not be overinterpreted during data analysis, especially when the data was collected in different labs. Furthermore, we recommend scaling datasets individually prior to pooling them which led to the lowest accuracy. We want to raise awareness that differences in datasets always exist and are recognizable by machine learning models. Researchers should thus think about how these differences might affect their results when combining data from different studies.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4404228296",
    "type": "article"
  },
  {
    "title": "GPT-4V(ision) as A Social Media Analysis Engine",
    "doi": "https://doi.org/10.1145/3709005",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Hanjia Lyu; Jinfa Huang; Daoan Zhang; Yongsheng Yu; Xinyi Mou; Jinsheng Pan; Zhengyuan Yang; Zhongyu Wei; Jiebo Luo",
    "corresponding_authors": "",
    "abstract": "Recent research has shed light on the capabilities of Large Multimodal Models (LMMs) across various general vision and language tasks. The performance of LMMs in specialized domains, such as social media, which integrates text, images, videos, and sometimes audio, remains an area of active interest. Effective analysis of such content requires models to interpret the complex interactions between different communication modalities and their influence on the conveyed message. This paper explores GPT-4V(ision)’s performance in social multimedia analysis. We evaluate GPT-4V across five representative tasks: sentiment analysis, hate speech detection, fake news identification, demographic inference, and political ideology detection. Our approach includes a preliminary quantitative analysis for each task using existing benchmark datasets, followed by a review of the results and a selection of qualitative samples to demonstrate GPT-4V’s performance in multimodal social media content analysis. GPT-4V shows effectiveness in these tasks, exhibiting capabilities like joint image-text understanding, contextual and cultural awareness, and commonsense knowledge application. However, challenges persist, including struggles with multilingual social multimedia comprehension and difficulty in adapting to the latest social media trends. It also sometimes generates incorrect information about evolving knowledge of celebrities and politicians. This preliminary study aims to inform further research across disciplines, particularly in computational social science and social media studies. The findings highlight the potential of LMMs to enhance our understanding of social media content and its users through multimodal analysis. All images and prompts used in this study will be available at https://github.com/VIStA-H/GPT-4V_Social_Media . Disclaimer: This paper contains some examples of offensive social media content. Reader discretion is advised.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4405566635",
    "type": "article"
  },
  {
    "title": "Multimodal Large Language Model with LoRA Fine-Tuning for Multimodal Sentiment Analysis",
    "doi": "https://doi.org/10.1145/3709147",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Jie Mu; Wei Wang; Wenqi Liu; Tiantian Yan; G. X. Wang",
    "corresponding_authors": "",
    "abstract": "Multimodal sentiment analysis has become a popular research topic in recent years. However, existing methods have two unaddressed limitations: (1) they use limited supervised labels to train models, which makes it impossible for model to fully learn sentiments in different modal data; (2) they employ text and image pre-trained models trained in different unimodal tasks to extract different modal features, so that the extracted features cannot take into account the interactive information between image and text. To solve these problems, in this paper we propose a Vision-Language Contrastive Learning network (VLCLNet). First, we introduce a pre-trained Large Language Model (LLM), which is trained from vast quantities of multimodal data, has better understanding ability for image and text contents, thus being effectively applied to different tasks while requiring few amount of labelled training data. Second, we adapt a Multimodal Large Language Model (MLLM), BLIP-2 (Bootstrapping Language-Image Pre-training) network, to extract multimodal fusion feature. Such MLLM can fully consider the correlation between images and texts when extracting features. In addition, due to the discrepancy between the pre-training task and the sentiment analysis task, the pre-trained model will output the suboptimal prediction results. We use LoRA (Low-Rank Adaptation) fine-tuning strategy to update the model parameters on sentiment analysis task, which avoids the issue of inconsistent task between pre-training task and downstream task. Experiments verify that the proposed VLCLNet is superior to other strong baselines.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4405638128",
    "type": "article"
  },
  {
    "title": "Personalized reading support for second-language web documents",
    "doi": "https://doi.org/10.1145/2438653.2438666",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Yo Ehara; Nobuyuki Shimizu; Takashi Ninomiya; Hiroshi Nakagawa",
    "corresponding_authors": "",
    "abstract": "A novel intelligent interface eases the browsing of Web documents written in the second languages of users. It automatically predicts words unfamiliar to the user by a collective intelligence method and glosses them with their meaning in advance. If the prediction succeeds, the user does not need to consult a dictionary; even if it fails, the user can correct the prediction. The correction data are collected and used to improve the accuracy of further predictions. The prediction is personalized in that every user's language ability is estimated by a state-of-the-art language testing model, which is trained in a practical response time with only a small sacrifice of prediction accuracy. The system was evaluated in terms of prediction accuracy and reading simulation. The reading simulation results show that this system can reduce the number of clicks for most readers with insufficient vocabulary to read documents and can significantly reduce the remaining number of unfamiliar words after the prediction and glossing for all users.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1985672254",
    "type": "article"
  },
  {
    "title": "Watch the Story Unfold with TextWheel",
    "doi": "https://doi.org/10.1145/2089094.2089096",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Weiwei Cui; Huamin Qu; Hong Zhou; Wenbin Zhang; Steve Skiena",
    "corresponding_authors": "",
    "abstract": "Keyword-based searching and clustering of news articles have been widely used for news analysis. However, news articles usually have other attributes such as source, author, date and time, length, and sentiment which should be taken into account. In addition, news articles and keywords have complicated macro/micro relations, which include relations between news articles (i.e., macro relation), relations between keywords (i.e., micro relation), and relations between news articles and keywords (i.e., macro-micro relation). These macro/micro relations are time varying and pose special challenges for news analysis. In this article we present a visual analytics system for news streams which can bring multiple attributes of the news articles and the macro/micro relations between news streams and keywords into one coherent analytical context, all the while conveying the dynamic natures of news streams. We introduce a new visualization primitive called TextWheel which consists of one or multiple keyword wheels, a document transportation belt, and a dynamic system which connects the wheels and belt. By observing the TextWheel and its content changes, some interesting patterns can be detected. We use our system to analyze several news corpora related to some major companies and the results demonstrate the high potential of our method.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2067528438",
    "type": "article"
  },
  {
    "title": "DClusterE",
    "doi": "https://doi.org/10.1145/2089094.2089100",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Yi Zhang; Tao Li",
    "corresponding_authors": "",
    "abstract": "Over the last decade, document clustering, as one of the key tasks in information organization and navigation, has been widely studied. Many algorithms have been developed for addressing various challenges in document clustering and for improving clustering performance. However, relatively few research efforts have been reported on evaluating and understanding document clustering results. In this article, we present DClusterE , a comprehensive and effective framework for document clustering evaluation and understanding using information visualization. DClusterE integrates cluster validation with user interactions and offers rich visualization tools for users to examine document clustering results from multiple perspectives. In particular, through informative views including force-directed layout view, matrix view, and cluster view, DClusterE provides not only different aspects of document inter/intra-clustering structures, but also the corresponding relationship between clustering results and the ground truth. Additionally, DClusterE supports general user interactions such as zoom in/out, browsing, and interactive access of the documents at different levels. Two new techniques are proposed to implement DClusterE : (1) A novel multiplicative update algorithm (MUA) for matrix reordering to generate narrow-banded (or clustered) nonzero patterns from documents. Combined with coarse seriation, MUA is able to provide better visualization of the cluster structures. (2) A Mallows-distance-based algorithm for establishing the relationship between the clustering results and the ground truth, which serves as the basis for coloring schemes. Experiments and user studies are conducted to demonstrate the effectiveness and efficiency of DClusterE .",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2115096331",
    "type": "article"
  },
  {
    "title": "Distance metric learning from uncertain side information for automated photo tagging",
    "doi": "https://doi.org/10.1145/1899412.1899417",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Lei Wu; Steven C. H. Hoi; Rong Jin; Jianke Zhu; Nenghai Yu",
    "corresponding_authors": "",
    "abstract": "Automated photo tagging is an important technique for many intelligent multimedia information systems, for example, smart photo management system and intelligent digital media library. To attack the challenge, several machine learning techniques have been developed and applied for automated photo tagging. For example, supervised learning techniques have been applied to automated photo tagging by training statistical classifiers from a collection of manually labeled examples. Although the existing approaches work well for small testbeds with relatively small number of annotation words, due to the long-standing challenge of object recognition, they often perform poorly in large-scale problems. Another limitation of the existing approaches is that they require a set of high-quality labeled data, which is not only expensive to collect but also time consuming. In this article, we investigate a social image based annotation scheme by exploiting implicit side information that is available for a large number of social photos from the social web sites. The key challenge of our intelligent annotation scheme is how to learn an effective distance metric based on implicit side information (visual or textual) of social photos. To this end, we present a novel “Probabilistic Distance Metric Learning” (PDML) framework, which can learn optimized metrics by effectively exploiting the implicit side information vastly available on the social web. We apply the proposed technique to photo annotation tasks based on a large social image testbed with over 1 million tagged photos crawled from a social photo sharing portal. Encouraging results show that the proposed technique is effective and promising for social photo based annotation tasks.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2124192166",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on intelligent systems for socially aware computing",
    "doi": "https://doi.org/10.1145/2483669.2483678",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Zhiwen Yu; Daqing Zhang; Nathan Eagle; Diane J. Cook",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the special section on intelligent systems for socially aware computing Authors: Zhiwen Yu Northwestern Polytechnical University, China Northwestern Polytechnical University, ChinaView Profile , Daqing Zhang Institute Telecom and Management SudPans, France Institute Telecom and Management SudPans, FranceView Profile , Nathan Eagle Media Lab, MIT, USA Media Lab, MIT, USAView Profile , Diane Cook Washington State University, USA Washington State University, USAView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 4Issue 3Article No.: 45pp 1–3https://doi.org/10.1145/2483669.2483678Published:01 July 2013Publication History 25citation183DownloadsMetricsTotal Citations25Total Downloads183Last 12 Months1Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1996528178",
    "type": "article"
  },
  {
    "title": "Dynamic Landmarking for Surface Feature Identification and Change Detection",
    "doi": "https://doi.org/10.1145/2168752.2168763",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Kiri L. Wagstaff; Julian Panetta; Adnan Ansar; R. Greeley; M. Pendleton Hoffer; M. K. Bunte; Norbert Schörghofer",
    "corresponding_authors": "",
    "abstract": "Given the large volume of images being sent back from remote spacecraft, there is a need for automated analysis techniques that can quickly identify interesting features in those images. Feature identification in individual images and automated change detection in multiple images of the same target are valuable for scientific studies and can inform subsequent target selection. We introduce a new approach to orbital image analysis called dynamic landmarking. It focuses on the identification and comparison of visually salient features in images. We have evaluated this approach on images collected by five Mars orbiters. These evaluations were motivated by three scientific goals: to study fresh impact craters, dust devil tracks, and dark slope streaks on Mars. In the process we also detected a different kind of surface change that may indicate seasonally exposed bedforms. These experiences also point the way to how this approach could be used in an onboard setting to analyze and prioritize data as it is collected.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2014849320",
    "type": "article"
  },
  {
    "title": "Activity Recognition for Dynamic Multi-Agent Teams",
    "doi": "https://doi.org/10.1145/2036264.2036282",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Gita Sukthankar; Katia Sycara",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of activity recognition for dynamic, physically embodied agent teams. We define team activity recognition as the process of identifying team behaviors from traces of agent positions over time; for many physical domains, military or athletic, coordinated team behaviors create distinctive spatio-temporal patterns that can be used to identify low-level action sequences. This article focuses on the novel problem of recovering agent-to-team assignments for complex team tasks where team composition, the mapping of agents into teams, changes over time. We suggest two methods for improving the computational efficiency of the multi-agent plan recognition process in these cases of changing team composition; our proposed approach is robust to sensor observation noise and errors in behavior classification.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2018363352",
    "type": "article"
  },
  {
    "title": "LONET",
    "doi": "https://doi.org/10.1145/2438653.2438665",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Neil Y. Yen; Timothy K. Shih; Qun Jin",
    "corresponding_authors": "",
    "abstract": "Sharing resources and information on the Internet has become an important activity for education. In distance learning, instructors can benefit from resources, also known as Learning Objects (LOs), to create plenteous materials for specific learning purposes. Our repository (called the MINE Registry) has been developed for storing and sharing learning objects, around 22,000 in total, in the past few years. To enhance reusability, one significant concept named Reusability Tree was implemented to trace the process of changes. Also, weighting and ranking metrics have been proposed to enhance the searchability in the repository. Following the successful implementation, this study goes further to investigate the relationships between LOs from a perspective of social networks. The LONET (Learning Object Network), as an extension of Reusability Tree, is newly proposed and constructed to clarify the vague reuse scenario in the past, and to summarize collaborative intelligence through past interactive usage experiences. We define a social structure in our repository based on past usage experiences from instructors, by proposing a set of metrics to evaluate the interdependency such as prerequisites and references. The structure identifies usage experiences and can be graphed in terms of implicit and explicit relations among learning objects. As a practical contribution, an adaptive algorithm is proposed to mine the social structure in our repository. The algorithm generates adaptive routes, based on past usage experiences, by computing possible interactive input, such as search criteria and feedback from instructors, and assists them in generating specific lectures.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2005577215",
    "type": "article"
  },
  {
    "title": "Mining Check-In History for Personalized Location Naming",
    "doi": "https://doi.org/10.1145/2490890",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Defu Lian; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Many innovative location-based services have been established to offer users greater convenience in their everyday lives. These services usually cannot map user's physical locations into semantic names automatically. The semantic names of locations provide important context for mobile recommendations and advertisements. In this article, we proposed a novel location naming approach which can automatically provide semantic names for users given their locations and time. In particular, when a user opens a GPS device and submits a query with her physical location and time, she will be returned the most appropriate semantic name. In our approach, we drew an analogy between location naming and local search, and designed a local search framework to propose a spatiotemporal and user preference (STUP) model for location naming. STUP combined three components, user preference (UP), spatial preference (SP), and temporal preference (TP), by leveraging learning-to-rank techniques. We evaluated STUP on 466,190 check-ins of 5,805 users from Shanghai and 135,052 check-ins of 1,361 users from Beijing. The results showed that SP was most effective among three components and that UP can provide personalized semantic names, and thus it was a necessity for location naming. Although TP was not as discriminative as the others, it can still be beneficial when integrated with SP and UP. Finally, according to the experimental results, STUP outperformed the proposed baselines and returned accurate semantic names for 23.6% and 26.6% of the testing queries from Beijing and Shanghai, respectively.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2029550988",
    "type": "article"
  },
  {
    "title": "Kinect Depth Recovery Using a Color-Guided, Region-Adaptive, and Depth-Selective Framework",
    "doi": "https://doi.org/10.1145/2700475",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Chongyu Chen; Jianfei Cai; Jianmin Zheng; Tat‐Jen Cham; Guangming Shi",
    "corresponding_authors": "",
    "abstract": "Considering that the existing depth recovery approaches have different limitations when applied to Kinect depth data, in this article, we propose to integrate their effective features including adaptive support region selection, reliable depth selection, and color guidance together under an optimization framework for Kinect depth recovery. In particular, we formulate our depth recovery as an energy minimization problem, which solves the depth hole filling and denoising simultaneously. The energy function consists of a fidelity term and a regularization term, which are designed according to the Kinect characteristics. Our framework inherits and improves the idea of guided filtering by incorporating structure information and prior knowledge of the Kinect noise model. Through analyzing the solution to the optimization framework, we also derive a local filtering version that provides an efficient and effective way of improving the existing filtering techniques. Quantitative evaluations on our developed synthesized dataset and experiments on real Kinect data show that the proposed method achieves superior performance in terms of recovery accuracy and visual quality.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2079920317",
    "type": "article"
  },
  {
    "title": "S-SMART",
    "doi": "https://doi.org/10.1145/2824286",
    "publication_date": "2016-02-11",
    "publication_year": 2016,
    "authors": "Michael Hardegger; Daniel Roggen; Alberto Calatroni; Gerhard Tröster",
    "corresponding_authors": "",
    "abstract": "The machine recognition of user trajectories and activities is fundamental to devise context-aware applications for support and monitoring in daily life. So far, tracking and activity recognition were mostly considered as orthogonal problems, which limits the richness of possible context inference. In this work, we introduce the novel unified computational and representational framework S-SMART that simultaneously models the environment state (semantic mapping), localizes the user within this map (tracking), and recognizes interactions with the environment (activity recognition). Thus, S-SMART identifies which activities the user executes where (e.g., turning a handle next to a window ), and reflects the outcome of these actions by updating the world model (e.g., the window is now open ). This in turn conditions the future possibility of executing actions at specific places (e.g., closing the window is likely to be the next action at this location). S-SMART works in a self-contained manner and iteratively builds the semantic map from wearable sensors only. This enables the seamless deployment to new environments. We characterize S-SMART in an experimental dataset with people performing hand actions as part of their usual routines at home and in office buildings. The framework combines dead reckoning from a foot-worn motion sensor with template-matching-based action recognition, identifying objects in the environment (windows, doors, water taps, phones, etc.) and tracking their state (open/closed, etc.). In real-life recordings with up to 23 action classes, S-SMART consistently outperforms independent systems for positioning and activity recognition, and constructs accurate semantic maps. This environment representation enables novel applications that build upon information about the arrangement and state of the user’s surroundings. For example, it may be possible to remind elderly people of a window that they left open before leaving the house, or of a plant they did not water yet, using solely wearable sensors.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2173276285",
    "type": "article"
  },
  {
    "title": "A Joyful Ode to Automatic Orchestration",
    "doi": "https://doi.org/10.1145/2897738",
    "publication_date": "2016-10-03",
    "publication_year": 2016,
    "authors": "François Pachet",
    "corresponding_authors": "François Pachet",
    "abstract": "Most works in automatic music generation have addressed so far specific tasks. Such a reductionist approach has been extremely successful and some of these tasks have been solved once and for all. However, few works have addressed the issue of generating automatically fully fledged music material, of human-level quality. In this article, we report on a specific experiment in holistic music generation: the reorchestration of Beethoven’s Ode to Joy , the European anthem, in seven styles. These reorchestrations were produced with algorithms developed in the Flow Machines project and within a short time frame. We stress the benefits of having had such a challenging and unifying goal, and the interesting problems and challenges it raised along the way.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2527926565",
    "type": "article"
  },
  {
    "title": "Sparse Passive-Aggressive Learning for Bounded Online Kernel Methods",
    "doi": "https://doi.org/10.1145/3156684",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Jing Lu; Doyen Sahoo; Peilin Zhao; Steven C. H. Hoi",
    "corresponding_authors": "",
    "abstract": "One critical deficiency of traditional online kernel learning methods is their unbounded and growing number of support vectors in the online learning process, making them inefficient and non-scalable for large-scale applications. Recent studies on scalable online kernel learning have attempted to overcome this shortcoming, e.g., by imposing a constant budget on the number of support vectors. Although they attempt to bound the number of support vectors at each online learning iteration, most of them fail to bound the number of support vectors for the final output hypothesis, which is often obtained by averaging the series of hypotheses over all the iterations. In this article, we propose a novel framework for bounded online kernel methods, named “Sparse Passive-Aggressive (SPA)” learning, which is able to yield a final output kernel-based hypothesis with a bounded number of support vectors. Unlike the common budget maintenance strategy used by many existing budget online kernel learning approaches, the idea of our approach is to attain the bounded number of support vectors using an efficient stochastic sampling strategy that samples an incoming training example as a new support vector with a probability proportional to its loss suffered. We theoretically prove that SPA achieves an optimal mistake bound in expectation, and we empirically show that it outperforms various budget online kernel learning algorithms. Finally, in addition to general online kernel learning tasks, we also apply SPA to derive bounded online multiple-kernel learning algorithms, which can significantly improve the scalability of traditional Online Multiple-Kernel Classification (OMKC) algorithms while achieving satisfactory learning accuracy as compared with the existing unbounded OMKC algorithms.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2791769216",
    "type": "article"
  },
  {
    "title": "Adaptive Online One-Class Support Vector Machines with Applications in Structural Health Monitoring",
    "doi": "https://doi.org/10.1145/3230708",
    "publication_date": "2018-11-13",
    "publication_year": 2018,
    "authors": "Ali Anaissi; Nguyen Lu Dang Khoa; Thierry Rakotoarivelo; Mehrisadat Makki Alamdari; Yang Wang",
    "corresponding_authors": "",
    "abstract": "One-class support vector machine (OCSVM) has been widely used in the area of structural health monitoring, where only data from one class (i.e., healthy) are available. Incremental learning of OCSVM is critical for online applications in which huge data streams continuously arrive and the healthy data distribution may vary over time. This article proposes a novel adaptive self-advised online OCSVM that incrementally tunes the kernel parameter and decides whether a model update is required or not. As opposed to existing methods, this novel online algorithm does not rely on any fixed threshold, but it uses the slack variables in the OCSVM to determine which new data points should be included in the training set and trigger a model update. The algorithm also incrementally tunes the kernel parameter of OCSVM automatically based on the spatial locations of the edge and interior samples in the training data with respect to the constructed hyperplane of OCSVM. This new online OCSVM algorithm was extensively evaluated using synthetic data and real data from case studies in structural health monitoring. The results showed that the proposed method significantly improved the classification error rates, was able to assimilate the changes in the positive data distribution over time, and maintained a high damage detection accuracy in all case studies.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2901168797",
    "type": "article"
  },
  {
    "title": "RelationLines",
    "doi": "https://doi.org/10.1145/3200766",
    "publication_date": "2018-12-13",
    "publication_year": 2018,
    "authors": "Wei Chen; Jing Xia; Xumeng Wang; Yì Wáng; Jun Chen; Liang Chang",
    "corresponding_authors": "",
    "abstract": "The increased accessibility of urban sensor data and the popularity of social network applications is enabling the discovery of crowd mobility and personal communication patterns. However, studying the egocentric relationships of an individual can be very challenging because available data may refer to direct contacts, such as phone calls between individuals, or indirect contacts, such as paired location presence. In this article, we develop methods to integrate three facets extracted from heterogeneous urban data (timelines, calls, and locations) through a progressive visual reasoning and inspection scheme. Our approach uses a detect-and-filter scheme such that, prior to visual refinement and analysis, a coarse detection is performed to extract the target individual and construct the timeline of the target. It then detects spatio-temporal co-occurrences or call-based contacts to develop the egocentric network of the individual. The filtering stage is enhanced with a line-based visual reasoning interface that facilitates a flexible and comprehensive investigation of egocentric relationships and connections in terms of time, space, and social networks. The integrated system, RelationLines, is demonstrated using a dataset that contains taxi GPS data, cell-base mobility data, mobile calling data, microblog data, and point-of-interest (POI) data from a city with millions of citizens. We examine the effectiveness and efficiency of our system with three case studies and user review.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2903663997",
    "type": "article"
  },
  {
    "title": "Goal and Plan Recognition Design for Plan Libraries",
    "doi": "https://doi.org/10.1145/3234464",
    "publication_date": "2019-01-23",
    "publication_year": 2019,
    "authors": "Reuth Mirsky; Kobi Gal; Roni Stern; Meir Kalech",
    "corresponding_authors": "",
    "abstract": "This article provides new techniques for optimizing domain design for goal and plan recognition using plan libraries. We define two new problems: Goal Recognition Design for Plan Libraries (GRD-PL) and Plan Recognition Design (PRD). Solving the GRD-PL helps to infer which goal the agent is trying to achieve, while solving PRD can help to infer how the agent is going to achieve its goal. For each problem, we define a worst-case distinctiveness measure that is an upper bound on the number of observations that are necessary to unambiguously recognize the agent’s goal or plan. This article studies the relationship between these measures, showing that the worst-case distinctiveness of GRD-PL is a lower bound of the worst-case plan distinctiveness of PRD and that they are equal under certain conditions. We provide two complete algorithms for minimizing the worst-case distinctiveness of plan libraries without reducing the agent’s ability to complete its goals: One is a brute-force search over all possible plans and one is a constraint-based search that identifies plans that are most difficult to distinguish in the domain. These algorithms are evaluated in three hierarchical plan recognition settings from the literature. We were able to reduce the worst-case distinctiveness of the domains using our approach, in some cases reaching 100% improvement within a predesignated time window. Our iterative algorithm outperforms the brute-force approach by an order of magnitude in terms of runtime.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2911569071",
    "type": "article"
  },
  {
    "title": "Charging and Storage Infrastructure Design for Electric Vehicles",
    "doi": "https://doi.org/10.1145/2513567",
    "publication_date": "2014-09-18",
    "publication_year": 2014,
    "authors": "Marjan Momtazpour; P. J. Butler; Naren Ramakrishnan; M. Shahriar Hossain; Mohammad Chehreghani Bozchalui; Ratnesh Sharma",
    "corresponding_authors": "",
    "abstract": "Ushered by recent developments in various areas of science and technology, modern energy systems are going to be an inevitable part of our societies. Smart grids are one of these modern systems that have attracted many research activities in recent years. Before utilizing the next generation of smart grids, we should have a comprehensive understanding of the interdependent energy networks and processes. Next-generation energy systems networks cannot be effectively designed, analyzed, and controlled in isolation from the social, economic, sensing, and control contexts in which they operate. In this article, we present a novel framework to support charging and storage infrastructure design for electric vehicles. We develop coordinated clustering techniques to work with network models of urban environments to aid in placement of charging stations for an electrical vehicle deployment scenario. Furthermore, we evaluate the network before and after the deployment of charging stations, to recommend the installation of appropriate storage units to overcome the extra load imposed on the network by the charging stations. We demonstrate the multiple factors that can be simultaneously leveraged in our framework to achieve practical urban deployment. Our ultimate goal is to help realize sustainable energy system management in urban electrical infrastructure by modeling and analyzing networks of interactions between electric systems and urban populations.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2154342740",
    "type": "article"
  },
  {
    "title": "Design of a Predictive Scheduling System to Improve Assisted Living Services for Elders",
    "doi": "https://doi.org/10.1145/2736700",
    "publication_date": "2015-07-24",
    "publication_year": 2015,
    "authors": "Valeria Soto-Mendoza; J. Antonio García‐Macías; Edgar Chávez; Ana I. Martínez-Garcia; Jesús Favela; Patricia Serrano-Alvarado; Maythé R. Zúñiga Rojas",
    "corresponding_authors": "",
    "abstract": "As the number of older adults increases, and with it the demand for dedicated care, geriatric residences face a shortage of caregivers, who themselves experience work overload, stress, and burden. We conducted a long-term field study in three geriatric residences to understand the work conditions of caregivers with the aim of developing technologies to assist them in their work and help them deal with their burdens. From this study, we obtained relevant requirements and insights to design, implement, and evaluate two prototypes for supporting caregivers’ tasks (e.g., electronic recording and automatic notifications) in order to validate the feasibility of their implementation in situ and their technical requirements. The evaluation in situ of the prototypes was conducted for a period of 4 weeks. The results of the evaluation, together with the data collected from 6 months of use, motivated the design of a predictive schedule, which was iteratively improved and evaluated in participative sessions with caregivers. PRESENCE, the predictive schedule we propose, triggers real-time alerts of risky situations (e.g., falls, entering off-limits areas such as the infirmary or the kitchen) and informs caregivers of routine tasks that need to be performed (e.g., medication administration, diaper change, etc.). Moreover, PRESENCE helps caregivers to record caring tasks (such as diaper changes or medication) and well-being assessments (such as the mood) that are difficult to automate. This facilitates caregiver's shift handover and can help to train new caregivers by suggesting routine tasks and by sending reminders and timely information about residents. It can be seen as a tool to reduce the workload of caregivers and medical staff. Instead of trying to substitute the caregiver with an automatic caring system, as proposed by others, we propose our predictive schedule system that blends caregiver assessments and measurements from sensors. We show the feasibility of predicting caregiver tasks and a formative evaluation with caregivers that provides preliminary evidence of its utility.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2276809822",
    "type": "article"
  },
  {
    "title": "Differential Flattening",
    "doi": "https://doi.org/10.1145/2898362",
    "publication_date": "2016-10-25",
    "publication_year": 2016,
    "authors": "Jungeun Kim; Jae-Gil Lee; Sungsu Lim",
    "corresponding_authors": "",
    "abstract": "A multi-layer graph consists of multiple layers of weighted graphs, where the multiple layers represent the different aspects of relationships. Considering multiple aspects (i.e., layers) together is essential to achieve a comprehensive and consolidated view. In this article, we propose a novel framework of differential flattening , which facilitates the analysis of multi-layer graphs, and apply this framework to community detection. Differential flattening merges multiple graphs into a single graph such that the graph structure with the maximum clustering coefficient is obtained from the single graph. It has two distinct features compared with existing approaches. First, dealing with multiple layers is done independently of a specific community detection algorithm, whereas previous approaches rely on a specific algorithm. Thus, any algorithm for a single graph becomes applicable to multi-layer graphs. Second, the contribution of each layer to the single graph is determined automatically for the maximum clustering coefficient. Since differential flattening is formulated by an optimization problem, the optimal solution is easily obtained by well-known algorithms such as interior point methods. Extensive experiments were conducted using the Lancichinetti-Fortunato-Radicchi (LFR) benchmark networks as well as the DBLP, 20 Newsgroups, and MIT Reality Mining networks. The results show that our approach of differential flattening leads to discovery of higher-quality communities than baseline approaches and the state-of-the-art algorithms.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2537105955",
    "type": "article"
  },
  {
    "title": "Deep Multi-scale Discriminative Networks for Double JPEG Compression Forensics",
    "doi": "https://doi.org/10.1145/3301274",
    "publication_date": "2019-02-15",
    "publication_year": 2019,
    "authors": "Cheng Deng; Zhao Li; Xinbo Gao; Dacheng Tao",
    "corresponding_authors": "",
    "abstract": "As JPEG is the most widely used image format, the importance of tampering detection for JPEG images in blind forensics is self-evident. In this area, extracting effective statistical characteristics from a JPEG image for classification remains a challenge. Effective features are designed manually in traditional methods, suggesting that extensive labor-consuming research and derivation is required. In this article, we propose a novel image tampering detection method based on deep multi-scale discriminative networks (MSD-Nets). The multi-scale module is designed to automatically extract multiple features from the discrete cosine transform (DCT) coefficient histograms of the JPEG image. This module can capture the characteristic information in different scale spaces. In addition, a discriminative module is also utilized to improve the detection effect of the networks in those difficult situations when the first compression quality ( QF 1) is higher than the second one ( QF 2). A special network in this module is designed to distinguish the small statistical difference between authentic and tampered regions in these cases. Finally, a probability map can be obtained and the specific tampering area is located using the last classification results. Extensive experiments demonstrate the superiority of our proposed method in both quantitative and qualitative metrics when compared with state-of-the-art approaches.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2963751765",
    "type": "article"
  },
  {
    "title": "Mediated Secure Multi-Party Protocols for Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3375402",
    "publication_date": "2020-02-24",
    "publication_year": 2020,
    "authors": "Erez Shmueli; Tamir Tassa",
    "corresponding_authors": "",
    "abstract": "Recommender systems have become extremely common in recent years and are utilized in a variety of domains such as movies, music, news, products, restaurants, and so on. While a typical recommender system bases its recommendations solely on users’ preference data collected by the system itself, the quality of recommendations can significantly be improved if several recommender systems (or vendors) share their data. However, such data sharing poses significant privacy and security challenges, both to the vendors and the users. In this article, we propose secure protocols for distributed item-based Collaborative Filtering. Our protocols allow to compute both the predicted ratings of items and their predicted rankings without compromising privacy nor predictions’ accuracy. Unlike previous solutions in which the secure protocols are executed solely by the vendors, our protocols assume the existence of a mediator that performs intermediate computations on encrypted data supplied by the vendors. Such a mediated setting is advantageous over the non-mediated one since it enables each vendor to communicate solely with the mediator. This yields reduced communication costs, and it allows each vendor to issue recommendations to its clients without being dependent on the availability and willingness of the other vendors to collaborate.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3010882570",
    "type": "article"
  },
  {
    "title": "Deep Neighborhood Component Analysis for Visual Similarity Modeling",
    "doi": "https://doi.org/10.1145/3375787",
    "publication_date": "2020-04-18",
    "publication_year": 2020,
    "authors": "Xueliang Liu; Xun Yang; Meng Wang; Richang Hong",
    "corresponding_authors": "",
    "abstract": "Learning effective visual similarity is an essential problem in multimedia research. Despite the promising progress made in recent years, most existing approaches learn visual features and similarities in two separate stages, which inevitably limits their performance. Once useful information has been lost in the feature extraction stage, it can hardly be recovered later. This article proposes a novel end-to-end approach for visual similarity modeling, called deep neighborhood component analysis , which discriminatively trains deep neural networks to jointly learn visual features and similarities. Specifically, we first formulate a metric learning objective that maximizes the intra-class correlations and minimizes the inter-class correlations under the neighborhood component analysis criterion, and then train deep convolutional neural networks to learn a nonlinear mapping that projects visual instances from original feature space to a discriminative and neighborhood-structure-preserving embedding space, thus resulting in better performance. We conducted extensive evaluations on several widely used and challenging datasets, and the impressive results demonstrate the effectiveness of our proposed approach.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3016436096",
    "type": "article"
  },
  {
    "title": "CNN-based Multiple Manipulation Detector Using Frequency Domain Features of Image Residuals",
    "doi": "https://doi.org/10.1145/3388634",
    "publication_date": "2020-05-31",
    "publication_year": 2020,
    "authors": "Divya Singhal; Abhinav Gupta; Anurag Tripathi; Ravi Kothari",
    "corresponding_authors": "",
    "abstract": "Increasingly sophisticated image editing tools make it easy to modify images. Often these modifications are elaborate, convincing, and undetectable by even careful human inspection. These considerations have prompted the development of forensic algorithms and approaches to detect modifications done to an image. However, these detectors are model-driven (i.e., manipulation-specific) and the choice of a potent detector requires knowledge of the type of manipulation, something that cannot be known ( a priori ). Thus, the latest effort is directed towards developing model-free (i.e., generalized) detectors capable of detecting multiple manipulation types. In this article, we propose a novel detector capable of exposing seven different manipulation types in low-resolution compressed images. Our proposed approach is based on a two-layer convolutional neural network (CNN) to extract frequency domain features of image median filtered residual that are classified using two different classifiers—softmax and extremely randomized trees. Extensive experiments demonstrate the efficacy of proposed detector over existing state-of-the-art detectors.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3090555730",
    "type": "article"
  },
  {
    "title": "Analyzing and Detecting Collusive Users Involved in Blackmarket Retweeting Activities",
    "doi": "https://doi.org/10.1145/3380537",
    "publication_date": "2020-04-18",
    "publication_year": 2020,
    "authors": "Udit Arora; Hridoy Sankar Dutta; Brihi Joshi; Aditya Chetan; Tanmoy Chakraborty",
    "corresponding_authors": "",
    "abstract": "With the rise in popularity of social media platforms like Twitter, having higher influence on these platforms has a greater value attached to it, since it has the power to influence many decisions in the form of brand promotions and shaping opinions. However, blackmarket services that allow users to inorganically gain influence are a threat to the credibility of these social networking platforms. Twitter users can gain inorganic appraisals in the form of likes, retweets, and follows through these blackmarket services either by paying for them or by joining syndicates wherein they gain such appraisals by providing similar appraisals to other users. These customers tend to exhibit a mix of organic and inorganic retweeting behavior, making it tougher to detect them. In this article, we investigate these blackmarket customers engaged in collusive retweeting activities. We collect and annotate a novel dataset containing various types of information about blackmarket customers and use these sources of information to construct multiple user representations. We adopt Weighted Generalized Canonical Correlation Analysis (WGCCA) to combine these individual representations to derive user embeddings that allow us to effectively classify users as: genuine users, bots, promotional customers, and normal customers. Our method significantly outperforms state-of-the-art approaches (32.95% better macro F1-score than the best baseline).",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3021508921",
    "type": "article"
  },
  {
    "title": "Aspect-Aware Response Generation for Multimodal Dialogue System",
    "doi": "https://doi.org/10.1145/3430752",
    "publication_date": "2021-02-04",
    "publication_year": 2021,
    "authors": "Mauajama Firdaus; Nidhi Thakur; Asif Ekbal",
    "corresponding_authors": "",
    "abstract": "Multimodality in dialogue systems has opened up new frontiers for the creation of robust conversational agents. Any multimodal system aims at bridging the gap between language and vision by leveraging diverse and often complementary information from image, audio, and video, as well as text. For every task-oriented dialog system, different aspects of the product or service are crucial for satisfying the user’s demands. Based upon the aspect, the user decides upon selecting the product or service. The ability to generate responses with the specified aspects in a goal-oriented dialogue setup facilitates user satisfaction by fulfilling the user’s goals. Therefore, in our current work, we propose the task of aspect controlled response generation in a multimodal task-oriented dialog system. We employ a multimodal hierarchical memory network for generating responses that utilize information from both text and images. As there was no readily available data for building such multimodal systems, we create a Multi-Domain Multi-Modal Dialog (MDMMD++) dataset. The dataset comprises the conversations having both text and images belonging to the four different domains, such as hotels, restaurants, electronics, and furniture. Quantitative and qualitative analysis on the newly created MDMMD++ dataset shows that the proposed methodology outperforms the baseline models for the proposed task of aspect controlled response generation.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3126278993",
    "type": "article"
  },
  {
    "title": "Active Learning for Effectively Fine-Tuning Transfer Learning to Downstream Task",
    "doi": "https://doi.org/10.1145/3446343",
    "publication_date": "2021-02-11",
    "publication_year": 2021,
    "authors": "Md Abul Bashar; Richi Nayak",
    "corresponding_authors": "",
    "abstract": "Language model (LM) has become a common method of transfer learning in Natural Language Processing (NLP) tasks when working with small labeled datasets. An LM is pretrained using an easily available large unlabelled text corpus and is fine-tuned with the labelled data to apply to the target (i.e., downstream) task. As an LM is designed to capture the linguistic aspects of semantics, it can be biased to linguistic features. We argue that exposing an LM model during fine-tuning to instances that capture diverse semantic aspects (e.g., topical, linguistic, semantic relations) present in the dataset will improve its performance on the underlying task. We propose a Mixed Aspect Sampling (MAS) framework to sample instances that capture different semantic aspects of the dataset and use the ensemble classifier to improve the classification performance. Experimental results show that MAS performs better than random sampling as well as the state-of-the-art active learning models to abuse detection tasks where it is hard to collect the labelled data for building an accurate classifier.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3131232155",
    "type": "article"
  },
  {
    "title": "Quantized Adam with Error Feedback",
    "doi": "https://doi.org/10.1145/3470890",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Congliang Chen; Li Shen; Haozhi Huang; Wei Liu",
    "corresponding_authors": "",
    "abstract": "In this article, we present a distributed variant of an adaptive stochastic gradient method for training deep neural networks in the parameter-server model. To reduce the communication cost among the workers and server, we incorporate two types of quantization schemes, i.e., gradient quantization and weight quantization, into the proposed distributed Adam. In addition, to reduce the bias introduced by quantization operations, we propose an error-feedback technique to compensate for the quantized gradient. Theoretically, in the stochastic nonconvex setting, we show that the distributed adaptive gradient method with gradient quantization and error feedback converges to the first-order stationary point, and that the distributed adaptive gradient method with weight quantization and error feedback converges to the point related to the quantized level under both the single-worker and multi-worker modes. Last, we apply the proposed distributed adaptive gradient methods to train deep neural networks. Experimental results demonstrate the efficacy of our methods.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3203803206",
    "type": "article"
  },
  {
    "title": "A Computational Framework for Modeling Biobehavioral Rhythms from Mobile and Wearable Data Streams",
    "doi": "https://doi.org/10.1145/3510029",
    "publication_date": "2022-03-03",
    "publication_year": 2022,
    "authors": "Runze Yan; Xinwen Liu; Janine M. Dutcher; Michael Tumminia; Daniella K. Villalba; Sheldon Cohen; David Creswell; Kasey G. Creswell; Jennifer Mankoff; Anind K. Dey; Afsaneh Doryab",
    "corresponding_authors": "",
    "abstract": "This paper presents a computational framework for modeling biobehavioral rhythms - the repeating cycles of physiological, psychological, social, and environmental events - from mobile and wearable data streams. The framework incorporates four main components: mobile data processing, rhythm discovery, rhythm modeling, and machine learning. We evaluate the framework with two case studies using datasets of smartphone, Fitbit, and OURA smart ring to evaluate the framework’s ability to (1) detect cyclic biobehavior, (2) model commonality and differences in rhythms of human participants in the sample datasets, and (3) predict their health and readiness status using models of biobehavioral rhythms. Our evaluation demonstrates the framework’s ability to generate new knowledge and findings through rigorous micro- and macro-level modeling of human rhythms from mobile and wearable data streams collected in the wild and using them to assess and predict different life and health outcomes.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4214846555",
    "type": "article"
  },
  {
    "title": "<scp>CrimeTensor</scp> : Fine-Scale Crime Prediction via Tensor Learning with Spatiotemporal Consistency",
    "doi": "https://doi.org/10.1145/3501807",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Weichao Liang; Zhiang Wu; Zhe Li; Yong Ge",
    "corresponding_authors": "",
    "abstract": "Crime poses a major threat to human life and property, which has been recognized as one of the most crucial problems in our society. Predicting the number of crime incidents in each region of a city before they happen is of great importance to fight against crime. There has been a great deal of research focused on crime prediction, ranging from introducing diversified data sources to exploring various prediction models. However, most of the existing approaches fail to offer fine-scale prediction results and take little notice of the intricate spatial-temporal-categorical correlations contained in crime incidents. In this article, we propose a tailor-made framework called CrimeTensor to predict the number of crime incidents belonging to different categories within each target region via tensor learning with spatiotemporal consistency. In particular, we model the crime data as a tensor and present an objective function which tries to take full advantage of the spatial, temporal, and categorical correlations contained in crime incidents. Moreover, a well-designed optimization algorithm which transforms the objective into a compact form and then applies CP decomposition to find the optimal solution is elaborated to solve the objective function. Furthermore, we develop an enhanced framework which takes a set of pre-selected regions to conduct prediction so as to further improve the computational efficiency of the optimization algorithm. Finally, extensive experiments are performed on both proprietary and public datasets and our framework significantly outperforms all the baselines in terms of each evaluation metric.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4220732194",
    "type": "article"
  },
  {
    "title": "Predicting Citywide Crowd Dynamics at Big Events: A Deep Learning System",
    "doi": "https://doi.org/10.1145/3472300",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "Renhe Jiang; Zekun Cai; Zhaonan Wang; Chuang Yang; Zipei Fan; Quanjun Chen; Xuan Song; Ryosuke Shibasaki",
    "corresponding_authors": "",
    "abstract": "Event crowd management has been a significant research topic with high social impact. When some big events happen such as an earthquake, typhoon, and national festival, crowd management becomes the first priority for governments (e.g., police) and public service operators (e.g., subway/bus operator) to protect people’s safety or maintain the operation of public infrastructures. However, under such event situations, human behavior will become very different from daily routines, which makes prediction of crowd dynamics at big events become highly challenging, especially at a citywide level. Therefore in this study, we aim to extract the “deep” trend only from the current momentary observations and generate an accurate prediction for the trend in the short future, which is considered to be an effective way to deal with the event situations. Motivated by these, we build an online system called DeepUrbanEvent, which can iteratively take citywide crowd dynamics from the current one hour as input and report the prediction results for the next one hour as output. A novel deep learning architecture built with recurrent neural networks is designed to effectively model these highly complex sequential data in an analogous manner to video prediction tasks. Experimental results demonstrate the superior performance of our proposed methodology to the existing approaches. Lastly, we apply our prototype system to multiple big real-world events and show that it is highly deployable as an online crowd management system.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4221058635",
    "type": "article"
  },
  {
    "title": "Clustering-based Active Learning Classification towards Data Stream",
    "doi": "https://doi.org/10.1145/3579830",
    "publication_date": "2023-01-09",
    "publication_year": 2023,
    "authors": "Chunyong Yin; Shuangshuang Chen; Zhichao Yin",
    "corresponding_authors": "",
    "abstract": "Many practical applications, such as social media and monitoring system, will constantly generate streaming data, which has problems of instability, lack of labels and multiclass imbalance. In order to solve these problems, a cluster-based active learning method is proposed to achieve data stream classification. Firstly, a label query strategy combining marginal threshold matrix is proposed, which selects difficult to classify or potential concept drift samples for marking, to solve the problem of high cost label and unbalanced data. Secondly, dynamic maintenance of a group of micro clusters, by adjusting the weight of micro clusters in the model, correctly reflects the current data distribution, and finally, uses the buffer to store new micro clusters to participate in the update of the model, to adapt to the new data environment. Experimental results on three real data sets and three synthetic data sets show that compared with the classical data stream classification algorithm, it is less affected by concept drift and has higher classification accuracy than the online semi-supervised learning algorithm ADSM. The average accuracy of the six datasets increased by 5.56%, 2.32%, 1.77%, 1.83%, 3.78%, and 2.04%, respectively. The model processes data streams online and improves classification performance with less memory consumption.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4313894180",
    "type": "article"
  },
  {
    "title": "DAS: Efficient Street View Image Sampling for Urban Prediction",
    "doi": "https://doi.org/10.1145/3576902",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Guozhen Zhang; Jinhui Yi; Jian Yuan; Yong Li; Depeng Jin",
    "corresponding_authors": "",
    "abstract": "Street view data is one of the most common data sources for urban prediction tasks, such as estimating socioeconomic status, sensing physical urban changes, and identifying urban villages. Typical research in this field consists of two steps: acquiring a dataset with a street view image sampling algorithm and designing a prediction algorithm for urban prediction tasks. However, most of the previous research focuses on the prediction algorithms, leaving the sampling algorithms underexplored. To fill this gap, we set out to investigate how different street view image sampling algorithms affect the performance of the follow-up tasks and develop an effective street view image sampling algorithm for urban prediction. Through a comprehensive analysis of the performance of different sampling algorithms in three of the most common urban prediction tasks, including commercial activeness prediction, urban liveliness prediction, and urban population prediction, we provide solid empirical evidence that the sampling algorithm significantly affects the performance of the prediction model. Specifically, the performance differences of different sampling algorithms can reach over 25%. Further, we revealed that the sampling step size and the sampling quality are two important factors that affect the performance of a sampling algorithm, while the sampling angle has little influence. Inspired by our analysis results, we propose an effective street view image sampling algorithm, DAS, which contains a denoising module and an adaptive sampling module. It can dynamically adjust the sampling step size to adapt to the optimal size for each region and get rid of the impact of noise images in the meantime. Experiments on three large-scale datasets demonstrate its superior performance over multiple state-of-the-art baselines, and further ablation study shows the effectiveness of each module. Finally, through a thorough discussion of our findings and experimental results, we provide insights into the street view image sampling algorithm design, and we call for more researches in this blank area.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4315706336",
    "type": "article"
  },
  {
    "title": "Learning Privacy-Preserving Embeddings for Image Data to Be Published",
    "doi": "https://doi.org/10.1145/3623404",
    "publication_date": "2023-09-08",
    "publication_year": 2023,
    "authors": "Chu-Chen Li; Cheng–Te Li; Shou-De Lin",
    "corresponding_authors": "",
    "abstract": "Deep learning shows superiority in learning feature representations that offer promising performance in various application domains. Recent advances have shown that privacy attributes of users and patients (e.g., identity, gender, and race) can be accurately inferred from image data. To avoid the risk of privacy leaking, data owners can resort to releasing the embeddings rather than the original images. In this article, we aim at learning to generate privacy-preserving embeddings from image data. The obtained embeddings are required to maintain the data utility (e.g., keeping the performance of the main task, such as disease prediction) and to simultaneously prevent the private attributes of data instances from being accurately inferred. We also want the hard embeddings to be successfully used to reconstruct the original images. We propose a hybrid method based on multi-task learning to reach the goal. The key idea is twofold. One is to learn the feature encoder that can benefit the main task and fool the sensitive task at the same time via iterative training and feature disentanglement. The other is to incorporate the learning of adversarial examples to mislead the sensitive attribute classification’s performance. Experiments conducted on Multi-Attribute Facial Landmark (MAFL) and NIH Chest X-ray datasets exhibit the effectiveness of our hybrid method. A set of advanced studies also shows the usefulness of each model component, the difficulty in data reconstruction, and the performance impact of task correlation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4386546988",
    "type": "article"
  },
  {
    "title": "What Your Next Check-in Might Look Like: Next Check-in Behavior Prediction",
    "doi": "https://doi.org/10.1145/3625234",
    "publication_date": "2023-09-29",
    "publication_year": 2023,
    "authors": "Heli Sun; Chen Cao; Xuguang Chu; Tingting Hu; Junzhi Lu; Liang He; Zhi Wang; Hui He; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "In recent years, the next-POI recommendation has become a trending research topic in the field of trajectory data mining. For protection of user privacy, users’ complete GPS trajectories are difficult to obtain. The check-in information posted by users on social networks has become an important data source for Spatio-temporal Trajectory research. However, state-of-the-art methods neglect the social meaning and the information dissemination function of check-in behavior. The social meaning is an important reason why users are willing to post check-in on social networks, and the information dissemination function means, users can affect each other’s behavior by check-ins. The above characteristics of the check-in behavior make it different from the visiting behavior. We consider a new problem of predicting the next check-in behavior including the check-in time, the POI (point-of-interest) where the check-in is located, functional semantics of the POI, and so on. To solve the proposed problem, we build a multi-task learning model called DPMTM, and a pre-training module is designed to extract dynamic social semantics of check-in behaviors. Our results show that the DPMTM model works well in the check-in behavior problem.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4387188031",
    "type": "article"
  },
  {
    "title": "Recognizing pair-activities by causality analysis",
    "doi": "https://doi.org/10.1145/1889681.1889686",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Yue Zhou; Bingbing Ni; Shuicheng Yan; Thomas S. Huang",
    "corresponding_authors": "",
    "abstract": "In this article, beyond solo-activity analysis for single object, we study the more complicated pair-activity recognition problem by exploring the relationship between two active objects based on their trajectory clues obtained from video sensor. Our contributions are three-fold. First, we design two sets of features for representing the pair-activities encoded as length-variable trajectory pairs. One set characterizes the strength of causality between two trajectories, for example, the causality ratio and feedback ratio based on the Granger Causality Test (GCT), and another set describes the style of causality between two trajectories, for example, the sampled frequency responses of the digital filter with these two trajectories as the input and output discrete signals respectively. These features along with conventional velocity and position features of a trajectory-pair are essentially of multi-modalities, and may be greatly different in scales and importance. To make full use of them, we then develop a novel feature fusing procedure to learn the coefficients for weighting these features by maximizing the discriminating power measured by weighted correlation. Finally, we collected a pair-activity database of five popular categories, each of which consists of about 170 instances. The extensive experiments on this database validate the effectiveness of the designed features for pair-activity representation, and also demonstrate that the proposed feature fusing procedure significantly boosts the pair-activity classification accuracy.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1969752788",
    "type": "article"
  },
  {
    "title": "Learning to Infer the Status of Heavy-Duty Sensors for Energy-Efficient Context-Sensing",
    "doi": "https://doi.org/10.1145/2089094.2089111",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Xueying Li; Huanhuan Cao; Enhong Chen; Jilei Tian",
    "corresponding_authors": "",
    "abstract": "With the prevalence of smart mobile devices with multiple sensors, the commercial application of intelligent context-aware services becomes more and more attractive. However, limited by the battery capacity, the energy efficiency of context-sensing is the bottleneck for the success of context-aware applications. Though several previous studies for energy-efficient context-sensing have been reported, none of them can be applied to multiple types of high-energy-consuming sensors. Moreover, applying machine learning technologies to energy-efficient context-sensing is underexplored too. In this article, we propose to leverage machine learning technologies for improving the energy efficiency of multiple high-energy-consuming context sensors by trading off the sensing accuracy. To be specific, we try to infer the status of high-energy-consuming sensors according to the outputs of software-based sensors and the physical sensors that are necessary to work all the time for supporting the basic functions of mobile devices. If the inference indicates the high-energy-consuming sensor is in a stable status, we avoid the unnecessary invocation and instead use the latest invoked value as the estimation. The experimental results on real datasets show that the energy efficiency of GPS sensing and audio-level sensing are significantly improved by the proposed approach while the sensing accuracy is over 90%.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2108426667",
    "type": "article"
  },
  {
    "title": "Temporal data mining approaches for sustainable chiller management in data centers",
    "doi": "https://doi.org/10.1145/1989734.1989738",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Debprakash Patnaik; Manish Marwah; Ratnesh Sharma; Naren Ramakrishnan",
    "corresponding_authors": "",
    "abstract": "Practically every large IT organization hosts data centers---a mix of computing elements, storage systems, networking, power, and cooling infrastructure---operated either in-house or outsourced to major vendors. A significant element of modern data centers is their cooling infrastructure, whose efficient and sustainable operation is a key ingredient to the “always-on” capability of data centers. We describe the design and implementation of CAMAS (Chiller Advisory and MAnagement System), a temporal data mining solution to mine and manage chiller installations. CAMAS embodies a set of algorithms for processing multivariate time-series data and characterizes sustainability measures of the patterns mined. We demonstrate three key ingredients of CAMAS---motif mining, association analysis, and dynamic Bayesian network inference---that help bridge the gap between low-level, raw, sensor streams, and the high-level operating regions and features needed for an operator to efficiently manage the data center. The effectiveness of CAMAS is demonstrated by its application to a real-life production data center managed by HP.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1964864810",
    "type": "article"
  },
  {
    "title": "Collection-based sparse label propagation and its application on social group suggestion from photos",
    "doi": "https://doi.org/10.1145/1899412.1899416",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Jie Yu; Xin Jin; Jiawei Han; Jiebo Luo",
    "corresponding_authors": "",
    "abstract": "Online social network services pose great opportunities and challenges for many research areas. In multimedia content analysis, automatic social group recommendation for images holds the promise to expand one's social network through media sharing. However, most existing techniques cannot generate satisfactory social group suggestions when the images are classified independently. In this article, we present novel methods to produce accurate suggestions of suitable social groups from a user's personal photo collection. First, an automatic clustering process is designed to estimate the group similarities, select the optimal number of clusters and categorize the social groups. Both visual content and textual annotations are integrated to generate initial predictions of the group categories for the images. Next, the relationship among images in a user's collection is modeled as a sparse graph. A collection-based sparse label propagation method is proposed to improve the group suggestions. Furthermore, the sparse graph-based collection model can be readily exploited to select the most influential and informative samples for active relevance feedback, which can be integrated with the label propagation process without the need for classifier retraining. The proposed methods have been tested on group suggestion tasks for real user collections and demonstrated superior performance over the state-of-the-art techniques.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2040161207",
    "type": "article"
  },
  {
    "title": "Distinguishing Facial Features for Ethnicity-Based 3D Face Recognition",
    "doi": "https://doi.org/10.1145/2168752.2168759",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Stefano Berretti; Alberto Del Bimbo; Pietro Pala",
    "corresponding_authors": "",
    "abstract": "Among different approaches for 3D face recognition, solutions based on local facial characteristics are very promising, mainly because they can manage facial expression variations by assigning different weights to different parts of the face. However, so far, a few works have investigated the individual relevance that local features play in 3D face recognition with very simple solutions applied in the practice. In this article, a local approach to 3D face recognition is combined with a feature selection model to study the relative relevance of different regions of the face for the purpose of discriminating between different subjects. The proposed solution is experimented using facial scans of the Face Recognition Grand Challenge dataset. Results of the experimentation are two-fold: they quantitatively demonstrate the assumption that different regions of the face have different relevance for face discrimination and also show that the relevance of facial regions changes for different ethnic groups.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2087750076",
    "type": "article"
  },
  {
    "title": "Entity-Relationship Queries over Wikipedia",
    "doi": "https://doi.org/10.1145/2337542.2337555",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Xiaonan Li; Chengkai Li; Cong Yu",
    "corresponding_authors": "",
    "abstract": "Wikipedia is the largest user-generated knowledge base. We propose a structured query mechanism, entity-relationship query , for searching entities in the Wikipedia corpus by their properties and interrelationships. An entity-relationship query consists of multiple predicates on desired entities. The semantics of each predicate is specified with keywords. Entity-relationship query searches entities directly over text instead of preextracted structured data stores. This characteristic brings two benefits: (1) Query semantics can be intuitively expressed by keywords; (2) It only requires rudimentary entity annotation, which is simpler than explicitly extracting and reasoning about complex semantic information before query-time. We present a ranking framework for general entity-relationship queries and a position-based Bounded Cumulative Model (BCM) for accurate ranking of query answers. We also explore various weighting schemes for further improving the accuracy of BCM. We test our ideas on a 2008 version of Wikipedia using a collection of 45 queries pooled from INEX entity ranking track and our own crafted queries. Experiments show that the ranking and weighting schemes are both effective, particularly on multipredicate queries.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2159867275",
    "type": "article"
  },
  {
    "title": "Large Sparse Cone Non-negative Matrix Factorization for Image Annotation",
    "doi": "https://doi.org/10.1145/2987379",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Dapeng Tao; Dacheng Tao; Xuelong Li; Xinbo Gao",
    "corresponding_authors": "",
    "abstract": "Image annotation assigns relevant tags to query images based on their semantic contents. Since Non-negative Matrix Factorization (NMF) has the strong ability to learn parts-based representations, recently, a number of algorithms based on NMF have been proposed for image annotation and have achieved good performance. However, most of the efforts have focused on the representations of images and annotations. The properties of the semantic parts have not been well studied. In this article, we revisit the sparseness-constrained NMF (sNMF) proposed by Hoyer [2004]. By endowing the sparseness constraint with a geometric interpretation and sNMF with theoretical analyses of the generalization ability, we show that NMF with such a sparseness constraint has three advantages for image annotation tasks: (i) The sparseness constraint is more ℓ 0 -norm oriented than the ℓ 1 -norm-based sparseness, which significantly enhances the ability of NMF to robustly learn semantic parts. (ii) The sparseness constraint has a large cone interpretation and thus allows the reconstruction error of NMF to be smaller, which means that the learned semantic parts are more powerful to represent images for tagging. (iii) The learned semantic parts are less correlated, which increases the discriminative ability for annotating images. Moreover, we present a new efficient large sparse cone NMF (LsCNMF) algorithm to optimize the sNMF problem by employing the Nesterov’s optimal gradient method. We conducted experiments on the PASCAL VOC07 dataset and demonstrated the effectiveness of LsCNMF for image annotation.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2605809234",
    "type": "article"
  },
  {
    "title": "Vertical Ensemble Co-Training for Text Classification",
    "doi": "https://doi.org/10.1145/3137114",
    "publication_date": "2017-10-25",
    "publication_year": 2017,
    "authors": "Gilad Katz; Cornelia Caragea; Asaf Shabtai",
    "corresponding_authors": "",
    "abstract": "High-quality, labeled data is essential for successfully applying machine learning methods to real-world text classification problems. However, in many cases, the amount of labeled data is very small compared to that of the unlabeled, and labeling additional samples could be expensive and time consuming. Co-training algorithms, which make use of unlabeled data to improve classification, have proven to be very effective in such cases. Generally, co-training algorithms work by using two classifiers, trained on two different views of the data, to label large amounts of unlabeled data. Doing so can help minimize the human effort required for labeling new data, as well as improve classification performance. In this article, we propose an ensemble-based co-training approach that uses an ensemble of classifiers from different training iterations to improve labeling accuracy. This approach, which we call vertical ensemble , incurs almost no additional computational cost. Experiments conducted on six textual datasets show a significant improvement of over 45% in AUC compared with the original co-training algorithm.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2765972116",
    "type": "article"
  },
  {
    "title": "illiad",
    "doi": "https://doi.org/10.1145/3066167",
    "publication_date": "2018-01-29",
    "publication_year": 2018,
    "authors": "Nikhil Muralidhar; Chen Wang; Nathan Self; Marjan Momtazpour; Kiyoshi Nakayama; Ratnesh Sharma; Naren Ramakrishnan",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPSs) are today ubiquitous in urban environments. Such systems now serve as the backbone to numerous critical infrastructure applications, from smart grids to IoT installations. Scalable and seamless operation of such CPSs requires sophisticated tools for monitoring the time series progression of the system, dynamically tracking relationships, and issuing alerts about anomalies to operators. We present an online monitoring system ( illiad ) that models the state of the CPS as a function of its relationships between constituent components, using a combination of model-based and data-driven strategies. In addition to accurate inference for state estimation and anomaly tracking, illiad also exploits the underlying network structure of the CPS (wired or wireless) for state estimation purposes. We demonstrate the application of illiad to two diverse settings: a wireless sensor motes application and an IEEE 33-bus microgrid.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2785888850",
    "type": "article"
  },
  {
    "title": "GAPs",
    "doi": "https://doi.org/10.1145/2036264.2036271",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Paulo Shakarian; V. S. Subrahmanian; Maria Luisa Sapino",
    "corresponding_authors": "",
    "abstract": "There are many applications where we observe various phenomena in space (e.g., locations of victims of a serial killer), and where we want to infer “partner” locations (e.g., the location where the killer lives) that are geospatially related to the observed phenomena. In this article, we define geospatial abduction problems (GAPs for short). We analyze the complexity of GAPs, develop exact and approximate algorithms (often with approximation guarantees) for these problems together with analyses of these algorithms, and develop a prototype implementation of our GAP framework. We demonstrate accuracy of our algorithms on a real world data set consisting of insurgent IED (improvised explosive device) attacks against U.S. forces in Iraq (the observations were the locations of the attacks, while the “partner” locations we were trying to infer were the locations of IED weapons caches).",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1973197387",
    "type": "article"
  },
  {
    "title": "A Fuzzy Logic System for Bargaining in Information Markets",
    "doi": "https://doi.org/10.1145/2089094.2089108",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Kostas Kolomvatsos; Christos Anagnostopoulos; Stathes Hadjiefthymiades",
    "corresponding_authors": "",
    "abstract": "Future Web business models involve virtual environments where entities interact in order to sell or buy information goods. Such environments are known as Information Markets (IMs). Intelligent agents are used in IMs for representing buyers or information providers (sellers). We focus on the decisions taken by the buyer in the purchase negotiation process with sellers. We propose a reasoning mechanism on the offers (prices of information goods) issued by sellers based on fuzzy logic. The buyer’s knowledge on the negotiation process is modeled through fuzzy sets. We propose a fuzzy inference engine dealing with the decisions that the buyer takes on each stage of the negotiation process. The outcome of the proposed reasoning method indicates whether the buyer should accept or reject the sellers’ offers. Our findings are very promising for the efficiency of automated transactions undertaken by intelligent agents.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2003822233",
    "type": "article"
  },
  {
    "title": "An Association-Based Unified Framework for Mining Features and Opinion Words",
    "doi": "https://doi.org/10.1145/2663359",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Zhen Hai; Kuiyu Chang; Gao Cong; Christopher C. Yang",
    "corresponding_authors": "",
    "abstract": "Mining features and opinion words is essential for fine-grained opinion analysis of customer reviews. It is observed that semantic dependencies naturally exist between features and opinion words, even among features or opinion words themselves. In this article, we employ a corpus statistics association measure to quantify the pairwise word dependencies and propose a generalized association-based unified framework to identify features, including explicit and implicit features, and opinion words from reviews. We first extract explicit features and opinion words via an association-based bootstrapping method (ABOOT). ABOOT starts with a small list of annotated feature seeds and then iteratively recognizes a large number of domain-specific features and opinion words by discovering the corpus statistics association between each pair of words on a given review domain. Two instances of this ABOOT method are evaluated based on two particular association models, likelihood ratio tests (LRTs) and latent semantic analysis (LSA). Next, we introduce a natural extension to identify implicit features by employing the recognized known semantic correlations between features and opinion words. Experimental results illustrate the benefits of the proposed association-based methods for identifying features and opinion words versus benchmark methods.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2089982664",
    "type": "article"
  },
  {
    "title": "Social Incentives in Paid Collaborative Crowdsourcing",
    "doi": "https://doi.org/10.1145/3078852",
    "publication_date": "2017-07-24",
    "publication_year": 2017,
    "authors": "Oluwaseyi Feyisetan; Elena Simperl",
    "corresponding_authors": "",
    "abstract": "Paid microtask crowdsourcing has traditionally been approached as an individual activity, with units of work created and completed independently by the members of the crowd. Other forms of crowdsourcing have, however, embraced more varied models, which allow for a greater level of participant interaction and collaboration. This article studies the feasibility and uptake of such an approach in the context of paid microtasks. Specifically, we compare engagement, task output, and task accuracy in a paired-worker model with the traditional, single-worker version. Our experiments indicate that collaboration leads to better accuracy and more output, which, in turn, translates into lower costs. We then explore the role of the social flow and social pressure generated by collaborating partners as sources of incentives for improved performance. We utilise a Bayesian method in conjunction with interface interaction behaviours to detect when one of the workers in a pair tries to exit the task. Upon this realisation, the other worker is presented with the opportunity to contact the exiting partner to stay: either for personal financial reasons (i.e., they have not completed enough tasks to qualify for a payment) or for fun (i.e., they are enjoying the task). The findings reveal that: (1) these socially motivated incentives can act as furtherance mechanisms to help workers attain and exceed their task requirements and produce better results than baseline collaborations; (2) microtask crowd workers are empathic (as opposed to selfish) agents, willing to go the extra mile to help their partners get paid; and, (3) social furtherance incentives create a win-win scenario for the requester and for the workers by helping more workers get paid by re-engaging them before they drop out.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2738182482",
    "type": "article"
  },
  {
    "title": "Personalized Microtopic Recommendation on Microblogs",
    "doi": "https://doi.org/10.1145/2932192",
    "publication_date": "2017-08-25",
    "publication_year": 2017,
    "authors": "Yang Li; Jing Jiang; Ting Liu; Minghui Qiu; Xiaofei Sun",
    "corresponding_authors": "",
    "abstract": "Microblogging services such as Sina Weibo and Twitter allow users to create tags explicitly indicated by the # symbol. In Sina Weibo, these tags are called microtopics , and in Twitter, they are called hashtags . In Sina Weibo, each microtopic has a designate page and can be directly visited or commented on. Recommending these microtopics to users based on their interests can help users efficiently acquire information. However, it is non-trivial to recommend microtopics to users to satisfy their information needs. In this article, we investigate the task of personalized microtopic recommendation, which exhibits two challenges. First, users usually do not give explicit ratings to microtopics. Second, there exists rich information about users and microtopics, for example, users' published content and biographical information, but it is not clear how to best utilize such information. To address the above two challenges, we propose a joint probabilistic latent factor model to integrate rich information into a matrix factorization-based solution to microtopic recommendation. Our model builds on top of collaborative filtering, content analysis, and feature regression. Using two real-world datasets, we evaluate our model with different kinds of content and contextual information. Experimental results show that our model significantly outperforms a few competitive baseline methods, especially in the circumstance where users have few adoption behaviors.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2745643029",
    "type": "article"
  },
  {
    "title": "Finding Semantically Valid and Relevant Topics by Association-Based Topic Selection Model",
    "doi": "https://doi.org/10.1145/3094786",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Yang Gao; Yuefeng Li; Raymond Y.K. Lau; Yue Xu; Md Abul Bashar",
    "corresponding_authors": "",
    "abstract": "Topic modelling methods such as Latent Dirichlet Allocation (LDA) have been successfully applied to various fields, since these methods can effectively characterize document collections by using a mixture of semantically rich topics. So far, many models have been proposed. However, the existing models typically outperform on full analysis on the whole collection to find all topics but difficult to capture coherent and specifically meaningful topic representations. Furthermore, it is very challenging to incorporate user preferences into existing topic modelling methods to extract relevant topics. To address these problems, we develop a novel personalized Association-based Topic Selection (ATS) model, which can identify semantically valid and relevant topics from a set of raw topics based on the semantical relatedness between users’ preferences and the structured patterns captured in topics. The advantage of the proposed ATS model is that it enables an interactive topic modelling process driven by users’ specific interests. Based on three benchmark datasets, namely, RCV1, R8, and WT10G under the context of information filtering (IF) and information retrieval (IR), our rigorous experiments show that the proposed ATS model can effectively identify relevant topics with respect to users’ specific interests, and hence to improve the performance of IF and IR.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2749627623",
    "type": "article"
  },
  {
    "title": "Personalized Air Travel Prediction",
    "doi": "https://doi.org/10.1145/3078845",
    "publication_date": "2017-12-19",
    "publication_year": 2017,
    "authors": "Jie Liu; Bin Liu; Yanchi Liu; Huipeng Chen; Lina Feng; Hui Xiong; Yalou Huang",
    "corresponding_authors": "",
    "abstract": "Human mobility analysis is one of the most important research problems in the field of urban computing. Existing research mainly focuses on the intra-city ground travel behavior modeling, while the inter-city air travel behavior modeling has been largely ignored. Actually, the inter-city travel analysis can be of equivalent importance and complementary to the intra-city travel analysis. Understanding massive passenger-air-travel behavior delivers intelligence for airlines’ precision marketing and related socioeconomic activities, such as airport planning, emergency management, local transportation planning, and tourism-related businesses. Moreover, it provides opportunities to study the characteristics of cities and the mutual relationships between them. However, modeling and predicting air traveler behavior is challenging due to the complex factors of the market situation and individual characteristics of customers (e.g., airlines’ market share, customer membership, and travelers’ intrinsic interests on destinations). To this end, in this article, we present a systematic study on the personalized air travel prediction problem, namely where a customer will fly to and which airline carrier to fly with, by leveraging real-world anonymized Passenger Name Record (PNR) data. Specifically, we first propose a relational travel topic model, which combines the merits of latent factor model with a neighborhood-based method, to uncover the personal travel preferences of aviation customers and the latent travel topics of air routes and airline carriers simultaneously. Then we present a multi-factor travel prediction framework, which fuses complex factors of the market situation and individual characteristics of customers, to predict airline customers’ personalized travel demands. Experimental results on two real-world PNR datasets demonstrate the effectiveness of our approach on both travel topic discovery and customer travel prediction.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2779451246",
    "type": "article"
  },
  {
    "title": "A Multi-Label Multi-View Learning Framework for In-App Service Usage Analysis",
    "doi": "https://doi.org/10.1145/3151937",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Yanjie Fu; Junming Liu; Xiaolin Li; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "The service usage analysis, aiming at identifying customers’ messaging behaviors based on encrypted App traffic flows, has become a challenging and emergent task for service providers. Prior literature usually starts from segmenting a traffic sequence into single-usage subsequences, and then classify the subsequences into different usage types. However, they could suffer from inaccurate traffic segmentations and mixed-usage subsequences. To address this challenge, we exploit a multi-label multi-view learning strategy and develop an enhanced framework for in-App usage analytics. Specifically, we first devise an enhanced traffic segmentation method to reduce mixed-usage subsequences. Besides, we develop a multi-label multi-view logistic classification method, which comprises two alignments. The first alignment is to make use of the classification consistency between packet-length view and time-delay view of traffic subsequences and improve classification accuracy. The second alignment is to combine the classification of single-usage subsequence and the post-classification of mixed-usage subsequences into a unified multi-label logistic classification problem. Finally, we present extensive experiments with real-world datasets to demonstrate the effectiveness of our approach. We find that the proposed multi-label multi-view framework can help overcome the pain of mixed-usage subsequences and can be generalized to latent activity analysis in sequential data, beyond in-App usage analytics.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2792969299",
    "type": "article"
  },
  {
    "title": "Using Social Dependence to Enable Neighbourly Behaviour in Open Multi-Agent Systems",
    "doi": "https://doi.org/10.1145/3319402",
    "publication_date": "2019-04-22",
    "publication_year": 2019,
    "authors": "Fatemeh Golpayegani; Ivana Dusparić; Siobhàn Clarke",
    "corresponding_authors": "",
    "abstract": "Agents frequently collaborate to achieve a shared goal or to accomplish a task that they cannot do alone. However, collaboration is difficult in open multi-agent systems where agents share constrained resources to achieve both individual and shared goals. In current approaches to collaboration, agents are organised into disjoint groups and social reasoning is used to capture their capabilities when selecting a qualified set of collaborators. These approaches are not useful when agents are in multiple, overlapping groups; depend on each other when using shared resources; have multiple goals to achieve simultaneously; and have to share the overall costs and benefits. In this article, agents use social reasoning to enhance their understanding of other agents’ goals and their dependencies, and self-adaptive techniques to adapt their level of self-interest in a collaborative process, with a view to contributing to lowering shared costs or increasing shared benefits. This model aims at improving the extent to which agents’ goals are met while improving shared resource usage efficiency. For example, in a public transport system where each mode of transport has limited capacity, commuters will be enabled to make choices that avoid over-capacity in different modes, or in a smart energy grid with limited capacity, users can make choices as to when they increase their demand. The model simultaneously helps avoid overloading a shared resource while allowing users to achieve their own goals. The proposed model is evaluated in an open multi-agent system with 100 agents operating in multiple overlapping groups and sharing multiple constrained resources. The impact of agents’ varying levels of social dependencies, mobility, and their groups’ density on their individual and shared goal achievement is analysed.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3033505662",
    "type": "article"
  },
  {
    "title": "Depth Error Elimination for RGB-D Cameras",
    "doi": "https://doi.org/10.1145/2735959",
    "publication_date": "2015-04-22",
    "publication_year": 2015,
    "authors": "Yue Gao; You Yang; Yi Zhen; Qionghai Dai",
    "corresponding_authors": "",
    "abstract": "The rapid spreading of RGB-D cameras has led to wide applications of 3D videos in both academia and industry, such as 3D entertainment and 3D visual understanding. Under these circumstances, extensive research efforts have been dedicated to RGB-D camera--oriented topics. In these topics, quality promotion of depth videos with the temporal characteristic is emerging and important. Due to the limited exposure time of RGB-D cameras, object movement can easily lead to motion blurs in intensive images, which can further result in obvious artifacts (holes or fake boundaries) in the corresponding depth frames. With regard to this problem, we propose a depth error elimination method based on time series analysis to remove the artifacts in depth images. In this method, we first locate the regions with erroneous depths in intensive images by using motion blur detection based on a time series analysis model. This is based on the fact that the depth image is calculated by intensive color images that are captured synchronously by RGB-D cameras. Then, the artifacts, such as holes or fake boundaries, are fixed by a depth error elimination method. To evaluate the performance of the proposed method, we conducted experiments on 250 images. Experimental results demonstrate that the proposed method can locate the error regions correctly and eliminate these artifacts effectively. The quality of depth video can be improved significantly by using the proposed method.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2011792300",
    "type": "article"
  },
  {
    "title": "Telco User Activity Level Prediction with Massive Mobile Broadband Data",
    "doi": "https://doi.org/10.1145/2856057",
    "publication_date": "2016-05-02",
    "publication_year": 2016,
    "authors": "Luo Chen; Jia Zeng; Mingxuan Yuan; Wenyuan Dai; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Telecommunication (telco) operators aim to provide users with optimized services and bandwidth in a timely manner. The goal is to increase user experience while retaining profit. To do this, knowing the changing behavior patterns of users through their activity levels in advance can be a great help for operators to adjust their management strategies and reduce operational risk. To achieve this goal, the operators can make use of knowledge discovered from telco’s historical mobile broadband (MBB) records to predict mobile access activity level at an early stage. In this article, we report our research in a real-world telco setting involving more than one million telco users. Our novel contribution includes representing users as documents containing a collection of changing spatiotemporal “words” that express user behavior. By extracting users’ space-time access records in MBB data, we use latent Dirichlet allocation (LDA) to learn user-specific compact topic features for user activity level prediction. We propose a scalable online expectation-maximization (OEM) algorithm that can scale LDA to massive MBB data, which is significantly faster than several state-of-the-art online LDA algorithms. Using these real-world MBB data, we confirm high performance in user activity level prediction. In addition, we show that the inferred topics indicate that future activity level anomalies correlate highly with early skewed bandwidth supply and demand relations. Thus, our prediction system can also guide the telco operators to balance the telecommunication network in terms of supply-demand relations, saving deployment costs and energy of cell towers in the future.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2345850743",
    "type": "article"
  },
  {
    "title": "Recognizing Parkinsonian Gait Pattern by Exploiting Fine-Grained Movement Function Features",
    "doi": "https://doi.org/10.1145/2890511",
    "publication_date": "2016-08-23",
    "publication_year": 2016,
    "authors": "Tianben Wang; Zhu Wang; Daqing Zhang; Tao Gu; Hongbo Ni; Jiangbo Jia; Xingshe Zhou; Jing Lv",
    "corresponding_authors": "",
    "abstract": "Parkinson's disease (PD) is one of the typical movement disorder diseases among elderly people, which has a serious impact on their daily lives. In this article, we propose a novel computation framework to recognize gait patterns in patients with PD. The key idea of our approach is to distinguish gait patterns in PD patients from healthy individuals by accurately extracting gait features that capture all three aspects of movement functions, that is, stability, symmetry, and harmony. The proposed framework contains three steps: gait phase discrimination, feature extraction and selection, and pattern classification. In the first step, we put forward a sliding window--based method to discriminate four gait phases from plantar pressure data. Based on the gait phases, we extract and select gait features that characterize stability, symmetry, and harmony of movement functions. Finally, we recognize PD gait patterns by applying a hybrid classification model. We evaluate the framework using an open dataset that contains real plantar pressure data of 93 PD patients and 72 healthy individuals. Experimental results demonstrate that our framework significantly outperforms the four baseline approaches.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2508096415",
    "type": "article"
  },
  {
    "title": "Directly Optimize Diversity Evaluation Measures",
    "doi": "https://doi.org/10.1145/2983921",
    "publication_date": "2017-01-12",
    "publication_year": 2017,
    "authors": "Jun Xu; Xia Long; Yanyan Lan; Jiafeng Guo; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "The queries issued to search engines are often ambiguous or multifaceted, which requires search engines to return diverse results that can fulfill as many different information needs as possible; this is called search result diversification . Recently, the relational learning to rank model, which designs a learnable ranking function following the criterion of maximal marginal relevance, has shown effectiveness in search result diversification [Zhu et al. 2014]. The goodness of a diverse ranking model is usually evaluated with diversity evaluation measures such as α-NDCG [Clarke et al. 2008], ERR-IA [Chapelle et al. 2009], and D#-NDCG [Sakai and Song 2011]. Ideally the learning algorithm would train a ranking model that could directly optimize the diversity evaluation measures with respect to the training data. Existing relational learning to rank algorithms, however, only train the ranking models by optimizing loss functions that loosely relate to the evaluation measures. To deal with the problem, we propose a general framework for learning relational ranking models via directly optimizing any diversity evaluation measure . In learning, the loss function upper-bounding the basic loss function defined on a diverse ranking measure is minimized. We can derive new diverse ranking algorithms under the framework, and several diverse ranking algorithms are created based on different upper bounds over the basic loss function. We conducted comparisons between the proposed algorithms with conventional diverse ranking methods using the TREC benchmark datasets. Experimental results show that the algorithms derived under the diverse learning to rank framework always significantly outperform the state-of-the-art baselines.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2572616666",
    "type": "article"
  },
  {
    "title": "i <sup>2</sup> tag",
    "doi": "https://doi.org/10.1145/3035968",
    "publication_date": "2017-09-18",
    "publication_year": 2017,
    "authors": "Xiaoyi Fan; Wei Gong; Jiangchuan Liu",
    "corresponding_authors": "",
    "abstract": "Many radio frequency identification (RFID) applications, such as virtual shopping cart and tag-assisted gaming, involve sensing and recognizing tag mobility. However, existing RFID localization methods are mostly designed for static or slowly moving targets (less than 0.3m/sec). More importantly, we observe that prior methods suffer from serious performance degradation for detecting real-world moving tags in typical indoor environments with multipath interference. In this article, we present i 2 tag, an intelligent mobility-aware activity identification system for RFID tags in multipath-rich environments (e.g., indoors). i 2 tag employs a supervised learning framework based on our novel fine-grain mobility provile, which can quantify different levels of mobility. Unlike previous methods that mostly rely on phase measurement, i 2 tag takes into account various measurements, including RSSI variance, packet loss rate, and our novel relative phase--based fingerprint. Additionally, we design a multidimensional dynamic time warping--based algorithm to robustly detect mobility and the associated activities. We show that i 2 tag is readily deployable using off-the-shelf RFID devices. A prototype has been implemented using a ThingMagic reader and standard-compatible tags. Experimental results demonstrate its superiority in mobility detection and activity identification in various indoor environments.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2754052029",
    "type": "article"
  },
  {
    "title": "SocialWave",
    "doi": "https://doi.org/10.1145/3106775",
    "publication_date": "2017-10-23",
    "publication_year": 2017,
    "authors": "Guodao Sun; Tan Tang; Tai‐Quan Peng; Ronghua Liang; Yingcai Wu",
    "corresponding_authors": "",
    "abstract": "Rapid advancement of social media tremendously facilitates and accelerates the information diffusion among users around the world. How and to what extent will the information on social media achieve widespread diffusion across the world? How can we quantify the interaction between users from different geolocations in the diffusion process? How will the spatial patterns of information diffusion change over time? To address these questions, a dynamic social gravity model (SGM) is proposed to quantify the dynamic spatial interaction behavior among social media users in information diffusion. The dynamic SGM includes three factors that are theoretically significant to the spatial diffusion of information: geographic distance, cultural proximity, and linguistic similarity. Temporal dimension is also taken into account to help detect recency effect, and ground-truth data is integrated into the model to help measure the diffusion power. Furthermore, SocialWave, a visual analytic system, is developed to support both spatial and temporal investigative tasks. SocialWave provides a temporal visualization that allows users to quickly identify the overall temporal diffusion patterns, which reflect the spatial characteristics of the diffusion network. When a meaningful temporal pattern is identified, SocialWave utilizes a new occlusion-free spatial visualization, which integrates a node-link diagram into a circular cartogram for further analysis. Moreover, we propose a set of rich user interactions that enable in-depth, multi-faceted analysis of the diffusion on social media. The effectiveness and efficiency of the mathematical model and visualization system are evaluated with two datasets on social media, namely, Ebola Epidemics and Ferguson Unrest.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2765576880",
    "type": "article"
  },
  {
    "title": "Real-Time Human Mobility Modeling with Multi-View Learning",
    "doi": "https://doi.org/10.1145/3092692",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Desheng Zhang; Tian He; Fan Zhang",
    "corresponding_authors": "",
    "abstract": "Real-time human mobility modeling is essential to various urban applications. To model such human mobility, numerous data-driven techniques have been proposed. However, existing techniques are mostly driven by data from a single view, for example, a transportation view or a cellphone view, which leads to over-fitting of these single-view models. To address this issue, we propose a human mobility modeling technique based on a generic multi-view learning framework called coMobile. In coMobile, we first improve the performance of single-view models based on tensor decomposition with correlated contexts, and then we integrate these improved single-view models together for multi-view learning to iteratively obtain mutually reinforced knowledge for real-time human mobility at urban scale. We implement coMobile based on an extremely large dataset in the Chinese city Shenzhen, including data about taxi, bus, and subway passengers along with cellphone users, capturing more than 27 thousand vehicles and 10 million urban residents. The evaluation results show that our approach outperforms a single-view model by 51% on average. More importantly, we design a novel application where urban taxis are dispatched based on unaccounted mobility demand inferred by coMobile.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2774646783",
    "type": "article"
  },
  {
    "title": "Enumerating Connected Subgraphs and Computing the Myerson and Shapley Values in Graph-Restricted Games",
    "doi": "https://doi.org/10.1145/3235026",
    "publication_date": "2019-01-12",
    "publication_year": 2019,
    "authors": "Oskar Skibski; Talal Rahwan; Tomasz Michalak; Michael Wooldridge",
    "corresponding_authors": "",
    "abstract": "At the heart of multi-agent systems is the ability to cooperate to improve the performance of individual agents and/or the system as a whole. While a widespread assumption in the literature is that such cooperation is essentially unrestricted, in many realistic settings this assumption does not hold. A highly influential approach for modelling such scenarios are graph-restricted games introduced by Myerson [36]. In this approach, agents are represented by nodes in a graph, edges represent communication channels, and a group can generate an arbitrary value only if there exists a direct or indirect communication channel between every pair of agents within the group. Two fundamental solution-concepts that were proposed for such games are the Myerson value and the Shapley value . While an algorithm has been developed to compute the Shapley value in arbitrary graph-restricted games, no such general-purpose algorithm has been developed for the Myerson value to date. With this in mind, we set out to develop for such games a general-purpose algorithm to compute the Myerson value, and a more efficient algorithm to compute the Shapley value. Since the computation of either value involves enumerating all connected induced subgraphs of the game’s underlying graph, we start by developing an algorithm dedicated to this enumeration, and then we show empirically that it is faster than the state of the art in the literature. Finally, we present a sample application of both algorithms, in which we test the Myerson value and the Shapley value as advanced measures of node centrality in networks.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2909093226",
    "type": "article"
  },
  {
    "title": "HERA",
    "doi": "https://doi.org/10.1145/3379501",
    "publication_date": "2020-04-03",
    "publication_year": 2020,
    "authors": "Gengyu Lyu; Songhe Feng; Yidong Li; Yi Jin; Guojun Dai; Congyan Lang",
    "corresponding_authors": "",
    "abstract": "Partial label learning (PLL) aims to learn from the data where each training instance is associated with a set of candidate labels, among which only one is correct. Most existing methods deal with this type of problem by either treating each candidate label equally or identifying the ground-truth label iteratively. In this article, we propose a novel PLL approach named HERA, which simultaneously incorporates the HeterogEneous Loss and the SpaRse and Low-rAnk procedure to estimate the labeling confidence for each instance while training the desired model. Specifically, the heterogeneous loss integrates the strengths of both the pairwise ranking loss and the pointwise reconstruction loss to provide informative label ranking and reconstruction information for label identification, whereas the embedded sparse and low-rank scheme constrains the sparsity of ground-truth label matrix and the low rank of noise label matrix to explore the global label relevance among the whole training data, for improving the learning model. Comprehensive ablation study demonstrates the effectiveness of our employed heterogeneous loss, and extensive experiments on both artificial and real-world datasets demonstrate that our method achieves superior or comparable performance against state-of-the-art methods.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3014734617",
    "type": "article"
  },
  {
    "title": "End-to-End Text-to-Image Synthesis with Spatial Constrains",
    "doi": "https://doi.org/10.1145/3391709",
    "publication_date": "2020-05-25",
    "publication_year": 2020,
    "authors": "Min Wang; Congyan Lang; Liqian Liang; Songhe Feng; Tao Wang; Yutong Gao",
    "corresponding_authors": "",
    "abstract": "Although the performance of automatically generating high-resolution realistic images from text descriptions has been significantly boosted, many challenging issues in image synthesis have not been fully investigated, due to shapes variations, viewpoint changes, pose changes, and the relations of multiple objects. In this article, we propose a novel end-to-end approach for text-to-image synthesis with spatial constraints by mining object spatial location and shape information. Instead of learning a hierarchical mapping from text to image, our algorithm directly generates multi-object fine-grained images through the guidance of the generated semantic layouts. By fusing text semantic and spatial information into a synthesis module and jointly fine-tuning them with multi-scale semantic layouts generated, the proposed networks show impressive performance in text-to-image synthesis for complex scenes. We evaluate our method both on single-object CUB dataset and multi-object MS-COCO dataset. Comprehensive experimental results demonstrate that our method significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3033404132",
    "type": "article"
  },
  {
    "title": "Shapelet-transformed Multi-channel EEG Channel Selection",
    "doi": "https://doi.org/10.1145/3397850",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Chenglong Dai; Dechang Pi; Stefanie I. Becker",
    "corresponding_authors": "",
    "abstract": "This article proposes an approach to select EEG channels based on EEG shapelet transformation, aiming to reduce the setup time and inconvenience for subjects and to improve the applicable performance of Brain-Computer Interfaces (BCIs). In detail, the method selects top- k EEG channels by solving a logistic loss-embedded minimization problem with respect to EEG shapelet learning, hyperplane learning, and EEG channel weight learning simultaneously. Especially, to learn distinguished EEG shapelets for weighting contributions of each EEG channel to the logistic loss, EEG shapelet similarity is also minimized during the procedure. Furthermore, the gradient descent strategy is adopted in the article to solve the non-convex optimization problem, which finally leads to the algorithm termed StEEGCS. In a result, classification accuracy, with those EEG channels selected by StEEGCS, is improved compared to that with all EEG channels, and classification time consumption is reduced as well. Additionally, the comparisons with several state-of-the-art EEG channel selection methods on several real-world EEG datasets also demonstrate the efficacy and superiority of StEEGCS.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3041767384",
    "type": "article"
  },
  {
    "title": "Social Science–guided Feature Engineering: A Novel Approach to Signed Link Analysis",
    "doi": null,
    "publication_date": "2020-01-09",
    "publication_year": 2020,
    "authors": "Ghazaleh Beigi; Jiliang Tang; Huan Liu",
    "corresponding_authors": "",
    "abstract": "Many real-world relations can be represented by signed networks with positive links (e.g., friendships and trust) and negative links (e.g., foes and distrust). Link prediction helps advance tasks in social network analysis such as recommendation systems. Most existing work on link analysis focuses on unsigned social networks. The existence of negative links piques research interests in investigating whether properties and principles of signed networks differ from those of unsigned networks and mandates dedicated efforts on link analysis for signed social networks. Recent findings suggest that properties of signed networks substantially differ from those of unsigned networks and negative links can be of significant help in signed link analysis in complementary ways. In this article, we center our discussion on a challenging problem of signed link analysis. Signed link analysis faces the problem of data sparsity, i.e., only a small percentage of signed links are given. This problem can even get worse when negative links are much sparser than positive ones as users are inclined more toward positive disposition rather than negative. We investigate how we can take advantage of other sources of information for signed link analysis. This research is mainly guided by three social science theories, Emotional Information, Diffusion of Innovations, and Individual Personality. Guided by these, we extract three categories of related features and leverage them for signed link analysis. Experiments show the significance of the features gleaned from social theories for signed link prediction and addressing the data sparsity challenge.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3122920151",
    "type": "article"
  },
  {
    "title": "Where2Stand",
    "doi": "https://doi.org/10.1145/2770879",
    "publication_date": "2015-10-07",
    "publication_year": 2015,
    "authors": "Yinting Wang; Mingli Song; Dacheng Tao; Yong Rui; Jiajun Bu; Ah Chung Tsoi; Shaojie Zhuo; Ping Tan",
    "corresponding_authors": "",
    "abstract": "People often take photographs at tourist sites and these pictures usually have two main elements: a person in the foreground and scenery in the background. This type of “souvenir photo” is one of the most common photos clicked by tourists. Although algorithms that aid a user-photographer in taking a well-composed picture of a scene exist [Ni et al. 2013], few studies have addressed the issue of properly positioning human subjects in photographs. In photography, the common guidelines of composing portrait images exist. However, these rules usually do not consider the background scene. Therefore, in this article, we investigate human-scenery positional relationships and construct a photographic assistance system to optimize the position of human subjects in a given background scene, thereby assisting the user in capturing high-quality souvenir photos. We collect thousands of well-composed portrait photographs to learn human-scenery aesthetic composition rules. In addition, we define a set of negative rules to exclude undesirable compositions. Recommendation results are achieved by combining the first learned positive rule with our proposed negative rules. We implement the proposed system on an Android platform in a smartphone. The system demonstrates its efficacy by producing well-composed souvenir photos.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2048647542",
    "type": "article"
  },
  {
    "title": "Crowdsourcing Human Annotation on Web Page Structure",
    "doi": "https://doi.org/10.1145/2870649",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Shuguang Han; Peng Dai; Praveen Paritosh; David Huynh",
    "corresponding_authors": "",
    "abstract": "Parsing the semantic structure of a web page is a key component of web information extraction. Successful extraction algorithms usually require large-scale training and evaluation datasets, which are difficult to acquire. Recently, crowdsourcing has proven to be an effective method of collecting large-scale training data in domains that do not require much domain knowledge. For more complex domains, researchers have proposed sophisticated quality control mechanisms to replicate tasks in parallel or sequential ways and then aggregate responses from multiple workers. Conventional annotation integration methods often put more trust in the workers with high historical performance; thus, they are called performance-based methods. Recently, Rzeszotarski and Kittur have demonstrated that behavioral features are also highly correlated with annotation quality in several crowdsourcing applications. In this article, we present a new crowdsourcing system, called Wernicke, to provide annotations for web information extraction. Wernicke collects a wide set of behavioral features and, based on these features, predicts annotation quality for a challenging task domain: annotating web page structure. We evaluate the effectiveness of quality control using behavioral features through a case study where 32 workers annotate 200 Q&amp;A web pages from five popular websites. In doing so, we discover several things: (1) Many behavioral features are significant predictors for crowdsourcing quality. (2) The behavioral-feature-based method outperforms performance-based methods in recall prediction, while performing equally with precision prediction. In addition, using behavioral features is less vulnerable to the cold-start problem, and the corresponding prediction model is more generalizable for predicting recall than precision for cross-website quality analysis. (3) One can effectively combine workers’ behavioral information and historical performance information to further reduce prediction errors.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2343442396",
    "type": "article"
  },
  {
    "title": "Efficient Methods for Influence-Based Network-Oblivious Community Detection",
    "doi": "https://doi.org/10.1145/2979682",
    "publication_date": "2016-12-06",
    "publication_year": 2016,
    "authors": "Nicola Barbieri; Francesco Bonchi; Giuseppe Manco",
    "corresponding_authors": "",
    "abstract": "We study the problem of detecting social communities when the social graph is not available but instead we have access to a log of user activity, that is, a dataset of tuples ( u , i , t ) recording the fact that user u “adopted” item i at time t . We propose a stochastic framework that assumes that the adoption of items is governed by an underlying diffusion process over the unobserved social network and that such a diffusion model is based on community-level influence . That is, we aim at modeling communities through the lenses of social contagion . By fitting the model parameters to the user activity log, we learn the community membership and the level of influence of each user in each community. The general framework is instantiated with two different diffusion models, one with discrete time and one with continuous time, and we show that the computational complexity of both approaches is linear in the number of users and in the size of the propagation log. Experiments on synthetic data with planted community structure show that our methods outperform non-trivial baselines. The effectiveness of the proposed techniques is further validated on real-word data, on which our methods are able to detect high-quality communities.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2560492758",
    "type": "article"
  },
  {
    "title": "Discovering Underlying Plans Based on Shallow Models",
    "doi": "https://doi.org/10.1145/3368270",
    "publication_date": "2020-01-24",
    "publication_year": 2020,
    "authors": "Hankz Hankui Zhuo; Yan Zha; Subbarao Kambhampati; Xin Tian",
    "corresponding_authors": "",
    "abstract": "Plan recognition aims to discover target plans (i.e., sequences of actions) behind observed actions, with history plan libraries or action models in hand. Previous approaches either discover plans by maximally “matching” observed actions to plan libraries, assuming target plans are from plan libraries, or infer plans by executing action models to best explain the observed actions, assuming that complete action models are available. In real-world applications, however, target plans are often not from plan libraries, and complete action models are often not available, since building complete sets of plans and complete action models are often difficult or expensive. In this article, we view plan libraries as corpora and learn vector representations of actions using the corpora; we then discover target plans based on the vector representations. Specifically, we propose two approaches, DUP and RNNPlanner, to discover target plans based on vector representations of actions. DUP explores the EM-style (Expectation Maximization) framework to capture local contexts of actions and discover target plans by optimizing the probability of target plans, while RNNPlanner aims to leverage long-short term contexts of actions based on RNNs (Recurrent Neural Networks) framework to help recognize target plans. In the experiments, we empirically show that our approaches are capable of discovering underlying plans that are not from plan libraries without requiring action models provided. We demonstrate the effectiveness of our approaches by comparing its performance to traditional plan recognition approaches in three planning domains. We also compare DUP and RNNPlanner to see their advantages and disadvantages.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3008027863",
    "type": "article"
  },
  {
    "title": "Learning Three-dimensional Skeleton Data from Sign Language Video",
    "doi": "https://doi.org/10.1145/3377552",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Heike Brock; Felix Law; Kazuhiro Nakadai; Yuji Nagashima",
    "corresponding_authors": "",
    "abstract": "Data for sign language research is often difficult and costly to acquire. We therefore present a novel pipeline able to generate motion three-dimensional (3D) skeleton data from single-camera sign language videos only. First, three recurrent neural networks are learned to infer the three-dimensional position data of body, face, and finger joints for a high resolution of the signer’s skeleton. Subsequently, the angular displacements of all joints over time are estimated using inverse kinematics and mapped to a virtual sign avatar for animation. Last, the generated data are evaluated in detail, including a sign language recognition and sign language synthesis scenario. Utilizing a neural word classifier trained on real motion capture data, we reliably classify word segments built from our newly generated position data with similar accuracy as motion capture data (absolute difference 3.8%). Furthermore, qualitative evaluation of sign animations shows that the avatar performs natural movements that are comprehensible and resemble animations created with original motion capture data.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3021295796",
    "type": "article"
  },
  {
    "title": "SafeRoute",
    "doi": "https://doi.org/10.1145/3402818",
    "publication_date": "2020-09-27",
    "publication_year": 2020,
    "authors": "Sharon Levy; Wenhan Xiong; Elizabeth Belding; William Yang Wang",
    "corresponding_authors": "",
    "abstract": "Recent studies show that 85% of women have changed their traveled routes to avoid harassment and assault. Despite this, current mapping tools do not empower users with information to take charge of their personal safety. We propose SafeRoute, a novel solution to the problem of navigating cities and avoiding street harassment and crime. Unlike other street navigation applications, SafeRoute introduces a new type of path generation via deep reinforcement learning. This enables us to successfully optimize for multi-criteria path-finding and incorporate representation learning within our framework. Our agent learns to pick favorable streets to create a safe and short path with a reward function that incorporates safety and efficiency. Given access to recent crime reports in many urban cities, we train our model for experiments in Boston, New York, and San Francisco. We test our model on areas of these cities, specifically the populated downtown regions with high foot traffic. We evaluate SafeRoute and successfully improve over state-of-the-art methods by up to 17% in local average distance from crimes while decreasing path length by up to 7%.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3090559339",
    "type": "article"
  },
  {
    "title": "Intelligent System of Game-Theory-Based Decision Making in Smart Sports Industry",
    "doi": "https://doi.org/10.1145/3447986",
    "publication_date": "2021-04-21",
    "publication_year": 2021,
    "authors": "Munish Bhatia",
    "corresponding_authors": "Munish Bhatia",
    "abstract": "Internet of Things (IoT) technology backed by Artificial Intelligence (AI) techniques has been increasingly utilized for the realization of the Industry 4.0 vision. Conspicuously, this work provides a novel notion of the smart sports industry for provisioning efficient services in the sports arena. Specifically, an IoT-inspired framework has been proposed for real-time analysis of athlete performance. IoT data is utilized to quantify athlete performance in the terms of probability parameters of Probabilistic Measure of Performance (PMP) and Level of Performance Measure (LoPM). Moreover, a two-player game-theory-based mathematical framework has been presented for efficient decision modeling by the monitoring officials. The presented model is validated experimentally by deployment in District Sports Academy (DSA) for 60 days over four players. Based on the comparative analysis with state-of-the-art decision-modeling approaches, the proposed model acquired enhanced performance values in terms of Temporal Delay, Classification Efficiency, Statistical Efficacy, Correlation Analysis, and Reliability.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3153998617",
    "type": "article"
  },
  {
    "title": "MetaStore: A Task-adaptative Meta-learning Model for Optimal Store Placement with Multi-city Knowledge Transfer",
    "doi": "https://doi.org/10.1145/3447271",
    "publication_date": "2021-04-21",
    "publication_year": 2021,
    "authors": "Yan Liu; Bin Guo; Daqing Zhang; Djamal Zeghlache; Jingmin Chen; Sizhe Zhang; Dan Zhou; Xinlei Shi; Zhiwen Yu",
    "corresponding_authors": "",
    "abstract": "Optimal store placement aims to identify the optimal location for a new brick-and-mortar store that can maximize its sale by analyzing and mining users’ preferences from large-scale urban data. In recent years, the expansion of chain enterprises in new cities brings some challenges because of two aspects: (1) data scarcity in new cities, so most existing models tend to not work (i.e., overfitting), because the superior performance of these works is conditioned on large-scale training samples; (2) data distribution discrepancy among different cities, so knowledge learned from other cities cannot be utilized directly in new cities. In this article, we propose a task-adaptative model-agnostic meta-learning framework, namely, MetaStore, to tackle these two challenges and improve the prediction performance in new cities with insufficient data for optimal store placement, by transferring prior knowledge learned from multiple data-rich cities. Specifically, we develop a task-adaptative meta-learning algorithm to learn city-specific prior initializations from multiple cities, which is capable of handling the multimodal data distribution and accelerating the adaptation in new cities compared to other methods. In addition, we design an effective learning strategy for MetaStore to promote faster convergence and optimization by sampling high-quality data for each training batch in view of noisy data in practical applications. The extensive experimental results demonstrate that our proposed method leads to state-of-the-art performance compared with various baselines.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3154693830",
    "type": "article"
  },
  {
    "title": "Significant DBSCAN+: Statistically Robust Density-based Clustering",
    "doi": "https://doi.org/10.1145/3474842",
    "publication_date": "2021-10-31",
    "publication_year": 2021,
    "authors": "Yiqun Xie; Xiaowei Jia; Shashi Shekhar; Han Bao; Xun Zhou",
    "corresponding_authors": "",
    "abstract": "Cluster detection is important and widely used in a variety of applications, including public health, public safety, transportation, and so on. Given a collection of data points, we aim to detect density-connected spatial clusters with varying geometric shapes and densities, under the constraint that the clusters are statistically significant. The problem is challenging, because many societal applications and domain science studies have low tolerance for spurious results, and clusters may have arbitrary shapes and varying densities. As a classical topic in data mining and learning, a myriad of techniques have been developed to detect clusters with both varying shapes and densities (e.g., density-based, hierarchical, spectral, or deep clustering methods). However, the vast majority of these techniques do not consider statistical rigor and are susceptible to detecting spurious clusters formed as a result of natural randomness. On the other hand, scan statistic approaches explicitly control the rate of spurious results, but they typically assume a single “hotspot” of over-density and many rely on further assumptions such as a tessellated input space. To unite the strengths of both lines of work, we propose a statistically robust formulation of a multi-scale DBSCAN, namely Significant DBSCAN+, to identify significant clusters that are density connected. As we will show, incorporation of statistical rigor is a powerful mechanism that allows the new Significant DBSCAN+ to outperform state-of-the-art clustering techniques in various scenarios. We also propose computational enhancements to speed-up the proposed approach. Experiment results show that Significant DBSCAN+ can simultaneously improve the success rate of true cluster detection (e.g., 10–20% increases in absolute F1 scores) and substantially reduce the rate of spurious results (e.g., from thousands/hundreds of spurious detections to none or just a few across 100 datasets), and the acceleration methods can improve the efficiency for both clustered and non-clustered data.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3216043206",
    "type": "article"
  },
  {
    "title": "Detecting and Analyzing Collusive Entities on YouTube",
    "doi": "https://doi.org/10.1145/3477300",
    "publication_date": "2021-10-31",
    "publication_year": 2021,
    "authors": "Hridoy Sankar Dutta; Mayank Jobanputra; Himani Negi; Tanmoy Chakraborty",
    "corresponding_authors": "",
    "abstract": "YouTube sells advertisements on the posted videos, which in turn enables the content creators to monetize their videos. As an unintended consequence, this has proliferated various illegal activities such as artificial boosting of views, likes, comments, and subscriptions. We refer to such videos (gaining likes and comments artificially) and channels (gaining subscriptions artificially) as “collusive entities.” Detecting such collusive entities is an important yet challenging task. Existing solutions mostly deal with the problem of spotting fake views, spam comments, fake content, and so on, and oftentimes ignore how such fake activities emerge via collusion. Here, we collect a large dataset consisting of two types of collusive entities on YouTube— videos submitted to gain collusive likes and comment requests and channels submitted to gain collusive subscriptions. We begin by providing an in-depth analysis of collusive entities on YouTube fostered by various blackmarket services . Following this, we propose models to detect three types of collusive YouTube entities: videos seeking collusive likes, channels seeking collusive subscriptions, and videos seeking collusive comments. The third type of entity is associated with temporal information. To detect videos and channels for collusive likes and subscriptions, respectively, we utilize one-class classifiers trained on our curated collusive entities and a set of novel features. The SVM-based model shows significant performance with a true positive rate of 0.911 and 0.910 for detecting collusive videos and collusive channels, respectively. To detect videos seeking collusive comments, we propose CollATe , a novel end-to-end neural architecture that leverages time-series information of posted comments along with static metadata of videos. CollATe is composed of three components: metadata feature extractor (which derives metadata-based features from videos), anomaly feature extractor (which utilizes the time-series data to detect sudden changes in the commenting activity), and comment feature extractor (which utilizes the text of the comments posted during collusion and computes a similarity score between the comments). Extensive experiments show the effectiveness of CollATe (with a true positive rate of 0.905) over the baselines.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3217255646",
    "type": "article"
  },
  {
    "title": "Integrating Algorithmic Sampling-Based Motion Planning with Learning in Autonomous Driving",
    "doi": "https://doi.org/10.1145/3469086",
    "publication_date": "2022-01-18",
    "publication_year": 2022,
    "authors": "Yifan Zhang; Jinghuai Zhang; Jindi Zhang; Jianping Wang; Kejie Lu; Jeff Hong",
    "corresponding_authors": "",
    "abstract": "Sampling-based motion planning (SBMP) is a major algorithmic trajectory planning approach in autonomous driving given its high efficiency and outstanding performance in practice. However, driving safety still calls for further refinement of SBMP. In this article we organically integrate algorithmic motion planning with learning models to improve SBMP in highway traffic scenarios from the following two perspectives. First, given the number of points to be sampled, we develop a new model to sample “important” points for SBMP by predicting the intention of surrounding vehicles and learning the distribution of human drivers’ trajectory. Second, we empirically study the relationship between the number of sample points and the environment, which is largely ignored in conventional SBMP. Then, we provide a guideline to select the appropriate number of points to be sampled under different scenarios to guarantee efficiency. The simulation experiments are conducted based on the vehicle trajectory dataset NGSIM. The results show that the proposed sampling strategy outperforms existing sampling strategies in terms of the computing time, traveling time, and smoothness of the trajectory.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4205266671",
    "type": "article"
  },
  {
    "title": "Modeling Continuous Time Sequences with Intermittent Observations using Marked Temporal Point Processes",
    "doi": "https://doi.org/10.1145/3545118",
    "publication_date": "2022-06-24",
    "publication_year": 2022,
    "authors": "Vinayak Gupta; Srikanta Bedathur; Sourangshu Bhattacharya; Abir De",
    "corresponding_authors": "",
    "abstract": "A large fraction of data generated via human activities such as online purchases, health records, spatial mobility etc. can be represented as a sequence of events over a continuous-time. Learning deep learning models over these continuous-time event sequences is a non-trivial task as it involves modeling the ever-increasing event timestamps, inter-event time gaps, event types, and the influences between different events within and across different sequences. In recent years neural enhancements to marked temporal point processes (MTPP) have emerged as a powerful framework to model the underlying generative mechanism of asynchronous events localized in continuous time. However, most existing models and inference methods in the MTPP framework consider only the complete observation scenario i.e. the event sequence being modeled is completely observed with no missing events -- an ideal setting that is rarely applicable in real-world applications. A recent line of work which considers missing events while training MTPP utilizes supervised learning techniques that require additional knowledge of missing or observed label for each event in a sequence, which further restricts its practicability as in several scenarios the details of missing events is not known apriori. In this work, we provide a novel unsupervised model and inference method for learning MTPP in presence of event sequences with missing events. Specifically, we first model the generative processes of observed events and missing events using two MTPP, where the missing events are represented as latent random variables. Then, we devise an unsupervised training method that jointly learns both the MTPP by means of variational inference. Such a formulation can effectively impute the missing data among the observed events and can identify the optimal position of missing events in a sequence.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4283379060",
    "type": "article"
  },
  {
    "title": "Deep Learning Embedded into Smart Traps for Fruit Insect Pests Detection",
    "doi": "https://doi.org/10.1145/3552435",
    "publication_date": "2022-07-30",
    "publication_year": 2022,
    "authors": "Lucas de Souza Freitas; Valter A. M. Martins; Marílton Sanchotene de Aguiar; Lisane Brisolara; Paulo R. Ferreira",
    "corresponding_authors": "",
    "abstract": "This article presents a novel approach to identify two species of fruit insect pests as part of a network of intelligent traps designed to monitor the population of these insects in a plantation. The proposed approach uses a simple Digital Image Processing technique to detect regions in the image that are likely the monitored pests and an Artificial Neural Network to classify the regions into the right class given their characteristics. This identification is done essentially by a Convolutional Neural Network (CNN), which learns the characteristics of the insects based on their images made from the adhesive floor inside a trap. We have trained several CNN architectures, with different configurations, through a data set of images collected in the field. We aimed to find the model with the highest precision and the lowest time needed for the classification. The best performance in classification was achieved by ResNet18, with a precision of 93.55% and 91.28% for the classification of the pests focused on this study, named Ceratitis capitata and Grapholita molesta , respectively, and a 90.72%overall accuracy. Yet, the classification must be embedded on a resource-constrained system inside the trap, then we exploited SqueezeNet, MobileNet, and MNASNet architectures to achieve a model with lesser inference time and small losses in accuracy when compared to the models we assessed. We also attempted to quantize our highest precision model to reduce even more inference time in embedded systems, which achieved a precision of 88.76% and 89.73% for C. capitata and G. molesta , respectively; notwithstanding, a decrease of roughly 2% on the overall accuracy was endured. According to the expertise of our partner company, our results are worthwhile for a real-world application, since general human laborers have a precision of about 85%.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4288758450",
    "type": "article"
  },
  {
    "title": "On the Relationship between Explanation and Recommendation: Learning to Rank Explanations for Improved Performance",
    "doi": "https://doi.org/10.1145/3569423",
    "publication_date": "2022-10-25",
    "publication_year": 2022,
    "authors": "Lei Li; Yongfeng Zhang; Li Chen",
    "corresponding_authors": "",
    "abstract": "Explaining to users why some items are recommended is critical, as it can help users to make better decisions, increase their satisfaction, and gain their trust in recommender systems (RS). However, existing explainable RS usually consider explanation as a side output of the recommendation model, which has two problems: (1) It is difficult to evaluate the produced explanations, because they are usually model-dependent, and (2) as a result, how the explanations impact the recommendation performance is less investigated. In this article, explaining recommendations is formulated as a ranking task and learned from data, similarly to item ranking for recommendation. This makes it possible for standard evaluation of explanations via ranking metrics (e.g., Normalized Discounted Cumulative Gain). Furthermore, this article extends traditional item ranking to an item–explanation joint-ranking formalization to study if purposely selecting explanations could reach certain learning goals, e.g., improving recommendation performance. A great challenge, however, is that the sparsity issue in the user-item-explanation data would be inevitably severer than that in traditional user–item interaction data, since not every user–item pair can be associated with all explanations. To mitigate this issue, this article proposes to perform two sets of matrix factorization by considering the ternary relationship as two groups of binary relationships. Experiments on three large datasets verify the solution’s effectiveness on both explanation ranking and item recommendation.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4307380586",
    "type": "article"
  },
  {
    "title": "Saliency Attack: Towards Imperceptible Black-box Adversarial Attack",
    "doi": "https://doi.org/10.1145/3582563",
    "publication_date": "2023-02-02",
    "publication_year": 2023,
    "authors": "Zeyu Dai; Shengcai Liu; Qing Li; Ke Tang",
    "corresponding_authors": "",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, even in the black-box setting where the attacker is only accessible to the model output. Recent studies have devised effective black-box attacks with high query efficiency. However, such performance is often accompanied by compromises in attack imperceptibility, hindering the practical use of these approaches. In this article, we propose to restrict the perturbations to a small salient region to generate adversarial examples that can hardly be perceived. This approach is readily compatible with many existing black-box attacks and can significantly improve their imperceptibility with little degradation in attack success rates. Furthermore, we propose the Saliency Attack, a new black-box attack aiming to refine the perturbations in the salient region to achieve even better imperceptibility. Extensive experiments show that compared to the state-of-the-art black-box attacks, our approach achieves much better imperceptibility scores, including most apparent distortion (MAD), L 0 and L 2 distances, and also obtains significantly better true success rate and effective query number judged by a human-like threshold on MAD. Importantly, the perturbations generated by our approach are interpretable to some extent. Finally, it is also demonstrated to be robust to different detection-based defenses.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4319034522",
    "type": "article"
  },
  {
    "title": "Noise-aware Local Model Training Mechanism for Federated Learning",
    "doi": "https://doi.org/10.1145/3591363",
    "publication_date": "2023-05-02",
    "publication_year": 2023,
    "authors": "Jinghui Zhang; Dingyang Lv; Qiangsheng Dai; Fa Xin; Fang Dong",
    "corresponding_authors": "",
    "abstract": "As a new paradigm in training intelligent models, federated learning is widely used to train a global model without requiring local data to be uploaded from end devices. However, there are often mislabeled samples (i.e., noisy samples) in the dataset, which will cause the model update to deviate from the correct direction during the training process, thus reducing the convergence accuracy of the global model. Existing works employ noisy label correction techniques to reduce the impact of noisy samples on model updates by correcting labels; however, such methods necessitate the use of prior knowledge and additional communication costs, which cannot be directly applied to federated learning due to data privacy concerns and limited communication resources. Therefore, this paper proposes a noise-aware local model training method that corrects the noisy labels directly at the end device under the constraints of federated learning. By constructing a label correction model, a joint optimization problem is formally defined for optimizing both the label correction model and the client-side local training model (e.g., classification model). As a solution to this optimization problem, we propose a robustness training algorithm using label correction, along with a cross-validation data sampling algorithm that updates both models simultaneously. It is verified through experiments that the mechanism can effectively improve the model convergence accuracy on noisy datasets in federated learning scenarios.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4367677014",
    "type": "article"
  },
  {
    "title": "Causal Feature Selection in the Presence of Sample Selection Bias",
    "doi": "https://doi.org/10.1145/3604809",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Shuai Yang; Xianjie Guo; Kui Yu; Xiaoling Huang; Tingting Jiang; Jin He; Lichuan Gu",
    "corresponding_authors": "",
    "abstract": "Almost all existing causal feature selection methods are proposed without considering the problem of sample selection bias. However, in practice, as data-gathering process cannot be fully controlled, sample selection bias often occurs, leading to spurious correlations between features and the class variable, which seriously deteriorates the performance of those existing methods. In this article, we study the problem of causal feature selection under sample selection bias and propose a novel Progressive Causal Feature Selection (PCFS) algorithm which has three phases. First, PCFS learns the sample weights to balance the treated group and control group distributions corresponding to each feature for removing spurious correlations. Second, based on the sample weights, PCFS uses a weighted cross-entropy model to estimate the causal effect of each feature and removes some irrelevant features from the confounder set. Third, PCFS progressively repeats the first two phases to remove more irrelevant features and finally obtains a causal feature set. Using synthetic and real-world datasets, the experiments have validated the effectiveness of PCFS, in comparison with several state-of-the-art classical and causal feature selection methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4381050468",
    "type": "article"
  },
  {
    "title": "Data-Aware Declarative Process Mining with SAT",
    "doi": "https://doi.org/10.1145/3600106",
    "publication_date": "2023-05-30",
    "publication_year": 2023,
    "authors": "Fabrizio Maria Maggi; Andrea Marrella; Fabio Patrizi; Vasyl Skydanienko",
    "corresponding_authors": "",
    "abstract": "Process Mining is a family of techniques for analyzing business process execution data recorded in event logs. Process models can be obtained as output of automated process discovery techniques or can be used as input of techniques for conformance checking or model enhancement. In Declarative Process Mining, process models are represented as sets of temporal constraints (instead of procedural descriptions where all control-flow details are explicitly modeled). An open research direction in Declarative Process Mining is whether multi-perspective specifications can be supported, i.e., specifications that not only describe the process behavior from the control-flow point of view, but also from other perspectives like data or time. In this article, we address this question by considering SAT (Propositional Satisfiability Problem) as a solving technology for a number of classical problems in Declarative Process Mining, namely, log generation, conformance checking, and temporal query checking. To do so, we first express each problem as a suitable FO (First-Order) theory whose bounded models represent solutions to the problem, and then find a bounded model of such theory by compilation into SAT.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4381279306",
    "type": "article"
  },
  {
    "title": "Explainable Product Classification for Customs",
    "doi": "https://doi.org/10.1145/3635158",
    "publication_date": "2023-12-01",
    "publication_year": 2023,
    "authors": "Eunji Lee; Sihyeon Kim; Sundong Kim; Soyeon Jung; Heeja Kim; Meeyoung Cha",
    "corresponding_authors": "",
    "abstract": "The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4389237479",
    "type": "article"
  },
  {
    "title": "Generating Daily Activities with Need Dynamics",
    "doi": "https://doi.org/10.1145/3637493",
    "publication_date": "2023-12-14",
    "publication_year": 2023,
    "authors": "Yuan Yuan; Jingtao Ding; Huandong Wang; Depeng Jin",
    "corresponding_authors": "",
    "abstract": "Daily activity data recording individuals’ various activities in daily life are widely used in many applications such as activity scheduling, activity recommendation, and policymaking. Though with high value, its accessibility is limited due to high collection costs and potential privacy issues. Therefore, simulating human activities to produce massive high-quality data is of great importance. However, existing solutions, including rule-based methods with simplified behavior assumptions and data-driven methods directly fitting real-world data, both cannot fully qualify for matching reality. In this article, motivated by the classic psychological theory, Maslow’s need theory describing human motivation, we propose a knowledge-driven simulation framework based on generative adversarial imitation learning. Our core idea is to model the evolution of human needs as the underlying mechanism that drives activity generation in the simulation model. Specifically, a hierarchical model structure that disentangles different need levels and the use of neural stochastic differential equations successfully capture the piecewise-continuous characteristics of need dynamics. Extensive experiments demonstrate that our framework outperforms the state-of-the-art baselines regarding data fidelity and utility. We also present the insightful interpretability of the need modeling. Moreover, privacy preservation evaluations validate that the generated data does not leak individual privacy. The code is available at https://github.com/tsinghua-fib-lab/Activity-Simulation-SAND .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4389736340",
    "type": "article"
  },
  {
    "title": "Recommender System-Induced Eating Disorder Relapse: Harmful Content and the Challenges of Responsible Recommendation",
    "doi": "https://doi.org/10.1145/3675404",
    "publication_date": "2024-07-05",
    "publication_year": 2024,
    "authors": "Jennifer Golbeck",
    "corresponding_authors": "Jennifer Golbeck",
    "abstract": "As users’ social media feeds have become increasingly driven by algorithmically recommended content, there is a need to understand the impact these recommendations have on users. People in recovery from eating disorders (ED) may try to avoid content that features severely underweight bodies or that encourages disordered eating. However, if recommender systems show them this type of content anyway, it may impact their recovery or even lead to relapse. In this study, we take a two-pronged approach to understanding the intersection of recommender systems, eating disorder content, and users in recovery. We performed a content analysis of tweets about recommended eating disorder content and conducted a small-scale study on Pinterest to show that eating disorder content is recommended in response to interaction with posts about eating disorder recovery. We discuss the implications for responsible recommendation and harm prevention.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4400360220",
    "type": "article"
  },
  {
    "title": "A constraint-based approach to scheduling an individual's activities",
    "doi": "https://doi.org/10.1145/1869397.1869401",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Ioannis Refanidis; Neil Yorke‐Smith",
    "corresponding_authors": "",
    "abstract": "The goal of helping to automate the management of an individual's time is ambitious in terms both of knowledge engineering and of the quality of the plans produced by an AI system. Modeling an individual's activities is itself a challenge, due to the variety of activity, constraint, and preference types involved. Activities might be simple or interruptible; they might have fixed or variable durations, constraints over their temporal domains, and binary constraints between them. Activities might require the individual being at specific locations in order, whereas traveling time should be taken into account. Some activities might require exclusivity, whereas others can be overlapped with compatible concurrent activities. Finally, while scheduled activities generate utility for the individual, extra utility might result from the way activities are scheduled in time, individually and in conjunction. This article presents a rigorous, expressive model to represent an individual's activities, that is, activities whose scheduling is not contingent on any other person. Joint activities such as meetings are outside our remit; it is expected that these are arranged manually or through negotiation mechanisms and they are considered as fixed busy times in the individual's calendar. The model, formulated as a constraint optimization problem, is general enough to accommodate a variety of situations. We present a scheduler that operates on this rich model, based on the general squeaky wheel optimization framework and enhanced with domain-dependent heuristics and forward checking. Our empirical evaluation demonstrates both the efficiency and the effectiveness of the selected approach. Part of the work described has been implemented in the SelfPlanner system, a Web-based intelligent calendar application that utilizes Google Calendar.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2125129296",
    "type": "article"
  },
  {
    "title": "Context-Aware Semi-Local Feature Detector",
    "doi": "https://doi.org/10.1145/2168752.2168758",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Rongrong Ji; Hongxun Yao; Qi Tian; Pengfei Xu; Xiaoshuai Sun; Xianming Liu",
    "corresponding_authors": "",
    "abstract": "How can interest point detectors benefit from contextual cues? In this articles, we introduce a context-aware semi-local detector (CASL) framework to give a systematic answer with three contributions: (1) We integrate the context of interest points to recurrently refine their detections. (2) This integration boosts interest point detectors from the traditionally local scale to a semi-local scale to discover more discriminative salient regions. (3) Such context-aware structure further enables us to bring forward category learning (usually in the subsequent recognition phase) into interest point detection to locate category-aware, meaningful salient regions. Our CASL detector consists of two phases. The first phase accumulates multiscale spatial correlations of local features into a difference of contextual Gaussians (DoCG) field. DoCG quantizes detector context to highlight contextually salient regions at a semi-local scale, which also reveals visual attentions to a certain extent. The second phase locates contextual peaks by mean shift search over the DoCG field, which subsequently integrates contextual cues into feature description. This phase enables us to integrate category learning into mean shift search kernels. This learning-based CASL mechanism produces more category-aware features, which substantially benefits the subsequent visual categorization process. We conducted experiments in image search, object characterization, and feature detector repeatability evaluations, which reported superior discriminability and comparable repeatability to state-of-the-art works.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2060698367",
    "type": "article"
  },
  {
    "title": "Formalizing and verifying protocol refinements",
    "doi": "https://doi.org/10.1145/2438653.2438656",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Scott N. Gerard; Munindar P. Singh",
    "corresponding_authors": "",
    "abstract": "A (business) protocol describes, in high-level terms, a pattern of communication between two or more participants, specifically via the creation and manipulation of the commitments between them. In this manner, a protocol offers both flexibility and rigor: a participant may communicate in any way it chooses as long as it discharges all of its activated commitments. Protocols thus promise benefits in engineering cross-organizational business processes. However, software engineering using protocols presupposes a formalization of protocols and a notion of the refinement of one protocol by another. Refinement for protocols is both intuitively obvious (e.g., PayViaCheck is clearly a kind of Pay ) and technically nontrivial (e.g., compared to Pay , PayViaCheck involves different participants exchanging different messages). This article formalizes protocols and their refinement. It develops Proton, an analysis tool for protocol specifications that overlays a model checker to compute whether one protocol refines another with respect to a stated mapping. Proton and its underlying theory are evaluated by formalizing several protocols from the literature and verifying all and only the expected refinements.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2085299005",
    "type": "article"
  },
  {
    "title": "Adversarial Geospatial Abduction Problems",
    "doi": "https://doi.org/10.1145/2089094.2089110",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Paulo Shakarian; John P. Dickerson; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Geospatial Abduction Problems (GAPs) involve the inference of a set of locations that “best explain” a given set of locations of observations. For example, the observations might include locations where a serial killer committed murders or where insurgents carried out Improvised Explosive Device (IED) attacks. In both these cases, we would like to infer a set of locations that explain the observations, for example, the set of locations where the serial killer lives/works, and the set of locations where insurgents locate weapons caches. However, unlike all past work on abduction, there is a strong adversarial component to this; an adversary actively attempts to prevent us from discovering such locations. We formalize such abduction problems as a two-player game where both players (an “agent” and an “adversary”) use a probabilistic model of their opponent (i.e., a mixed strategy). There is asymmetry as the adversary can choose both the locations of the observations and the locations of the explanation, while the agent (i.e., us) tries to discover these. In this article, we study the problem from the point of view of both players. We define reward functions axiomatically to capture the similarity between two sets of explanations (one corresponding to the locations chosen by the adversary, one guessed by the agent). Many different reward functions can satisfy our axioms. We then formalize the Optimal Adversary Strategy (OAS) problem and the Maximal Counter-Adversary strategy (MCA) and show that both are NP-hard, that their associated counting complexity problems are #P-hard, and that MCA has no fully polynomial approximation scheme unless P=NP. We show that approximation guarantees are possible for MCA when the reward function satisfies two simple properties (zero-starting and monotonicity) which many natural reward functions satisfy. We develop a mixed integer linear programming algorithm to solve OAS and two algorithms to (approximately) compute MCA; the algorithms yield different approximation guarantees and one algorithm assumes a monotonic reward function. Our experiments use real data about IED attacks over a 21-month period in Baghdad. We are able to show that both the MCA algorithms work well in practice; while MCA-GREEDY-MONO is both highly accurate and slightly faster than MCA-LS, MCA-LS (to our surprise) always completely and correctly maximized the expected benefit to the agent while running in an acceptable time period.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1999390142",
    "type": "article"
  },
  {
    "title": "Latent Geospatial Semantics of Social Media",
    "doi": "https://doi.org/10.1145/2337542.2337549",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Sergej Sizov",
    "corresponding_authors": "Sergej Sizov",
    "abstract": "Multimodal understanding of shared content is an important success factor for many Web 2.0 applications and platforms. This article addresses the fundamental question of geo-spatial awareness in social media applications. In this context, we introduce an approach for improved characterization of social media by combining text features (e.g., tags as a prominent example of short, unstructured text labels) with spatial knowledge (e.g., geotags, coordinates of images, and videos). Our model-based framework GeoFolk combines these two aspects in order to construct better algorithms for content management, retrieval, and sharing. We demonstrate in systematic studies the benefits of this combination for a broad spectrum of scenarios related to social media: recommender systems, automatic content organization and filtering, and event detection. Furthermore, we establish a simple and technically sound model that can be seen as a reference baseline for future research in the field of geotagged social media.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2013345460",
    "type": "article"
  },
  {
    "title": "Data-Driven Frequency-Based Airline Profit Maximization",
    "doi": "https://doi.org/10.1145/3041217",
    "publication_date": "2017-03-22",
    "publication_year": 2017,
    "authors": "Bo An; Haipeng Chen; Noseong Park; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Although numerous traditional models predict market share and demand along airline routes, the prediction of existing models is not precise enough, and to the best of our knowledge, there is no use of data mining--based forecasting techniques for improving airline profitability. We propose the maximizing airline profits (MAP) architecture designed to help airlines and make two key contributions in airline market share and route demand prediction and prediction-based airline profit optimization. Compared to past methods used to forecast market share and demand along airline routes, we introduce a novel ensemble forecasting (MAP-EF) approach considering two new classes of features: (i) features derived from clusters of similar routes and (ii) features based on equilibrium pricing. We show that MAP-EF achieves much better Pearson correlation coefficients (greater than 0.95 vs. 0.82 for market share, 0.98 vs. 0.77 for demand) and R 2 -values compared to three state-of-the-art works for forecasting market share and demand while showing much lower variance. Using the results of MAP-EF, we develop MAP--bilevel branch and bound (MAP-BBB) and MAP-greedy (MAP-G) algorithms to optimally allocate flight frequencies over multiple routes to maximize an airline’s profit. We also study two extensions of the profit maximization problem considering frequency constraints and long-term profits. Furthermore, we develop algorithms for computing Nash equilibrium frequencies when there are multiple strategic airlines. Experimental results show that airlines can increase profits by a significant margin. All experiments were conducted with data aggregated from four sources: the U.S. Bureau of Transportation Statistics (BTS), the U.S. Bureau of Economic Analysis (BEA), the National Transportation Safety Board (NTSB), and the U.S. Census Bureau (CB).",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2603226953",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Mobile Video Streaming",
    "doi": "https://doi.org/10.1145/3102301",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Wei Zhang; Rui Fan; Yonggang Wen; Zhiyuan Liu",
    "corresponding_authors": "",
    "abstract": "Video streaming is one of the most widely used mobile applications today, and it also accounts for a large fraction of mobile battery usage. Much of the energy consumption is for wireless data transmission and is highly correlated to network bandwidth conditions. In periods of poor connectivity, up to 90% of mobile energy can be used for wireless data transfer. In this article, we study the problem of energy-efficient mobile video streaming. We make use of the observed correlation between bandwidth and user location , and also observe that a user’s location is predictable in many situations, such as when commuting to a known destination. Based on the user’s predicted locations and bandwidth conditions, we optimize wireless transmission times to achieve high quality video playback while minimizing energy use. We propose an optimal offline algorithm for this problem, which runs in O ( Tk ) time, where T is the duration of the video and k is the size of the video buffer. We also propose LAWS, a Location AWare Streaming algorithm. LAWS learns from historical location-aware bandwidth conditions and predicts future bandwidths along a planned route to make online wireless download decisions. We evaluate LAWS using real bandwidth traces, and show that LAWS closely approximates the performance of the optimal offline algorithm, achieving 90.6% of the optimal performance on average, and 97% in certain cases. LAWS also outperforms three popular strategies used in practice by, on average, 69%, 63%, and 38%, respectively. Lastly, we show that LAWS is able to deal with noisy data and can attain the stated performance after sampling bandwidth conditions only five times.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2747573668",
    "type": "article"
  },
  {
    "title": "Exploring Indoor White Spaces in Metropolises",
    "doi": "https://doi.org/10.1145/3059149",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Xuhang Ying; Jincheng Zhang; Lichao Yan; Yu Chen; Guanglin Zhang; Minghua Chen; Ranveer Chandra",
    "corresponding_authors": "",
    "abstract": "It is a promising vision to exploit white spaces , that is, vacant VHF and UHF TV channels, to meet the rapidly growing demand for wireless data services in both outdoor and indoor scenarios. While most prior works have focused on outdoor white space, the indoor story is largely open for investigation. Motivated by this observation and discovering that 70% of the spectrum demand comes from indoor environment, we carry out a comprehensive study to explore indoor white spaces. We first conduct a large-scale measurement study and compare outdoor and indoor TV spectrum occupancy at 30+ diverse locations in a typical metropolis—Hong Kong. Our results show that abundant white spaces are available in different areas in Hong Kong, which account for more than 50% and 70% of the entire TV spectrum in outdoor and indoor scenarios, respectively. Although there are substantially more white spaces indoors than outdoors, there have been very few solutions for identifying indoor white space. To fill in this gap, we develop the first data-driven, low-cost indoor white space identification system for White-space Indoor Spectrum EnhanceR (WISER), to allow secondary users to identify white spaces for communication without sensing the spectrum themselves. We design the architecture and algorithms to address the inherent challenges. We build a WISER prototype and carry out real-world experiments to evaluate its performance. Our results show that WISER can identify 30%--40% more indoor white spaces with negligible false alarms, as compared to alternative baseline approaches.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2748137522",
    "type": "article"
  },
  {
    "title": "Risk-Sensitive Stochastic Orienteering Problems for Trip Optimization in Urban Environments",
    "doi": "https://doi.org/10.1145/3080575",
    "publication_date": "2018-02-08",
    "publication_year": 2018,
    "authors": "Pradeep Varakantham; Akshat Kumar; Hoong Chuin Lau; William Yeoh",
    "corresponding_authors": "",
    "abstract": "Orienteering Problems (OPs) are used to model many routing and trip planning problems. OPs are a variant of the well-known traveling salesman problem where the goal is to compute the highest reward path that includes a subset of vertices and has an overall travel time less than a specified deadline. However, the applicability of OPs is limited due to the assumption of deterministic and static travel times. To that end, Campbell et al. extended OPs to Stochastic OPs (SOPs) to represent uncertain travel times (Campbell et al. 2011). In this article, we make the following key contributions: (1) We extend SOPs to Dynamic SOPs (DSOPs), which allow for time-dependent travel times; (2) we introduce a new objective criterion for SOPs and DSOPs to represent a percentile measure of risk; (3) we provide non-linear optimization formulations along with their linear equivalents for solving the risk-sensitive SOPs and DSOPs; (4) we provide a local search mechanism for solving the risk-sensitive SOPs and DSOPs; and (5) we provide results on existing benchmark problems and a real-world theme park trip planning problem.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2792788646",
    "type": "article"
  },
  {
    "title": "Dynamic Optimization of the Level of Operational Effectiveness of a CSOC Under Adverse Conditions",
    "doi": "https://doi.org/10.1145/3173457",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Ankit Shah; Rajesh Ganesan; Sushil Jajodia; Hasan Çam",
    "corresponding_authors": "",
    "abstract": "The analysts at a cybersecurity operations center (CSOC) analyze the alerts that are generated by intrusion detection systems (IDSs). Under normal operating conditions, sufficient numbers of analysts are available to analyze the alert workload. For the purpose of this article, this means that the cybersecurity analysts in each shift can fully investigate each and every alert that is generated by the IDSs in a reasonable amount of time and perform their normal tasks in a shift. Normal tasks include analysis time, time to attend training programs, report writing time, personal break time, and time to update the signatures on new patterns in alerts as detected by the IDS. There are several disruptive factors that occur randomly and can adversely impact the normal operating condition of a CSOC, such as (1) higher alert generation rates from a few IDSs, (2) new alert patterns that decrease the throughput of the alert analysis process, and (3) analyst absenteeism. The impact of the preceding factors is that the alerts wait for a long duration before being analyzed, which impacts the level of operational effectiveness (LOE) of the CSOC. To return the CSOC to normal operating conditions, the manager of a CSOC can take several actions, such as increasing the alert analysis time spent by analysts in a shift by canceling a training program, spending some of his own time to assist the analysts in alert investigation, and calling upon the on-call analyst workforce to boost the service rate of alerts. However, additional resources are limited in quantity over a 14-day work cycle, and the CSOC manager must determine when and how much action to take in the face of uncertainty, which arises from both the intensity and the random occurrences of the disruptive factors. The preceding decision by the CSOC manager is nontrivial and is often made in an ad hoc manner using prior experiences. This work develops a reinforcement learning (RL) model for optimizing the LOE throughout the entire 14-day work cycle of a CSOC in the face of uncertainties due to disruptive events. Results indicate that the RL model is able to assist the CSOC manager with a decision support tool to make better decisions than current practices in determining when and how much resource to allocate when the LOE of a CSOC deviates from the normal operating condition.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2802236629",
    "type": "article"
  },
  {
    "title": "Analysis of the Impact of a Tag Recommendation System in a Real-World Folksonomy",
    "doi": "https://doi.org/10.1145/2743026",
    "publication_date": "2015-09-22",
    "publication_year": 2015,
    "authors": "Frederic Font; Joan Serrà; Xavier Serra",
    "corresponding_authors": "",
    "abstract": "Collaborative tagging systems have emerged as a successful solution for annotating contributed resources to online sharing platforms, facilitating searching, browsing, and organizing their contents. To aid users in the annotation process, several tag recommendation methods have been proposed. It has been repeatedly hypothesized that these methods should contribute to improving annotation quality and reducing the cost of the annotation process. It has been also hypothesized that these methods should contribute to the consolidation of the vocabulary of collaborative tagging systems. However, to date, no empirical and quantitative result supports these hypotheses. In this work, we deeply analyze the impact of a tag recommendation system in the folksonomy of Freesound, a real-world and large-scale online sound sharing platform. Our results suggest that tag recommendation effectively increases vocabulary sharing among users of the platform. In addition, tag recommendation is shown to contribute to the convergence of the vocabulary as well as to a partial increase in the quality of annotations. However, according to our analysis, the cost of the annotation process does not seem to be effectively reduced. Our work is relevant to increase our understanding about the nature of tag recommendation systems and points to future directions for the further development of those systems and their analysis.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1967841946",
    "type": "article"
  },
  {
    "title": "Significant Correlation Pattern Mining in Smart Homes",
    "doi": "https://doi.org/10.1145/2700484",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Yi‐Cheng Chen; Wen-Chih Peng; Jiun‐Long Huang; Wang-Chien Lee",
    "corresponding_authors": "",
    "abstract": "Owing to the great advent of sensor technology, the usage data of appliances in a house can be logged and collected easily today. However, it is a challenge for the residents to visualize how these appliances are used. Thus, mining algorithms are much needed to discover appliance usage patterns. Most previous studies on usage pattern discovery are mainly focused on analyzing the patterns of single appliance rather than mining the usage correlation among appliances. In this article, a novel algorithm, namely Correlation Pattern Miner (CoPMiner), is developed to capture the usage patterns and correlations among appliances probabilistically. CoPMiner also employs four pruning techniques and a statistical model to reduce the search space and filter out insignificant patterns, respectively. Furthermore, the proposed algorithm is applied on a real-world dataset to show the practicability of correlation pattern mining.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2060549966",
    "type": "article"
  },
  {
    "title": "Validation of an ontological medical decision support system for patient treatment using a repository of patient data",
    "doi": "https://doi.org/10.1145/2508037.2508049",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Atif Khan; John A. Doucette; Robin Cohen",
    "corresponding_authors": "",
    "abstract": "In this article, we begin by presenting OMeD, a medical decision support system, and argue for its value over purely probabilistic approaches that reason about patients for time-critical decision scenarios. We then progress to present Holmes, a Hybrid Ontological and Learning MEdical System which supports decision making about patient treatment. This system is introduced in order to cope with the case of missing data. We demonstrate its effectiveness by operating on an extensive set of real-world patient health data from the CDC, applied to the decision-making scenario of administering sleeping pills. In particular, we clarify how the combination of semantic, ontological representations, and probabilistic reasoning together enable the proposal of effective patient treatments. Our focus is thus on presenting an approach for interpreting medical data in the context of real-time decision making. This constitutes a comprehensive framework for the design of medical recommendation systems for potential use by medical professionals and patients both, with the end result being personalized patient treatment. We conclude with a discussion of the value of our particular approach for such diverse considerations as coping with misinformation provided by patients, performing effectively in time-critical environments where real-time decisions are necessary, and potential applications facilitating patient information gathering.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2081989102",
    "type": "article"
  },
  {
    "title": "A Novel Classification Framework for Evaluating Individual and Aggregate Diversity in Top-N Recommendations",
    "doi": "https://doi.org/10.1145/2700491",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Jennifer Moody; David H. Glass",
    "corresponding_authors": "",
    "abstract": "The primary goal of a recommender system is to generate high quality user-centred recommendations. However, the traditional evaluation methods and metrics were developed before researchers understood all the factors that increase user satisfaction. This study is an introduction to a novel user and item classification framework. It is proposed that this framework should be used during user-centred evaluation of recommender systems and the need for this framework is justified through experiments. User profiles are constructed and matched against other users’ profiles to formulate neighbourhoods and generate top-N recommendations. The recommendations are evaluated to measure the success of the process. In conjunction with the framework, a new diversity metric is presented and explained. The accuracy, coverage, and diversity of top-N recommendations is illustrated and discussed for groups of users. It is found that in contradiction to common assumptions, not all users suffer as expected from the data sparsity problem. In fact, the group of users that receive the most accurate recommendations do not belong to the least sparse area of the dataset.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2262226974",
    "type": "article"
  },
  {
    "title": "<i>Daehr</i>",
    "doi": "https://doi.org/10.1145/3007195",
    "publication_date": "2017-02-08",
    "publication_year": 2017,
    "authors": "Haoyi Xiong; Jinghe Zhang; Yu Huang; Kevin Leach; Laura E. Barnes",
    "corresponding_authors": "",
    "abstract": "Electronic health records (EHR) provide a rich source of temporal data that present a unique opportunity to characterize disease patterns and risk of imminent disease. While many data-mining tools have been adopted for EHR-based disease early detection, linear discriminant analysis (LDA) is one of the most commonly used statistical methods. However, it is difficult to train an accurate LDA model for early disease diagnosis when too few patients are known to have the target disease. Furthermore, EHR data are heterogeneous with significant noise. In such cases, the covariance matrices used in LDA are usually singular and estimated with a large variance. This article presents Daehr , an extension of the LDA framework using electronic health record data to address these issues. Beyond existing LDA analyzers, we propose Daehr to (1) eliminate the data noise caused by the manual encoding of EHR data and (2) lower the variance of parameter (covariance matrices) estimation for LDA models when only a few patients’ EHR are available for training. To achieve these two goals, we designed an iterative algorithm to improve the covariance matrix estimation with embedded data-noise/parameter-variance reduction for LDA. We evaluated Daehr extensively using the College Health Surveillance Network, a large, real-world EHR dataset. Specifically, our experiments compared the performance of LDA to three baselines (i.e., LDA and its derivatives) in identifying college students at high risk for mental health disorders from 23 U.S. universities. Experimental results demonstrate Daehr significantly outperforms the three baselines by achieving 1.4%--19.4% higher accuracy and a 7.5%--43.5% higher F1-score.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2586515896",
    "type": "article"
  },
  {
    "title": "Analyzing and Optimizing Access Control Choice Architectures in Online Social Networks",
    "doi": "https://doi.org/10.1145/3046676",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Ron S. Hirschprung; Eran Toch; Hadas Chassidim; Tamir Mendel; Oded Maimon",
    "corresponding_authors": "",
    "abstract": "The way users manage access to their information and computers has a tremendous effect on the overall security and privacy of individuals and organizations. Usually, access management is conducted using a choice architecture , a behavioral economics concept that describes the way decisions are framed to users. Studies have consistently shown that the design of choice architectures, mainly the selection of default options, has a strong effect on the final decisions users make by nudging them toward certain behaviors. In this article, we propose a method for optimizing access control choice architectures in online social networks. We empirically evaluate the methodology on Facebook, the world's largest online social network, by measuring how well the default options cover the existing user choices and preferences and toward which outcome the choice architecture nudges users. The evaluation includes two parts: (a) collecting access control decisions made by 266 users of Facebook for a period of 3 months; and (b) surveying 533 participants who were asked to express their preferences regarding default options. We demonstrate how optimal defaults can be algorithmically identified from users’ decisions and preferences, and we measure how existing defaults address users’ preferences compared with the optimal ones. We analyze how access control defaults can better serve existing users, and we discuss how our method can be used to establish a common measuring tool when examining the effects of default options.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2613465221",
    "type": "article"
  },
  {
    "title": "ACM TIST Special Issue on Data-Driven Intelligence for Wireless Networking",
    "doi": "https://doi.org/10.1145/3104984",
    "publication_date": "2017-09-29",
    "publication_year": 2017,
    "authors": "Wenwu Zhu; Jean Walrand; Yike Guo; Zhi Wang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2759558933",
    "type": "article"
  },
  {
    "title": "Simulating Urban Pedestrian Crowds of Different Cultures",
    "doi": "https://doi.org/10.1145/3102302",
    "publication_date": "2018-01-18",
    "publication_year": 2018,
    "authors": "Gal A. Kaminka; Natalie Fridman",
    "corresponding_authors": "",
    "abstract": "Models of crowd dynamics are critically important for urban planning and management. They support analysis, facilitate qualitative and quantitative predictions, and synthesize behaviors for simulations. One promising approach to crowd modeling relies on micro-level agent-based simulations, where the interactions of simulated individual agents in the crowd result in macro-level crowd dynamics which are the object of study. This article reports on an agent-based model of urban pedestrian crowds, where culture is explicitly modeled . We extend an established agent-based social agent model, inspired by social psychology, to account for individual cultural attributes discussed in social science literature. We then embed the model in a simulation of pedestrians and explore the resulting macro-level crowd behaviors, such as pedestrian flow, lane changes rate, and so on. We validate the model by quantitatively comparing the simulation results to the pedestrian dynamics in movies of human crowds in five different countries: Iraq, Israel, England, Canada, and France. We conclude that the model can faithfully replicate urban pedestrians in different cultures. Encouraged by these results, we explore simulations of mixed-culture pedestrian crowds.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2789183464",
    "type": "article"
  },
  {
    "title": "Optimum Velocity Profile of Multiple Bernstein-Bézier Curves Subject to Constraints for Mobile Robots",
    "doi": "https://doi.org/10.1145/3183891",
    "publication_date": "2018-06-01",
    "publication_year": 2018,
    "authors": "Andrej Zdešar; Igor Škrjanc",
    "corresponding_authors": "",
    "abstract": "This article deals with trajectory planning that is suitable for nonholonomic differentially driven wheeled mobile robots. The path is approximated with a spline that consists of multiple Bernstein-Bézier curves that are merged together in a way that continuous curvature of the spline is achieved. The article presents the approach for optimization of velocity profile of Bernstein-Bézier spline subject to velocity and acceleration constraints. For the purpose of optimization, velocity and turning points are introduced. Based on these singularity points, local segments are defined where local velocity profiles are optimized independently of each other. From the locally optimum velocity profiles, the global optimum velocity profile is determined. Since each local velocity profile can be evaluated independently, the algorithm is suitable for concurrent implementation and modification of one part of the curve does not require recalculation of all local velocity profiles. These properties enable efficient implementation of the optimization algorithm. The optimization algorithm is also suitable for the splines that consist of Bernstein-Bézier curves that have substantially different lengths. The proposed optimization approach was experimentally evaluated and validated in simulation environment and on real mobile robots.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2806731640",
    "type": "article"
  },
  {
    "title": "Interactive Visual Graph Mining and Learning",
    "doi": "https://doi.org/10.1145/3200764",
    "publication_date": "2018-07-18",
    "publication_year": 2018,
    "authors": "Ryan A. Rossi; Nesreen K. Ahmed; Rong Zhou; Hoda Eldardiry",
    "corresponding_authors": "",
    "abstract": "This article presents a platform for interactive graph mining and relational machine learning called GraphVis. The platform combines interactive visual representations with state-of-the-art graph mining and relational machine learning techniques to aid in revealing important insights quickly as well as learning an appropriate and highly predictive model for a particular task (e.g., classification, link prediction, discovering the roles of nodes, and finding influential nodes). Visual representations and interaction techniques and tools are developed for simple, fast, and intuitive real-time interactive exploration, mining, and modeling of graph data. In particular, we propose techniques for interactive relational learning (e.g., node/link classification), interactive link prediction and weighting, role discovery and community detection, higher-order network analysis (via graphlets, network motifs), among others. GraphVis also allows for the refinement and tuning of graph mining and relational learning methods for specific application domains and constraints via an end-to-end interactive visual analytic pipeline that learns, infers, and provides rapid interactive visualization with immediate feedback at each change/prediction in real-time. Other key aspects include interactive filtering, querying, ranking, manipulating, exporting, as well as tools for dynamic network analysis and visualization, interactive graph generators (including new block model approaches), and a variety of multi-level network analysis techniques.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2884146159",
    "type": "article"
  },
  {
    "title": "Few-Shot Text and Image Classification via Analogical Transfer Learning",
    "doi": "https://doi.org/10.1145/3230709",
    "publication_date": "2018-10-29",
    "publication_year": 2018,
    "authors": "Wenhe Liu; Xiaojun Chang; Yan Yan; Yi Yang; Alexander G. Hauptmann",
    "corresponding_authors": "",
    "abstract": "Learning from very few samples is a challenge for machine learning tasks, such as text and image classification. Performance of such task can be enhanced via transfer of helpful knowledge from related domains, which is referred to as transfer learning. In previous transfer learning works, instance transfer learning algorithms mostly focus on selecting the source domain instances similar to the target domain instances for transfer. However, the selected instances usually do not directly contribute to the learning performance in the target domain. Hypothesis transfer learning algorithms focus on the model/parameter level transfer. They treat the source hypotheses as well-trained and transfer their knowledge in terms of parameters to learn the target hypothesis. Such algorithms directly optimize the target hypothesis by the observable performance improvements. However, they fail to consider the problem that instances that contribute to the source hypotheses may be harmful for the target hypothesis, as instance transfer learning analyzed. To relieve the aforementioned problems, we propose a novel transfer learning algorithm, which follows an analogical strategy. Particularly, the proposed algorithm first learns a revised source hypothesis with only instances contributing to the target hypothesis. Then, the proposed algorithm transfers both the revised source hypothesis and the target hypothesis (only trained with a few samples) to learn an analogical hypothesis. We denote our algorithm as Analogical Transfer Learning. Extensive experiments on one synthetic dataset and three real-world benchmark datasets demonstrate the superior performance of the proposed algorithm.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2898895571",
    "type": "article"
  },
  {
    "title": "Visual Interfaces for Recommendation Systems",
    "doi": "https://doi.org/10.1145/3200490",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Fan Du; Catherine Plaisant; Neil Spring; Ben Shneiderman",
    "corresponding_authors": "",
    "abstract": "Recommendation applications can guide users in making important life choices by referring to the activities of similar peers. For example, students making academic plans may learn from the data of similar students, while patients and their physicians may explore data from similar patients to select the best treatment. Selecting an appropriate peer group has a strong impact on the value of the guidance that can result from analyzing the peer group data. In this article, we describe a visual interface that helps users review the similarity and differences between a seed record and a group of similar records and refine the selection. We introduce the LikeMeDonuts, Ranking Glyph, and History Heatmap visualizations. The interface was refined through three rounds of formative usability evaluation with 12 target users, and its usefulness was evaluated by a case study with a student review manager using real student data. We describe three analytic workflows observed during use and summarize how users’ input shaped the final design.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2902308725",
    "type": "article"
  },
  {
    "title": "D-Map+",
    "doi": "https://doi.org/10.1145/3183347",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Siming Chen; Shuai Chen; Zhenhuang Wang; Jie Liang; WU Ya; Xiaoru Yuan",
    "corresponding_authors": "",
    "abstract": "Information diffusion analysis is important in social media. In this work, we present a coherent ego-centric and event-centric model to investigate diffusion patterns and user behaviors. Applying the model, we propose Diffusion Map+ (D-Maps+), a novel visualization method to support exploration and analysis of user behaviors and diffusion patterns through a map metaphor. For ego-centric analysis, users who participated in reposting (i.e., resending a message initially posted by others) one central user’s posts (i.e., a series of original tweets) are collected. Event-centric analysis focuses on multiple central users discussing a specific event, with all the people participating and reposting messages about it. Social media users are mapped to a hexagonal grid based on their behavior similarities and in the chronological order of repostings. With the additional interactions and linkings, D-Map+ is capable of providing visual profiling of influential users, describing their social behaviors and analyzing the evolution of significant events in social media. A comprehensive visual analysis system is developed to support interactive exploration with D-Map+. We evaluate our work with real-world social media data and find interesting patterns among users and events. We also perform evaluations including user studies and expert feedback to certify the capabilities of our method.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2903240147",
    "type": "article"
  },
  {
    "title": "Dancing with Trump in the Stock Market",
    "doi": "https://doi.org/10.1145/3403578",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Kun Yuan; Guannan Liu; Junjie Wu; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "It is always deemed crucial to identify the key factors that could have significant impact on the stock market trend. Recently, an interesting phenomenon has emerged that some of President Trump’s posts in Twitter can surge into a dominant role on the stock market for a certain time period, although studies along this line are still in their infancy. Therefore, in this article, we study whether and how this new-rising information can help boost the performance of stock market prediction. Specifically, we have found that the echoing reinforced effect of financial news with Trump’s market-related tweets can influence the market movement—that is, some of Trump’s tweets directly impact the stock market in a short time, and the impact can be further intensified when it echoes with other financial news reports. Along this line, we propose a deep information echoing model to predict the hourly stock market trend, such as the rise and fall of the Dow Jones Industrial Average. In particular, to model the discovered echoing reinforced impact, we design a novel information echoing module with a gating mechanism in a sequential deep learning framework to capture the fused knowledge from both Trump’s tweets and financial news. Extensive experiments have been conducted on the real-world U.S. stock market data to validate the effectiveness of our model and its interpretability in understanding the usability of Trump’s posts. Our proposed deep echoing model outperforms other baselines by achieving the best accuracy of 60.42% and obtains remarkable accumulated profits in a trading simulation, which confirms our assumption that Trump’s tweets contain indicative information for short-term market trends. Furthermore, we find that Trump’s tweets about trade and political events are more likely to be associated with short-term market movement, and it seems interesting that the impact would not degrade as time passes.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3046223032",
    "type": "article"
  },
  {
    "title": "Conveying Semantics through Visual Metaphor",
    "doi": "https://doi.org/10.1145/2589483",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Derrall Heath; D. P. Norton; Dan Ventura",
    "corresponding_authors": "",
    "abstract": "In the field of visual art, metaphor is a way to communicate meaning to the viewer. We present a computational system for communicating visual metaphor that can identify adjectives for describing an image based on a low-level visual feature representation of the image. We show that the system can use this visual-linguistic association to render source images that convey the meaning of adjectives in a way consistent with human understanding. Our conclusions are based on a detailed analysis of how the system's artifacts cluster, how these clusters correspond to the semantic relationships of adjectives as documented in WordNet, and how these clusters correspond to human opinion.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1994410245",
    "type": "article"
  },
  {
    "title": "Identifying Points of Interest Using Heterogeneous Features",
    "doi": "https://doi.org/10.1145/2668111",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Yiyang Yang; Zhiguo Gong; Leong Hou U",
    "corresponding_authors": "",
    "abstract": "Deducing trip-related information from web-scale datasets has received large amounts of attention recently. Identifying points of interest (POIs) in geo-tagged photos is one of these problems. The problem can be viewed as a standard clustering problem of partitioning two-dimensional objects. In this work, we study spectral clustering, which is the first attempt for the identification of POIs. However, there is no unified approach to assigning the subjective clustering parameters, and these parameters vary immensely in different metropolitans and locations. To address this issue, we study a self-tuning technique that can properly determine the parameters for the clustering needed. Besides geographical information, web photos inherently store other rich information. Such heterogenous information can be used to enhance the identification accuracy. Thereby, we study a novel refinement framework that is based on the tightness and cohesion degree of the additional information. We thoroughly demonstrate our findings by web-scale datasets collected from Flickr.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2017403776",
    "type": "article"
  },
  {
    "title": "Multi-Label Classification Based on Multi-Objective Optimization",
    "doi": "https://doi.org/10.1145/2505272",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Chuan Shi; Xiangnan Kong; Di Fu; Philip S. Yu; Bin Wu",
    "corresponding_authors": "",
    "abstract": "Multi-label classification refers to the task of predicting potentially multiple labels for a given instance. Conventional multi-label classification approaches focus on single objective setting, where the learning algorithm optimizes over a single performance criterion (e.g., Ranking Loss ) or a heuristic function. The basic assumption is that the optimization over one single objective can improve the overall performance of multi-label classification and meet the requirements of various applications. However, in many real applications, an optimal multi-label classifier may need to consider the trade-offs among multiple inconsistent objectives, such as minimizing Hamming Loss while maximizing Micro F1 . In this article, we study the problem of multi-objective multi-label classification and propose a novel solution (called M oml ) to optimize over multiple objectives simultaneously. Note that optimization objectives may be inconsistent, even conflicting, thus one cannot identify a single solution that is optimal on all objectives. Our M oml algorithm finds a set of non-dominated solutions which are optimal according to different trade-offs among multiple objectives. So users can flexibly construct various predictive models from the solution set, which provides more meaningful classification results in different application scenarios. Empirical studies on real-world tasks demonstrate that the M oml can effectively boost the overall performance of multi-label classification by optimizing over multiple objectives simultaneously.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2138709957",
    "type": "article"
  },
  {
    "title": "Crowdsourcing Empathetic Intelligence",
    "doi": "https://doi.org/10.1145/2897369",
    "publication_date": "2016-05-02",
    "publication_year": 2016,
    "authors": "Christina Katsimerou; Joris Albeda; Alina Huldtgren; Ingrid Heynderickx; Judith Redi",
    "corresponding_authors": "",
    "abstract": "Unobtrusive recognition of the user's mood is an essential capability for affect-adaptive systems. Mood is a subtle, long-term affective state, often misrecognized even by humans. The challenge to train a machine to recognize it from, for example, a video of the user, is significant, and already begins with the lack of ground truth for supervised learning. Existing affective databases consist mainly of short videos, annotated in terms of expressed emotions rather than mood. In very few cases, we encounter perceived mood annotations, of questionable reliability, however, due to the subjectivity of mood estimation and the small number of coders involved. In this work, we introduce a new database for mood recognition from video. Our database contains 180 long, acted videos, depicting typical daily scenarios, and subtle facial and bodily expressions. The videos cover three visual modalities (face, body, Kinect data), and are annotated in terms of emotions (via G-trace) and mood (via the Self-Assessment Manikin and the AffectButton). To annotate the database exhaustively, we exploit crowdsourcing to reach out to an extensive number of nonexpert coders. We validate the reliability of our crowdsourced annotations by (1) adopting a number of criteria to filter out unreliable coders, and (2) comparing the annotations of a subset of our videos with those collected in a controlled lab setting.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2347036789",
    "type": "article"
  },
  {
    "title": "Tempo Driven Audio-to-Score Alignment Using Spectral Decomposition and Online Dynamic Time Warping",
    "doi": "https://doi.org/10.1145/2926717",
    "publication_date": "2016-10-21",
    "publication_year": 2016,
    "authors": "Francisco J. Rodríguez-Serrano; Julio J. Carabias-Orti; P. Vera‐Candeas; D. Martínez-Muñoz",
    "corresponding_authors": "",
    "abstract": "In this article, we present an online score following framework designed to deal with automatic accompaniment. The proposed framework is based on spectral factorization and online Dynamic Time Warping (DTW) and has two separated stages: preprocessing and alignment. In the first one, we convert the score into a reference audio signal using a MIDI synthesizer software and we analyze the provided information in order to obtain the spectral patterns (i.e., basis functions) associated to each score unit. In this work, a score unit represents the occurrence of concurrent or isolated notes in the score. These spectral patterns are learned from the synthetic MIDI signal using a method based on Non-negative Matrix Factorization (NMF) with Beta-divergence, where the gains are initialized as the ground-truth transcription inferred from the MIDI. On the second stage, a non-iterative signal decomposition method with fixed spectral patterns per score unit is used over the magnitude spectrogram of the input signal resulting in a distortion matrix that can be interpreted as the cost of the matching for each score unit at each frame. Finally, the relation between the performance and the musical score times is obtained using a strategy based on online DTW, where the optimal path is biased by the speed of interpretation. Our system has been evaluated and compared to other systems, yielding reliable results and performance.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2534325196",
    "type": "article"
  },
  {
    "title": "Multi-Task Learning for Entity Recommendation and Document Ranking in Web Search",
    "doi": "https://doi.org/10.1145/3396501",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Jizhou Huang; Haifeng Wang; Wei Zhang; Ting Liu",
    "corresponding_authors": "",
    "abstract": "Entity recommendation, providing users with an improved search experience by proactively recommending related entities to a given query, has become an indispensable feature of today’s Web search engine. Existing studies typically only consider the query issued at the current timestep while ignoring the in-session user search behavior (short-term search history) or historical user search behavior across all sessions (long-term search history) when generating entity recommendations. As a consequence, they may fail to recommend entities of interest relevant to a user’s actual information need. In this work, we believe that both short-term and long-term search history convey valuable evidence that could help understand the user’s search intent behind a query, and take both of them into consideration for entity recommendation. Furthermore, there has been little work on exploring whether the use of other companion tasks in Web search such as document ranking as auxiliary tasks could improve the performance of entity recommendation. To this end, we propose a multi-task learning framework with deep neural networks (DNNs) to jointly learn and optimize two companion tasks in Web search engines: entity recommendation and document ranking, which can be easily trained in an end-to-end manner. Specifically, we regard document ranking as an auxiliary task to improve the main task of entity recommendation, where the representations of queries, sessions, and users are shared across all tasks and optimized by the multi-task objective during training. We evaluate our approach using large-scale, real-world search logs of a widely-used commercial Web search engine. We also performed extensive ablation experiments over a number of facets of the proposed multi-task DNN model to figure out their relative importance. The experimental results show that both short-term and long-term search history can bring significant improvements in recommendation effectiveness, and the combination of both outperforms using either of them individually. In addition, the experiments show that the performance of both entity recommendation and document ranking can be significantly improved, which demonstrates the effectiveness of using multi-task learning to jointly optimize the two companion tasks in Web search.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3041141374",
    "type": "article"
  },
  {
    "title": "Session-based Hotel Recommendations Dataset",
    "doi": "https://doi.org/10.1145/3412379",
    "publication_date": "2020-11-13",
    "publication_year": 2020,
    "authors": "Jens Adamczak; Yashar Deldjoo; Farshad Bakhshandegan Moghaddam; Peter Knees; Gerard-Paul Leyson; Philipp Monreal",
    "corresponding_authors": "",
    "abstract": "In 2019, the Recommender Systems Challenge [17] dealt for the first time with a real-world task from the area of e-tourism, namely the recommendation of hotels in booking sessions. In this context, we present the release of a new dataset that we believe is vitally important for recommendation systems research in the area of hotel search, from both academic and industry perspectives. In this article, we describe the qualitative characteristics of the dataset and present the comparison of several baseline algorithms trained on the data.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3100408341",
    "type": "article"
  },
  {
    "title": "Causal Mechanism Transfer Network for Time Series Domain Adaptation in Mechanical Systems",
    "doi": "https://doi.org/10.1145/3445033",
    "publication_date": "2021-03-09",
    "publication_year": 2021,
    "authors": "Zijian Li; Ruichu Cai; Hong Wei Ng; Marianne Winslett; Tom Z. J. Fu; Boyan Xu; Xiaoyan Yang; Zhenjie Zhang",
    "corresponding_authors": "",
    "abstract": "Data-driven models are becoming essential parts in modern mechanical systems, commonly used to capture the behavior of various equipment and varying environmental characteristics. Despite the advantages of these data-driven models on excellent adaptivity to high dynamics and aging equipment, they are usually hungry for massive labels, mostly contributed by human engineers at a high cost. Fortunately, domain adaptation enhances the model generalization by utilizing the labeled source data and the unlabeled target data. However, the mainstream domain adaptation methods cannot achieve ideal performance on time series data, since they assume that the conditional distributions are equal. This assumption works well in the static data but is inapplicable for the time series data. Even the first-order Markov dependence assumption requires the dependence between any two consecutive time steps. In this article, we assume that the causal mechanism is invariant and present our Causal Mechanism Transfer Network (CMTN) for time series domain adaptation. By capturing causal mechanisms of time series data, CMTN allows the data-driven models to exploit existing data and labels from similar systems, such that the resulting model on a new system is highly reliable even with limited data. We report our empirical results and lessons learned from two real-world case studies, on chiller plant energy optimization and boiler fault detection, which outperform the existing state-of-the-art method.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3139303763",
    "type": "article"
  },
  {
    "title": "Identifying Illicit Drug Dealers on Instagram with Large-scale Multimodal Data Fusion",
    "doi": "https://doi.org/10.1145/3472713",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Chuanbo Hu; Minglei Yin; Bin Liu; Xin Li; Yanfang Ye",
    "corresponding_authors": "",
    "abstract": "Illicit drug trafficking via social media sites such as Instagram have become a severe problem, thus drawing a great deal of attention from law enforcement and public health agencies. How to identify illicit drug dealers from social media data has remained a technical challenge for the following reasons. On the one hand, the available data are limited because of privacy concerns with crawling social media sites; on the other hand, the diversity of drug dealing patterns makes it difficult to reliably distinguish drug dealers from common drug users. Unlike existing methods that focus on posting-based detection, we propose to tackle the problem of illicit drug dealer identification by constructing a large-scale multimodal dataset named Identifying Drug Dealers on Instagram (IDDIG). Nearly 4,000 user accounts, of which more than 1,400 are drug dealers, have been collected from Instagram with multiple data sources including post comments, post images, homepage bio, and homepage images. We then design a quadruple-based multimodal fusion method to combine the multiple data sources associated with each user account for drug dealer identification. Experimental results on the constructed IDDIG dataset demonstrate the effectiveness of the proposed method in identifying drug dealers (almost 95% accuracy). Moreover, we have developed a hashtag-based community detection technique for discovering evolving patterns, especially those related to geography and drug types.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3189420631",
    "type": "article"
  },
  {
    "title": "A GDPR-compliant Ecosystem for Speech Recognition with Transfer, Federated, and Evolutionary Learning",
    "doi": "https://doi.org/10.1145/3447687",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Di Jiang; Conghui Tan; Jinhua Peng; Chaotao Chen; Xueyang Wu; Weiwei Zhao; Yuanfeng Song; Yongxin Tong; Chang Liu; Qian Xu; Qiang Yang; Li Deng",
    "corresponding_authors": "",
    "abstract": "Automatic Speech Recognition (ASR) is playing a vital role in a wide range of real-world applications. However, Commercial ASR solutions are typically “one-size-fits-all” products and clients are inevitably faced with the risk of severe performance degradation in field test. Meanwhile, with new data regulations such as the European Union’s General Data Protection Regulation (GDPR) coming into force, ASR vendors, which traditionally utilize the speech training data in a centralized approach, are becoming increasingly helpless to solve this problem, since accessing clients’ speech data is prohibited. Here, we show that by seamlessly integrating three machine learning paradigms (i.e., T ransfer learning, F ederated learning, and E volutionary learning (TFE)), we can successfully build a win-win ecosystem for ASR clients and vendors and solve all the aforementioned problems plaguing them. Through large-scale quantitative experiments, we show that with TFE, the clients can enjoy far better ASR solutions than the “one-size-fits-all” counterpart, and the vendors can exploit the abundance of clients’ data to effectively refine their own ASR products.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3158873112",
    "type": "article"
  },
  {
    "title": "Disentangled Item Representation for Recommender Systems",
    "doi": "https://doi.org/10.1145/3445811",
    "publication_date": "2021-02-26",
    "publication_year": 2021,
    "authors": "Zeyu Cui; Feng Yu; Shu Wu; Qiang Liu; Liang Wang",
    "corresponding_authors": "",
    "abstract": "Item representations in recommendation systems are expected to reveal the properties of items. Collaborative recommender methods usually represent an item as one single latent vector. Nowadays the e-commercial platforms provide various kinds of attribute information for items (e.g., category, price, and style of clothing). Utilizing this attribute information for better item representations is popular in recent years. Some studies use the given attribute information as side information, which is concatenated with the item latent vector to augment representations. However, the mixed item representations fail to fully exploit the rich attribute information or provide explanation in recommender systems. To this end, we propose a fine-grained Disentangled Item Representation (DIR) for recommender systems in this article, where the items are represented as several separated attribute vectors instead of a single latent vector. In this way, the items are represented at the attribute level, which can provide fine-grained information of items in recommendation. We introduce a learning strategy, LearnDIR, which can allocate the corresponding attribute vectors to items. We show how DIR can be applied to two typical models, Matrix Factorization (MF) and Recurrent Neural Network (RNN). Experimental results on two real-world datasets show that the models developed under the framework of DIR are effective and efficient. Even using fewer parameters, the proposed model can outperform the state-of-the-art methods, especially in the cold-start situation. In addition, we make visualizations to show that our proposition can provide explanation for users in real-world applications.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3183346198",
    "type": "article"
  },
  {
    "title": "Temporal Hierarchical Graph Attention Network for Traffic Prediction",
    "doi": "https://doi.org/10.1145/3446430",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Ling Huang; Xingxing Liu; Shuqiang Huang; Chang‐Dong Wang; Wei Tu; Jia-Meng Xie; Shuai Tang; Xie Wendi",
    "corresponding_authors": "",
    "abstract": "As a critical task in intelligent traffic systems, traffic prediction has received a large amount of attention in the past few decades. The early efforts mainly model traffic prediction as the time-series mining problem, in which the spatial dependence has been largely ignored. As the rapid development of deep learning, some attempts have been made in modeling traffic prediction as the spatio-temporal data mining problem in a road network, in which deep learning techniques can be adopted for modeling the spatial and temporal dependencies simultaneously. Despite the success, the spatial and temporal dependencies are only modeled in a regionless network without considering the underlying hierarchical regional structure of the spatial nodes, which is an important structure naturally existing in the real-world road network. Apart from the challenge of modeling the spatial and temporal dependencies like the existing studies, the extra challenge caused by considering the hierarchical regional structure of the road network lies in simultaneously modeling the spatial and temporal dependencies between nodes and regions and the spatial and temporal dependencies between regions. To this end, this article proposes a new Temporal Hierarchical Graph Attention Network (TH-GAT). The main idea lies in augmenting the original road network into a region-augmented network, in which the hierarchical regional structure can be modeled. Based on the region-augmented network, the region-aware spatial dependence model and the region-aware temporal dependence model can be constructed, which are two main components of the proposed TH-GAT model. In addition, in the region-aware spatial dependence model, the graph attention network is adopted, in which the importance of a node to another node, of a node to a region, of a region to a node, and of a region to another region, can be captured automatically by means of the attention coefficients. Extensive experiments are conducted on two real-world traffic datasets, and the results have confirmed the superiority of the proposed TH-GAT model.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3217451197",
    "type": "article"
  },
  {
    "title": "Similar Trajectory Search with Spatio-Temporal Deep Representation Learning",
    "doi": "https://doi.org/10.1145/3466687",
    "publication_date": "2021-12-11",
    "publication_year": 2021,
    "authors": "David Alexander Tedjopurnomo; Xiucheng Li; Zhifeng Bao; Gao Cong; Farhana Choudhury; A. K. Qin",
    "corresponding_authors": "",
    "abstract": "Similar trajectory search is a crucial task that facilitates many downstream spatial data analytic applications. Despite its importance, many of the current literature focus solely on the trajectory’s spatial similarity while neglecting the temporal information. Additionally, the few papers that use both the spatial and temporal features based their approach on a traditional point-to-point comparison. These methods model the importance of the spatial and temporal aspect of the data with only a single, pre-defined balancing factor for all trajectories, even though the relative spatial and temporal balance can change from trajectory to trajectory. In this article, we propose the first spatio-temporal, deep-representation-learning-based approach to similar trajectory search. Experiments show that utilizing both features offers significant improvements over existing point-to-point comparison and deep-representation-learning approach. We also show that our deep neural network approach is faster and performs more consistently compared to the point-to-point comparison approaches.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4200143088",
    "type": "article"
  },
  {
    "title": "Representation Learning on Variable Length and Incomplete Wearable-Sensory Time Series",
    "doi": "https://doi.org/10.1145/3531228",
    "publication_date": "2022-07-08",
    "publication_year": 2022,
    "authors": "Xian Wu; Chao Huang; Pablo Robles-Granda; Nitesh V. Chawla",
    "corresponding_authors": "",
    "abstract": "The prevalence of wearable sensors (e.g., smart wristband) is creating unprecedented opportunities to not only inform health and wellness states of individuals, but also assess and infer personal attributes, including demographic and personality attributes. However, the data captured from wearables, such as heart rate or number of steps, present two key challenges: (1) the time series is often of variable length and incomplete due to different data collection periods (e.g., wearing behavior varies by person); and (2) there is inter-individual variability to external factors like stress and environment. This article addresses these challenges and brings us closer to the potential of personalized insights about an individual, taking the leap from quantified self to qualified self. Specifically, HeartSpace proposed in this article learns embedding of the time-series data with variable length and missing values via the integration of a time-series encoding module and a pattern aggregation network. Additionally, HeartSpace implements a Siamese-triplet network to optimize representations by jointly capturing intra- and inter-series correlations during the embedding learning process. The empirical evaluation over two different real-world data presents significant performance gains over state-of-the-art baselines in a variety of applications, including user identification, personality prediction, demographics inference, job performance prediction, and sleep duration estimation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3005510897",
    "type": "article"
  },
  {
    "title": "Cross-Silo Federated Learning for Multi-Tier Networks with Vertical and Horizontal Data Partitioning",
    "doi": "https://doi.org/10.1145/3543433",
    "publication_date": "2022-07-06",
    "publication_year": 2022,
    "authors": "Anirban Das; Timothy Castiglia; Shiqiang Wang; Stacy Patterson",
    "corresponding_authors": "",
    "abstract": "We consider federated learning in tiered communication networks. Our network model consists of a set of silos, each holding a vertical partition of the data. Each silo contains a hub and a set of clients, with the silo’s vertical data shard partitioned horizontally across its clients. We propose Tiered Decentralized Coordinate Descent (TDCD), a communication-efficient decentralized training algorithm for such two-tiered networks. The clients in each silo perform multiple local gradient steps before sharing updates with their hub to reduce communication overhead. Each hub adjusts its coordinates by averaging its workers’ updates, and then hubs exchange intermediate updates with one another. We present a theoretical analysis of our algorithm and show the dependence of the convergence rate on the number of vertical partitions and the number of local updates. We further validate our approach empirically via simulation-based experiments using a variety of datasets and objectives.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3196084215",
    "type": "article"
  },
  {
    "title": "Improving Availability of Vertical Federated Learning: Relaxing Inference on Non-overlapping Data",
    "doi": "https://doi.org/10.1145/3501817",
    "publication_date": "2022-05-12",
    "publication_year": 2022,
    "authors": "Zhenghang Ren; Liu Yang; Kai Chen",
    "corresponding_authors": "",
    "abstract": "Vertical Federated Learning (VFL) enables multiple parties to collaboratively train a machine learning model over vertically distributed datasets without data privacy leakage. However, there is a limitation of the current VFL solutions: current VFL models fail to conduct inference on non-overlapping samples during inference. This limitation seriously damages the VFL model’s availability because, in practice, overlapping samples may only take up a small portion of the whole data at each party which means a large part of inference tasks will fail. In this article, we propose a novel VFL framework which enables federated inference on non-overlapping data. Our framework regards the distributed features as privileged information which is available in the training period but disappears during inference. We distill the knowledge of such privileged features and transfer them to the parties’ local model which only processes local features. Furthermore, we adopt Oblivious Transfer (OT) to preserve data ID privacy during training and inference. Empirically, we evaluate the model on the real-world dataset collected from Criteo and Taobao. Besides, we also provide a security analysis of the proposed framework.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4280588203",
    "type": "article"
  },
  {
    "title": "Incorporation of Data-Mined Knowledge into Black-Box SVM for Interpretability",
    "doi": "https://doi.org/10.1145/3548775",
    "publication_date": "2022-07-14",
    "publication_year": 2022,
    "authors": "Shaohan Chen; Chuanhou Gao; Ping Zhang",
    "corresponding_authors": "",
    "abstract": "The lack of interpretability often makes black-box models challenging to be applied in many practical domains. For this reason, the current work, from the black-box model input port, proposes to incorporate data-mined knowledge into the black-box soft-margin SVM model to enhance accuracy and interpretability. The concept and incorporation mechanism of data-mined knowledge are successively developed, based on which a partially interpretable soft-margin SVM ( pTsm -SVM) optimization model is designed and then solved through reformulating the optimization problem as standard quadratic programming. An algorithm for mining linear positive (negative) class knowledge from general data sets is also proposed, which generates a linear two-dimensional discriminative rule with specificity (sensitivity) equal to 1 and the highest possible sensitivity (specificity) among all two-dimensional feature spaces. The knowledge-integrated pTsm -SVM works by achieving a good trade-off among the “large margin”, “high specificity”, and “high sensitivity”. Our experimental results on eight UCI datasets demonstrate the superiority of the proposed pTsm -SVM over the standard soft-margin SVM both in terms of accuracy and interpretability.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4285389264",
    "type": "article"
  },
  {
    "title": "Source-free Unsupervised Domain Adaptation with Trusted Pseudo Samples",
    "doi": "https://doi.org/10.1145/3570510",
    "publication_date": "2022-11-03",
    "publication_year": 2022,
    "authors": "Qing Tian; Shun Peng; Tinghuai Ma",
    "corresponding_authors": "",
    "abstract": "Source-free unsupervised domain adaptation (SFUDA) aims to accomplish the task of adaptation to the target domain by utilizing pre-trained source domain model and unlabeled target domain samples, without directly accessing any source domain data. Although many SFUDA works use the pseudo-labeling strategy to improve the accuracy of pseudo-labels in the target domain, these strategies ignore the influence of domain shift on calculating the reference distribution of pseudo-labels. In this article, we propose a novel kind of SFUDA with trusted pseudo samples (SFUDA-TPS), which uses reliable feature reference distribution to solve the SFUDA problem. In SFUDA-TPS, we design a target feature correcting classifier to alleviate the problem of feature reference distribution deviating from target domain samples distribution. On this basis, the more reliable feature reference distribution is calculated by selecting the target domain samples with a high amount of information, i.e., low entropy in the fixed source domain classifier and target feature correcting classifier. The implicit alignment between the source domain and target domain is realized by learning the source domain distributions hidden in the fixed source domain classifier. Experimental evaluations illustrate the effectiveness of our proposed method in solving SFUDA tasks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4308445188",
    "type": "article"
  },
  {
    "title": "Modeling Within-Basket Auxiliary Item Recommendation with Matchability and Ubiquity",
    "doi": "https://doi.org/10.1145/3574157",
    "publication_date": "2023-02-17",
    "publication_year": 2023,
    "authors": "En Xu; Zhiwen Yu; Zhuo Sun; Bin Guo; Lina Yao",
    "corresponding_authors": "",
    "abstract": "Within-basket recommendation is to recommend suitable items for the current basket with some already known items. The within-basket auxiliary item recommendation ( WBAIR ) is to recommend auxiliary items based on the primary items in the basket. Such a task exists in many real-life scenarios. Unlike the associations between items that can be transmitted in both directions, primary and auxiliary relationships are unidirectional. Then, the suitable matching patterns between primary and auxiliary items cannot be explored by traditional directionless methods. Therefore, we design the Matc4Rec algorithm to integrate the primary and auxiliary factors, and finally recommend items that not only match the interests of users but also satisfy the primary and auxiliary relationships between items. Specifically, we capture the pattern from three aspects: matchability within-basket , matchability between baskets , and ubiquity . By exploiting this pattern, the designed algorithm not only achieves good results on real-world datasets but also improves the interpretability of recommendations. As a result, we can know which commodities are suitable as auxiliary items. The experiment results demonstrate that our algorithm can also alleviate the cold start problem.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4321222982",
    "type": "article"
  },
  {
    "title": "Fast Real-Time Video Object Segmentation with a Tangled Memory Network",
    "doi": "https://doi.org/10.1145/3585076",
    "publication_date": "2023-02-23",
    "publication_year": 2023,
    "authors": "Jianbiao Mei; Mengmeng Wang; Yu Yang; Yanjun Li; Yong Liu",
    "corresponding_authors": "",
    "abstract": "In this article, we present a fast real-time tangled memory network that segments the objects effectively and efficiently for semi-supervised video object segmentation (VOS). We propose a tangled reference encoder and a memory bank organization mechanism based on a state estimator to fully utilize the mask features and alleviate memory overhead and computational burden brought by the unlimited memory bank used in many memory-based methods. First, the tangled memory network exploits the mask features that uncover abundant object information like edges and contours but are not fully explored in existing methods. Specifically, a tangled two-stream reference encoder is designed to extract and fuse the features from both RGB frames and the predicted masks. Second, to indicate the quality of the predicted mask and feedback the online prediction state for organizing the memory bank, we devise a target state estimator to learn the IoU score between the predicted mask and ground truth. Moreover, to accelerate the forward process and avoid memory overflow, we use a memory bank of fixed size to store historical features by designing a new efficient memory bank organization mechanism based on the mask state score provided by the state estimator. We conduct comprehensive experiments on the public benchmarks DAVIS and YouTube-VOS, demonstrating that our method obtains competitive results while running at high speed (66 FPS on the DAVIS16-val set).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4321605883",
    "type": "article"
  },
  {
    "title": "STExplorer: A Hierarchical Autonomous Exploration Strategy with Spatio-temporal Awareness for Aerial Robots",
    "doi": "https://doi.org/10.1145/3595184",
    "publication_date": "2023-05-02",
    "publication_year": 2023,
    "authors": "Bolei Chen; Yongzheng Cui; Ping Zhong; Wang Yang; Yixiong Liang; Jianxin Wang",
    "corresponding_authors": "",
    "abstract": "The autonomous exploration task we consider requires Unmanned Aerial Vehicles (UAVs) to actively navigate through unknown environments with the goal of fully perceiving and mapping the environments. Some existing exploration strategies suffer from rough cost budgets, ambiguous Information Gain (IG), and unnecessary backtracking exploration caused by Fragmented Regions (FRs). In our work, a hierarchical spatio-temporal-aware exploration framework is proposed to alleviate these problems. At the local exploration level, the Asymmetrical Traveling Salesman Problem (ATSP) is solved by comprehensively considering exploration time, IG, and heading consistency to avoid blindly exploring. Specifically, the exploration time is reasonably budgeted by fast marching in an artificial potential field. Meanwhile, a transformer-based map occupancy predictor is designed to assist in IG calculation by imagining spatial clues out of the Field of View (FoV), facilitating the prescient exploration. We verify that our local exploration is effective in alleviating the unnecessary back-and-forth movements caused by FRs and the interference of potential obstacle occlusion on the IG calculation. At the global exploration level, the classical Next Best View Points (NBVP) are generalized to Next Best Sub-Regions (NBSR) to choose informative sub-regions for further forward-looking exploration based on a well-designed utility function. Safe flight paths and dynamically feasible trajectories are reasonably generated throughout the exploration process by fast marching and B-spline curve optimization. Comparative simulations and benchmark tests demonstrate that our proposed exploration strategy is quite competitive in terms of exploration path length, total exploration time, and exploration ratio.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4367680234",
    "type": "article"
  },
  {
    "title": "Faithful and Consistent Graph Neural Network Explanations with Rationale Alignment",
    "doi": "https://doi.org/10.1145/3616542",
    "publication_date": "2023-08-23",
    "publication_year": 2023,
    "authors": "Tianxiang Zhao; Dongsheng Luo; X. D. Zhang; Suhang Wang",
    "corresponding_authors": "",
    "abstract": "Uncovering rationales behind predictions of graph neural networks (GNNs) has received increasing attention over recent years. Instance-level GNN explanation aims to discover critical input elements, such as nodes or edges, that the target GNN relies upon for making predictions. Though various algorithms are proposed, most of them formalize this task by searching the minimal subgraph, which can preserve original predictions. However, an inductive bias is deep-rooted in this framework: Several subgraphs can result in the same or similar outputs as the original graphs. Consequently, they have the danger of providing spurious explanations and failing to provide consistent explanations. Applying them to explain weakly performed GNNs would further amplify these issues. To address this problem, we theoretically examine the predictions of GNNs from the causality perspective. Two typical reasons for spurious explanations are identified: confounding effect of latent variables like distribution shift and causal factors distinct from the original input. Observing that both confounding effects and diverse causal rationales are encoded in internal representations, we propose a new explanation framework with an auxiliary alignment loss, which is theoretically proven to be optimizing a more faithful explanation objective intrinsically. Concretely for this alignment loss, a set of different perspectives are explored: anchor-based alignment, distributional alignment based on Gaussian mixture models, mutual-information-based alignment, and so on. A comprehensive study is conducted both on the effectiveness of this new framework in terms of explanation faithfulness/consistency and on the advantages of these variants. For our codes, please refer to the following URL link: https://github.com/TianxiangZhao/GraphNNExplanation",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386096518",
    "type": "article"
  },
  {
    "title": "GNN-based Advanced Feature Integration for ICS Anomaly Detection",
    "doi": "https://doi.org/10.1145/3620676",
    "publication_date": "2023-09-05",
    "publication_year": 2023,
    "authors": "Shuaiyi Lu; Kai Wang; Yuliang Wei; Hongri Liu; Qilin Fan; Bailing Wang",
    "corresponding_authors": "",
    "abstract": "Recent adversaries targeting the Industrial Control Systems (ICSs) have started exploiting their sophisticated inherent contextual semantics such as the data associativity among heterogeneous field devices. In light of the subtlety rendered in these semantics, anomalies triggered by such interactions tend to be extremely covert, hence giving rise to extensive challenges in their detection. Driven by the critical demands of securing ICS processes, a Graph-Neural-Network (GNN) based method is presented to tackle these subtle hostilities by leveraging an ICS’s advanced contextual features refined from a universal perspective, rather than exclusively following GNN’s conventional local aggregation paradigm. Specifically, we design and implement the Graph Sample-and-Integrate Network (GSIN), a general chained framework performing node-level anomaly detection via advanced feature integration, which combines a node’s local awareness with the graph’s prominent global properties extracted via process-oriented pooling. The proposed GSIN is evaluated on multiple well-known datasets with different kinds of integration configurations, and results demonstrate its superiority consistently on not only anomaly detection performance (e.g., F1 score and AUPRC) but also runtime efficiency over recent representative baselines.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386443011",
    "type": "article"
  },
  {
    "title": "MHANER: A Multi-source Heterogeneous Graph Attention Network for Explainable Recommendation in Online Games",
    "doi": "https://doi.org/10.1145/3626243",
    "publication_date": "2023-10-09",
    "publication_year": 2023,
    "authors": "Dongjin Yu; Xingliang Wang; Yu Xiong; Xudong Shen; Runze Wu; Dongjing Wang; Zhene Zou; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "Recommender system helps address information overload problem and satisfy consumers’ personalized requirement in many applications such as e-commerce, social networks, and in-game store. However, existing approaches mainly focus on improving the accuracy of recommendation tasks but usually ignore how to improve the interpretability of recommendation, which is still a challenging and crucial task, especially for some complicated scenarios such as large-scale online games. A few previous attempts on explainable recommendation mostly depend on a large amount of a priori knowledge or user-provided review corpus, which is labor consuming as well as often suffers from data deficiency. To relieve this issue, we propose a Multi-source Heterogeneous Graph Attention Network for Explainable Recommendation (MHANER) for the case without enough a priori knowledge or corpus of user comments. Specifically, MHANER employs the attention mechanism to model players’ preference to in-game store items as the support for the explanation of recommendation. Then a graph neural network–based method is designed to model players’ multi-source heterogeneous information, including the players’ historical behavior data, historical purchase data, and attributes of the player-controlled character, which is leveraged to recommend possible items for players to buy. Finally, the multi-level subgraph pattern mining is adopted to combine the characteristics of a recommendation list to generate corresponding explanations of items. Extensive experiments on three real-world datasets, two collected from JD and one from NetEase game, demonstrate that the proposed model MHANER outperforms state-of-the-art baselines. Moreover, the generated explanations are verified by human encoding comprised of hard-core game players and endorsed by experts from game developers.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4387460496",
    "type": "article"
  },
  {
    "title": "T-Distributed Stochastic Neighbor Embedding for Co-Representation Learning",
    "doi": "https://doi.org/10.1145/3627823",
    "publication_date": "2023-10-13",
    "publication_year": 2023,
    "authors": "Wei Chen; Hongjun Wang; Yinghui Zhang; Ping Deng; Zhipeng Luo; Tianrui Li",
    "corresponding_authors": "",
    "abstract": "Co-clustering is the simultaneous clustering of the samples and attributes of a data matrix that provides deeper insight into data than traditional clustering. However, there is a lack of representation learning algorithms that serve this mechanism of co-clustering, and the current representation learning algorithms are limited to the sample perspective and lack the use of information in the attribute perspective. To solve this problem, in this article, ctSNE , a co-representation learning model based on t-distributed stochastic neighbor embedding, is proposed for unsupervised co-clustering, where ctSNE makes the dataset representation outputted more discriminative of row and column clusters (i.e. co-discrimination). On the basis of t-distributed stochastic neighbor embedding retaining the sample data distribution and local data structure, the philosophy of collaboration is introduced (i.e., row and column hidden relationship information) so that the ctSNE model is equipped with co-representation learning capability, which can effectively improve the performance of co-clustering. To prove the effectiveness of the ctSNE model, several classic co-clustering algorithms are used to check the co-representation performance of ctSNE, and a novel internal index based on an internal clustering index, known as total inertia, is proposed to demonstrate the effect of co-clustering. The numerous experimental results show that ctSNE has tremendous co-representation capability and can significantly improve the performance of co-clustering algorithms.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4387614639",
    "type": "article"
  },
  {
    "title": "Temporal Implicit Multimodal Networks for Investment and Risk Management",
    "doi": "https://doi.org/10.1145/3643855",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Gary Ang; Ee‐Peng Lim",
    "corresponding_authors": "",
    "abstract": "Many deep learning works on financial time-series forecasting focus on predicting future prices/returns of individual assets with numerical price-related information for trading, and hence propose models designed for univariate, single-task, and/or unimodal settings. Forecasting for investment and risk management involves multiple tasks in multivariate settings: forecasts of expected returns and risks of assets in portfolios, and correlations between these assets. As different sources/types of time-series influence future returns, risks, and correlations of assets in different ways, it is also important to capture time-series from different modalities. Hence, this article addresses financial time-series forecasting for investment and risk management in a multivariate, multitask, and multimodal setting. Financial time-series forecasting, however, is challenging due to the low signal-to-noise ratios typical in financial time-series, and as intra-series and inter-series relationships of assets evolve across time. To address these challenges, our proposed Temporal Implicit Multimodal Network (TIME) model learns implicit inter-series relationship networks between assets from multimodal financial time-series at multiple time-steps adaptively. TIME then uses dynamic network and temporal encoding modules to jointly capture such evolving relationships, multimodal financial time-series, and temporal representations. Our experiments show that TIME outperforms other state-of-the-art models on multiple forecasting tasks and investment and risk management applications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4391448896",
    "type": "article"
  },
  {
    "title": "Robust Recommender Systems with Rating Flip Noise",
    "doi": "https://doi.org/10.1145/3641285",
    "publication_date": "2024-02-29",
    "publication_year": 2024,
    "authors": "Shanshan Ye; Jie Lü",
    "corresponding_authors": "",
    "abstract": "Recommender systems have become important tools in the daily life of human beings since they are powerful to address information overload, and discover relevant and useful items for users. The success of recommender systems largely relies on the interaction history between users and items, which is expected to accurately reflect the preferences of users on items. However, the expectation is easily broken in practice, due to the corruptions made in the interaction history, resulting in unreliable and untrusted recommender systems. Previous works either ignore this issue (assume that the interaction history is precise) or are limited to handling additive noise. Motivated by this, in this paper, we study rating flip noise which is widely existed in the interaction history of recommender systems and combat it by modelling the noise generation process. Specifically, the rating flip noise allows a rating to be flipped to any other ratings within the given rating set, which reflects various real-world situations of rating corruption, e.g. , a user may randomly click a rating from the rating set and then submit it. The noise generation process is modelled by the noise transition matrix that denotes the probabilities of a clean rating flip into a noisy rating. A statistically consistent algorithm is afterwards applied with the estimated transition matrix to learn a robust recommender system against rating flip noise. Comprehensive experiments on multiple benchmarks confirm the superiority of our method.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4392285508",
    "type": "article"
  },
  {
    "title": "Developing Time Series Forecasting Models with Generative Large Language Models",
    "doi": "https://doi.org/10.1145/3663485",
    "publication_date": "2024-05-07",
    "publication_year": 2024,
    "authors": "Juan Morales-García; Antonio Llanes; Francisco Arcas-Túnez; Fernando Terroso-Sáenz",
    "corresponding_authors": "",
    "abstract": "Nowadays, Generative Large Language Models (GLLMs) have made a significant impact in the field of Artificial Intelligence (AI). One of the domains extensively explored for these models is their ability as generators of functional source code for software projects. Nevertheless, their potential as assistants to write the code needed to generate and model Machine Learning (ML) or Deep Learning (DL) architectures has not been fully explored to date. For this reason, this work focuses on evaluating the extent to which different tools based on GLLMs, such as ChatGPT or Copilot, are able to correctly define the source code necessary to generate viable predictive models. The use case defined is the forecasting of a time series that reports the indoor temperature of a greenhouse. The results indicate that, while it is possible to achieve good accuracy metrics with simple predictive models generated by GLLMs, the composition of predictive models with complex architectures using GLLMs is still far from improving the accuracy of predictive models generated by human data scientists.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4396708807",
    "type": "article"
  },
  {
    "title": "Physics-based Abnormal Trajectory Gap Detection",
    "doi": "https://doi.org/10.1145/3673235",
    "publication_date": "2024-06-15",
    "publication_year": 2024,
    "authors": "Arun Sharma; Subhankar Ghosh; Shashi Shekhar",
    "corresponding_authors": "",
    "abstract": "Given trajectories with gaps (i.e., missing data), we investigate algorithms to identify abnormal gaps in trajectories which occur when a given moving object did not report its location, but other moving objects in the same geographic region periodically did. The problem is important due to its societal applications, such as improving maritime safety and regulatory enforcement for global security concerns such as illegal fishing, illegal oil transfers, and trans-shipments. The problem is challenging due to the difficulty of bounding the possible locations of the moving object during a trajectory gap, and the very high computational cost of detecting gaps in such a large volume of location data. The current literature on anomalous trajectory detection assumes linear interpolation within gaps, which may not be able to detect abnormal gaps since objects within a given region may have traveled away from their shortest path. In preliminary work, we introduced an abnormal gap measure that uses a classical space-time prism model to bound an object’s possible movement during the trajectory gap and provided a scalable memoized gap detection algorithm (Memo-AGD). In this paper, we propose a Space Time-Aware Gap Detection (STAGD) approach to leverage space-time indexing and merging of trajectory gaps. We also incorporate a Dynamic Region Merge-based (DRM) approach to efficiently compute gap abnormality scores. We provide theoretical proofs that both algorithms are correct and complete and also provide analysis of asymptotic time complexity. Experimental results on synthetic and real-world maritime trajectory data show that the proposed approach substantially improves computation time over the baseline technique.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4399701818",
    "type": "article"
  },
  {
    "title": "Federated Learning Survey: A Multi-Level Taxonomy of Aggregation Techniques, Experimental Insights, and Future Frontiers",
    "doi": "https://doi.org/10.1145/3678182",
    "publication_date": "2024-07-17",
    "publication_year": 2024,
    "authors": "Meriem Arbaoui; Mohamed‐el‐Amine Brahmia; Abdellatif Rahmoun; Mourad Zghal",
    "corresponding_authors": "",
    "abstract": "The emerging integration of Internet of Things (IoT) and AI has unlocked numerous opportunities for innovation across diverse industries. However, growing privacy concerns and data isolation issues have inhibited this promising advancement. Unfortunately, traditional centralized Machine Learning (ML) methods have demonstrated their limitations in addressing these hurdles. In response to this ever-evolving landscape, Federated Learning (FL) has surfaced as a cutting-edge ML paradigm, enabling collaborative training across decentralized devices. FL allows users to jointly construct AI models without sharing their local raw data, ensuring data privacy, network scalability, and minimal data transfer. One essential aspect of FL revolves around proficient knowledge aggregation within a heterogeneous environment. Yet, the inherent characteristics of FL have amplified the complexity of its practical implementation compared to centralized ML. This survey delves into three prominent clusters of FL research contributions: personalization, optimization, and robustness. The objective is to provide a well-structured and fine-grained classification scheme related to these research areas through a unique methodology for selecting related work. Unlike other survey papers, we employed a hybrid approach that amalgamates bibliometric analysis and systematic scrutinizing to find the most influential work in the literature. Therefore, we examine challenges and contemporary techniques related to heterogeneity, efficiency, security, and privacy. Another valuable asset of this study is its comprehensive coverage of FL aggregation strategies, encompassing architectural features, synchronization methods, and several federation motivations. To further enrich our investigation, we provide practical insights into evaluating novel FL proposals and conduct experiments to assess and compare aggregation methods under IID and non-IID data distributions. Finally, we present a compelling set of research avenues that call for further exploration to open up a treasure of advancement.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4400729590",
    "type": "article"
  },
  {
    "title": "Surveying More Than Two Decades of Music Information Retrieval Research on Playlists",
    "doi": "https://doi.org/10.1145/3688398",
    "publication_date": "2024-08-12",
    "publication_year": 2024,
    "authors": "Giovanni Gabbolini; Derek Bridge",
    "corresponding_authors": "",
    "abstract": "In this article, we present an extensive survey of music information retrieval (MIR) research into music playlists. Our survey spans more than 20 years, and includes around 300 papers about playlists, with over 70 supporting sources. It is the first survey that is self-contained in the sense that it combines all the different MIR research into playlists. It embraces topics such as algorithms for automatic generation, for automatic continuation, for assisting with manual generation, for tagging and for captioning. It looks at manually constructed playlists, both those that are constructed for and by individuals and those constructed in collaboration with others. It covers ground-breaking research into enhancing playlists by cross-fading consecutive songs and by interleaving consecutive songs with speech, similar to what happens on a radio show. Most significantly, it is the first survey that can fully incorporate the paradigm shift that has taken place in the way people consume recorded music: the shift from physical media to music streaming. This has wrought profound changes in the size of music collections available to listeners and thus the algorithms that support the construction, curation and presentation of playlists and the methods adopted by users when they also construct, curate and listen to playlists.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4401516066",
    "type": "article"
  },
  {
    "title": "Quantum Informative Analysis in Smart Power Distribution",
    "doi": "https://doi.org/10.1145/3691350",
    "publication_date": "2024-08-31",
    "publication_year": 2024,
    "authors": "Tariq Ahamed Ahanger; Munish Bhatia; Abdulaziz Aldaej",
    "corresponding_authors": "",
    "abstract": "Advancements in the Internet of Things (IoT) paradigm have greatly improved the quality of services in the electricity industry through the integration of smart energy distribution and dependable electric devices. Conspicuously, the current research introduces a method for managing electricity consumption in smart residences using IoT-Fog technology, focusing on efficient energy allocation and real-time energy needs. The study specifically examines the effectiveness of electricity grid sub-stations in distributing energy using fog computing technology. By utilizing a Quantum Computing-assisted approach, optimal energy distribution is achieved by calculating a novel Electricity Usage Measure (EUM) based on actual energy usage patterns of smart homes. Furthermore, the Quantumized Neural Network (QiM-NN) technique is developed to forecast the electricity distribution over grid substations. For performance assessment, 4-month data is collected using four smart houses. Comparative analysis with existing data assessment techniques illustrates the effectiveness in terms of Temporal Delay (6.33 ms), Optimization Performance (Specificity (93.00%), Sensitivity (90.86%), Precision (96.66%), Coverage (96.66 %)), Reliability (93.76%), and Stability (71%).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4402088492",
    "type": "article"
  },
  {
    "title": "Who is Doing What and When",
    "doi": "https://doi.org/10.1145/2036264.2036269",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Shiwan Zhao; Michelle X. Zhou; Xiatian Zhang; Quan Yuan; Wentao Zheng; Rongyao Fu",
    "corresponding_authors": "",
    "abstract": "Content-centric social Web sites, such as discussion forums and blog sites, have flourished during the past several years. These sites often contain overwhelming amounts of information that are also being updated rapidly. To help users locate their interests at such sites (e.g., interesting blogs to read or discussion forums to join), researchers have developed a number of recommendation technologies. However, it is difficult to make effective recommendations for new users (a.k.a. the cold start problem) due to a lack of user information (e.g., preferences and interests). Furthermore, the complexity of recommendation algorithms often prevents users from comprehending let alone trusting the recommended results. To tackle these above two challenges, we are building a social map-based recommender system called Pharos. A social map summarizes users’ content-related social behavior over time (e.g., reading, writing, and commenting behavior during the past week) as a set of latent communities. For a given time interval, each community is characterized by the theme of the content being discussed and the key people involved. By discovering, ranking, and displaying the most popular latent communities at different time intervals, Pharos creates a time-sensitive, visual social map of a Web site. This enables new users to obtain a quick overview of the site, alleviating the cold start problem. Furthermore, we use the social map as a context to help explain Pharos-recommended content and people. Users can also interactively explore the social map to locate the content in which they are interested or people that are not being explicitly recommended, compensating for the imperfections in the recommendation algorithms. We have developed several Pharos applications, one of which is deployed within our company. Our preliminary evaluation of the deployed application shows the usefulness of Pharos.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1995255720",
    "type": "article"
  },
  {
    "title": "Sustainable biomass power plant location in the Italian Emilia-Romagna region",
    "doi": "https://doi.org/10.1145/1989734.1989737",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Massimiliano Cattafi; Marco Gavanelli; Michela Milano; Paolo Cagnoli",
    "corresponding_authors": "",
    "abstract": "Biomass power plants are very promising for reducing carbon oxides emissions, because they provide energy with a carbon-neutral process. Biomass comes from trees and vegetables, so they provide a renewable type of energy. However, biomass plants location, along with their provisioning basins, are heavily regulated by economical aspects, often without careful consideration of their environmental footprint. For example, some Italian biomass plants import from overseas palm-tree oil that is economically convenient. However, the energy consumed for the oil transportation is definitely greater than the energy produced by the palm-tree oil burning. In this way biomass power plants turn out to be environmentally inefficient, even if they produce renewable energy. We propose an Integer Linear Programming approach for defining the energy and cost-efficient biomass plant location along with the corresponding provisioning basin. In addition, the model enables to evaluate existing plants and their energy and cost efficiency. Our study is based on real data gathered in the Emilia-Romagna region of Italy. Finally, this optimization tool is just a small part of a wider perspective that is aimed to define decision support tools for the improvement of regional planning and its precise strategic environmental assessment.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2001970292",
    "type": "article"
  },
  {
    "title": "Web Page Summarization for Just-in-Time Contextual Advertising",
    "doi": "https://doi.org/10.1145/2036264.2036278",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Aris Anagnostopoulos; Andrei Broder; Evgeniy Gabrilovich; Vanja Josifovski; Lance Riedel",
    "corresponding_authors": "",
    "abstract": "Contextual advertising is a type of Web advertising, which, given the URL of a Web page, aims to embed into the page the most relevant textual ads available. For static pages that are displayed repeatedly, the matching of ads can be based on prior analysis of their entire content; however, often ads need to be matched to new or dynamically created pages that cannot be processed ahead of time. Analyzing the entire content of such pages on-the-fly entails prohibitive communication and latency costs. To solve the three-horned dilemma of either low relevance or high latency or high load, we propose to use text summarization techniques paired with external knowledge (exogenous to the page) to craft short page summaries in real time. Empirical evaluation proves that matching ads on the basis of such summaries does not sacrifice relevance, and is competitive with matching based on the entire page content. Specifically, we found that analyzing a carefully selected 6% fraction of the page text can sacrifice only 1%--3% in ad relevance. Furthermore, our summaries are fully compatible with the standard JavaScript mechanisms used for ad placement: they can be produced at ad-display time by simple additions to the usual script, and they only add 500--600 bytes to the usual request. We also compared our summarization approach, which is based on structural properties of the HTML content of the page, with a more principled one based on one of the standard text summarization tools (MEAD), and found their performance to be comparable.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2161914364",
    "type": "article"
  },
  {
    "title": "Mining the “Voice of the Customer” for Business Prioritization",
    "doi": "https://doi.org/10.1145/2089094.2089114",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Wei Peng; Tong Sun; Shriram Revankar; Tao Li",
    "corresponding_authors": "",
    "abstract": "To gain competitiveness and sustained growth in the 21st century, most businesses are on a mission to become more customer-centric. In order to succeed in this endeavor, it is crucial not only to synthesize and analyze the VOC (the VO ice of the C ustomer) data (i.e., the feedbacks or requirements raised by customers), but also to quickly turn these data into actionable knowledge. Although there are many technologies being developed in this complex problem space, most existing approaches in analyzing customer requests are ad hoc, time-consuming, error-prone, people-based processes which hardly scale well as the quantity of customer information explodes. This often results in the slow response to customer requests. In this article, in order to mine VOC to extract useful knowledge for the best product or service quality, we develop a hybrid framework that integrates domain knowledge with data-driven approaches to analyze the semi-structured customer requests. The framework consists of capturing functional features, discovering the overlap or correlation among the features, and identifying the evolving feature trend by using the knowledge transformation model. In addition, since understanding the relative importance of the individual customer request is very critical and has a direct impact on the effective prioritization in the development process, we develop a novel semantic enhanced link-based ranking (SELRank) algorithm for relatively rating/ranking both customer requests and products. The framework has been successfully applied on Xerox Office Group Feature Enhancement Requirements (XOG FER) datasets to analyze customer requests.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2056492794",
    "type": "article"
  },
  {
    "title": "Connecting people through physical proximity and physical resources at a conference",
    "doi": "https://doi.org/10.1145/2483669.2483683",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Alvin Chin; Bin Xu; Hao Wang; Lele Chang; Hao Wang; Lijun Zhu",
    "corresponding_authors": "",
    "abstract": "This work investigates how to bridge the gap between offline and online behaviors at a conference and how the physical resources in the conference (the physical objects used in the conference for gathering attendees together in engaging an activity such as rooms, sessions, and papers) can be used to help facilitate social networking. We build Find and Connect, a system that integrates offline activities and interactions captured in real time with online connections in a conference environment, to provide a list of potential people one should connect to for forming an ephemeral social network. We investigate how social connections can be established and integrated with physical resources through positioning technology, and the relationship between physical proximity encounters and online social connections. Results from our two datasets of two trials, one at the UIC/ATC 2010 conference and GCJK internal marketing event, show that social connections that are reciprocal in relationship, such as friendship and exchanged contacts, have tighter, denser, and highly clustered networks compared to unidirectional relationships such as follow. We discover that there is a positive relationship between physical proximity encounters and online social connections before the social connection is made for friends, but a negative relationship for after the social connection is made. The first indicates social selection is strong, and the second indicates social influence is weak. Even though our dataset is sparse, nonetheless we believe our work is promising and novel which is worthy of future research.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2073002077",
    "type": "article"
  },
  {
    "title": "Scalable Urban Mobile Crowdsourcing",
    "doi": "https://doi.org/10.1145/3078842",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Shih-Fen Cheng; Cen Chen; Thivya Kandappu; Hoong Chuin Lau; Archan Misra; Nikita Jaiman; Randy Tandriansyah; Desmond Koh",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate effective ways of utilizing crowdworkers in providing various urban services. The task recommendation platform that we design can match tasks to crowdworkers based on workers’ historical trajectories and time budget limits, thus making recommendations personal and efficient. One major challenge we manage to address is the handling of crowdworker’s trajectory uncertainties. In this article, we explicitly allow multiple routine routes to be probabilistically associated with each worker. We formulate this problem as an integer linear program whose goal is to maximize the expected total utility achieved by all workers. We further exploit the separable structures of the formulation and apply the Lagrangian relaxation technique to scale up computation. Numerical experiments have been performed over the instances generated using the realistic public transit dataset in Singapore. The results show that we can find significantly better solutions than the deterministic formulation, and in most cases we can find solutions that are very close to the theoretical performance limit. To demonstrate the practicality of our approach, we deployed our recommendation engine to a campus-scale field trial, and we demonstrate that workers receiving our recommendations incur fewer detours and complete more tasks, and are more efficient against workers relying on their own planning (25% more for top workers who receive recommendations). This is achieved despite having highly uncertain worker trajectories. We also demonstrate how to further improve the robustness of the system by using a simple multi-coverage mechanism.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2774095456",
    "type": "article"
  },
  {
    "title": "SmartTransfer",
    "doi": "https://doi.org/10.1145/3232229",
    "publication_date": "2018-11-08",
    "publication_year": 2018,
    "authors": "Bowen Du; Yifeng Cui; Yanjie Fu; Runxing Zhong; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "In urban transportation systems, transfer stations refer to hubs connecting a variety of bus and subway lines and, thus, are the most important nodes in transportation networks. The pervasive availability of large-scale travel traces of passengers, collected from automated fare collection (AFC) systems, has provided unprecedented opportunities for understanding citywide transfer patterns, which can benefit smart transportation, such as smart route recommendation to avoid crowded lines, and dynamic bus scheduling to enhance transportation efficiency. To this end, in this article, we provide a systematic study of the measurement, patterns, and modeling of spatiotemporal dynamics of passenger transfers. Along this line, we develop a data-driven analytical system for modeling the transfer volumes of each transfer station. More specifically, we first identify and quantify the discriminative patterns of spatiotemporal dynamics of passenger transfers by utilizing heterogeneous sources of transfer related data for each station. Also, we develop a multi-task spatiotemporal learning model for predicting the transfer volumes of a specific station at a specific time period. Moreover, we further leverage the predictive model of passenger transfers to provide crowdedness-aware route recommendations. Finally, we conduct the extensive evaluations with a variety of real-world data. Experimental results demonstrate the effectiveness of our proposed modeling method and its applications for smart transportation.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2899647666",
    "type": "article"
  },
  {
    "title": "Secure Deduplication System with Active Key Update and Its Application in IoT",
    "doi": "https://doi.org/10.1145/3356468",
    "publication_date": "2019-10-25",
    "publication_year": 2019,
    "authors": "Jin Li; Tong Li; Zheli Liu; Xiaofeng Chen",
    "corresponding_authors": "",
    "abstract": "The rich cloud services in the Internet of Things create certain needs for edge computing, in which devices should be able to handle storage tasks securely, reliably, and efficiently. When processing the storage requests from edge devices, each cloud server is supposed to eliminate duplicate copies of repeating data to reduce the amount of storage space and save on bandwidth. To protect data confidentiality while supporting deduplication, some convergent-encryption-based techniques have been proposed to encrypt the data before uploading. However, all these works cannot meet two requirements while preventing brute-force attacks: (i) power-constrained edge nodes should update encryption keys efficiently when an edge node is abandoned; and (ii) the access privacy of edge nodes should be guaranteed. In this article, we propose a novel encryption scheme for secure chunk-level deduplication. Based on this scheme, we present two constructions of the secure deduplication system that support an efficient key update protocol. The key update protocol does not involve any edge node in computational tasks, so that the deduplication system can adopt an active key update strategy. Moreover, one of our constructions, which is called advance construction, can provide access privacy assurances for edge nodes. The security analysis is given in terms of the proposed threat model. The experimental analysis demonstrates that the proposed deduplication system is practical.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2981736628",
    "type": "article"
  },
  {
    "title": "A Causal Approach to the Study of TCP Performance",
    "doi": "https://doi.org/10.1145/2770878",
    "publication_date": "2015-12-14",
    "publication_year": 2015,
    "authors": "Hadrien Hours; Ernst W. Biersack; Patrick Loiseau",
    "corresponding_authors": "",
    "abstract": "Communication networks are complex systems whose operation relies on a large number of components that work together to provide services to end users. As the quality of these services depends on different parameters, understanding how each of them impacts the final performance of a service is a challenging but important problem. However, intervening on individual factors to evaluate the impact of the different parameters is often impractical due to the high cost of intervention in a network. It is, therefore, desirable to adopt a formal approach to understand the role of the different parameters and to predict how a change in any of these parameters will impact performance. The approach of causality pioneered by J. Pearl provides a powerful framework to investigate these questions. Most of the existing theory is non-parametric and does not make any assumption on the nature of the system under study. However, most of the implementations of causal model inference algorithms and most of the examples of usage of a causal model to predict intervention rely on assumptions such linearity, normality, or discrete data. In this article, we present a methodology to overcome the challenges of working with real-world data and extend the application of causality to complex systems in the area of telecommunication networks, for which assumptions of normality, linearity and discrete data do no hold. Specifically, we study the performance of TCP, which is the prevalent protocol for reliable end-to-end transfer in the Internet. Analytical models of the performance of TCP exist, but they take into account the state of network only and disregard the impact of the application at the sender and the receiver, which often influences TCP performance. To address this point, we take as application the file transfer protocol (FTP), which uses TCP for reliable transfer. Studying a well-understood protocol such as TCP allows us to validate our approach and compare its results to previous studies. We first present and evaluate our methodology using TCP traffic obtained via network emulation, which allows us to experimentally validate the prediction of an intervention. We then apply the methodology to real-world TCP traffic sent over the Internet. Throughout the article, we compare the causal approach for studying TCP performance to other approaches such as analytical modeling or simulation and and show how they can complement each other.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1184121831",
    "type": "article"
  },
  {
    "title": "Markov models of social dynamics",
    "doi": "https://doi.org/10.1145/2483669.2483686",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Herbert Gintis",
    "corresponding_authors": "Herbert Gintis",
    "abstract": "This article shows how agent-based models of social dynamics can be treated rigorously and analytically as finite Markov processes, and their long-run properties are then given by an expanded version of the ergodic theorem for Markov processes. A Markov process model of a simplified market economy shows the fruitfulness of this approach.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1984114946",
    "type": "article"
  },
  {
    "title": "Multi-Keyword Multi-Click Advertisement Option Contracts for Sponsored Search",
    "doi": "https://doi.org/10.1145/2743027",
    "publication_date": "2015-10-01",
    "publication_year": 2015,
    "authors": "Bowei Chen; Jun Wang; Ingemar J. Cox; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "In sponsored search, advertisement (abbreviated ad) slots are usually sold by a search engine to an advertiser through an auction mechanism in which advertisers bid on keywords. In theory, auction mechanisms have many desirable economic properties. However, keyword auctions have a number of limitations including: the uncertainty in payment prices for advertisers; the volatility in the search engine’s revenue; and the weak loyalty between advertiser and search engine. In this article, we propose a special ad option that alleviates these problems. In our proposal, an advertiser can purchase an option from a search engine in advance by paying an upfront fee, known as the option price. The advertiser then has the right, but no obligation, to purchase among the prespecified set of keywords at the fixed cost-per-clicks (CPCs) for a specified number of clicks in a specified period of time. The proposed option is closely related to a special exotic option in finance that contains multiple underlying assets (multi-keyword) and is also multi-exercisable (multi-click). This novel structure has many benefits: advertisers can have reduced uncertainty in advertising; the search engine can improve the advertisers’ loyalty as well as obtain a stable and increased expected revenue over time. Since the proposed ad option can be implemented in conjunction with the existing keyword auctions, the option price and corresponding fixed CPCs must be set such that there is no arbitrage between the two markets. Option pricing methods are discussed and our experimental results validate the development. Compared to keyword auctions, a search engine can have an increased expected revenue by selling an ad option.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1994130471",
    "type": "article"
  },
  {
    "title": "Community Discovery from Social Media by Low-Rank Matrix Recovery",
    "doi": "https://doi.org/10.1145/2668110",
    "publication_date": "2015-01-23",
    "publication_year": 2015,
    "authors": "Jinfeng Zhuang; Tao Mei; Steven C. H. Hoi; Xian‐Sheng Hua; Yongdong Zhang",
    "corresponding_authors": "",
    "abstract": "The pervasive usage and reach of social media have attracted a surge of attention in the multimedia research community. Community discovery from social media has therefore become an important yet challenging issue. However, due to the subjective generating process, the explicitly observed communities (e.g., group-user and user-user relationship) are often noisy and incomplete in nature. This paper presents a novel approach to discovering communities from social media, including the group membership and user friend structure, by exploring a low-rank matrix recovery technique. In particular, we take Flickr as one exemplary social media platform. We first model the observed indicator matrix of the Flickr community as a summation of a low-rank true matrix and a sparse error matrix. We then formulate an optimization problem by regularizing the true matrix to coincide with the available rich context and content (i.e., photos and their associated tags). An iterative algorithm is developed to recover the true community indicator matrix. The proposed approach leads to a variety of social applications, including community visualization, interest group refinement, friend suggestion, and influential user identification. The evaluations on a large-scale testbed, consisting of 4,919 Flickr users, 1,467 interest groups, and over five million photos, show that our approach opens a new yet effective perspective to solve social network problems with sparse learning technique. Despite being focused on Flickr, our technique can be applied in any other social media community.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2008945622",
    "type": "article"
  },
  {
    "title": "TerraFly GeoCloud",
    "doi": "https://doi.org/10.1145/2700494",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Mingjin Zhang; Huibo Wang; Yun Lu; Tao Li; Yudong Guang; Chang Liu; Erik Edrosa; Hongtai Li; Naphtali Rishe",
    "corresponding_authors": "",
    "abstract": "With the exponential growth of the usage of web map services, geo-data analysis has become more and more popular. This article develops an online spatial data analysis and visualization system, TerraFly GeoCloud, which helps end-users visualize and analyze spatial data and share the analysis results. Built on the TerraFly Geo spatial database, TerraFly GeoCloud is an extra layer running upon the TerraFly map and can efficiently support many different visualization functions and spatial data analysis models. Furthermore, users can create unique URLs to visualize and share the analysis results. TerraFly GeoCloud also enables the MapQL technology to customize map visualization using SQL-like statements. The system is available at http://terrafly.fiu.edu/GeoCloud/.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2024209898",
    "type": "article"
  },
  {
    "title": "A modified random walk framework for handling negative ratings and generating explanations",
    "doi": "https://doi.org/10.1145/2414425.2414437",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Yu‐Chih Chen; Yu-Shi Lin; Yu-Chun Shen; Shou-De Lin",
    "corresponding_authors": "",
    "abstract": "The concept of random walk (RW) has been widely applied in the design of recommendation systems. RW-based approaches are effective in handling locality problem and taking extra information, such as the relationships between items or users, into consideration. However, the traditional RW-based approach has a serious limitation in handling bidirectional opinions. The propagation of positive and negative information simultaneously in a graph is nontrivial using random walk. To address the problem, this article presents a novel and efficient RW-based model that can handle both positive and negative comments with the guarantee of convergence. Furthermore, we argue that a good recommendation system should provide users not only a list of recommended items but also reasonable explanations for the decisions. Therefore, we propose a technique that generates explanations by backtracking the influential paths and subgraphs. The results of experiments on the MovieLens and Netflix datasets show that our model significantly outperforms state-of-the-art RW-based algorithms, and is capable of improving the overall performance in the ensemble with other models.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2066432005",
    "type": "article"
  },
  {
    "title": "A parts-based approach for automatic 3D shape categorization using belief functions",
    "doi": "https://doi.org/10.1145/2438653.2438668",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Hedi Tabia; Mohamed Daoudi; Jean‐Philippe Vandeborre; Olivier Colot",
    "corresponding_authors": "",
    "abstract": "Grouping 3D objects into (semantically) meaningful categories is a challenging and important problem in 3D mining and shape processing. Here, we present a novel approach to categorize 3D objects. The method described in this article, is a belief-function-based approach and consists of two stages: the training stage, where 3D objects in the same category are processed and a set of representative parts is constructed, and the labeling stage, where unknown objects are categorized. The experimental results obtained on the Tosca-Sumner and the Shrec07 datasets show that the system efficiently performs in categorizing 3D models.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2101997551",
    "type": "article"
  },
  {
    "title": "Personalized tag recommendation based on generalized rules",
    "doi": "https://doi.org/10.1145/2542182.2542194",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Luca Cagliero; Alessandro Fiori; Luigi Grimaudo",
    "corresponding_authors": "",
    "abstract": "Tag recommendation is focused on recommending useful tags to a user who is annotating a Web resource. A relevant research issue is the recommendation of additional tags to partially annotated resources, which may be based on either personalized or collective knowledge. However, since the annotation process is usually not driven by any controlled vocabulary, the collections of user-specific and collective annotations are often very sparse. Indeed, the discovery of the most significant associations among tags becomes a challenging task. This article presents a novel personalized tag recommendation system that discovers and exploits generalized association rules, that is, tag correlations holding at different abstraction levels, to identify additional pertinent tags to suggest. The use of generalized rules relevantly improves the effectiveness of traditional rule-based systems in coping with sparse tag collections, because: (i) correlations hidden at the level of individual tags may be anyhow figured out at higher abstraction levels and (ii) low-level tag associations discovered from collective data may be exploited to specialize high-level associations discovered in the user-specific context. The effectiveness of the proposed system has been validated against other personalized approaches on real-life and benchmark collections retrieved from the popular photo-sharing system Flickr.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2163426343",
    "type": "article"
  },
  {
    "title": "Analyzing Activity Recognition Uncertainties in Smart Home Environments",
    "doi": "https://doi.org/10.1145/2651445",
    "publication_date": "2015-08-13",
    "publication_year": 2015,
    "authors": "Eunju Kim; Sumi Helal; Chris Nugent; Mark Beattie",
    "corresponding_authors": "",
    "abstract": "In spite of the importance of activity recognition (AR) for intelligent human-computer interaction in emerging smart space applications, state-of-the-art AR technology is not ready or adequate for real-world deployments due to its insufficient accuracy. The accuracy limitation is directly attributed to uncertainties stemming from multiple sources in the AR system. Hence, one of the major goals of AR research is to improve system accuracy by minimizing or managing the uncertainties encountered throughout the AR process. As we cannot manage uncertainties well without measuring them, we must first quantify their impact. Nevertheless, such a quantification process is very challenging given that uncertainties come from diverse and heterogeneous sources. In this article, we propose an approach, which can account for multiple uncertainty sources and assess their impact on AR systems. We introduce several metrics to quantify the various uncertainties and their impact. We then conduct a quantitative impact analysis of uncertainties utilizing data collected from actual smart spaces that we have instrumented. The analysis is intended to serve as groundwork for developing “diagnostic” accuracy measures of AR systems capable of pinpointing the sources of accuracy loss. This is to be contrasted with the currently used accuracy measures.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2213698557",
    "type": "article"
  },
  {
    "title": "On Network Neutrality Measurements",
    "doi": "https://doi.org/10.1145/3040966",
    "publication_date": "2017-05-06",
    "publication_year": 2017,
    "authors": "Alex Maltinsky; Ran Giladi; Yuval Shavitt",
    "corresponding_authors": "",
    "abstract": "Network level surveillance, censorship, and various man-in-the-middle attacks target only specific types of network traffic (e.g., HTTP, HTTPS, VoIP, or Email). Therefore, packets of these types will likely receive “special” treatment by a transit network or a man-in-the-middle attacker. A transit Internet Service Provider (ISP) or an attacker may pass the targeted traffic through special software or equipment to gather data or perform an attack. This creates a measurable difference between the performance of the targeted traffic versus the general case. In networking terms, it violates the principle of “network neutrality,” which states that all traffic should be treated equally. Many techniques were designed to detect network neutrality violations, and some have naturally suggested using them to detect surveillance and censorship. In this article, we show that the existing network neutrality measurement techniques can be easily detected and therefore circumvented. We then briefly propose a new approach to overcome the drawbacks of current measurement techniques.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2612372623",
    "type": "article"
  },
  {
    "title": "A Risk-Scoring Feedback Model for Webpages and Web Users Based on Browsing Behavior",
    "doi": "https://doi.org/10.1145/2928274",
    "publication_date": "2017-05-06",
    "publication_year": 2017,
    "authors": "Michal Ben Neria; Nancy‐Sarah Yacovzada; Irad Ben‐Gal",
    "corresponding_authors": "",
    "abstract": "It has been claimed that many security breaches are often caused by vulnerable (naïve) employees within the organization [Ponemon Institute LLC 2015a]. Thus, the weakest link in security is often not the technology itself but rather the people who use it [Schneier 2003]. In this article, we propose a machine learning scheme for detecting risky webpages and risky browsing behavior, performed by naïve users in the organization. The scheme analyzes the interaction between two modules: one represents naïve users, while the other represents risky webpages. It implements a feedback loop between these modules such that if a webpage is exposed to a lot of traffic from risky users, its “risk score” increases, while in a similar manner, as the user is exposed to risky webpages (with a high “risk score”), his own “risk score” increases. The proposed scheme is tested on a real-world dataset of HTTP logs provided by a large American toolbar company. The results suggest that a feedback learning process involving webpages and users can improve the scoring accuracy and lead to the detection of unknown malicious webpages.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2612726345",
    "type": "article"
  },
  {
    "title": "RCMC",
    "doi": "https://doi.org/10.1145/3086636",
    "publication_date": "2017-08-12",
    "publication_year": 2017,
    "authors": "Haytham Assem; Teodora Sandra Buda; Declan O’Sullivan",
    "corresponding_authors": "",
    "abstract": "During the past few years, the analysis of data generated from Location-Based Social Networks (LBSNs) have aided in the identification of urban patterns, understanding activity behaviours in urban areas, as well as producing novel recommender systems that facilitate users’ choices. Recognizing crowd-mobility patterns in cities is very important for public safety, traffic managment, disaster management, and urban planning. In this article, we propose a framework for Recognizing the Crowd Mobility Patterns in Cities using LBSN data. Our proposed framework comprises four main components: data gathering, recurrent crowd-mobility patterns extraction, temporal functional regions detection, and visualization component. More specifically, we employ a novel approach based on Non-negative Matrix Factorization and Gaussian Kernel Density Estimation for extracting the recurrent crowd-mobility patterns in cities illustrating how crowd shifts from one area to another during each day across various time slots. Moreover, the framework employs a hierarchical clustering-based algorithm for identifying what we refer to as temporal functional regions by modeling functional areas taking into account temporal variation by means of check-ins’ categories. We build the framework using a spatial-temporal dataset crawled from Twitter for two entire years (2013 and 2014) for the area of Manhattan in New York City. We perform a detailed analysis of the extracted crowd patterns with an exploratory visualization showing that our proposed approach can identify clearly obvious mobility patterns that recur over time and location in the urban scenario. Using same time interval, we show that correlating the temporal functional regions with the recognized recurrent crowd-mobility patterns can yield to a deeper understanding of city dynamics and the motivation behind the crowd mobility. We are confident that our proposed framework not only can help in managing complex city environments and better allocation of resources based on the expected crowd mobility and temporal functional regions but also can have a direct implication on a variety of applications such as personalized recommender systems, anomalous event detection, disaster resilience management systems, and others.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2747190710",
    "type": "article"
  },
  {
    "title": "Co-saliency Detection with Graph Matching",
    "doi": "https://doi.org/10.1145/3313874",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Zun Li; Congyan Lang; Jiashi Feng; Yidong Li; Tao Wang; Songhe Feng",
    "corresponding_authors": "",
    "abstract": "Recently, co-saliency detection, which aims to automatically discover common and salient objects appeared in several relevant images, has attracted increased interest in the computer vision community. In this article, we present a novel graph-matching based model for co-saliency detection in image pairs. A solution of graph matching is proposed to integrate the visual appearance, saliency coherence, and spatial structural continuity for detecting co-saliency collaboratively. Since the saliency and the visual similarity have been seamlessly integrated, such a joint inference schema is able to produce more accurate and reliable results. More concretely, the proposed model first computes the intra-saliency for each image by aggregating multiple saliency cues. The common and salient regions across multiple images are thus discovered via a graph matching procedure. Then, a graph reconstruction scheme is proposed to refine the intra-saliency iteratively. Compared to existing co-saliency detection methods that only utilize visual appearance cues, our proposed model can effectively exploit both visual appearance and structure information to better guide co-saliency detection. Extensive experiments on several challenging image pair databases demonstrate that our model outperforms state-of-the-art baselines significantly.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2938472358",
    "type": "article"
  },
  {
    "title": "Recognizing Multi-Agent Plans When Action Models and Team Plans Are Both Incomplete",
    "doi": "https://doi.org/10.1145/3319403",
    "publication_date": "2019-05-30",
    "publication_year": 2019,
    "authors": "Hankz Hankui Zhuo",
    "corresponding_authors": "Hankz Hankui Zhuo",
    "abstract": "Multi-Agent Plan Recognition (MAPR) aims to recognize team structures (which are composed of team plans) from the observed team traces (action sequences) of a set of intelligent agents. In this article, we introduce the problem formulation of MAPR based on partially observed team traces, and present a weighted MAX-SAT–based framework to recognize multi-agent plans from partially observed team traces with the help of two types of auxiliary knowledge to help recognize multi-agent plans, i.e., a library of incomplete team plans and a set of incomplete action models. Our framework functions with two phases. We first build a set of hard constraints that encode the correctness property of the team plans, and a set of soft constraints that encode the optimal utility property of team plans based on the input team trace, incomplete team plans, and incomplete action models. After that, we solve all of the constraints using a weighted MAX-SAT solver and convert the solution to a set of team plans that best explain the structure of the observed team trace. We empirically exhibit both effectiveness and efficiency of our framework in benchmark domains from International Planning Competition (IPC).",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2947294569",
    "type": "article"
  },
  {
    "title": "Single Image Snow Removal Using Sparse Representation and Particle Swarm Optimizer",
    "doi": "https://doi.org/10.1145/3372116",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Shih-Chia Huang; Da-Wei Jaw; Bo‐Hao Chen; Sy‐Yen Kuo",
    "corresponding_authors": "",
    "abstract": "Images are often corrupted by natural obscuration (e.g., snow, rain, and haze) during acquisition in bad weather conditions. The removal of snowflakes from only a single image is a challenging task due to situational variety and has been investigated only rarely. In this article, we propose a novel snow removal framework for a single image, which can be separated into a sparse image approximation module and an adaptive tolerance optimization module. The first proposed module takes the advantage of sparsity-based regularization to reconstruct a potential snow-free image. An auto-tuning mechanism for this framework is then proposed to seek a better reconstruction of a snow-free image via the time-varying inertia weight particle swarm optimizers in the second proposed module. Through collaboration of these two modules iteratively, the number of snowflakes in the reconstructed image is reduced as generations progress. By the experimental results, the proposed method achieves a better efficacy of snow removal than do other state-of-the-art techniques via both objective and subjective evaluations. As a result, the proposed method is able to remove snowflakes successfully from only a single image while preserving most original object structure information.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3009037420",
    "type": "article"
  },
  {
    "title": "Modeling with Node Popularities for Autonomous Overlapping Community Detection",
    "doi": "https://doi.org/10.1145/3373760",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Di Jin; Bingyi Li; Pengfei Jiao; Dongxiao He; Hongyu Shan; Weixiong Zhang",
    "corresponding_authors": "",
    "abstract": "Overlapping community detection has triggered recent research in network analysis. One of the promising techniques for finding overlapping communities is the popular stochastic models, which, unfortunately, have some common drawbacks. They do not support an important observation that highly connected nodes are more likely to reside in the overlapping regions of communities in the network. These methods are in essence not truly unsupervised, since they require a threshold on probabilistic memberships to derive overlapping structures and need the number of communities to be specified a priori . We develop a new method to address these issues for overlapping community detection. We first present a stochastic model to accommodate the relative importance and the expected degree of every node in each community. We then infer every overlapping community by ranking the nodes according to their importance. Second, we determine the number of communities under the Bayesian framework. We evaluate our method and compare it with five state-of-the-art methods. The results demonstrate the superior performance of our method. We also apply this new method to two applications, showing its superb performance on practical problems.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3020846497",
    "type": "article"
  },
  {
    "title": "Copula-Based Anomaly Scoring and Localization for Large-Scale, High-Dimensional Continuous Data",
    "doi": "https://doi.org/10.1145/3372274",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Gábor Horväth; Edith Kovács; Roland Molontay; Szabolcs Nováczki",
    "corresponding_authors": "",
    "abstract": "The anomaly detection method presented by this article has a special feature: it not only indicates whether or not an observation is anomalous but also tells what exactly makes an anomalous observation unusual. Hence, it provides support to localize the reason of the anomaly. The proposed approach is model based; it relies on the multivariate probability distribution associated with the observations. Since the rare events are present in the tails of the probability distributions, we use copula functions, which are able to model the fat-tailed distributions well. The presented procedure scales well; it can cope with a large number of high-dimensional samples. Furthermore, our procedure can cope with missing values as well, which occur frequently in high-dimensional datasets. In the second part of the article, we demonstrate the usability of the method through a case study, where we analyze a large dataset consisting of the performance counters of a real mobile telecommunication network. Since such networks are complex systems, the signs of sub-optimal operation can remain hidden for a potentially long time. With the proposed procedure, many such hidden issues can be isolated and indicated to the network operator.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3022118908",
    "type": "article"
  },
  {
    "title": "Social Science–guided Feature Engineering",
    "doi": "https://doi.org/10.1145/3364222",
    "publication_date": "2020-01-09",
    "publication_year": 2020,
    "authors": "Ghazaleh Beigi; Jiliang Tang; Huan Liu",
    "corresponding_authors": "",
    "abstract": "Many real-world relations can be represented by signed networks with positive links (e.g., friendships and trust) and negative links (e.g., foes and distrust). Link prediction helps advance tasks in social network analysis such as recommendation systems. Most existing work on link analysis focuses on unsigned social networks. The existence of negative links piques research interests in investigating whether properties and principles of signed networks differ from those of unsigned networks, and mandates dedicated efforts on link analysis for signed social networks. Recent findings suggest that properties of signed networks substantially differ from those of unsigned networks and negative links can be of significant help in signed link analysis in complementary ways. In this article, we center our discussion on a challenging problem of signed link analysis. Signed link analysis faces the problem of data sparsity, i.e. only a small percentage of signed links are given. This problem can even get worse when negative links are much sparser than positive ones as users are inclined more towards positive disposition rather than negative. We investigate how we can take advantage of other sources of information for signed link analysis. This research is mainly guided by three social science theories, Emotional Information, Diffusion of Innovations, and Individual Personality. Guided by these, we extract three categories of related features and leverage them for signed link analysis. Experiments show the significance of the features gleaned from social theories for signed link prediction and addressing the data sparsity challenge.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4288083600",
    "type": "article"
  },
  {
    "title": "Robust Multiview Feature Learning for RGB-D Image Understanding",
    "doi": "https://doi.org/10.1145/2735521",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Zheng-Jun Zha; Yang Yang; Jinhui Tang; Meng Wang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "The availability of massive RGB-depth (RGB-D) images poses a compelling need for effective RGB-D content understanding techniques. RGB-D images provide synchronized information from multiple views (e.g., color and depth) of real-world objects and scenes. This work proposes learning compact and discriminative features from the multiple views of RGB-D content toward effective feature representation for RGB-D image understanding. In particular, a robust multiview feature learning approach is developed, which exploits the intrinsic relations among multiple views. The feature learning in multiple views is jointly optimized in an integrated formulation. The joint optimization essentially exploits the intrinsic relations among the views, leading to effective features and making the learning process robust to noises. The feature learning function is formulated as a robust nonnegative graph embedding function over multiple graphs in various views. The graphs characterize the local geometric and discriminating structure of the multiview data. The joint sparsity in ℓ 1 -norm graph embedding and ℓ 21 -norm data factorization further enhances the robustness of feature learning. We derive an efficient computational solution for the proposed approach and provide rigorous theoretical proof with regard to its convergence. We apply the proposed approach to two RGB-D image understanding tasks: RGB-D object classification and RGB-D scene categorization. We conduct extensive experiments on two real-world RGB-D image datasets. The experimental results have demonstrated the effectiveness of the proposed approach.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2045298021",
    "type": "article"
  },
  {
    "title": "Identifying Controversial Wikipedia Articles Using Editor Collaboration Networks",
    "doi": "https://doi.org/10.1145/2630075",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Hoda Sepehri-Rad; Denilson Barbosa",
    "corresponding_authors": "",
    "abstract": "Wikipedia is probably the most commonly used knowledge reference nowadays, and the high quality of its articles is widely acknowledged. Nevertheless, disagreement among editors often causes some articles to become controversial over time. These articles span thousands of popular topics, including religion, history, and politics, to name a few, and are manually tagged as controversial by the editors, which is clearly suboptimal. Moreover, disagreement, bias, and conflict are expressed quite differently in Wikipedia compared to other social media, rendering previous approaches ineffective. On the other hand, the social process of editing Wikipedia is partially captured in the edit history of the articles, opening the door for novel approaches. This article describes a novel controversy model that builds on the interaction history of the editors and not only predicts controversy but also sheds light on the process that leads to controversy. The model considers the collaboration history of pairs of editors to predict their attitude toward one another. This is done in a supervised way, where the votes of Wikipedia administrator elections are used as labels indicating agreement (i.e., support vote) or disagreement (i.e., oppose vote). From each article, a collaboration network is built, capturing the pairwise attitude among editors, allowing the accurate detection of controversy. Extensive experimental results establish the superiority of this approach compared to previous work and very competitive baselines on a wide range of settings.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2093447054",
    "type": "article"
  },
  {
    "title": "Intelligent Interface for Textual Attitude Analysis",
    "doi": "https://doi.org/10.1145/2535912",
    "publication_date": "2014-09-18",
    "publication_year": 2014,
    "authors": "Alena Neviarouskaya; Masaki Aono; Helmut Prendinger; Mitsuru Ishizuka",
    "corresponding_authors": "",
    "abstract": "This article describes a novel intelligent interface for attitude sensing in text driven by a robust computational tool for the analysis of fine-grained attitudes (emotions, judgments, and appreciations) expressed in text. The module responsible for textual attitude analysis was developed using a compositional linguistic approach based on the attitude-conveying lexicon, the analysis of syntactic and dependency relations between words in a sentence, the compositionality principle applied at various grammatical levels, the rules elaborated for semantically distinct verb classes, and a method considering the hierarchy of concepts. The performance of this module was evaluated on sentences from personal stories about life experiences. The developed web-based interface supports recognition of nine emotions, positive and negative judgments, and positive and negative appreciations conveyed in text. It allows users to adjust parameters, to enable or disable various functionality components of the algorithm, and to select the format of text annotation and attitude statistics visualization.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2122868386",
    "type": "article"
  },
  {
    "title": "The Role of Cores in Recommender Benchmarking for Social Bookmarking Systems",
    "doi": "https://doi.org/10.1145/2700485",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Stephan Doerfel; Robert Jäschke; Gerd Stumme",
    "corresponding_authors": "",
    "abstract": "Social bookmarking systems have established themselves as an important part in today’s Web. In such systems, tag recommender systems support users during the posting of a resource by suggesting suitable tags. Tag recommender algorithms have often been evaluated in offline benchmarking experiments. Yet, the particular setup of such experiments has rarely been analyzed. In particular, since the recommendation quality usually suffers from difficulties such as the sparsity of the data or the cold-start problem for new resources or users, datasets have often been pruned to so-called cores (specific subsets of the original datasets), without much consideration of the implications on the benchmarking results. In this article, we generalize the notion of a core by introducing the new notion of a set-core , which is independent of any graph structure, to overcome a structural drawback in the previous constructions of cores on tagging data. We show that problems caused by some types of cores can be eliminated using set-cores. Further, we present a thorough analysis of tag recommender benchmarking setups using cores. To that end, we conduct a large-scale experiment on four real-world datasets, in which we analyze the influence of different cores on the evaluation of recommendation algorithms. We can show that the results of the comparison of different recommendation approaches depends on the selection of core type and level. For the benchmarking of tag recommender algorithms, our results suggest that the evaluation must be set up more carefully and should not be based on one arbitrarily chosen core type and level.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2278342822",
    "type": "article"
  },
  {
    "title": "Community Detection with Topological Structure and Attributes in Information Networks",
    "doi": "https://doi.org/10.1145/2979681",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "Zhonggang Wu; Zhao Lu; Shan-Yuan Ho",
    "corresponding_authors": "",
    "abstract": "Information networks contain objects connected by multiple links and described by rich attributes. Detecting community for these networks is a challenging research problem, because there is a scarcity of effective approaches that balance the features of the network structure and the characteristics of the nodes. Some methods detect communities by considering topological structures while ignoring the contributions of attributes. Other methods have considered both topological structure and attributes but pay a high price in time complexity. We establish a new community detection algorithm which explores both topological &lt;u&gt;S&lt;/u&gt;tructure and &lt;u&gt;A&lt;/u&gt;ttributes using &lt;u&gt;G&lt;/u&gt;lobal structure and &lt;u&gt;L&lt;/u&gt;ocal neighborhood features (SAGL) which also has low computational complexity. The first step of SAGL evaluates the global importance of every node and calculates the similarity of each node pair by combining edge strength and node attribute similarity. The second step of SAGL uses a clustering algorithm that identifies communities by measuring the similarity of two nodes, calculated by the distance of their neighbors. Experimental results on three real-world datasets show the effectiveness of SAGL, particularly its fast convergence compared to current state-of-the-art attributed graph clustering methods.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2547734801",
    "type": "article"
  },
  {
    "title": "Industrial Federated Topic Modeling",
    "doi": "https://doi.org/10.1145/3418283",
    "publication_date": "2021-02-17",
    "publication_year": 2021,
    "authors": "Di Jiang; Yongxin Tong; Yuanfeng Song; Xueyang Wu; Weiwei Zhao; Jinhua Peng; Rongzhong Lian; Qian Xu; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Probabilistic topic modeling has been applied in a variety of industrial applications. Training a high-quality model usually requires a massive amount of data to provide comprehensive co-occurrence information for the model to learn. However, industrial data such as medical or financial records are often proprietary or sensitive, which precludes uploading to data centers. Hence, training topic models in industrial scenarios using conventional approaches faces a dilemma: A party (i.e., a company or institute) has to either tolerate data scarcity or sacrifice data privacy. In this article, we propose a framework named Industrial Federated Topic Modeling (iFTM), in which multiple parties collaboratively train a high-quality topic model by simultaneously alleviating data scarcity and maintaining immunity to privacy adversaries. iFTM is inspired by federated learning, supports two representative topic models (i.e., Latent Dirichlet Allocation and SentenceLDA) in industrial applications, and consists of novel techniques such as private Metropolis-Hastings, topic-wise normalization, and heterogeneous model integration. We conduct quantitative evaluations to verify the effectiveness of iFTM and deploy iFTM in two real-life applications to demonstrate its utility. Experimental results verify iFTM’s superiority over conventional topic modeling.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3129277622",
    "type": "article"
  },
  {
    "title": "Local Graph Edge Partitioning",
    "doi": "https://doi.org/10.1145/3466685",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Shengwei Ji; Chenyang Bu; Lei Li; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "Graph edge partitioning, which is essential for the efficiency of distributed graph computation systems, divides a graph into several balanced partitions within a given size to minimize the number of vertices to be cut. Existing graph partitioning models can be classified into two categories: offline and streaming graph partitioning models. The former requires global graph information during the partitioning, which is expensive in terms of time and memory for large-scale graphs. The latter creates partitions based solely on the received graph information. However, the streaming model may result in a lower partitioning quality compared with the offline model. Therefore, this study introduces a Local Graph Edge Partitioning model, which considers only the local information (i.e., a portion of a graph instead of the entire graph) during the partitioning. Considering only the local graph information is meaningful because acquiring complete information for large-scale graphs is expensive. Based on the Local Graph Edge Partitioning model, two local graph edge partitioning algorithms—Two-stage Local Partitioning and Adaptive Local Partitioning—are given. Experimental results obtained on 14 real-world graphs demonstrate that the proposed algorithms outperform rival algorithms in most tested cases. Furthermore, the proposed algorithms are proven to significantly improve the efficiency of the real graph computation system GraphX.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3201680717",
    "type": "article"
  },
  {
    "title": "S3-Net: A Fast Scene Understanding Network by Single-Shot Segmentation for Autonomous Driving",
    "doi": "https://doi.org/10.1145/3470660",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Yuan Cheng; Yuchao Yang; Hai‐Bao Chen; Ngai Wong; Hao Yu",
    "corresponding_authors": "",
    "abstract": "Real-time segmentation and understanding of driving scenes are crucial in autonomous driving. Traditional pixel-wise approaches extract scene information by segmenting all pixels in a frame, and hence are inefficient and slow. Proposal-wise approaches only learn from the proposed object candidates, but still require multiple steps on the expensive proposal methods. Instead, this work presents a fast single-shot segmentation strategy for video scene understanding. The proposed net, called S3-Net, quickly locates and segments target sub-scenes , and meanwhile extracts attention-aware time-series sub-scene features ( ats-features ) as inputs to an attention-aware spatio-temporal model (ASM) . Utilizing tensorization and quantization techniques, S3-Net is intended to be lightweight for edge computing. Experiments results on CityScapes, UCF11, HMDB51, and MOMENTS datasets demonstrate that the proposed S3-Net achieves an accuracy improvement of 8.1% versus the 3D-CNN based approach on UCF11, a storage reduction of 6.9× and an inference speed of 22.8 FPS on CityScapes with a GTX1080Ti GPU.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3203983741",
    "type": "article"
  },
  {
    "title": "Weakly Supervised Video Object Segmentation via Dual-attention Cross-branch Fusion",
    "doi": "https://doi.org/10.1145/3506716",
    "publication_date": "2022-03-03",
    "publication_year": 2022,
    "authors": "Lili Wei; Congyan Lang; Liqian Liang; Songhe Feng; Tao Wang; Shidi Chen",
    "corresponding_authors": "",
    "abstract": "Recently, concerning the challenge of collecting large-scale explicitly annotated videos, weakly supervised video object segmentation (WSVOS) using video tags has attracted much attention. Existing WSVOS approaches follow a general pipeline including two phases, i.e., a pseudo masks generation phase and a refinement phase. To explore the intrinsic property and correlation buried in the video frames, most of them focus on the later phase by introducing optical flow as temporal information to provide more supervision. However, these optical flow-based studies are greatly affected by illumination and distortion and lack consideration of the discriminative capacity of multi-level deep features. In this article, with the goal of capturing more effective temporal information and investigating a temporal information fusion strategy accordingly, we propose a unified WSVOS model by adopting a two-branch architecture with a multi-level cross-branch fusion strategy, named as dual-attention cross-branch fusion network (DACF-Net). Concretely, the two branches of DACF-Net, i.e., a temporal prediction subnetwork (TPN) and a spatial segmentation subnetwork (SSN), are used for extracting temporal information and generating predicted segmentation masks, respectively. To perform the cross-branch fusion between TPN and SSN, we propose a dual-attention fusion module that can be plugged into the SSN flexibly. We also pose a cross-frame coherence loss (CFCL) to achieve smooth segmentation results by exploiting the coherence of masks produced by TPN and SSN. Extensive experiments demonstrate the effectiveness of proposed approach compared with the state-of-the-arts on two challenging datasets, i.e., Davis-2016 and YouTube-Objects.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4214861803",
    "type": "article"
  },
  {
    "title": "INN: An Interpretable Neural Network for AI Incubation in Manufacturing",
    "doi": "https://doi.org/10.1145/3519313",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Xiaoyu Chen; Yingyan Zeng; SungKu Kang; Ran Jin",
    "corresponding_authors": "",
    "abstract": "Both artificial intelligence (AI) and domain knowledge from human experts play an important role in manufacturing decision making. Smart manufacturing emphasizes a fully automated data-driven decision-making; however, the AI incubation process involves human experts to enhance AI systems by integrating domain knowledge for modeling, data collection and annotation, and feature extraction. Such an AI incubation process not only enhances the domain knowledge discovery but also improves the interpretability and trustworthiness of AI methods. In this article, we focus on the knowledge transfer from human experts to a supervised learning problem by learning domain knowledge as interpretable features and rules, which can be used to construct rule-based systems to support manufacturing decision making, such as process modeling and quality inspection. Although many advanced statistical and machine learning methods have shown promising modeling accuracy and efficiency, rule-based systems are still highly preferred and widely adopted due to their interpretability for human experts to comprehend. However, most of the existing rule-based systems are constructed based on deterministic human-crafted rules, whose parameters, such as thresholds of decision rules, are suboptimal. Yet the machine learning methods, such as tree models or neural networks, can learn a decision rule based structure without much interpretation or agreement with domain knowledge. Therefore, the traditional machine learning models and human experts’ domain knowledge cannot be directly improved by learning from data. In this research, we propose an interpretable neural network (INN) model with a center-adjustable sigmoid activation function to efficiently optimize the rule-based systems. Using the rule-based system from domain knowledge to regulate the INN architecture not only improves the prediction accuracy with optimized parameters but also ensures the interpretability by adopting the interpretable rule-based systems from domain knowledge. The proposed INN will be effective for supervised learning problems when rule-based systems are available. The merits of the INN model are demonstrated via a simulation study and a real case study in the quality modeling of a semiconductor manufacturing process. The source code of this work is hosted here: https://github.com/XiaoyuChenUofL/Interpretable-Neural-Network .",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4220751842",
    "type": "article"
  },
  {
    "title": "Self-supervised Short-text Modeling through Auxiliary Context Generation",
    "doi": "https://doi.org/10.1145/3511712",
    "publication_date": "2022-04-12",
    "publication_year": 2022,
    "authors": "Nurendra Choudhary; Charų C. Aggarwal; Karthik Subbian; Chandan K. Reddy",
    "corresponding_authors": "",
    "abstract": "Short text is ambiguous and often relies predominantly on the domain and context at hand in order to attain semantic relevance. Existing classification models perform poorly on short text due to data sparsity and inadequate context. Auxiliary context, which can often provide sufficient background regarding the domain, is typically available in several application scenarios. While some of the existing works aim to leverage real-world knowledge to enhance short-text representations, they fail to place appropriate emphasis on the auxiliary context. Such models do not harness the full potential of the available context in auxiliary sources. To address this challenge, we reformulate short-text classification as a dual channel self-supervised learning problem (that leverages auxiliary context) with a generation network and a corresponding prediction model. We propose a self-supervised framework, Pseudo-Auxiliary Context generation network for Short-text Modeling (PACS) , to comprehensively leverage auxiliary context and it is jointly learned with a prediction network in an end-to-end manner. Our PACS model consists of two sub-networks: a Context Generation Network (CGN) that models the auxiliary context’s distribution and a Prediction Network (PN) to map the short-text features and auxiliary context distribution to the final class label. Our experimental results on diverse datasets demonstrate that PACS outperforms formidable state-of-the-art baselines. We also demonstrate the performance of our model on cold-start scenarios (where contextual information is non-existent) during prediction. Furthermore, we perform interpretability and ablation studies to analyze various representational features captured by our model and the individual contribution of its modules to the overall performance of PACS, respectively.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4223472728",
    "type": "article"
  },
  {
    "title": "Steering-by-example for Progressive Visual Analytics",
    "doi": "https://doi.org/10.1145/3531229",
    "publication_date": "2022-06-08",
    "publication_year": 2022,
    "authors": "Marius Hogräfer; Marco Angelini; Giuseppe Santucci; Hans‐Jörg Schulz",
    "corresponding_authors": "",
    "abstract": "Progressive visual analytics allows users to interact with early, partial results of long-running computations on large datasets. In this context, computational steering is often brought up as a means to prioritize the progressive computation. This is meant to focus computational resources on data subspaces of interest so as to ensure their computation is completed before all others. Yet, current approaches to select a region of the view space and then to prioritize its corresponding data subspace either require a one-to-one mapping between view and data space, or they need to establish and maintain computationally costly index structures to trace complex mappings between view and data space. We present steering-by-example, a novel interactive steering approach for progressive visual analytics, which allows prioritizing data subspaces for the progression by generating a relaxed query from a set of selected data items. Our approach works independently of the particular visualization technique and without additional index structures. First benchmark results show that steering-by-example considerably improves Precision and Recall for prioritizing unprocessed data for a selected view region, clearly outperforming random uniform sampling.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4281618615",
    "type": "article"
  },
  {
    "title": "Budget Distributed Support Vector Machine for Non-ID Federated Learning Scenarios",
    "doi": "https://doi.org/10.1145/3539734",
    "publication_date": "2022-05-31",
    "publication_year": 2022,
    "authors": "A. Navia-Vázquez; Roberto Díaz-Morales; M. Fernández-Díaz",
    "corresponding_authors": "",
    "abstract": "In recent years, there has been remarkable growth in Federated Learning (FL) approaches because they have proven to be very effective in training large Machine Learning (ML) models and also serve to preserve data confidentiality, as recommended by the GDPR or other business confidentiality restrictions that may apply. Despite the success of FL, performance is greatly reduced when data is not distributed identically (non-ID) across participants, as local model updates tend to diverge from the optimal global solution and thus the model averaging procedure in the aggregator is less effective. Kernel methods such as Support Vector Machines (SVMs) have not seen an equivalent evolution in the area of privacy preserving edge computing because they suffer from inherent computational, privacy and scalability issues. Furthermore, non-linear SVMs do not naturally lead to federated schemes, since locally trained models cannot be passed to the aggregator because they reveal training data (they are built on Support Vectors), and the global model cannot be updated at every worker using gradient descent. In this article, we explore the use of a particular controlled complexity (“Budget”) Distributed SVM (BDSVM) in the FL scenario with non-ID data, which is the least favorable situation, but very common in practice. The proposed BDSVM algorithm is as follows: model weights are broadcasted to workers, which locally update some kernel Gram matrices computed according to a common architectural base and send them back to the aggregator, which finally combines them, updates the global model, and repeats the procedure until a convergence criterion is met. Experimental results using synthetic 2D datasets show that the proposed method can obtain maximal margin decision boundaries even when the data is non-ID distributed. Further experiments using real-world datasets with non-ID data distribution show that the proposed algorithm provides better performance with less communication requirements than a comparable Multilayer Perceptron (MLP) trained using FedAvg. The advantage is more remarkable for a larger number of edge devices. We have also demonstrated the robustness of the proposed method against information leakage, membership inference attacks, and situations with dropout or straggler participants. Finally, in experiments run on separate processes/machines interconnected via the cloud messaging service developed in the context of the EU-H2020 MUSKETEER project, BDSVM is able to train better models than FedAvg in about half the time.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4281638103",
    "type": "article"
  },
  {
    "title": "Defending against Poisoning Backdoor Attacks on Federated Meta-learning",
    "doi": "https://doi.org/10.1145/3523062",
    "publication_date": "2022-09-23",
    "publication_year": 2022,
    "authors": "Chien-Lun Chen; Sara Babakniya; Marco Paolieri; Leana Golubchik",
    "corresponding_authors": "",
    "abstract": "Federated learning allows multiple users to collaboratively train a shared classification model while preserving data privacy. This approach, where model updates are aggregated by a central server, was shown to be vulnerable to poisoning backdoor attacks : a malicious user can alter the shared model to arbitrarily classify specific inputs from a given class. In this article, we analyze the effects of backdoor attacks on federated meta-learning , where users train a model that can be adapted to different sets of output classes using only a few examples. While the ability to adapt could, in principle, make federated learning frameworks more robust to backdoor attacks (when new training examples are benign), we find that even one-shot attacks can be very successful and persist after additional training. To address these vulnerabilities, we propose a defense mechanism inspired by matching networks , where the class of an input is predicted from the similarity of its features with a support set of labeled examples. By removing the decision logic from the model shared with the federation, the success and persistence of backdoor attacks are greatly reduced.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4296857612",
    "type": "article"
  },
  {
    "title": "Describing UI Screenshots in Natural Language",
    "doi": "https://doi.org/10.1145/3564702",
    "publication_date": "2022-09-26",
    "publication_year": 2022,
    "authors": "Luis A. Leiva; Asutosh Hota; Antti Oulasvirta",
    "corresponding_authors": "",
    "abstract": "Being able to describe any user interface (UI) screenshot in natural language can promote understanding of the main purpose of the UI, yet currently it cannot be accomplished with state-of-the-art captioning systems. We introduce XUI, a novel method inspired by the global precedence effect to create informative descriptions of UIs, starting with an overview and then providing fine-grained descriptions about the most salient elements. XUI builds upon computational models for topic classification, visual saliency prediction, and natural language generation (NLG). XUI provides descriptions with up to three different granularity levels that, together, describe what is in the interface and what the user can do with it. We found that XUI descriptions are highly readable, are perceived to accurately describe the UI, and score similarly to human-generated UI descriptions. XUI is available as open-source software.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4297220110",
    "type": "article"
  },
  {
    "title": "MVST: A Multi-View Spatial-Temporal Model for Fine-Grained Crime Prediction",
    "doi": "https://doi.org/10.1145/3712607",
    "publication_date": "2025-01-17",
    "publication_year": 2025,
    "authors": "Chang Wei; Wengen Li; Yichao Zhang; Jihong Guan; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "Given a specific region, crime prediction aims to predict the occurrence of various crime events within a certain period of time in future, which is of high significance for guaranteeing urban safety. In practice, crime events are usually affected by a variety of factors from different views, e.g., the attributes of the region, the correlations between different regions, and the correlations between different categories of crime events. Moreover, these correlations are dynamically changing over time, which makes it difficult to learn the regularity and patterns in crime data for achieving accurate prediction. To address this issue, we proposed a new M ulti- V iew S patial- T emporal (MVST) model for fine-grained crime prediction. MVST model first builds a static region graph to capture the similarity between regions in terms of region attributes such as census records and economy statistics, and creates a time-dependent graph to capture the dynamic correlations between regions based on human mobility data. Meanwhile, both static and dynamic graphs are created to capture the correlations between different categories of crime events. After that, those graphs created from different views are fused together with a multi-view graph fusion module to achieve crime prediction with fine-grained time granularities, e.g., 4 hours and 12 hours. According to the experiments on two real crime datasets, our MVST model obviously outperforms existing crime prediction methods. The code of MVST model is available at https://github.com/weichang811/MVST .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406533580",
    "type": "article"
  },
  {
    "title": "SAug: Structural Imbalance Aware Augmentation for Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3712699",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Kejia Chen; W. Mu; Zulong Liu; Zheng Liu",
    "corresponding_authors": "",
    "abstract": "Graph machine learning (GML) has made great progress in node classification, link prediction, graph classification and so on. However, graphs in reality are often structurally imbalanced, that is, only a few hub nodes have a denser local structure and higher influence. The imbalance may compromise the robustness of existing GML models, especially in learning tail nodes. This paper proposes a selective graph augmentation method to solve this problem. Firstly, a Pagerank-based sampling strategy is designed to identify hub nodes and tail nodes in the graph. Secondly, a selective augmentation strategy is proposed, which drops the noise neighbors of hub nodes on one side, and discovers the latent neighbors and generates pseudo neighbors for tail nodes on the other side. Also, it can alleviate the structural imbalance between two types of nodes. Finally, a GNN model is retrained on the augmented graph. Extensive experiments demonstrate that the proposed method can significantly improve the backbone GNNs and achieve superior performance to its competitors of graph augmentation methods and hub/tail aware methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406686078",
    "type": "article"
  },
  {
    "title": "A GPT-assisted Multi-Granularity Contrastive Learning approach for Knowledge Graph Entity Typing",
    "doi": "https://doi.org/10.1145/3714429",
    "publication_date": "2025-01-23",
    "publication_year": 2025,
    "authors": "Hongbin Zhang; Tao Wang; Zhuowei Wang; Nankai Lin; Chong Chen; Lianglun Cheng",
    "corresponding_authors": "",
    "abstract": "Knowledge graph entity typing (KGET) is an efficient way to infer possible missing types for entities, which has become a key instrument to enhance the construction of knowledge graphs (KGs). Existing models to KGET have mainly focused on a single granularity information such as distinct entity information, but other granularity information including entity-to-type-clusters, the same cluster and interaction information have not been fully explored, resulting in inferring incorrect types in KGs. To address this, we propose a GPT-assisted Multi-Granularity Contrastive Learning (GMGCL) approach to acquire entity-to-type-clusters, entity, type-cluster and relation information by GPT-assisted entity-to-type-clusters clustering, entity-based, cluster-based and relation-based contrastive learning, respectively. Our approach is evaluated on FB15kET and YAGO43kET datasets, outperforming other baselines and obtaining a 1.35% average improvement at least on MRR.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406760780",
    "type": "article"
  },
  {
    "title": "Cost-aware Best Arm Identification in Stochastic Bandits",
    "doi": "https://doi.org/10.1145/3712290",
    "publication_date": "2025-01-24",
    "publication_year": 2025,
    "authors": "Zhida Qin; WEI-WEI XUE; Lu Zheng; Xiaoying Gan; Hongqiu Wu; Haiming Jin; Luoyi Fu",
    "corresponding_authors": "",
    "abstract": "The best arm identification problem in multi-armed bandit model has been widely applied into many practical applications, such as spectrum sensing, online advertising, and cloud computing. Although lots of works have been devoted into this area, most of them do not consider the cost of pulling actions, i.e., a player has to pay some cost when she pulls an arm. Motivated by this, we study a ratio-based best arm identification problem, where each arm is associated with a random reward as well as a random cost. For any \\(\\delta\\in(0,1)\\) , with probability at least \\(1-\\delta\\) , the player aims to find the arm with the largest ratio of expected reward to expected cost using as few samplings as possible. Specifically, we consider two settings: 1) the precise setting, i.e., identifying the precise optimal one; 2) the PAC (Probably Approximate Correct) setting, which identifies the \\(\\epsilon\\) -optimal one. For the precise setting, we design the elimination-type algorithms and provide a fundamental lower bound which asymptotically matches the upper bound, while in the PAC setting, an UCB-type algorithm which amed \\(\\epsilon\\) -RCB algorithm is proposed. We show that for all algorithms, the sample complexities, i.e., the pulling times for all arms, grow logarithmically as \\(\\frac{1}{\\delta}\\) increases. Moreover, compared to existing works, the running of our algorithms is independent of the arm-related parameters, which is more practical. Finally, we validate our theoretical results through numerical experiments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406801206",
    "type": "article"
  },
  {
    "title": "Improving the Summarization Effectiveness of Abstractive Datasets through Contrastive Learning",
    "doi": "https://doi.org/10.1145/3716851",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Junho Shin; Younghoon Lee",
    "corresponding_authors": "",
    "abstract": "Most studies on abstractive summarization are conducted in a supervised learning framework, aiming to generate a golden summary from the original document. In this process, the model focuses on portions of the document that closely resemble the golden summary to produce a coherent output. Consequently, current methodologies tend to achieve higher performance on extractive datasets compared to abstractive datasets, indicating diminished effectiveness on more abstracted content. To address this, our study proposes a methodology that maintains high effectiveness on abstractive datasets. Specifically, we introduce a multi-task learning approach that incorporates both salient and non-salient information during training. This is implemented by adding a contrastive objective to the fine-tuning phase of an encoder–decoder language model. Salient and non-salient parts are selected based on ROUGE-L F1 scores, and their relationships are learned through a triplet loss function. The proposed method is evaluated on five benchmark summarization datasets, including two extractive and three abstractive datasets. Experimental results demonstrate significant performance improvements on abstractive datasets, particularly those with high levels of abstraction, compared to existing abstractive summarization methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407370240",
    "type": "article"
  },
  {
    "title": "JASRNet: Learning Joint Adaptive Sampling and Reconstruction for Depth Sensing",
    "doi": "https://doi.org/10.1145/3716852",
    "publication_date": "2025-02-12",
    "publication_year": 2025,
    "authors": "Chunyang Bi; Ming Yang Teng; Tian Xie; Kun Li; Jingyu Yang",
    "corresponding_authors": "",
    "abstract": "Recent attempts to exploit irregular sampling strategies for depth sensing have shown prominent merits over the uniform rectangular sampling in terms of depth reconstruction quality, particularly at low sampling rates. However, the separate treatment of depth sampling and reconstruction did not enjoy potential merits of joint optimization. In this paper, we propose a joint adaptive depth sampling and reconstruction network, named JASRNet , for the RGB-D sensing configuration, to simultaneously optimize both the sampling and reconstruction of the depth information in an end-to-end manner. The sampling sub-network infers the locations to sample according to the significance distribution generated from the associated RGB image without any prior information of the underlying depth maps. The depth reconstruction sub-network learns and then fuses global and local depth features with attention guidance, which helps to obtain more accurate depth reconstruction results at boundaries. A hybrid loss function is further proposed to promote sharp discontinuities of the reconstructed depth maps. Qualitative and quantitative results show that our method achieves better depth sensing quality than several state-of-the-art methods for various indoor and outdoor scenes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407405824",
    "type": "article"
  },
  {
    "title": "Considering Time and Feature Entropy in Calibrated Recommendations",
    "doi": "https://doi.org/10.1145/3716858",
    "publication_date": "2025-02-13",
    "publication_year": 2025,
    "authors": "Diego Corrêa da Silva; Dietmar Jannach; Frederico Araújo Dur�ão",
    "corresponding_authors": "",
    "abstract": "The essence of calibration in recommender systems is to generate recommendations that match the distribution of a given user’s past preferences regarding certain item features—e.g., in terms of preferred genres in the case of movies—while preserving relevance. The user’s past preference distribution is usually derived by considering the features of all items that the user previously liked. However, the most common approach in the literature to derive this distribution has certain limitations. First, it does not consider that user preferences may change over time. Second, there are domains where the relevant item features are set-valued, e.g., a movie can have several genres. In such cases, existing calibration approaches may represent the true user’s preference distribution in a suboptimal way. In this work, we, therefore, propose two novel approaches to derive the preference distributions of users for the purpose of calibration. The first method allows us to decrease the relevance of possibly outdated preference information. The second method is an entropy-based approach, which aims to capture better the user’s true preferences towards certain item features. Extensive experimental evaluations on four distinct datasets confirm that the proposed techniques are more effective in reducing the level of miscalibration than the common state-of-the-art calibration approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407450016",
    "type": "article"
  },
  {
    "title": "The Evaluation Framework and Benchmark for Large Language Models in the Government Affairs Domain",
    "doi": "https://doi.org/10.1145/3716854",
    "publication_date": "2025-02-13",
    "publication_year": 2025,
    "authors": "S. Liu; Lin Zhang; Weidong Liu; Jianfeng Zhang; Donghui Gao; Xiaofeng Jia",
    "corresponding_authors": "",
    "abstract": "The rapid evolution of artificial intelligence (AI) has driven advancements across numerous sectors. In the domain of government affairs, large language models (LLMs) hold significant potential for applications such as policy analysis, data processing, and decision support. However, their adoption in government settings faces considerable challenges, including data accessibility issues, the absence of standardized evaluation criteria, and concerns regarding model accuracy, reliability, and security. To address these challenges, we propose a comprehensive evaluation framework specifically designed for LLMs in government affairs. Built on modular principles, this framework ensures adaptability across various industries. Additionally, we introduce the Multi-Scenario Government Affairs Benchmark (MSGABench 1 )dataset, a Chinese-language dataset specifically crafted to meet the practical needs of government professionals. Employing the proposed framework and the MSGA dataset, we conducted an empirical evaluation of 15 prominent LLMs, revealing critical insights: (1)Performance: many models demonstrated low accuracy and reliability, particularly under minor input variations, with some dropping below 35% accuracy, whereas GPT-4 achieved above 95% reliability; (2) Security and Compliance: significant concerns were identified, including privacy vulnerabilities, legal compliance risks, and persistent biases, which may hinder secure deployments in government contexts; (3)Task Avoidance: certain models exhibited excessive caution, often avoiding responses to basic tasks like document classification and government-related inquiries, which restricts their usability. These findings highlight essential limitations and opportunities for improvement, contributing to the safe and effective application of LLMs in the government sector.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407450298",
    "type": "article"
  },
  {
    "title": "PRO-MTL : Parameterized Route Optimization using Multi-Task Learning",
    "doi": "https://doi.org/10.1145/3718092",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Jayant Vyas; Jayesh Budhwani; Debasis Das",
    "corresponding_authors": "",
    "abstract": "In the current ridesharing scenario, finding a compatible passenger is highly challenging and largely dependent on chance. Existing algorithms prioritize the shortest route without considering future requests or traffic conditions, which reduces the likelihood of matching with another compatible passenger. This uncertainty leads to increased congestion along shortest routes and fewer ridesharing trips overall. This paper proposes a route recommendation strategy that goes beyond the shortest route, aiming to address these issues. The proposed strategy results in higher demand, reduced congestion, broader coverage of points of interests, and an increased probability of finding compatible passengers during a trip. To achieve this, we introduce a time-series forecasting method leveraging a multi-task long short-term memory model to predict demand and traffic patterns in city-zone neighborhoods. These predictions are then used to recommend optimized routes. To evaluate our approach, we tested it on three datasets containing trip and traffic details from New York City, Los Angeles, and Shenzhen. Our model demonstrated 96% accuracy and a 2% RMSE loss in predicting the expected number of passengers. Furthermore, during route recommendations, we observed a 23% increase in passenger count for 97% of trips and a reduction in travel time for the shortest path in 60% of trips. In light of the above experimentation, we believe that while our approach recommends a longer route than the shortest one (for 40% cases), it helps taxi drivers to find compatible passengers on most trips which increases the profit of ridesharing services, and reduces the waiting time for passengers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407682168",
    "type": "article"
  },
  {
    "title": "Cosine Additive Angular Margin Loss for Breast Cancer Classification in Histopathological Images with Small AI Systems",
    "doi": "https://doi.org/10.1145/3718093",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Pendar Alirezazadeh; Fadi Dornaika; Abdelmalik Moujahid",
    "corresponding_authors": "",
    "abstract": "Breast cancer claims thousands of lives annually, emphasizing the need for swift and accurate histopathology image classification to expedite diagnoses. Despite the rapid evolution of Convolutional Neural Networks (CNNs), the conventional softmax loss lacks the robustness required to discern intricate features in breast cancer classification from histopathological images. In response, our study introduces the Cosine Additive Angular Margin Loss (CAAM) to address this limitation and achieve both enhanced intra-class cohesion and distinct inter-class boundaries concurrently. By normalizing weight and feature vectors, we eliminate radial variations before imposing angular and cosine margin constraints on the softmax angle space. This process maximizes the decision margin, resulting in a discriminative feature embedding. Extensive experiments conducted on the BreakHis dataset demonstrate that CAAM consistently outperforms existing methods in breast cancer histopathological image classification. Our findings underscore the efficacy of angular margin-based softmax losses in bolstering the performance of advanced CNN models for breast cancer classification.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407682179",
    "type": "article"
  },
  {
    "title": "Prediction for Sensor-less Locations Using Multi-View Graph Fusion Approach with Approximation Module: A Case Study on Dengue Fever Risk Sensor",
    "doi": "https://doi.org/10.1145/3718094",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Pei-Xuan Li; Hsun-Ping Hsieh",
    "corresponding_authors": "",
    "abstract": "Dengue fever is an emergency disease spread by mosquitoes. The most direct way to prevent the disease is to predict risky areas and bolster mosquito preventive strategies. Risk is usually evaluated by monitoring the number of eggs in the ovitraps set up by the government. However, areas without sensors still need to be checked and managed for dengue risk. In this study, we focus on forecasting each region’s fine-grained dengue fever risk, especially in regions without sensor coverage. The paucity of historical data makes this endeavor challenging. Furthermore, determining how to effectively blend different features is another important research challenge and practical issue. We propose a M ulti- V iew G raph Fusion Approach with A pproximation M odule (MVGAM) to address these two issues. For the regions that have no sensor coverage, MVGAM first uses a feature extractor to learn their representation based on their dynamic and static features. Then we use a graph constructor to formulate the relationship between sensors from different perspectives, and a multi-view graph fusion module to learn the embedding of sensors. Finally, we use an approximation module to deal with the lack of historical data. We conducted experiments using a real-world dataset from the urban area of Tainan, Taiwan. The results show that the proposed MVGAM outperforms the state-of-the-art methods and baselines. The ablation study also shows that every component in MVGAM has a significant impact on boosting the prediction effectiveness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407682184",
    "type": "article"
  },
  {
    "title": "Efficiency and Performance Optimization in Large Language Models through IB Fine-Tuning",
    "doi": "https://doi.org/10.1145/3718096",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Ashly Ann Jo; Ebin Deni Raj; Jayakrushna Sahoo",
    "corresponding_authors": "",
    "abstract": "In the rapidly evolving field of Natural Language Processing (NLP), optimizing methods for fine-tuning Large Language Models (LLMs) is increasingly critical for improving generalization and performance. Fine-tuning LLMs is challenging due to high costs, overfitting, and difficulty adapting to diverse tasks. These challenges grow as LLMs scale, making traditional fine-tuning methods inefficient and expensive. To address these issues, a novel Information Bottleneck (IB) method for fine-tuning LLMs is proposed, focusing on retaining only the most critical and relevant information in the model’s internal representations. By striking a balance between information compression and predictive relevance, the IB method aims to reduce overfitting and enhance generalization. This approach also integrates reinforcement learning and continual learning to enhance LLM performance further. The proposed framework considers two key metrics: (1) compression effectiveness, which reduces redundancy and improves generalization, and (2) predictive relevance, which ensures high task-specific performance. The proposed scheme achieves scalable fine-tuning across diverse NLP tasks using a lightweight proxy model to enhance computational efficiency. The proposed framework empirical evaluations and ablation studies show that the IB method improves accuracy while significantly reducing computational costs, enabling efficient, interpretable, and adaptable LLM optimization and increasing convergence.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407682194",
    "type": "article"
  },
  {
    "title": "Modeling N-ary Relational Knowledge Bases with Tensor Decomposition",
    "doi": "https://doi.org/10.1145/3709002",
    "publication_date": "2025-02-26",
    "publication_year": 2025,
    "authors": "Yu Liu; Quanming Yao; Yong Li",
    "corresponding_authors": "",
    "abstract": "The binary relational knowledge base (KB, a.k.a. knowledge graph), representing real-world knowledge with binary relations and entities, has been an important research topic in artificial intelligence, while, considerable knowledge also involves beyond-binary relations. Recently, the area proposes to model n-ary relational KBs with both binary and beyond-binary relations included. However, most current models are extended from translational distance and neural network models in binary relational KBs, which suffer from weak expressiveness and high complexity, respectively. To overcome such issues, in this work, we propose a novel two-step modeling framework, GETD, generalizing the powerful tensor decomposition technique from binary relational KBs to the n-ary case. For n-ary relational KBs with single-arity relations, the GETD framework introduces Tucker decomposition and Tensor Ring decomposition for expressive and efficient modeling. Furthermore, the framework is technically extended for the representation of n-ary relational KBs with mixed-arity relations. The existing negative sampling technique is also generalized to the n-ary case for GETD. In addition, we theoretically prove that the GETD framework is fully expressive to completely represent any KBs. Empirical results on two representative datasets show that the proposed framework significantly outperforms the state-of-the-art methods, achieving 11–26% and 4–7% improvements on Hits@10 for the single-arity and the mixed-arity cases, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407957904",
    "type": "article"
  },
  {
    "title": "Alleviating Confirmation Bias in Learning with Noisy Labels via Two-Network Collaboration",
    "doi": "https://doi.org/10.1145/3723009",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "C. Xu; Peipei Song; Shengeng Tang; Dan Guo; Xun Yang",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have achieved remarkable success in various computer vision tasks, e.g ., image classification. However, most of the existing models depend heavily on annotated data, where label noise is inevitable. Training with such noisy data negatively impacts the generalization performance of DNNs. To this end, recent advances in learning with noisy labels (LNL) adopt the sample selection strategy that identifies clean samples from the noisy dataset to update DNNs, using semi-supervised learning where rejected samples are treated as unlabeled data. However, existing LNL methods often overlook the varying fitting difficulties of different classes, resulting in suboptimal sample selection and confirmation bias, and consequently, the errors accumulate during semi-supervised training. In this paper, we propose a novel method, TNCollab, which aims at alleviating confirmation bias in both sample selection and semi-supervised training stages via two-network collaboration. Specifically, we introduce a class-adaptive threshold for sample selection to address the varying fitting difficulties across different classes. Additionally, we construct a hard set consisting of samples where the two networks disagree, and introduce a noise-robust loss to extract potentially useful information while maintaining robustness against label noise. Furthermore, we propose a dual consistency loss to ensure consistent predictions between the networks across different augmented views of the same sample, facilitating mutual learning. Extensive experiments demonstrate that TNCollab achieves state-of-the-art performance on image classification and facial expression recognition tasks, particularly on CIFAR-10, CIFAR-100, WebVision, Clothing1M, Tiny-ImageNet, and RAF-DB datasets, showing improved visual understanding and generalization capabilities. Our codes are available at https://github.com/Delete12137/TNCollab .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408302655",
    "type": "article"
  },
  {
    "title": "Enhancing Aspect Sentiment Classification with Dual-Channel Graph Convolutional Network",
    "doi": "https://doi.org/10.1145/3721844",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "Xin Sun; Y. Mi; Hongao Li",
    "corresponding_authors": "",
    "abstract": "Aspect sentiment classification (ASC) constitutes a crucial research area within sentiment analysis tasks, aiming to predict sentiment polarity towards different aspects in given contexts. Identifying the relations between aspects and sentiments can be a challenging task, as aspects and sentiments are not always predefined. Most existing studies have demonstrated the effectiveness of using dependency parsing tree and graph convolutional network (GCN), achieving good experimental results. However, existing methods have mainly focused on either semantic or syntactic information individually, and may introduce errors when the input sentence lacks clear syntactic information. To address these issues, we propose a novel approach based on Dual-Channel Graph Convolutional Network (DC-GCN), which integrates feature fusion within a dual-channel architecture. Our model can effectively capture the semantic information and enhance the feature representation of syntactic structures by introducing the multi-head self-attention graph convolution, guided by the TopK strategy, and the directional densely connected graph convolutional network. We further employ a bi-affine strategy and multi-layer perceptron to integrate semantic and syntactic information. Experimental results on publicly available datasets demonstrate the superior performance of our model over state-of-the-art methods. Specifically, our model improves upon baseline models on the Twitter, Lap14, Rest14, Rest15, and Rest16 datasets, with increases in accuracy/macro-F1 scores of 0.06/0.58, 0.58/0.47, 0.25/1.19, 0.23/1.05, and 0.36/1.32, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408332131",
    "type": "article"
  },
  {
    "title": "Disentangling User Interest and Geographical Context for POI Recommendations",
    "doi": "https://doi.org/10.1145/3723008",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "Wenhui Meng; Jiayi Xie; Jing Yi; Yaochen Zhu; Zhenzhong Chen",
    "corresponding_authors": "",
    "abstract": "POI recommendation plays an important role in many applications, such as mobility prediction and location-based advertisements. Existing POI recommendation methods mainly capture the observed patterns in user visits for recommendations, without a comprehensive consideration of the underlying reasons behind the visits. Therefore, different causes of a visit, i.e., users’ interest and geographical context, are entangled. When the underlying causes change (e.g., when a user moves to a new place), the robustness of the recommendations cannot be guaranteed. To address the above challenges, we propose DUIG, a novel user interest and geographical influences disentanglement framework for POI recommendations. We first design a personalized disentanglement strategy to divide check-ins through geographical influence. Specifically, the colliding effect of causality is leveraged to the divide cause-specific check-ins, such that user interest and geographical influence can be properly disentangled in user and POI embeddings. Through this mechanism, even if the underlying reasons that affect a user’s preference change, intervention can be conducted upon the causes to make recommendations generalized to the new scenario. In addition, a geographical-aware negative sampling strategy is proposed to utilize hard negatives to regularize the embedding and disentanglement in the latent space, where a larger sampling probability is introduced for negative samples containing more geographic information. Extensive experiments on two real-world POI recommendation datasets demonstrate the superior performance of DUIG.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408332310",
    "type": "article"
  },
  {
    "title": "A Multi-hop Graph Reasoning Network for Knowledge-based VQA",
    "doi": "https://doi.org/10.1145/3724125",
    "publication_date": "2025-03-19",
    "publication_year": 2025,
    "authors": "Zihan Hu; Jiuxiang You; Zhenguo Yang; Xiaoping Li; Haoran Xie; Qing Li; Wenyin Liu",
    "corresponding_authors": "",
    "abstract": "Knowledge-based visual question answering (KB-VQA) requires reasoning about the visual grounding relations between the images and questions by incorporating external knowledge. Existing works typically retrieve knowledge from knowledge graphs by leveraging global multimodal representations of image-text pairs for graph convolution, which neglect contextual clues at hop granularity, resulting in suboptimal spreading and leveraging of contextual information. To this end, we propose a multi-hop graph reasoning network (MGRN) for KB-VQA, which consists of a knowledge graph constructor (KGC) module, a semantic-instructed graph reasoning (SGR) module, and an answering module. MGRN exploits multimodal semantics from given images and questions as instructions for graph reasoning to obtain the knowledge representation from either the scene graph and knowledge base. Specifically, KGC fuses the scene graph with triplets from ConceptNet and Comet to construct a contextual knowledge graph for retrieving knowledge representation. Furthermore, SGR conducts multi-hop graph reasoning to select top- \\(K\\) knowledge items for answering by passing and filtering interplay messages on contextual knowledge graphs under the guidance of multimodal semantic representation. Extensive experiments conducted on two public datasets show the effectiveness and outperformance of our method.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408611773",
    "type": "article"
  },
  {
    "title": "SubgroupTE: Advancing Treatment Effect Estimation with Subgroup Identification",
    "doi": "https://doi.org/10.1145/3718097",
    "publication_date": "2025-03-19",
    "publication_year": 2025,
    "authors": "Seungyeon Lee; Ruoqi Liu; Wenyu Song; Lang Li; Ping Zhang",
    "corresponding_authors": "",
    "abstract": "Precise estimation of treatment effects is crucial for accurately evaluating the intervention. While deep learning models have exhibited promising performance in learning counterfactual representations for treatment effect estimation (TEE), a major limitation in most of these models is that they often overlook the diversity of treatment effects across potential subgroups that have varying treatment effects and characteristics, treating the entire population as a homogeneous group. This limitation restricts the ability to precisely estimate treatment effects and provide targeted treatment recommendations. In this paper, we propose a novel treatment effect estimation model, named SubgroupTE, which incorporates subgroup identification in TEE. SubgroupTE identifies heterogeneous subgroups with different responses and more precisely estimates treatment effects by considering subgroup-specific treatment effects in the estimation process. In addition, we introduce an expectation-maximization (EM)-based training process that iteratively optimizes estimation and subgrouping networks to improve both estimation and subgroup identification. Comprehensive experiments on the synthetic and semi-synthetic datasets demonstrate the outstanding performance of SubgroupTE compared to the existing works for treatment effect estimation and subgrouping models. Additionally, a real-world study demonstrates the capabilities of SubgroupTE in enhancing targeted treatment recommendations for patients with opioid use disorder (OUD) by incorporating subgroup identification with treatment effect estimation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408611956",
    "type": "article"
  },
  {
    "title": "A Gated Graph Neural Network Approach to Fast-Convergent Dynamic Average Estimation",
    "doi": "https://doi.org/10.1145/3725857",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Antonio Marino; Claudio Pacchierotti; Paolo Robuffo Giordano",
    "corresponding_authors": "",
    "abstract": "Dynamic average estimation is a critical problem in multi-agent systems, enabling agents to collaboratively estimate time-varying signals using only local information exchange. Traditional model-based approaches often face challenges related to convergence speed and sensitivity to network topology changes. This paper introduces a novel learning-based solution leveraging Gated Graph Neural Networks (GGNNs) for fast-convergent dynamic average estimation in a fully distributed manner. Taking advantage of the inherent structure of GGNNs, the proposed method models the estimation process as a distributed autoregressor, ensuring rapid convergence while maintaining stability. We incorporate a regularization term during training to enforce convergence guarantees and introduce an encoding-decoding mechanism to reduce communication overhead without sacrificing accuracy compared to standard GGNNs. Extensive numerical experiments demonstrate that our approach significantly outperforms conventional model-based estimators in terms of both convergence speed and precision, making it a promising alternative for multi-agent applications that require dynamic average estimation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408812855",
    "type": "article"
  },
  {
    "title": "Do LLMs Dream of Ontologies?",
    "doi": "https://doi.org/10.1145/3725852",
    "publication_date": "2025-03-26",
    "publication_year": 2025,
    "authors": "Marco Bombieri; Paolo Fiorini; Simone Paolo Ponzetto; Marco Rospocher",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across diverse natural language processing tasks, yet their ability to memorize structured knowledge remains underexplored. In this paper, we investigate the extent to which general-purpose pre-trained LLMs retain and correctly reproduce concept identifier (ID)–label associations from publicly available ontologies. We conduct a systematic evaluation across multiple ontological resources, including the Gene Ontology, Uberon, Wikidata, and ICD-10, using LLMs such as Pythia-12B , Gemini-1.5-Flash , GPT-3.5 , and GPT-4 . Our findings reveal that only a small fraction of ontological concepts is accurately memorized, with GPT-4 demonstrating the highest performance. To understand why certain concepts are memorized more effectively than others, we analyze the relationship between memorization accuracy and concept popularity on the Web. Our results indicate a strong correlation between the frequency of a concept’s occurrence online and the likelihood of accurately retrieving its ID from the label. This suggests that LLMs primarily acquire such knowledge through indirect textual exposure rather than directly from structured ontological resources. Furthermore, we introduce new metrics to quantify prediction invariance, demonstrating that the stability of model responses across variations in prompt language and temperature settings can serve as a proxy for estimating memorization robustness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408869297",
    "type": "article"
  },
  {
    "title": "Graph Contrastive Learning on Multi-label Classification for Recommendations",
    "doi": "https://doi.org/10.1145/3725854",
    "publication_date": "2025-04-02",
    "publication_year": 2025,
    "authors": "Jiayang Wu; Wensheng Gan; H. J. Lu; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "In business analysis, providing effective recommendations is crucial for boosting company profits. Graph structures, especially bipartite graphs, are favored for analyzing complex data relationships. Link prediction is crucial for recommending specific items to users. Traditional methods have primarily focused on binary classification tasks. These methods, which identify patterns in graph structures or use representation techniques like graph neural networks (GNNs), face challenges with increasing data volume and label count. Data growth strains system performance and efficiency. More labels intensify data sparsity, as users and items focus on only a few labels, leading to sparse matrices that hamper recommendation algorithms. To tackle these issues, we introduce the Graph Contrastive Learning for Multi-label Classification (MCGCL) model. It uses contrastive learning to improve recommendations and has two training phases: a main task of holistic user-item graph learning to grasp user-item relationships, and a subtask of constructing homogeneous user-user (item-item) subgraphs to capture user-user and item-item relationships. Comparative experiments with state-of-the-art methods confirm the effectiveness of MCGCL, highlighting its potential for improving recommendation systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409094715",
    "type": "article"
  },
  {
    "title": "GenFighter: A Generative and Evolutive Textual Attack Removal",
    "doi": "https://doi.org/10.1145/3729240",
    "publication_date": "2025-04-10",
    "publication_year": 2025,
    "authors": "Md Athikul Islam; Edoardo Serra; Sushil Jajodia",
    "corresponding_authors": "",
    "abstract": "Adversarial attacks pose significant challenges to deep neural networks (DNNs) such as Transformer models in natural language processing (NLP). This paper introduces a novel defense strategy, called GenFighter , which enhances adversarial robustness by learning and reasoning on the training classification distribution. GenFighter identifies potentially malicious instances deviating from the distribution, transforms them into semantically equivalent instances aligned with the training data, and employs ensemble techniques for a unified and robust response. By conducting extensive experiments, we show that GenFighter outperforms state-of-the-art defenses in accuracy under attack and attack success rate metrics while maintaining the same or superior generalization capabilities. Additionally, it requires a high number of queries per attack, making the attack more challenging in real scenarios. Finally, The ablation study shows that our approach proficiently integrates transfer learning, a generative/evolutive procedure, and an ensemble method, providing an effective defense against NLP adversarial attacks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409330016",
    "type": "article"
  },
  {
    "title": "Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge",
    "doi": "https://doi.org/10.1145/3729236",
    "publication_date": "2025-04-11",
    "publication_year": 2025,
    "authors": "Kebing Jin; Hankz Hankui Zhuo",
    "corresponding_authors": "",
    "abstract": "Natural language processing (NLP) aims at investigating the interactions between agents and humans, which processes and analyzes large amounts of natural language data. Large-scale language models play an important role in current natural language processing. However, the challenges of explainability and complexity come along with the development of language models. One way is to introduce logical relations and rules into natural language processing models, such as making use of Automated Planning. Automated planning (AI planning) focuses on building symbolic domain models and synthesizing plans to transit initial states to goals based on domain models. Recently, there have been plenty of works related to those two fields, which have the abilities to generate explicit knowledge, e.g., preconditions and effects of action models, and learn from tacit knowledge, e.g., neural models, respectively. Integrating AI planning and natural language processing effectively improves the communication between human and intelligent agents. This paper outlines the commons and relations between AI planning and natural language processing, and it argues that each of them can effectively impact the other one in six areas: (1) planning-based text understanding, (2) planning-based natural language processing, (3) text-based human-robot interaction, (4) planning-based explainability, (5) evaluation metrics, and (6) applications. We also explore some potential future issues between AI planning and natural language processing. To the best of our knowledge, this survey is the first that addresses the deep connections between AI planning and Natural language processing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409349005",
    "type": "article"
  },
  {
    "title": "<i>GOAT-Bench</i> : Safety Insights to Large Multimodal Models through Meme-Based Social Abuse",
    "doi": "https://doi.org/10.1145/3729239",
    "publication_date": "2025-04-11",
    "publication_year": 2025,
    "authors": "Hongzhan Lin; Ziyang Luo; Bo Wang; Ruichao Yang; Jing Ma",
    "corresponding_authors": "",
    "abstract": "The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and image. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g., GPT-4V, LLaVA, and Qwen-VL) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench , comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Bench , we delve into the ability of LMMs to accurately assess hatefulness, misogyny, offensiveness, sarcasm, and harmful content. Our extensive experiments across a range of LMMs reveal that current models still exhibit a deficiency in safety awareness, showing insensitivity to various forms of implicit abuse. We posit that this shortfall represents a critical impediment to the realization of safe artificial intelligence. The GOAT-Bench and accompanying resources are publicly accessible at https://goatlmm.github.io/ , contributing to ongoing research in this vital field.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409349018",
    "type": "article"
  },
  {
    "title": "Probing the Symbolic Logical Reasoning Ability of Large Language Models",
    "doi": "https://doi.org/10.1145/3729238",
    "publication_date": "2025-04-15",
    "publication_year": 2025,
    "authors": "Jianchao Ji; Zelong Li; Shuyuan Xu; Wenyue Hua; Juntao Tan; Haoming Gong; Yongfeng Zhang",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have achieved significant successes in various research domains by learning the relationship between words. However, while these models are capable of making predictions and inferences based on the learned patterns, they lack logical reasoning abilities, which are crucial for solving problems in both theoretical and practical domains. In addition, traditional logic inference methods are effective in solving problems that are based on logic, but not suitable for general tasks such as recommendations. In response to these challenges, this paper introduces a Logical Large Language Model (L3M) that integrates the strengths of logical reasoning and large language models. The data in L3M is represented in logical expressions and the model uses logical constraints to learn the rules of basic logical operations such as And, Or, and Not. We conduct experiments on both theoretical tasks (solving logical equations) and practical tasks (recommender systems). The results of our theoretical experiments demonstrate that L3M is highly effective in solving logical expressions and variables. Additionally, L3M outperforms the state-of-the-art recommendation models in sequential recommendation tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409476341",
    "type": "article"
  },
  {
    "title": "Can Interpretability of Deep Learning Models Detect Textual Adversarial Distribution?",
    "doi": "https://doi.org/10.1145/3729235",
    "publication_date": "2025-04-15",
    "publication_year": 2025,
    "authors": "Ahoud Alhazmi; Abdulwahab Aljubairy; Wei Emma Zhang; Quan Z. Sheng; Elaf Alhazmi",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) are widely used in Natural Language Processing (NLP). However, adversarial samples attack benign inputs to readily fool the DNN models. The detection of these samples is a significant challenge that has received little attention in textual domains. Existing defense strategies either assume prior knowledge of specific threats or do not perform well on complex models. In this paper, we provide a new framework, namely TADD for detecting textual adversarial samples by leveraging the interpretability of DNNs. In particular, we distinguish between the adversarial distribution and the benign distribution for the decision boundary of the victim models. Our method applies to NLP tasks and does not require re-training victim models and prior knowledge of adversarial attack methods. We evaluate our detector against the state-of-the-art attack methods on various real-world datasets. As demonstrated in the extensive experiments, our approach effectively discriminates between adversarial and benign samples. Additionally, our method is competitive against unseen attacks, reflecting its ability to discover new adversarial samples generated by future attack methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409477972",
    "type": "article"
  },
  {
    "title": "Towards AI-Assisted Inclusive Language Writing in Italian Formal Communications",
    "doi": "https://doi.org/10.1145/3729237",
    "publication_date": "2025-04-16",
    "publication_year": 2025,
    "authors": "Salvatore Greco; Moreno La Quatra; Luca Cagliero; Tania Cerquitelli",
    "corresponding_authors": "",
    "abstract": "Formal communications such as public calls, announcements, or regulations are supposed to exhibit respect for diversity in terms of gender, race, age, and disability. However, human writers often lack adequate inclusive writing skills. For instance, they tend to overuse the masculine as a neutral form, mainly because they are self-trained on biased text examples. To overcome this issue, we propose to leverage Generative Artificial Intelligence to support inclusive language writing. Focusing on formal Italian communications, we have designed and developed an AI-assisted tool for non-inclusive text detection and reformulation. Thanks to the joint work with a team of linguistic experts, we first define a set of linguistic criteria necessary to model inclusive writing forms in Italian. Based on these criteria, we collect and annotate a dataset of Italian administrative documents enriched with fine-grained inclusive annotations. Finally, we train deep learning models on the collected data for non-inclusive language detection and inclusive language reformulation tasks. We perform quantitative and human-driven evaluations on the trained models. The best detection model correctly classifies 89% of the sentences, whereas the best reformulation model produces 73% fully correct reformulations. Both models have been integrated into a writing assistance tool acting as a text proofreader and self-learning tool for non-expert writers, namely Inclusively . Once a non-inclusive piece of text is detected, the proposed approach suggests inclusive reformulations. The tool also provides explanations of the models’ outputs to increase system transparency. Furthermore, it allows expert end-users to provide further annotations for system fine-tuning. The trained models and the writing assistance tool are publicly available for research purposes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409498128",
    "type": "article"
  },
  {
    "title": "Cascade Transformer for Hierarchical Semantic Reasoning in Text-Based Visual Question Answering",
    "doi": "https://doi.org/10.1145/3729242",
    "publication_date": "2025-04-17",
    "publication_year": 2025,
    "authors": "Yuan Gao; Dezhen Feng; Laurence T. Yang; Jing Yang; Xiaowen Jiang; Jieming Yang",
    "corresponding_authors": "",
    "abstract": "Text-based Visual Question Answering (TextVQA) aims to answer questions by understanding scene text in images. However, many current methods overly depend on the accuracy of OCR systems, while overlooking the significance of visual objects. They tend to perform poorly when the question involves the relationships between visual objects and scene text. To address the above issues, we focus on raising the status of visual objects and innovatively propose a hierarchical semantic reasoning network (CT-HSR) based on the cascade transformer architecture, achieving fine-grained cross-modal reasoning and visual semantic enhancement. Specifically, the visual representations containing rich semantic information of the question modality are obtained through the cross-modal transformer-based vision-language pre-training model firstly. Then, the uni-modal transformer for unified modality encoding module is utilized to capture visual objects that are more semantically related to OCR texts. In addition, we further alleviate the cross-modal noise interference through the feature filtering strategy. Finally, we better align the three modalities by introducing TextVQA pre-training tasks, and generate prediction answers through multi-step iterative prediction during fine-tuning. Extensive experiments on the TextVQA, ST-VQA and OCR-VQA datasets have demonstrated the effectiveness of our proposed model compared to the state-of-the-art methods. The code will be released at https://github.com/FTFWO/CT-HSR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409539127",
    "type": "article"
  },
  {
    "title": "Self-optimizing Teacher and Auto-matching Student Framework for Change-point Representation Learning in Time Series Forecasting",
    "doi": "https://doi.org/10.1145/3718091",
    "publication_date": "2025-04-22",
    "publication_year": 2025,
    "authors": "Jinxiao Fan; Pengfei Wang; Liang Liu; Huadóng Ma",
    "corresponding_authors": "",
    "abstract": "Real-world time series data is inherently complex, noisy, and exhibits abrupt changes, posing various challenges in data modeling. Given the ubiquity and importance of time-series data, accurately forecasting change points, instead of the overall predictive performance, has become increasingly attractive as it assists in risk mitigation and loss prevention. In this task, we argue that the past and future interactions involving the target points determine the comprehensive structure contributing to abrupt changes. However, traditional left-to-right auto-regressive approaches only consider the historical sequence, resulting in a flawed learning process and limited performance. In this paper, we extend the teacher-student learning and propose a novel S elf-optimizing T eacher and A uto-matching S tudent framework (named ST-AS) to predict change points in time series data. Our framework models change point representations specific to the target points by integrating future knowledge while avoiding data leakage. Specifically, we design a Gumbel-enhanced filter for our self-optimizing teacher, which constructs selected and filtered sub-groups to derive discriminative representations using a positive-unlabeled learning strategy. Given this well-trained teacher, we propose an adaptive pattern matcher for our auto-matching student model, which learns missing information by automatically aligning relevant features. After that, a novel two-stage dual-guided learning process is then designed to mimic teacher’s decision-making behavior and enhance student’s excavate capability. Finally, we conduct extensive experiments on four real-world datasets to demonstrate that our proposed ST-AS exhibits significantly better prediction performance compared to existing state-of-the-art alternatives.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409667686",
    "type": "article"
  },
  {
    "title": "IT-RUDA: Information Theory Assisted Robust Unsupervised Domain Adaptation",
    "doi": "https://doi.org/10.1145/3716853",
    "publication_date": "2025-04-28",
    "publication_year": 2025,
    "authors": "Shima Rashidi; Ruwan Tennakoon; Aref Miri Rekavandi; Papangkorn Jessadatavornwong; Amanda Freis; Garret Huff; Mark Easton; Adrian P. Mouritz; Reza Hoseinnezhad; Alireza Bab‐Hadiashar",
    "corresponding_authors": "",
    "abstract": "Domain adaptation is a well-studied field in machine learning. Distribution shift between train (source) and test (target) datasets is a common problem encountered in machine learning applications. One approach to resolve this issue is to use the Unsupervised Domain Adaptation (UDA) technique that carries out knowledge transfer from a label-rich source domain to an unlabeled target domain. Outliers that exist in either source or target datasets can introduce additional challenges when using UDA in practice. In this paper, \\(\\alpha\\) -divergence is used as a measure to minimize the discrepancy between the source and target distributions while inheriting robustness, adjustable with a single parameter \\(\\alpha\\) , as the prominent feature of this measure. Here, it is shown that the other well-known divergence-based UDA techniques can be derived as special cases of the proposed method. Furthermore, a theoretical upper bound is derived for the loss in the target domain in terms of the source loss and the \\(\\alpha\\) -divergence between the joint distributions in the two domains. The robustness of the proposed method is validated through testing on several benchmarked datasets in open-set and partial UDA setups where extra classes existing in target and source datasets are considered as outliers. Code is publicly available at https://github.com/rashidis/IT-RUDA .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409887807",
    "type": "article"
  },
  {
    "title": "Adaptive Target Oriented Tracking",
    "doi": "https://doi.org/10.1145/3732785",
    "publication_date": "2025-04-29",
    "publication_year": 2025,
    "authors": "Sixian Chan; Xianpeng Zeng; Zhoujian Wu; Yu Wang; Xiaolong Zhou; Tinglong Tang; Jie Hu",
    "corresponding_authors": "",
    "abstract": "The current one-stream tracking pipelines are early relation modeling in feature extraction. However, insufficient discrimination may result in ambiguous relation modeling during early feature extraction. Moreover, the non-target information occupies most of the search image, rendering most relation modeling futile. To tackle the above issues, we propose tracking via learning adaptive target-oriented representation, named ATOTrack . We design an Untied positional encoding to mark the template token and the search region token separately, which reduces the confused relationship between the template and the search region. Besides, we introduce an Auto-Mask Learner to decouple the target and non-target information in the search region. Interestingly, the Auto-Mask Learner can self-learn and mask the ineffective information to interpret adaptive target oriented representation. Extensive experiments demonstrate that ATOTrack is superior to existing methods, which achieves state-of-the-art performance on six tracking benchmarks. In Particular, ATOTrack establishes a new record on AViST with 57% AO. The code and models will be released as soon.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409918288",
    "type": "article"
  },
  {
    "title": "PREUS: Proactive and Robust Edge-UAV Systems for Autonomous Monitoring in Dynamic Environments",
    "doi": "https://doi.org/10.1145/3733836",
    "publication_date": "2025-05-06",
    "publication_year": 2025,
    "authors": "Ismail AlQerm; Nuo Cheng; Jianli Pan",
    "corresponding_authors": "",
    "abstract": "Edge computing and AI can potentially empower Unmanned Aerial Vehicle (UAV) systems with automated decision-making and resource support for monitoring in future science tasks such as emergency response, search and rescue, inspections, and wildfires. However, it is challenging to achieve autonomous and robust monitoring in such systems, given the dynamic environmental situations, the limited capabilities, and the unbalanced load of the UAVs. For instance, the monitoring activity levels at different locations might vary, which leads to an unbalanced monitoring load for the corresponding UAVs. Moreover, the UAVs require regular recharging/maintenance and can have malfunctions that will disrupt the monitoring task. In this article, we develop a novel proactive and robust Edge-UAV framework named PREUS to enable autonomous and efficient monitoring of dynamic environments when faced with dynamic environment situations and various UAV workload stresses that can jeopardize the monitoring performance. PREUS features a unique design to handle the varying UAV workload stress of the monitored area. It incorporates novel spatial, temporal, and proactive exploration vs. exploitation planning to balance the UAVs’ workloads in various locations with fluctuating activities. In addition, PREUS includes novel Deep Reinforcement Learning (DRL) design specialized to maximize coverage in the complex environments and provides faster and stabler decision-making capabilities than the existing methods. The positive impact brought by PREUS is demonstrated in terms of the achieved monitoring performance, including coverage and balanced UAV load.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410120860",
    "type": "article"
  },
  {
    "title": "Evaluating GPT-4’s Semantic Understanding of Obstetric-based Healthcare Text through Nurse Ruth",
    "doi": "https://doi.org/10.1145/3735647",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Tia Pope; Stephanie Gilbertson‐White; Ahmad Patooghy",
    "corresponding_authors": "",
    "abstract": "Nurse Ruth, an AI-driven assistant, is designed to support obstetric nursing in resource-limited environments and for non-specialist healthcare providers. To develop and validate Nurse Ruth, we introduced novel evaluation metrics—Semantic Transparency Metric (STM) and Semantic Understanding Metric (SUM)—to assess response accuracy, contextual relevance, and robustness against conventional and adversarial clinical queries. Through iterative refinement and targeted knowledge integration, Nurse Ruth surpassed the 80% threshold for STM and SUM, reinforcing its ability to provide clear, evidence-based, and contextually precise clinical guidance. While excelling in response clarity and contextual accuracy, further improvements are needed to enhance recall in complex, multi-domain obstetric scenarios. A comparative evaluation against leading AI models (GPT-4o, GPT-4, and GPT-o1) for semantic validation demonstrated Nurse Ruth’s superiority. It achieved 100% accuracy on obstetric challenge queries, outperforming general-purpose AI models in both precision and efficiency. Unlike these models, Nurse Ruth delivered concise, rapid responses, making it the most effective system for real-world clinical applications. These findings validate Nurse Ruth’s semantic understanding and establish a replicable framework for AI-driven decision support in specialized medical fields. Future work will focus on refining recall in multi-faceted obstetric cases and validating real-world clinical impact.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410343639",
    "type": "article"
  },
  {
    "title": "Cross-Hierarchical Structure-Detail-Aware Transformer for Single Image Deblurring",
    "doi": "https://doi.org/10.1145/3735649",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Wei‐Yen Hsu; Jiayan Yang",
    "corresponding_authors": "",
    "abstract": "Blurred images, resulting from a mix of camera shake and object motion, typically exhibit directional and uneven blurring, which diminishes overall visual quality. Despite many single-image deblurring methods proposed in recent years, their effectiveness remains limited, particularly in real-world scenarios involving different scales, degrees of depth, and background-object confusion. To address these issues, we propose a novel Cross-hierarchical Structure-Detail-aware transFormer (CSDFormer) for single image deblurring. Our model operates on multiple scales (multi-scale) and layers (multi-layer), focusing on both large-scale and local blur as well as varying blur depths. We introduce the Structure-aware Feature Extraction (SaFE) Module and Detail-aware Feature Extraction (DaFE) Module to extract significant features layer by layer across different scales (cross-layer). For effective feature exchange between different scales (cross-scale), we propose two cross-scale information exchange modules: the fine-to-coarse and coarse-to-fine Cross-scale LSTM Information Exchange (CsLSTM-IE) modules. These modules aim to restore structural and textural details by progressively learning features from fine to coarse scale and back. The experimental results demonstrate that the CSDFormer model outperforms state-of-the-art methods in both synthetic and real-world datasets, both quantitatively and qualitatively. It excels in removing blur across various scales and depths, restoring backgrounds, and preserving details.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410343839",
    "type": "article"
  },
  {
    "title": "Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation for Wide-area SST Prediction",
    "doi": "https://doi.org/10.1145/3735646",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Han Peng; Wengen Li; Chang Jin; Yichao Zhang; Jihong Guan; Hanchen Yang; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "Accurate prediction of sea surface temperature (SST) is of high importance in marine science, benefiting applications ranging from ecosystem protection to extreme weather forecasting and climate analysis. Wide-area SST usually shows diverse SST patterns in different sea areas due to the changes of temperature zones and the dynamics of ocean currents. However, existing studies on SST prediction often focus on small-area predictions and lack the consideration of diverse SST patterns. Furthermore, SST shows an annual periodicity, but the periodicity is not strictly adherent to an annual cycle. Existing SST prediction methods struggle to adapt to this non-strict periodicity. To address these two issues, we proposed the Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation (RGCN-PSA) model which is equipped with the Cross-Region Graph Convolutional Network module and the Periodicity Shift Adaption module. The Cross-Region Graph Convolutional Network module enhances wide-area SST prediction by learning and incorporating diverse SST patterns. Meanwhile, the periodicity Shift Adaptation module accounts for the annual periodicity and enable the model to adapt to the possible temporal shift automatically. We conduct experiments on two real-world SST datasets, and the results demonstrate that our RGCN-PSA model obviously outperforms baseline models in terms of prediction accuracy. The code of RGCN-PSA model is available at https://github.com/ADMIS-TONGJI/RGCN-PSA/ .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410344813",
    "type": "article"
  },
  {
    "title": "AEKG4APT: An AI-Enhanced Knowledge Graph for Advanced Persistent Threats with Large Language Model Analysis",
    "doi": "https://doi.org/10.1145/3735645",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Yinghai Zhou; Ziyu Wang; Yunxin Jiang; Bingqi Ma; Rui Wang; Yuan Liu; Yue Zhao; Zhihong Tian",
    "corresponding_authors": "",
    "abstract": "This paper introduces AEKG4APT, an APT Knowledge Graph (KG) enhanced by Large Language Models (LLMs), as a way to deal with the cybersecurity problems caused by Advanced Persistent Threats (APTs). The core of AEKG4APT lies in the combined application of LLMs, Cyber Threat Intelligence (CTI), and KG. The first part of the paper goes into great detail about how the AEKG4APT was constructed, including its ontology schema, data sources, and dataset features. There are also statistics on the AEKG4APT’s nodes, relationships, and key attributes. Secondly, it was shown how to utilize LLMs and public sandboxes for the collection and analysis of CTI Additionally, tests that compare traditional deep learning models to LLM methods show that LLM is both more efficient and more accurate at extracting information. Subsequently, the Decision Making Trial and Evaluation Laboratory - Interpretive Structural Modeling (DEMATEL-ISM) analytical method was introduced to identify and analyse the factors and their interrelationships within the AEKG4APT data, thereby revealing the key dependencies and influence paths within the data structure. Experiments were designed to demonstrate its applications in modeling, computing, and obtaining interpretable computational results on AEKG4APT. In addition, this paper also explores the dynamic expansion capabilities of AEKG4APT, including data expansion, schema expansion, and permanent maintenance strategies, to address the evolving APT threats. Finally, this paper summarizes the competitiveness and application value of AEKG4APT by comparing it with other CTI KGs and platforms in academia and industry, demonstrating its extensive application potential in the field of cybersecurity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410344873",
    "type": "article"
  },
  {
    "title": "Mitigating Data Redundancy to Revitalize Transformer-based Long-Term Time Series Forecasting System",
    "doi": "https://doi.org/10.1145/3735651",
    "publication_date": "2025-05-16",
    "publication_year": 2025,
    "authors": "Mingjie Li; Rui Liu; Guangsi Shi; Mingfei Han; Chenji Li; Lina Yao; Xiaojun Chang; Ling Chen",
    "corresponding_authors": "",
    "abstract": "Long-term time-series forecasting (LTSF) is fundamental to various real-world applications, where Transformer-based models have become the dominant framework due to their ability to capture long-range dependencies. However, these models often experience overfitting due to data redundancy in rolling forecasting settings, limiting their generalization ability particularly evident in longer sequences with highly similar adjacent data. In this work, we introduce CLMFormer, a novel framework that mitigates redundancy through curriculum learning and a memory-driven decoder. Specifically, we progressively introduce Bernoulli noise to the training samples, which effectively breaks the high similarity between adjacent data points. This curriculum-driven noise introduction aids the memory-driven decoder by supplying more diverse and representative training data, enhancing the decoder’s ability to model seasonal tendencies and dependencies in the time-series data. To further enhance forecasting accuracy, we introduce a memory-driven decoder. This component enables the model to capture seasonal tendencies and dependencies in the time-series data and leverages temporal relationships to facilitate the forecasting process. Extensive experiments on six real-world LTSF benchmarks show that CLMFormer consistently improves Transformer-based models by up to 30%, demonstrating its effectiveness in long-horizon forecasting.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410431151",
    "type": "article"
  },
  {
    "title": "Large-Scale Tensorized Multi-View Kernel Subspace Clustering",
    "doi": "https://doi.org/10.1145/3735644",
    "publication_date": "2025-05-16",
    "publication_year": 2025,
    "authors": "Guangyu Zhang; Dong Huang; Chang‐Dong Wang",
    "corresponding_authors": "",
    "abstract": "The Anchor-based Multi-view Subspace Clustering (AMSC) has turned into a favourable tool for large-scale multi-view clustering. However, there still exist some limitations to the current AMSC approaches. First, they typically recover anchor graph structure in the original linear space, restricting their feasibility for nonlinear scenarios. Second, they usually overlook the potential benefits of jointly capturing the inter-view and intra-view information for enhancing the anchor representation learning. Third, these approaches mostly perform anchor-based subspace learning by a specific matrix norm, neglecting the latent high-order correlation across different views. To overcome these limitations, this paper presents an efficient and effective approach termed Large-scale Tensorized Multi-view Kernel Subspace Clustering (LTKMSC). Different from the existing AMSC approaches, our LTKMSC approach exploits both inter-view and intra-view awareness for anchor-based representation building. Concretely, the low-rank tensor learning is leveraged to capture the high-order correlation (i.e., the inter-view complementary information) among distinct views, upon which the \\(l_{1,2}\\) norm is imposed to explore the intra-view anchor graph structure in each view. Moreover, the kernel learning technique is leveraged to explore the nonlinear anchor-sample relationships embedded in multiple views. With the unified objective function formulated, an efficient optimization algorithm that enjoys low computational complexity is further designed. Extensive experiments on a variety of multi-view datasets have confirmed the efficiency and effectiveness of our approach when compared with the other competitive approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410456880",
    "type": "article"
  },
  {
    "title": "Race Against the Machine Learning Courses",
    "doi": "https://doi.org/10.1145/3737650",
    "publication_date": "2025-05-27",
    "publication_year": 2025,
    "authors": "R. Deshpande; Donald Mlombwa; Leo Anthony Celi; Jack Gallifant; Helen D’Couto",
    "corresponding_authors": "",
    "abstract": "Despite the rapid integration of AI in healthcare, a critical gap exists in current machine learning courses: the lack of education on identifying and mitigating bias in datasets. This oversight risks perpetuating existing health disparities through biased AI models. Analyzing 11 prominent online courses, we found only 5 addressed dataset bias, often dedicating minimal time compared to technical aspects. This paper urges course developers to prioritize education on data context, equipping learners with the tools to critically evaluate the origin, collection methods, and potential biases inherent in the data. This approach fosters the creation of fair algorithms and the incorporation of diverse data sources, ultimately mitigating the harmful effects of bias in healthcare AI. While this analysis focused on publicly available courses, it underscores the urgency of addressing bias in all healthcare machine learning education. Early intervention in algorithm development is crucial to prevent the amplification of dataset and model bias, ensuring responsible and equitable AI implementation in healthcare.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410837890",
    "type": "article"
  },
  {
    "title": "Hypernetwork-Enhanced Hierarchical Federated Learning for Long-Term Traffic Prediction with Transformer",
    "doi": "https://doi.org/10.1145/3742792",
    "publication_date": "2025-06-03",
    "publication_year": 2025,
    "authors": "Siyue Shuai; Xiangjie Kong; L. C. Liu; Wenhong Zhao; Guojiang Shen; Ivan Lee",
    "corresponding_authors": "",
    "abstract": "The Transformer model, with its ability to capture long-term dependencies, has demonstrated significant potential in enhancing long-term traffic flow prediction for effective urban transportation management. However, most existing Transformer-based methods adhere to a centralized approach, failing to address privacy concerns and to optimize computational resource utilization. Although emerging Federated Learning paradigms offer privacy protection, the average aggregation still overlooks client heterogeneity and lacks the synchronous efficiency required for traffic flow prediction tasks. Consequently, we introduce FedTFormer, a hierarchical federated learning framework tailored to boost the performance of Transformer models in decentralized environments, involving clients, edge servers, and a central server. Initially, clients are organized into clusters through a sophisticated static clustering mechanism anchored in bipartite graph theory. FedTFormer enhances robustness of Transformer by facilitating synchronous average aggregation within clusters. Additionally, it performs asynchronous fine-tuning of cluster-specific parameters, leveraging hypernetwork constructed on the central server. Clients utilize an optimized Transformer model for localized training, harnessing its proficiency in capturing long-term spatio-temporal dependencies. Ultimately, we conduct extensive experiments across three datasets, comparing our method against ten sophisticated approaches and demonstrating the effectiveness and robustness of FedTFormer.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410991029",
    "type": "article"
  },
  {
    "title": "Counter-Samples: A Stateless Strategy to Neutralize Black Box Adversarial Attacks",
    "doi": "https://doi.org/10.1145/3744657",
    "publication_date": "2025-06-13",
    "publication_year": 2025,
    "authors": "Roey Bokobza; Yisroel Mirsky",
    "corresponding_authors": "",
    "abstract": "Our paper introduces a novel defense mechanism against black-box attacks, where attackers exploit the victim model as an oracle to craft adversarial examples. Unlike traditional pre-processing defenses that rely on sanitizing input samples, our stateless strategy directly counters the attack process itself. For each query, we evaluate a counter-sample, an optimized version of the original sample, designed to thwart the attacker's objective. By responding to every black-box query with a targeted white-box optimization, our strategy introduces a strategic asymmetry that significantly advantages the defender. Our approach proves to be highly effective against state-of-the-art black-box attacks, outperforming existing defenses on both CIFAR-10 and ImageNet datasets. Specifically, our method achieves an average attack failure rate (AFR) of 74.7% (up from 13%) on ImageNet and 67.7% (up from 3.5%) on CIFAR-10 when tested against 10 state-of-the-art query-based black-box attacks. Moreover, it maintains the model's performance on legitimate inputs, with accuracy (ACC) reduced by only 0.7% on ImageNet and 0.9% on CIFAR-10. This is in stark contrast to other defenses tested, which can cause accuracy drops of up to 50%. Such a modest decrease ensures negligible performance degradation on legitimate tasks. Furthermore, we demonstrate that our defense exhibits superior robustness across datasets and attack scenarios, including adaptive attacks specifically designed to try to bypass our method. This robustness highlights the strength and adaptability of our approach in countering adversarial threats.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411275962",
    "type": "article"
  },
  {
    "title": "Horizon Forcing: Improving the Recurrent Forecasting of Chaotic Systems",
    "doi": "https://doi.org/10.1145/3718090",
    "publication_date": "2025-06-25",
    "publication_year": 2025,
    "authors": "Yinyong Zhuang; Matthew Almeida; Patrick J. Flynn; Wei Ding; Shafiqul Islam; Zihan Li; Ping Chen",
    "corresponding_authors": "",
    "abstract": "Chaotic dynamics are ubiquitous in many real-world systems, ranging from biological and industrial processes to climate dynamics and the spread of viruses. These systems are characterized by high sensitivity to initial conditions, making it challenging to predict their future behavior confidently. In this study, we propose a novel deep-learning framework that addresses this challenge by directly exploiting the long-term compounding of local prediction errors during model training, aiming to extend the time horizon for reliable predictions of chaotic systems. Our approach observes the future trajectories of initial errors at a time horizon, modeling the evolution of the loss to that point through the use of two major components: 1) a recurrent architecture (Error Trajectory Tracing) designed to trace the trajectories of predictive errors through phase space, and 2) a training regime, Horizon Forcing, that pushes the model’s focus out to a predetermined time horizon. We validate our method on three classic chaotic systems and six real-world time series prediction tasks with chaotic characteristics. The results show that our approach outperforms the state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411644343",
    "type": "article"
  },
  {
    "title": "Prompt-based Masked Language Modeling for Numerical Reasoning",
    "doi": "https://doi.org/10.1145/3746455",
    "publication_date": "2025-06-27",
    "publication_year": 2025,
    "authors": "Sujit Kumar; Monika Singh; Abhishek Raj Ranjan; Tanveen Tanveen; Sanasam Ranbir Singh",
    "corresponding_authors": "",
    "abstract": "Headline generation, a crucial task in summarization, aims to summarize an entire article into a concise, single line. Despite the proficiency of sequence-to-sequence encoder-decoder models and transformer-based large language models in text generation and summarization, generating headlines that include numerals representing the numerals in the news body remains a significant challenge. Generating a numeral-aware headline requires the ability of models to solve numerical and mathematical reasoning capabilities to infer relationships between numerals in the news body. Given the challenges in numeral-aware headline generation and numerical reasoning over numerals in news bodies, this study conducts an empirical investigation of Large Language Models (LLMs) using various strategies, including Pretrained , Few-Shot Prompting , and Chain-of-Thought Prompting , for numeral aware headline generation and numerical reasoning for headline generation. Building upon the insights gained from our empirical study on LLMs for numeral-aware headline generation and numerical reasoning, we propose two novel approaches: instruction tuning with Large Language Models for numeral-aware headline generation and prompt-based masked language modelling for numerical reasoning. We conducted our experiments on the NumHG dataset. We observed that our proposed method outperforms the Pretrained , Few-Shot Prompting , and Chain-of-Thought Prompting setups of Large Language Models (LLMs), as well as baseline models from the literature, on both numeral-aware headline generation and numerical reasoning tasks. Observations from the experimental results reveal that our proposed Prompt-Based Masked Language Modeling significantly improves the performance of small and medium-sized language models on numerical reasoning tasks. We also study the robustness of our proposed models by evaluating their performance in fact-checking numerical claims and performing numerical reasoning for numeral-aware text summarization. Our findings suggest that the proposed Prompt-Based Masked Language Modeling approach is also effective for numerical claim verification and numerical reasoning for numeral-aware text summarization.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411712574",
    "type": "article"
  },
  {
    "title": "Learning to Associate: Multimodal Inference with Fully Missing Modalities",
    "doi": "https://doi.org/10.1145/3746456",
    "publication_date": "2025-06-27",
    "publication_year": 2025,
    "authors": "Jack Geraghty; Andrew Hines; Fatemeh Golpayegani",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose Cross-Modal Association Models (C-MAMs) , a novel approach for handling missing modalities during inference in multimodal learning. Unlike existing methods that modify the training process, C-MAMs generate missing modality features post-training , preserving the integrity of the original multimodal model. In this paper, we: (i) formalise the problem of missing modality inference and its challenges, (ii) introduce C-MAMs as a flexible, lightweight, post-hoc solution for reconstructing missing modality embeddings, (iii) evaluate their effectiveness across diverse datasets, tasks, and baseline models, and (iv) analyze the quality of the generated versus the ground-truth features to quantify the reconstruction fidelity. Experimental results show that C-MAMs significantly mitigate performance degradation due to missing modalities, in some cases fully restoring baseline performance, even when trained on 10% of the data. We conclude that post-training feature reconstruction is an effective, targeted alternative to existing methods, with broad applicability in multimodal systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411712577",
    "type": "article"
  },
  {
    "title": "Integrated Hybrid Transformer and Multi-Receptive Feature Extraction Mechanism for Electrocardiogram Denoising using Score-Based Diffusion Model",
    "doi": "https://doi.org/10.1145/3744654",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Baofeng Zhu; Wanjun Cheng; Xia Zhang; J. Y. Liu",
    "corresponding_authors": "",
    "abstract": "Electrocardiogram (ECG) is the foundation of the analysis of cardiac disease. In the hospital clinical ECG diagnostic scenarios, when doctors analyze electrocardiogram signals or when an ECG intelligent diagnostic system is used, there might be strong noises like baseline wander or muscle artifact in the electrocardiogram signals due to the unstable state of the subjects and such interferences are usually difficult to be filtered out by traditional filters, which can lead to serious errors in the subsequent signal analysis. To solve this problem, we propose a novel network which integrates hybrid transformer and multi-receptive feature extraction mechanism into score-based diffusion model. We used score-based diffusion model to reconstruct the clean ECG signals from noisy ones. The experiment was conducted on the QT Database and the MIT-BIH Noise Stress Test Database to verify the feasibility of our method. Baseline methods are used for comparison. The evaluation results show that our method can achieve an outstanding performance on four distance-based evaluation metrics by at least 26% overall improvement in the comparison with the best baseline method. The study demonstrates that the signal denoising and reconstruction method based on the self-designed score-based diffusion model can effectively remove the interferences in the electrocardiogram signals, thereby facilitating the subsequent diagnosis in real world situation. It also has huge potential for establishing the ECG intelligent analysis system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411870738",
    "type": "article"
  },
  {
    "title": "Robust Few-Shot Ensemble Learning with Focal Diversity-Based Pruning",
    "doi": "https://doi.org/10.1145/3746457",
    "publication_date": "2025-07-07",
    "publication_year": 2025,
    "authors": "Selim Furkan Tekin; Fatih İlhan; Tiansheng Huang; Sihao Hu; Margaret L. Loper; Ling Liu",
    "corresponding_authors": "",
    "abstract": "This paper presents FusionShot , a focal diversity optimized few-shot ensemble learning approach for boosting the robustness and generalization performance of pre-trained few-shot models. The paper makes three original contributions. First, we explore the unique characteristics of few-shot learning to ensemble multiple few-shot (FS) models by creating three alternative fusion channels. Second, we introduce the concept of focal error diversity to learn the most efficient ensemble teaming strategy, rather than assuming that an ensemble of a larger number of base models will outperform those sub-ensembles of smaller size. We develop a focal-diversity ensemble pruning method to effectively prune out the candidate ensembles with low ensemble error diversity and recommend top- \\(K\\) FS ensembles with the highest focal error diversity. Finally, we capture the complex non-linear patterns of ensemble few-shot predictions by designing the learn-to-combine algorithm, which can learn the diverse weight assignments for robust ensemble fusion over different member models. Extensive experiments on representative few-shot benchmarks show that the top-K ensembles recommended by FusionShot can outperform the representative SOTA few-shot models on novel tasks (different distributions and unknown at training), and can prevail over existing few-shot learners in both cross-domain settings and adversarial settings. For reproducibility purposes, FusionShot trained models, results, and code are made available at https://github.com/sftekin/fusionshot .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412070848",
    "type": "article"
  },
  {
    "title": "Causal Flow-based Variational Auto-Encoder for Disentangled Causal Representation Learning",
    "doi": "https://doi.org/10.1145/3748660",
    "publication_date": "2025-07-14",
    "publication_year": 2025,
    "authors": "Di Fan; Yannian Kou; Chuanhou Gao",
    "corresponding_authors": "",
    "abstract": "Disentangled representation learning aims to learn low-dimensional representations where each dimension corresponds to an underlying generative factor. While the Variational Auto-Encoder (VAE) is widely used for this purpose, most existing methods assume independence among factors, a simplification that does not hold in many real-world scenarios where factors are often interdependent and exhibit causal relationships. To overcome this limitation, we propose the Disentangled Causal Variational Auto-Encoder (DCVAE), a novel supervised VAE framework that integrates causal flows into the representation learning process, enabling the learning of more meaningful and interpretable disentangled representations. We evaluate DCVAE on both synthetic and real-world datasets, demonstrating its superior ability in causal disentanglement and intervention experiments. Furthermore, DCVAE outperforms state-of-the-art methods in various downstream tasks, highlighting its potential for learning true causal structures among factors.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412400209",
    "type": "article"
  },
  {
    "title": "Learning Causality-Aware Exploration with Transformers for Goal-Oriented Navigation",
    "doi": "https://doi.org/10.1145/3748659",
    "publication_date": "2025-07-16",
    "publication_year": 2025,
    "authors": "Ruibao Wang; Tong Yu; Mingjie Li; Yuanjiang Cao; Yao Liu; Lina Yao",
    "corresponding_authors": "",
    "abstract": "Navigation is a fundamental task in the research of Embodied AI, and recent advances in machine learning algorithms have garnered growing interest in developing versatile Embodied AI systems. However, current research in this domain reveals opportunities for improvement. First, the direct application of RNNs and Transformers often overlooks the distinct characteristics of navigation tasks compared to traditional sequential data modeling. These methods are inherently designed to capture long-term dependencies, which are relatively weak in navigation scenarios, potentially limiting their performance in such tasks. Second, the reliance on task-specific configurations, such as pre-trained modules and dataset-specific logic, compromises the generalizability of these methods. We address these constraints by initially exploring the unique differences between Navigation tasks and other sequential data tasks through the lens of Causality, presenting a causal framework to elucidate the inadequacies of conventional sequential methods for Navigation. By leveraging this causal perspective, we propose Causality-Aware Transformer (CAT) Networks for Navigation, featuring a Causal Understanding Module to enhance the model’s Environmental Understanding capability. Meanwhile, our method is devoid of task-specific inductive biases and can be trained in an End-to-End manner, which enhances the method’s generalizability across various contexts. Empirical evaluations demonstrate that our methodology consistently surpasses benchmark performances across a spectrum of settings, tasks, and simulation environments, specifically, in Object Navigation within RoboTHOR, Objective Navigation, Point Navigation in Habitat, and R2R Navigation. Extensive ablation studies reveal that the performance gains can be attributed to the Causal Understanding Module, which demonstrates effectiveness and efficiency in both Reinforcement Learning and Supervised Learning settings. Additionally, further analysis highlights the robustness of our method, demonstrating its capacity to consistently perform well across diverse experimental settings and varying conditions. This robustness underscores the adaptability and generalizability of our approach, reinforcing its potential for application across a wide range of tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412477085",
    "type": "article"
  },
  {
    "title": "REMEND: Neural Decompilation for Reverse Engineering Math Equations from Binary Executables",
    "doi": "https://doi.org/10.1145/3749988",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Meet Udeshi; P. Krishnamurthy; Ramesh Karri; Farshad Khorrami",
    "corresponding_authors": "",
    "abstract": "Analysis of binary executables implementing mathematical equations can benefit from the reverse engineering of semantic information about the implementation. Traditional algorithmic reverse engineering tools either do not recover semantic information or rely on dynamic analysis and symbolic execution with high reverse engineering time. Algorithmic tools also require significant re-engineering effort to target new platforms and languages. Recently, neural methods for decompilation have been developed to recover human-like source code, but they do not extract semantic information explicitly. We develop REMEND, a neural decompilation framework to reverse engineer math equations from binaries to explicitly recover program semantics like data flow and order of operations. REMEND combines a transformer encoder-decoder model for neural decompilation with algorithmic processing for enhanced symbolic reasoning necessary for math equations. REMEND is the first work to demonstrate that transformers for neural decompilation go beyond source code and reason about program semantics in the form of math equations. We train on a synthetically generated dataset containing multiple implementations and compilations of math equations to produce a robust neural decompilation model and demonstrate retargettability. REMEND obtains an accuracy of 89.8% to 92.4% across three Instruction Set Architectures (ISAs), three optimization levels, and two programming languages with a single trained model, extending the capability of state-of-the-art neural decompilers. We achieve high accuracy with a small model of upto 12 million parameters and an average execution time of 0.132 seconds per function. On a real-world dataset collected from open-source programs, REMEND generalizes better than state-of-the-art neural decompilers despite being trained with synthetic data, achieving 8% higher accuracy. The synthetic and real-world datasets are provided at https://hf.co/udiboy1209/REMEND .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412565291",
    "type": "article"
  },
  {
    "title": "Mobility Data Driven Privacy-preserving Model for Detecting High Risk Infection Cases",
    "doi": "https://doi.org/10.1145/3742789",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Wenjie Fu; Huandong Wang; Chen Gao; Guanghua Liu; Yong Li; Tao Jiang",
    "corresponding_authors": "",
    "abstract": "In the past few years, infectious diseases like COVID-19 have caused serious distress to the global society and the economy. To prevent its spread, the early detection and assessment of infectious diseases based on molecular tests or antigen testing of bodily have led to countless labor and material costs. Fortunately, with the rapid development of mobile localization and web techniques, the collected massive mobile trajectory data provides a promising solution for detecting positive cases. However, existing mobility data-driven infection case detection methods are limited in terms of modeling the complicated epidemic spreading processes and preserving user privacy of the mobility data. In this paper, we propose a novel graph convolutional networks (GCN) model for detecting high risk infection cases, where we incorporate a spatio-temporal hypergraph to model the complex interaction of individuals. Then, we elaborately design a privacy-preserving framework tightly coupled with the structure of the spatio-temporal hypergraph, which includes a mobility data obfuscation module to protect privacy and an accompanying confidence-aware mechanism to mitigate the consequent performance decline. Moreover, we introduce a causal propagation mechanism to further guarantee the temporal dependency and causal effect of the feature propagation in our spatio-temporal hypergraph, which introduces both the causal transform of node features and the causal gathering of edge features. Finally, extensive experiments on a large mobility dataset collected from location-based services (LBS) show that the proposed model improves the performance of infection case detection by at least \\(12.47\\%\\) when compared with several widely adopted baselines. Besides, our code and datasets are available at the link 1 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412565300",
    "type": "article"
  },
  {
    "title": "RMTrans: Robust Multimodal Transformers for Patient Prognosis under Backdoor Threats",
    "doi": "https://doi.org/10.1145/3749989",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Tao Tang; Guoqing Han; Renqiang Luo; Feng Ding; Shuo Yu; Ivan Lee",
    "corresponding_authors": "",
    "abstract": "Transformers, with their self-attention mechanisms and positional encoding, excel at modeling long-range dependencies. Such attribute has demonstrated significant potential in capturing complex disease patterns by integrating multimodal information, for example clinical notes and radiographs. However, their reliance on pre-trained deep neural networks to extract modality-specific features from large datasets makes them vulnerable to backdoor attacks, posing critical challenges for their deployment in healthcare applications. To address these vulnerabilities, we propose a robust multimodal Transformer-based framework, RMTrans, which mitigates the impact of malicious imaging data containing backdoor triggers while enhancing the model's robustness. In the imaging data pre-processing stage, we introduce an efficient patch-based processing method that shifts the model's focus toward learning global features rather than over-fitting to localized (patch-level) patterns, thereby ensuring a more secure and reliable training process. Following this, we fuse multimodal representations and train a Vision Transformer (ViT) for disease prediction. Extensive experiments conducted on real-world datasets, including MIMIC-IV and CXR, validate the effectiveness of RMTrans. The proposed framework outperforms state-of-the-art baselines, demonstrating its potential as a secure and reliable solution for multimodal disease prediction.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412565306",
    "type": "article"
  },
  {
    "title": "Modeling the Chaotic Semantic States of Generative Artificial Intelligence (AI): A Quantum Mechanics Analogy Approach",
    "doi": "https://doi.org/10.1145/3757927",
    "publication_date": "2025-08-01",
    "publication_year": 2025,
    "authors": "Tong Liu; Timothy R. McIntosh; Teo Sušnjak; Paul Watters; Malka N. Halgamuge",
    "corresponding_authors": "",
    "abstract": "Generative artificial intelligence (AI) models have revolutionized intelligent systems by enabling machines to produce human-like content across diverse domains. However, their outputs often exhibit unpredictability due to complex and opaque internal semantic states, posing challenges for reliability in real-world applications. In this paper, we introduce the AI Uncertainty Principle , a novel theoretical framework inspired by quantum mechanics, to model and quantify the inherent unpredictability in generative AI outputs. By drawing parallels with the uncertainty principle and superposition, we formalize the trade-off between the precision of internal semantic states and output variability. Through comprehensive experiments involving state-of-the-art models and a variety of prompt designs, we analyze how factors such as specificity, complexity, tone, and style influence model behavior. Our results demonstrate that carefully engineered prompts can significantly enhance output predictability and consistency, while excessive complexity or irrelevant information can increase uncertainty. We also show that ensemble techniques, such as Sigma-weighted aggregation across models and prompt variations, effectively improve reliability. Our findings have profound implications for the development of intelligent systems, emphasizing the critical role of prompt engineering and theoretical modeling in creating AI technologies that perceive, reason, and act predictably in the real world.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412827292",
    "type": "article"
  },
  {
    "title": "Exploring Large Language Models for Scientific Question Answering via Natural Language to SPARQL Translation",
    "doi": "https://doi.org/10.1145/3757923",
    "publication_date": "2025-08-01",
    "publication_year": 2025,
    "authors": "Antonello Meloni; Diego Reforgiato Recupero; Francesco Osborne; Angelo A. Salatino; Enrico Motta; Sahar Vahdati; Jens Lehmann",
    "corresponding_authors": "",
    "abstract": "Translating scientific questions expressed in natural language into SPARQL queries that can be executed over knowledge graphs remains a significant challenge in the field of question answering. Recently, several prominent benchmarks, notably SciQA and DBLP-QuAD, have emerged to evaluate performance in this domain. In this paper, we provide a comprehensive analysis of the performance of language models on these benchmarks, assessing various optimization strategies. Our results indicate that the combined use of fine-tuning and prompting techniques, especially when incorporating strategic few-shot selection, produces excellent results on both benchmarks. These findings underscore an urgent need for more challenging benchmarks to better assess model capabilities. We identify key insights, common error patterns, and potential opportunities for transfer learning, and we discuss their implications for optimizing the performance of large language models in knowledge graph-based question answering tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412827322",
    "type": "article"
  },
  {
    "title": "Cognitive Decision Modeling for Quality of Service in Domestic Pipeline Network",
    "doi": "https://doi.org/10.1145/3757926",
    "publication_date": "2025-08-04",
    "publication_year": 2025,
    "authors": "Munish Bhatia",
    "corresponding_authors": "Munish Bhatia",
    "abstract": "The Internet of Things (IoT) has transformed the industrial sector. This study presents a novel framework for real-time evaluation of service quality in residential gas pipeline networks. IoT devices collect critical operational and environmental data, which are processed through a fog-cloud architecture using Bayesian modeling. This enables the calculation of a comprehensive Quality of Service Measure (QSM) and a Service Quality Delivery Value (SQDV) to assess and interpret service performance. A two-level decision-tree model further supports decisions by regulators and end-users. The framework was validated using 73,462 service interaction records, showing significant improvements over existing approaches: reduced data delay (179.01 s), high classification performance (Specificity: 94.22%, Sensitivity: 92.78%, Precision: 93.15%), enhanced decision-making (Accuracy: 95.45%, Error Rate: 1.29%), improved reliability (93.69%), and robust system stability (73.25%).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412928614",
    "type": "article"
  },
  {
    "title": "LLM-Enhanced User–Item Interactions: Leveraging Edge Information for Optimized Recommendations",
    "doi": "https://doi.org/10.1145/3757925",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Xinyuan Wang; Liang Wu; Liangjie Hong; Hao Liu; Yanjie Fu",
    "corresponding_authors": "",
    "abstract": "Graph recommendation methods, representing a connected interaction perspective, reformulate user–item interactions as graphs to leverage graph structure and topology to recommend and have proved practical effectiveness at scale. Large language models (LLMs), representing a textual generative perspective, excel at modeling user languages, understanding behavioral contexts, capturing user–item semantic relationships, analyzing textual sentiments, and generating coherent and contextually relevant texts as recommendations. However, there is a gap between the connected graph perspective and the text generation perspective as the task formulations are different. A research question arises: how can we effectively integrate the two perspectives for more personalized RecSys? To fill this gap, we propose to incorporate graph-edge information into LLMs via prompt and attention innovations. We reformulate recommendations as a probabilistic generative problem using prompts. We develop a framework to incorporate graph edge information from the prompt and attention mechanisms for graph-structured LLM recommendations. We develop a new prompt design that brings in both first-order and second-order graph relationships; we devise an improved LLM attention mechanism to embed direct the spatial and connectivity information of edges. Our evaluation of real-world datasets demonstrates the framework’s ability to understand connectivity information in graph data and to improve the relevance and quality of recommendation results. Our code is released at: https://github.com/anord-wang/LLM4REC.git .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412991654",
    "type": "article"
  },
  {
    "title": "Artificial Intelligence-inspired Anxiety Detection in Smart Office: Cyber Twin Perspective",
    "doi": "https://doi.org/10.1145/3759253",
    "publication_date": "2025-08-06",
    "publication_year": 2025,
    "authors": "Munish Bhatia",
    "corresponding_authors": "Munish Bhatia",
    "abstract": "Cyber twin technology, a successful branch of simulation modeling in business, is now being applied in the healthcare sector. An intelligent architecture inspired by cyber twins is proposed to explore the unique visual, behavioral, and physiological experiences of individuals with anxiety disorders while working in smart office environments. Temporal data mining is utilized for framing data granules, and quantum probability techniques are employed for anomaly detection within the framework. Additionally, a novel multilayer Convolutional Neural Network is introduced to predict a quantifiable Health Vulnerability Index. A smart alert system is included, capable of notifying caregivers of any identified health concerns, enabling timely assistance. To evaluate the effectiveness of the proposed strategy, it was tested on real-world data comprising 82,235 cases. The results demonstrate that the method excels in several key performance metrics: time efficiency (24.6s), classification efficiency (Precision (92.77%), Specificity (92.43%), and Sensitivity (92.82%)), decision-making efficiency ( \\(r^{2}=79\\%\\) ), error rate (AAE 0.31%), and stability (75%), surpassing current state-of-the-art methodologies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413019878",
    "type": "article"
  },
  {
    "title": "Entropy Causal Graphs for Multivariate Time Series Anomaly Detection",
    "doi": "https://doi.org/10.1145/3757922",
    "publication_date": "2025-08-07",
    "publication_year": 2025,
    "authors": "Falih Gozi Febrinanto; Kristen Moore; Chandra Thapa; Mujie Liu; Vidya Saikrishna; Jiangang Ma; Feng Xia",
    "corresponding_authors": "",
    "abstract": "Many multivariate time series anomaly detection frameworks have been proposed and widely applied. However, most of these frameworks do not consider intrinsic relationships between variables in multivariate time series data, thus ignoring the causal relationship among variables and degrading anomaly detection performance. This work proposes a novel framework called CGAD, an entropy Causal Graph for multivariate time series Anomaly Detection. CGAD utilizes transfer entropy to construct graph structures that unveil the underlying causal relationships among time series data. Weighted graph convolutional networks combined with causal convolutions are employed to model both the causal graph structures and the temporal patterns within multivariate time series data. Furthermore, CGAD applies anomaly scoring, leveraging median absolute deviation-based normalization to improve the robustness of the anomaly identification process. Extensive experiments demonstrate that CGAD outperforms state-of-the-art methods on real-world datasets with a 9% average improvement in terms of three different multivariate time series anomaly detection metrics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413135358",
    "type": "article"
  },
  {
    "title": "Trajectory Representation Learning on Grids and Road Networks with Spatio-Temporal Dynamics",
    "doi": "https://doi.org/10.1145/3757929",
    "publication_date": "2025-08-07",
    "publication_year": 2025,
    "authors": "Stefan Schestakov; Simon Gottschalk",
    "corresponding_authors": "",
    "abstract": "Urban Foundation Models (UFMs) are emerging as a transformative paradigm for understanding and managing complex urban systems, offering new capabilities to improve and transform urban environments. Trajectory data (e.g., vehicle movements) contains rich spatio-temporal patterns of human mobility and urban dynamics that are crucial for understanding city-wide movement behaviors, traffic patterns, and transportation system operations. Effectively modeling such trajectory data is crucial for UFMs, yet this poses significant challenges due to the high-dimensional nature of raw trajectories and their complex spatio-temporal dynamics. Trajectory representation learning addresses these challenges by transforming raw trajectory data into compact, meaningful representations that capture essential mobility patterns and facilitates the application to various urban tasks, such as trajectory similarity computation, travel time estimation, or destination prediction. This is achieved by learning low-dimensional representations from high-dimensional and raw trajectory data. However, existing methods for trajectory representation learning either rely on grid-based or road-based representations, which are inherently different and thus, could lose information contained in the other modality. Moreover, these methods overlook the dynamic nature of urban traffic, relying on static road network features rather than time-varying traffic patterns. In this paper, we propose TIGR , a novel model designed to integrate grid and road network modalities while incorporating spatio-temporal dynamics to learn rich, general-purpose representations of trajectories. We evaluate TIGR on three real-world datasets and demonstrate the effectiveness of combining both modalities by substantially outperforming state-of-the-art methods, i.e., up to 59.34% for trajectory similarity, up to 16.65% for travel time estimation, and up to 14.81% for destination prediction.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413135400",
    "type": "article"
  },
  {
    "title": "Multi-Autonomous Underwater Vehicle Trajectory Planning in Ocean Current Based on Hierarchical Hunting and Evolutionary Learning",
    "doi": "https://doi.org/10.1145/3757928",
    "publication_date": "2025-08-19",
    "publication_year": 2025,
    "authors": "Bin Jiang; Yining Wang; Fung Kew. Kong; Jian Wang",
    "corresponding_authors": "",
    "abstract": "In the context of rising demands for marine resource exploitation and scientific research, collaborative trajectory planning for multiple Autonomous Underwater Vehicles (AUVs) in complex underwater environments—marked by obstacles, ocean currents, and low visibility—remains a critical challenge. Although the Gray Wolf Optimization (GWO) algorithm has advanced multi-objective trajectory planning, it faces issues such as poor high-dimensional space adaptability, susceptibility to local optima, and insufficient constraint handling. To address these, this paper proposes a multi-AUV trajectory planning algorithm (EA-GWO) based on evolutionary learning to improve GWO. The method optimizes multi-AUV trajectory planning by leveraging hierarchical population hunting behavior, integrating position update equations to prioritize population bootstrapping, and balancing exploration and exploitation via fitness-based population distribution. Experimental validation across general, ocean current, and threat environments compares EA-GWO with the traditional GWO and multiple population gray wolf optimization (MP-GWO). For sailing time: In the general environment, EA-GWO reduces total time by 90.6% compared to GWO and 90.6% compared to MP-GWO; In the ocean current environment, it cuts time by 0.9% versus GWO and 2.4% versus MP-GWO; In the threat environment, it cuts time by 13.6% versus GWO and 14.9% versus MP-GWO. For sailing distance: In the general environment, EA-GWO shortens total distance by 9.8% compared to GWO and 3.4% compared to MP-GWO; In the ocean current environment, it reduces distance by 2.3% versus GWO and 4.9% versus MP-GWO; In the threat environment, it shortens distance by 5.5% versus GWO and 1.0% versus MP-GWO. In terms of convergence performance reflected by the fitness curve: across the three environments, EA-GWO demonstrates faster convergence speed. These results highlight that EA-GWO outperforms the other two algorithms in sailing time, distance, and convergence efficiency, verifying its effectiveness in real-time dynamic coordination and constraint handling for multi-AUV missions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413325704",
    "type": "article"
  },
  {
    "title": "PEAS: A Strategy for Crafting Transferable Adversarial Examples",
    "doi": "https://doi.org/10.1145/3763003",
    "publication_date": "2025-08-22",
    "publication_year": 2025,
    "authors": "Bar Avraham; Yisroel Mirsky",
    "corresponding_authors": "",
    "abstract": "Black box attacks, where adversaries have limited knowledge of the target model, pose a significant threat to machine learning systems. Adversarial examples generated with a substitute model often suffer from limited transferability to the target model. While recent work explores ranking perturbations for improved success rates, these methods see only modest gains. We propose a novel strategy called PEAS that can boost the transferability of existing black box attacks. PEAS leverages the insight that samples which are perceptually equivalent exhibit significant variability in their adversarial transferability. Our approach first generates a set of images from an initial sample via subtle augmentations. We then evaluate the transferability of adversarial perturbations on these images using a set of substitute models. Finally, the most transferable adversarial example is selected and used for the attack. Our experiments show that PEAS can double the performance of existing attacks, achieving a 2.5x improvement in attack success rates on average over current ranking methods. We thoroughly evaluate PEAS on ImageNet and CIFAR-10, analyze hyperparameter impacts, and provide an ablation study to isolate each component's importance. Beyond performance, PEAS also introduces a novel perceptual equivalence-based search space that challenges the common \\(\\epsilon\\) -ball constraint used in adversarial machine learning, and reveals that natural augmentations alone can induce adversarial failures.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413418612",
    "type": "article"
  },
  {
    "title": "On Evaluating LLM Integration into Robotic Architectures",
    "doi": "https://doi.org/10.1145/3754340",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Vasanth Sarathy; Marlow Fawn; Matthew McWilliams; Matthias Scheutz; Bradley Oosterveld",
    "corresponding_authors": "",
    "abstract": "LLMs are being increasingly integrated into embodied robotic systems. A useful capability that the LLMs bring to robots is translating noisy spoken human natural language instructions into executable robot actions. However, these integrations are somewhat ad-hoc and understudied as they tend to not consider the gamut of syntactic, semantic, as well as, pragmatic aspects of embodied human communication. What is missing is a characterization of the different paradigms for integrating LLMs into robotic architectures as well as a set of evaluation metrics that capture whether an LLM-equipped robot can correctly understand these different aspects of human instruction. In this paper, we present a suite of evaluation metrics together with data augmentation techniques for evaluating these architectures, using concepts from the cognitive science and human communication literature. To illustrate an application of these metrics and augmentation techniques, we conduct experiments to to compare two integration methods: LLMs as pre-processing components that map human instructions into more constrained versions to be processed by the architecture’s natural language understanding (NLU) subsystem, or LLMs as a wholesale replacement for the NLU’s parser. We provide experimental evaluations and a robotic implementation to show the inherent tradeoffs between the methods. Our results suggest that while they offer increased explainability, traditional parsing tools coupled with LLMs do not perform as well as an LLM that replaces a parser entirely. The proposed evaluation metrics together with the characterization of different LLM integration approaches offer the promise of systematically evaluating LLMs as natural language interfaces to robotic systems as well as tackle the important tradeoff between explainability/verifiability/interpretability and robustness to noisy input and broad language understanding in an open-world embodied setting.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413591978",
    "type": "article"
  },
  {
    "title": "Learning to Hash Knowledge Graph: Element-wise Rotation",
    "doi": "https://doi.org/10.1145/3763005",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Yeshuai He; Jianqiang Cheng; Yong Ge",
    "corresponding_authors": "",
    "abstract": "Knowledge graphs are vital for many tasks, including recommendation systems and node search. Learning to hash knowledge graph is to infer binary-vector representations of the graph. Compared with traditional knowledge graph embedding that learns continuous-vector representations, knowledge graph hashing could significantly reduce storage and computational time due to its binary nature. Despite the potential advantage, the problem of knowledge graph hashing is challenging due to the large-scale binary decision variables. In this paper, we propose a novel discrete optimization framework for knowledge graph hashing. We treat the relations between heads and tails in the knowledge graph as element-wise rotation to learn binary codes. An alternating optimization algorithm is then proposed to produce high-quality code that captures knowledge graph information well. Furthermore, to obtain superior binary representations, we employ a dynamic range method during the alternating optimization process to adjust the approximations of the ReLU function \\([x]_{+}\\) . This ensures that valuable measures of dissimilarity are not overlooked, leading to more accurate computations. The evaluation results on five publicly-available data sets demonstrate the superiority of the proposed algorithm against several state-of-the-art baseline methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413592551",
    "type": "article"
  },
  {
    "title": "You Can Only Tune Normalization: A Simple and Effective Approach to Parameter-Efficient Fine-Tuning",
    "doi": "https://doi.org/10.1145/3763004",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Lingyun Huang; Jianxu Mao; Junfei Yi; Ziming Tao; Ziyang Peng; Wei He; Rui Liu; Yaonan Wang",
    "corresponding_authors": "",
    "abstract": "To tackle the issue of excessive parameter volumes during fine-tuning of large-scale pre-trained models with full parameters, Parameter-Efficient Fine-Tuning (PEFT) methods have been introduced. The core concept involves freezing the backbone network of the model and updating only a small subset of parameters. This strategy not only decreases the number of parameters needed for training but also delivers performance comparable to Full-Tuning, even surpassing it on certain datasets. However, most popular PEFT methods introduce extra parameters or modules for fine-tuning, which come with inherent limitations. In response, we propose a straightforward and efficient PEFT method called You Can Only Tune Normalization (YONO). YONO focuses solely on tuning the normalization layer and the final classification layer of the model. This method avoids adding extra modules, making it easily applicable to any model without causing inference delays. We extensively tested YONO on 28 benchmark datasets, and the results indicate that it requires significantly fewer parameters compared to other advanced PEFT methods. Additionally, we validated YONO's efficiency and generalizability across various vision models. Finally, we further explore the essence of PEFT methods, whether they learn new knowledge or expose the capabilities that a model has already learned. Our findings suggest that YONO is more sensitive to improvements in dataset quality, making it a promising candidate for future scaling to larger models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413641312",
    "type": "article"
  },
  {
    "title": "Help Me Screen: Analyzing and Predicting the Success of Start-ups in Dynamic Venture Capital Networks",
    "doi": "https://doi.org/10.1145/3763001",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Shiwei Lyu; Xiaofeng Li; Suting Hong; Qing Ke; Jinjie Gu; Kunpeng Zhang; Haipeng Zhang",
    "corresponding_authors": "",
    "abstract": "Most start-ups fail, and early-stage ventures face even lower survival rates. Identifying high-potential start-ups remains a critical challenge for venture capital (VC) investors and policymakers. While predictive models exist, the evolving relationships between VC investors, start-ups, and management teams in dynamic networks are underexplored. We propose a method to predict whether a start-up will succeed within five years of its first funding round. Using a 40-year global VC dataset, we model the VC ecosystem as a dynamic bipartite network linking start-ups to individuals (investors/managers). Our approach incrementally updates graph embeddings through unsupervised self-attention to incorporate new nodes, edges, and their neighbors. Node embeddings are further fine-tuned via link prediction and classification tasks, while temporal dependencies are captured to form sequential representations. The model identifies early-stage start-ups with twice the success likelihood of those chosen by professional investors. Key factors including networking and education align with VC literature. Additionally, we provide model complexity analysis and open-source our implementation to support practical applications and future research.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413682941",
    "type": "article"
  },
  {
    "title": "Advances in Pre-trained Language Models for Domain-Specific Text Classification: A Systematic Review",
    "doi": "https://doi.org/10.1145/3763002",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Zhyar Rzgar K Rostam; Gábor Kertész",
    "corresponding_authors": "",
    "abstract": "The exponential increase in scientific literature and online information necessitates efficient methods for extracting knowledge from textual data. Natural Language Processing (NLP) plays a crucial role in addressing this challenge, particularly in text classification tasks. While Large Language Models (LLMs) have achieved remarkable success in NLP, their accuracy can suffer in domain-specific contexts due to specialized vocabulary, unique grammatical structures, and imbalanced data distributions. In this Systematic Literature Review (SLR), we investigate the utilization of Pre-trained Language Models (PLMs) for domain-specific text classification. We systematically review 41 articles published between 2018 and January 2024, adhering to the PRISMA statement (Preferred Reporting Items for Systematic Reviews and Meta-Analyses). This review methodology involved rigorous inclusion criteria and a multi-step selection process employing AI-powered tools. We delve into the evolution of text classification techniques and differentiate between traditional and modern approaches. We emphasize transformer-based models and explore the challenges and considerations associated with using LLMs for domain-specific text classification. Furthermore, we categorize existing research based on various PLMs and propose a taxonomy of techniques used in the field. To validate our findings, we conducted a comparative experiment involving BERT, SciBERT, and BioBERT in biomedical sentence classification. Finally, we present a comparative study on the performance of LLMs in text classification tasks across different domains. In addition, we examine recent advancements in PLMs for domain-specific text classification and offer insights into future directions and limitations in this rapidly evolving domain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414014852",
    "type": "review"
  },
  {
    "title": "Ensuring Pre-Fusion Modality Consistency: A New Approach to Multimodal Sentiment Detection",
    "doi": "https://doi.org/10.1145/3748658",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Yulou Shu; Wengen Li; Yu-Ping Ruan; Wuchao Liu; Yichao Zhang; Jihong Guan; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "With the growing diversity of data formats on social media, such as text, images, and videos, there is a growing need to analyze sentiment from multiple modalities. Multimodal sentiment detection, which aims to identify users’ sentiment by jointly modeling information from different modalities, has thus attracted increasing attention. However, most existing multimodal sentiment detection methods fuse multimodal information directly after the unimodal encoding, and overlook the modality consistency of multimodal vector spaces before the fusion, which may damage the accuracy of multimodal sentiment detection. To address this issue, we propose a contrastive learning-based multimodal sentiment detection model termed EPMC which can map the representations of different modalities into a unified semantic space before fusion. EPMC operates in two stages, i.e., pre-training stage and fine-tuning stage. At the pre-training stage, we designed a cross-modal transformation module to map different modalities into a unified feature space. Meanwhile, to further capture the relationship between the cross-modal transformation vectors and the unimodal encoding vectors, we propose a multimodal consistency contrastive learning task that helps the model discern and amplify the cross-modal similarity between different modalities, thereby learning more discriminative features for sentiment detection. At the fine-tuning stage, EPMC is iteratively refined using the learned multimodal representation and guided by the cross-entropy loss. Extensive experiments conducted on three public multimodal datasets validate the effectiveness of EPMC model. The official implementation of EPMC is released at https://github.com/ADMIS-TONGJI/EPMC .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414203465",
    "type": "article"
  },
  {
    "title": "Urban Computing in the Era of Large Language Models",
    "doi": "https://doi.org/10.1145/3768163",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Zhonghang Li; Lianghao Xia; Xubin Ren; Jiabin Tang; Tianyi Chen; Yong Xu; Chao Huang",
    "corresponding_authors": "",
    "abstract": "Urban computing has emerged as a multidisciplinary field that harnesses data-driven technologies to address challenges and improve urban living. Traditional approaches, while beneficial, often face challenges with generalization, scalability, and contextual understanding. The advent of Large Language Models (LLMs) offers transformative potential in this domain. This survey explores the intersection of LLMs and urban computing, emphasizing the impact of LLMs in processing and analyzing urban data, enhancing decision-making, and fostering citizen engagement. We provide a concise overview of the evolution and core technologies of LLMs. Additionally, we survey their applications across key urban domains, such as transportation, public safety, and environmental monitoring, summarizing essential tasks and prior works in various urban contexts, while highlighting LLMs’ functional roles and implementation patterns. Building on this, we propose potential LLM-based solutions to address unresolved challenges. To facilitate in-depth research, we compile a list of available datasets and tools applicable to diverse urban scenarios. Finally, we discuss the limitations of current approaches and outline future directions for advancing LLMs in urban computing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414203706",
    "type": "article"
  },
  {
    "title": "Online Distributed Heterogeneous Streaming Feature Selection",
    "doi": "https://doi.org/10.1145/3767722",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Peng Zhou; Huiqi Deng; Yunyun Zhang; Zhaolong Ling; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "Data is exploding in many fields and may exist in the streaming mode. When the generation speed of massive streaming data far exceeds the processing speed of a single node, and the generated data needs to be processed in real-time, traditional centralized learning models are challenging in meeting the efficiency requirements. Therefore, online distributed learning models emerge. As time progresses, features may continuously emerge from various sources in a distributed and heterogeneous fashion. Therefore, we study the problem of online distributed heterogeneous streaming feature selection and propose a novel framework to address it, named DHSFS. The framework comprises two main components: sub-node streaming feature selection and global information synchronization. The sub-node component uses a dynamic strategy to select strong features, discard irrelevant ones, and cache weakly relevant features. In the global information synchronization stage, each sub-node synchronizes statistics information with the master node to adjust the global thresholds dynamically. Finally, the features selected by each sub-node are summarized and output. Experiments on 16 datasets show that the DHSFS framework has both high prediction accuracy and high efficiency of online stream feature selection.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414203745",
    "type": "article"
  },
  {
    "title": "Fighting Misinformation in Health News: DCNN-CapsNet for Cross-Domain Health Misinformation Detection",
    "doi": "https://doi.org/10.1145/3748514",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Mohammad Hadi Goldani; Saeedeh Momtazi; Reza Safabakhsh",
    "corresponding_authors": "",
    "abstract": "Abstract: Misinformation propagation poses a significant challenge in the digital information era, particularly during crises such as pandemics. Detecting and combating misinformation is crucial for ensuring public health and safety. In this study, we focus on cross-domain misinformation detection for health news by leveraging a Covid-19 dataset to train a model capable of identifying Monkeypox misinformation articles. We propose a novel hybrid model that combines the strengths of both Deep Convolutional Neural Network (DCNN) and Capsule Neural Network (CapsNet), referred to as DCNN-CapsNet. This model reaps the benefits of both DCNN and CapsNet as two different neural network architectures that have been used as classifiers. To enhance the learning process, we employ incremental fine-tuning, which enables our model to begin with dynamic, pre-trained word embeddings that are updated throughout the training phase. This approach ensures that the embeddings remain relevant to the specific task of misinformation detection, adapting to the nuances of the dataset. Additionally, we incorporate margin loss as a critical component of our architecture. Margin loss is designed to improve the model’s ability to learn discriminative features by maximizing intra-cluster similarity and inter-cluster dissimilarity. This loss function addresses the limitations of traditional cross-entropy loss by enforcing a margin between predicted outputs and decision boundaries, thus reducing class overlap and mitigating the risk of overfitting. By ensuring that the learned representations of “real” and “fake” news are sufficiently separated, margin loss enhances the model’s robustness in detecting misinformation across different domains. Our model outperforms several baseline models on a Covid-19 dataset, achieving a 97.34% accuracy and 97.29% F1-score. Furthermore, it surpasses baselines on a Monkeypox dataset, achieving a 96.03% accuracy and 95.75% F1-score. The cross-domain evaluation, training on Covid-19 data, and testing on Monkeypox data, also demonstrates strong performance with an 89.25% accuracy and 94.16% F1-score, exceeding the performance of the same baseline models in the cross-domain setting. These results highlight the effectiveness of our approach for cross-domain misinformation detection and its potential for broader application in combating misinformation across diverse contexts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414203821",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Multi-View Classification: Methods, Applications, and Challenges",
    "doi": "https://doi.org/10.1145/3767728",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Kamal Berahmand; Fatemeh Daneshfar; Maryam Rahmaninia; Maryam Haghighat; Mahdi Jalili",
    "corresponding_authors": "",
    "abstract": "Multi-view Classification (MVC) has emerged as a promising approach in machine learning, aimed at enhancing classification accuracy by leveraging information from multiple perspectives. As the demand for more robust, interpretable, and effective machine learning models grows, MVC has shown significant progress over the past decade, yet it faces new challenges. Despite extensive literature on this subject, there is a notable absence of a comprehensive synthesis of MVC methods. This paper addresses this gap by presenting a thorough overview and classification of MVC methods, categorizing them into seven distinct classes: text, image, time series, hyperspectral, video, signal, and 3D shape. Our meticulous examination within each class highlights advancements and evaluates their applicability in both supervised and semi-supervised learning contexts. Beyond this retrospective analysis, we explore future directions for research and development in this domain. This survey serves as a compendium of existing knowledge and as a guide for future endeavours in MVC, shaping the trajectory of ongoing research and innovation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414242124",
    "type": "article"
  },
  {
    "title": "Frequency Modulated Transformer Self-Attention for Advanced Infectious Disease Prediction",
    "doi": "https://doi.org/10.1145/3768162",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Asmita Mahajan; Durga Toshniwal",
    "corresponding_authors": "",
    "abstract": "Time series forecasting of infectious diseases is crucial to addressing significant global health challenges. The application of Artificial Intelligence (AI), particularly deep learning (DL) algorithms, has demonstrated substantial success in sequence modeling; however, their performance in epidemiological forecasting remains constrained by the non-stationary nature and complex frequency dynamics of disease transmission. This research introduces a novel Frequency Modulated Transformer (FMT) framework to address these challenges. The FMT framework decomposes time series data into distinct frequency-modulated signals, utilizing self-attention mechanisms to capture temporal frequencies. A transformer encoder-decoder architecture then predicts and captures multi-scale temporal dependencies and makes accurate predictions. The novelty of the proposed approach lies in decomposing the input time series into Intrinsic Mode Functions (IMFs) and integrating the frequency-specific components into a Transformer architecture via entropy-based feature selection. The FMT framework significantly reduces Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) by approximately 50% and 65%, respectively, compared to conventional methods. Additionally, it achieves an 8% increase in the R2 score, demonstrating enhanced predictive accuracy. The proposed methodology is evaluated using COVID-19 datasets from multiple countries along with an influenza dataset, and benchmarked against statistical, machine learning, and state-of-the-art deep learning baselines. The contribution of entropy-based IMF integration is systematically examined by comparing results with and without this component, underscoring its importance in improving predictive accuracy. This work highlights substantial improvements in predictive accuracy and computational efficiency, advancing epidemiological forecasting and supporting real-time public health decision-making and AI-driven disease surveillance systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414242221",
    "type": "article"
  },
  {
    "title": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World",
    "doi": "https://doi.org/10.1145/3768625",
    "publication_date": "2025-09-19",
    "publication_year": 2025,
    "authors": "Yu Zheng",
    "corresponding_authors": "Yu Zheng",
    "abstract": "The proliferation of artificial intelligence has enabled a diversity of applications that bridge the gap between digital and physical worlds. As physical environments are too complex to model through a single information acquisition approach, it is crucial to fuse multimodal data generated by different sources, such as sensors, devices, systems, and people, to solve a problem in the real world. Unfortunately, it is neither applicable nor sustainable to deploy new resources to collect original data from scratch for every problem. Thus, when data is inadequate in the domain of problem, it is vital to fuse knowledge from multimodal data that is already available in other domains. We call this cross-domain knowledge fusion. Existing research focus on fusing multimodal data in a single domain, supposing the knowledge from different datasets is intrinsically aligned; however, this assumption may not hold in the scenarios of cross-domain knowledge fusion. In this paper, we formally define the cross-domain multimodal data fusion problem, discussing its unique challenges, differences and advantages beyond data fusion in a single domain. We propose a four-layer framework, consisting of Domains, Links, Models and Data layers, answering three key questions: “what to fuse”, “why can be fused”, and “how to fuse”. The Domains Layer selects relevant data from different domains for a given problem. The Links Layer reveals the philosophy of knowledge alignment beyond specific model structures. The Models Layer provides two knowledge fusion paradigms based on the fundamental mechanisms for processing data. The Data Layer turns data of different structures, resolutions, scales and distributions into a consistent representation that can be fed into an AI model. With this framework, we can design solutions that fuse cross-domain multimodal data effectively for solving real-world problems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414378209",
    "type": "article"
  },
  {
    "title": "Similarity Search with Data Missing",
    "doi": "https://doi.org/10.1145/3724124",
    "publication_date": "2025-09-23",
    "publication_year": 2025,
    "authors": "Changyi Ma; Xuan Song",
    "corresponding_authors": "",
    "abstract": "Similarity search is a fundamental research problem with broad applications in various research fields, including data mining, information retrieval, and machine learning. The core idea of similarity search is to find the most similar data sample of given query items, based on a specific similarity metric with the highest similarity score with all the search candidates in a large-scale database. It may suffer from a prohibitive computation cost and storage cost, which motivates us to design effective and fast similarity search algorithms in various scenarios. However, data missing is unavoidable in real-world scenarios, which results in a less accurate similarity score and further leads to an inaccurate similarity matrix. Therefore, obtaining an accurate similarity matrix is non-trivial when there are incomplete observations. To solve this problem, we propose a similarity matrix calibration method to estimate a high-quality similarity matrix and further provide a better similarity search performance. Firstly, we propose an objective function to minimize the difference between the initial inaccurate similarity matrix and the optimal estimated similarity matrix, where the inherent symmetric and positive semi-definiteness (PSD) properties are utilized as the constraint to guide the calibration process. Then, we design an effective algorithm with high efficiency to provide a high-quality similarity matrix that approximates the ground truth similarity matrix. Theoretical analysis demonstrates the efficiency guarantee of our proposed method, and extensive experimental results on real-world datasets verify the effectiveness and efficiency of the proposed method on the similarity matrix calibration task and the downstream similarity search task.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414438911",
    "type": "article"
  },
  {
    "title": "Transformer Model Embedding Dual Stream for Modulation Classification of Short Signal Samples",
    "doi": "https://doi.org/10.1145/3770082",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Thien-Thanh Dao; Quoc‐Viet Pham; Thien Huynh‐The; Won–Joo Hwang",
    "corresponding_authors": "",
    "abstract": "Automatic modulation classification (AMC) is a critical task in modern communication systems, particularly under diverse signal conditions and limited data scenarios. Existing transformer-based AMC models often rely on single-stream architectures and uniform input formats, which limit their effectiveness in capturing rich signal features. To address these limitations, we propose DTNet, a novel transformer-based dual-stream network designed for efficient and accurate modulation classification. DTNet introduces two key innovations: (1) a scale feature and extension (SFE) block that applies a scaling function to transform signals into a structured output map, followed by an extension module that reconstructs the signal into a square matrix and integrates a response map using adaptive filters; and (2) a convolutional stream that extracts discriminative features from multiscale signal representations. Furthermore, a modified feature embedding to leverage the transformer architecture is introduced to capture global dependencies and contextual information from the input signal, thereby enhancing the modulation classification accuracy. Experimental results show that DTNet achieves superior performance on benchmark datasets, reaching classification accuracies of 93.4% on RML2016.10A and 94.4% on RML2016.10B, outperforming state-of-the-art deep learning methods while maintaining lower computational complexity. The source code is available at https://github.com/daothanh2011/DTNet .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414653499",
    "type": "article"
  },
  {
    "title": "Verifying Online Safety Properties for Safe Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3770068",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Luca Marzari; Ferdinando Cicalese; Alessandro Farinelli; Christopher Amato; Enrico Marchesini",
    "corresponding_authors": "",
    "abstract": "Ensuring safety in reinforcement learning (RL) is critical for deploying agents in real-world applications. During training, current safe RL approaches often rely on indicator cost functions that provide sparse feedback, resulting in two key limitations: (i) poor sample efficiency due to the lack of safety information in neighboring states, and (ii) dependence on cost-value functions, leading to brittle convergence and suboptimal performance. After training, safety is guaranteed via formal verification methods for deep neural networks (FV), whose computational complexity hinders their application during training. We address the limitations of using cost functions via verification by proposing a safe RL method based on a violation value—the risk associated with policy decisions in a portion of the state space. Our approach verifies safety properties (i.e., state-action pairs) that may lead to unsafe behavior, and quantifies the size of the state space where properties are violated. This violation value is then used to penalize the agent during training to encourage safer policy behavior. Given the NP-hard nature of FV, we propose an efficient, sample-based approximation with probabilistic guarantees to compute the violation value. Extensive experiments on standard benchmarks and real-world robotic navigation tasks show that violation-augmented approaches significantly improve safety by reducing the number of unsafe states encountered while achieving superior performance compared to existing methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414654073",
    "type": "article"
  },
  {
    "title": "A Survey on Automatic Credibility Assessment Using Textual Credibility Signals in the Era of Large Language Models",
    "doi": "https://doi.org/10.1145/3770077",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Ivan Srba; Olesya Razuvayevskaya; João A. Leite; Róbert Moró; Ipek Baris Schlicht; Sara Tonelli; Francisco Moreno; Santiago Barrio Lottmann; Denis Teyssou; Valentin Porcellini; Carolina Scarton; Kalina Bontcheva; Mária Bieliková",
    "corresponding_authors": "",
    "abstract": "In the age of social media and generative AI, the ability to automatically assess the credibility of online content has become increasingly critical, complementing traditional approaches to false information detection. Credibility assessment relies on aggregating diverse credibility signals – small units of information, such as content subjectivity, bias, or a presence of persuasion techniques – into a final credibility label/score. However, current research in automatic credibility assessment and credibility signals detection remains highly fragmented, with many signals studied in isolation and lacking integration. Notably, there is a scarcity of approaches that detect and aggregate multiple credibility signals simultaneously. These challenges are further exacerbated by the absence of a comprehensive and up-to-date overview of research works that connects these research efforts under a common framework and identifies shared trends, challenges, and open problems. In this survey, we address this gap by presenting a systematic and comprehensive literature review of 175 research papers, focusing on textual credibility signals within the field of Natural Language Processing (NLP), which undergoes a rapid transformation due to advancements in Large Language Models (LLMs). While positioning the NLP research into the the broader multidisciplinary landscape, we examine both automatic credibility assessment methods as well as the detection of nine categories of credibility signals. We provide an in-depth analysis of three key categories: 1) factuality, subjectivity and bias, 2) persuasion techniques and logical fallacies, and 3) check-worthy and fact-checked claims. In addition to summarising existing methods, datasets, and tools, we outline future research direction and emerging opportunities, with particular attention to evolving challenges posed by generative AI.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414654425",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Evaluations of Large Language Models Part 1",
    "doi": "https://doi.org/10.1145/3770500",
    "publication_date": "2025-10-01",
    "publication_year": 2025,
    "authors": "Jindong Wang; Linyi Yang; Sunayana Sitaram; Qiang Yang; Bhiksha Raj",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414730031",
    "type": "article"
  },
  {
    "title": "RenHaze: A Coarse-to-Fine Rendering Framework for Improving Robustness to Haze",
    "doi": "https://doi.org/10.1145/3770745",
    "publication_date": "2025-10-03",
    "publication_year": 2025,
    "authors": "Trung-Hieu Le; Shih-Chia Huang; Quoc-Viet Hoang; Zhihui Lu",
    "corresponding_authors": "",
    "abstract": "Large-scale datasets centered on images have driven advancements in deep learning-based computer vision applications. While there is an abundance of datasets containing images depicting favorable weather scenes, datasets featuring images of adverse weather conditions, especially the presence of haze, are scarce due to challenges in their collection. In response, we leverage the advantages of deep learning techniques to introduce a novel approach for facilitating the rendering of realistic and diverse hazy images, named RenHaze. To be specific, RenHaze adopts a denseness parameter \\(\\omega\\) to control the haze level of output images and consists five subnets, including a content exploitation (CE) subnet, a depth exploitation (DE) subnet, a haze exploitation (HE) subnet, an image generation (IG) subnet, and an image discernment (ID) subnet. The CE, DE, and HE subnets are responsible for extracting features from the source clear image, depth image, and reference hazy image, respectively, and then providing them for IG subnet. The IG subnet is used to perform image translation in a coarse-to-fine manner, while the ID subnet is employed to discern the realism of the rendered image and provide feedback to the IG subnet for generating the desired output. Extensive experiments demonstrate the superiority of the proposed model over competing image generation methods in terms of the realism and diversity of synthesized hazy images, as well as its effectiveness in boosting the performance of computer vision tasks such as object detection and semantic segmentation in real-world hazy environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414783269",
    "type": "article"
  },
  {
    "title": "OCP: Proactive Optimal Charging Planning for Electric Vehicles",
    "doi": "https://doi.org/10.1145/3771722",
    "publication_date": "2025-10-14",
    "publication_year": 2025,
    "authors": "Saeed Nasehi; Farhana Choudhury; Egemen Tanin",
    "corresponding_authors": "",
    "abstract": "Due to the limited driving range, insufficient charging facilities, and time-consuming recharging, optimizing charging routes for Electric Vehicles (EVs) presents unique challenges compared to conventional vehicles. The time and location of EV charging during a trip not only affect an individual EV’s travel time but also influence others, as queues may form at Charging Station(s). This issue is at large seen as a significant constraint for uplifting EV sales in many countries. In this study, we introduce a novel Electric Vehicle Route Planning problem, which involves two parts: (i) Finding the fastest route with recharging for an EV routing request. We model the problem as a new graph problem and prove its NP-hardness. We propose an innovative two-phase algorithm that efficiently traverses the graph to identify the optimal charging route for each EV. (ii) We find routes with minimized travel time for an EV while strategically avoid charging stations and time to recharge at those stations which can lead to minimized travel time for upcoming EVs. For this purpose, we introduce the concept of an ’influence factor’ to guide heuristic decisions. Our results demonstrate that this method reduces total travel time by 50% compared to the state-of-the-art on real-world datasets, with benefits becoming more significant as the number of EVs on the road increases.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415157137",
    "type": "article"
  },
  {
    "title": "Planning interventions in biological networks",
    "doi": "https://doi.org/10.1145/1869397.1869400",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Daniel Bryce; Michael Verdicchio; Seungchan Kim",
    "corresponding_authors": "",
    "abstract": "Modeling the dynamics of biological processes has recently become an important research topic in computational biology and systems engineering. One of the most important reasons to model a biological process is to enable high-throughput in-silico experiments that attempt to predict or intervene in the process. These experiments can help accelerate the design of therapies through their rapid and inexpensive replication and alteration. While some techniques exist for reasoning with biological processes, few take advantage of the flexible and scalable algorithms popular in AI research. In reasoning about interventions in biological processes, where scalability is crucial for feasible application, we apply AI planning-based search techniques and demonstrate their advantage over existing enumerative methods. We also present a novel formulation of intervention planning that relies on models that characterize and attempt to change the phenotype of a system. We study three biological systems: the yeast cell cycle, a model of the human aging process, and the Wnt5a network governing the metastasis of melanoma in humans. The contribution of our investigation is in demonstrating that: (i) prior approaches, based on dynamic programming, cannot scale as well as heuristic search, and (ii) the newly found scalability enables us to plan previously unknown sequences of interventions that reveal novel and biologically significant responses in the systems which are consistent with biological knowledge in the literature.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2157810920",
    "type": "article"
  },
  {
    "title": "Accessible image search for colorblindness",
    "doi": "https://doi.org/10.1145/1858948.1858956",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Meng Wang; Bo Liu; Xian‐Sheng Hua",
    "corresponding_authors": "",
    "abstract": "This article introduces an intelligent system that accommodates colorblind users in image search. Color plays an important role in the human perception and recognition of images. However, there are about 8% of men and 0.8% of women suffering from colorblindness. We show that the existing image search techniques cannot provide satisfactory results for these users since many images will not be well perceived by them due to the loss of color information. To deal with this difficulty, we introduce a system named Accessible Image Search (AIS) to accommodate these users. Different from the general image search scheme that aims at returning more relevant results, AIS further takes into account the colorblind accessibilities of the returned results, that is, the image qualities in the eyes of colorblind users. The system contains three components: accessibility assessment, accessibility improvement, and color indication. The accessibility assessment component measures the accessibility scores of images, and consequently different reranking methods can be performed to prioritize images with high accessibilities. In the accessibility improvement component, we propose an efficient recoloring algorithm to modify the colors of the images such that they can be better perceived by colorblind users. Color indication aims to indicate the name of the interesting color in an image. We evaluate the introduced system with more than 60 queries and 20 anonymous colorblind users, and the empirical results demonstrate its effectiveness and usefulness.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2015611483",
    "type": "article"
  },
  {
    "title": "Prediction in financial markets",
    "doi": "https://doi.org/10.1145/1961189.1961191",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Vasant Dhar",
    "corresponding_authors": "Vasant Dhar",
    "abstract": "Predictive models in regression and classification problems typically have a single model that covers most, if not all, cases in the data. At the opposite end of the spectrum is a collection of models, each of which covers a very small subset of the decision space. These are referred to as “small disjuncts.” The trade-offs between the two types of models have been well documented. Single models, especially linear ones, are easy to interpret and explain. In contrast, small disjuncts do not provides as clean or as simple an interpretation of the data, and have been shown by several researchers to be responsible for a disproportionately large number of errors when applied to out-of-sample data. This research provides a counterpoint, demonstrating that a portfolio of “simple” small disjuncts provides a credible model for financial market prediction, a problem with a high degree of noise. A related novel contribution of this article is a simple method for measuring the “yield” of a learning system, which is the percentage of in-sample performance that the learned model can be expected to realize on out-of-sample data. Curiously, such a measure is missing from the literature on regression learning algorithms. Pragmatically, the results suggest that for problems characterized by a high degree of noise and lack of a stable knowledge base it makes sense to reconstruct the portfolio of small rules periodically.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2085492866",
    "type": "article"
  },
  {
    "title": "An Ensemble Architecture for Learning Complex Problem-Solving Techniques from Demonstration",
    "doi": "https://doi.org/10.1145/2337542.2337560",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Xiaoqin Shelley Zhang; Bhavesh Shrestha; Sung‐Wook Yoon; Subbarao Kambhampati; Phillip DiBona; Jinhong K. Guo; Daniel C. McFarlane; Martin Hofmann; Kenneth R. Whitebread; Darren Scott Appling; Elizabeth Whitaker; Ethan Trewhitt; Li Ding; James Michaelis; Deborah L. McGuinness; James Hendler; Janardhan Rao Doppa; Charles Parker; Thomas G. Dietterich; Prasad Tadepalli; Weng‐Keen Wong; Derek Green; Anton Rebguns; Diana F. Spears; Ugur Kuter; Geoff Levine; Gerald DeJong; Reid MacTavish; Santiago Ontañón; Jainarayan Radhakrishnan; Ashwin Ram; Hala Mostafa; Huzaifa Zafar; Chongjie Zhang; Daniel D. Corkill; Victor Lesser; Zhexuan Song",
    "corresponding_authors": "",
    "abstract": "We present a novel ensemble architecture for learning problem-solving techniques from a very small number of expert solutions and demonstrate its effectiveness in a complex real-world domain. The key feature of our “Generalized Integrated Learning Architecture” (GILA) is a set of heterogeneous independent learning and reasoning (ILR) components, coordinated by a central meta-reasoning executive (MRE). The ILRs are weakly coupled in the sense that all coordination during learning and performance happens through the MRE. Each ILR learns independently from a small number of expert demonstrations of a complex task. During performance, each ILR proposes partial solutions to subproblems posed by the MRE, which are then selected from and pieced together by the MRE to produce a complete solution. The heterogeneity of the learner-reasoners allows both learning and problem solving to be more effective because their abilities and biases are complementary and synergistic. We describe the application of this novel learning and problem solving architecture to the domain of airspace management, where multiple requests for the use of airspaces need to be deconflicted, reconciled, and managed automatically. Formal evaluations show that our system performs as well as or better than humans after learning from the same training data. Furthermore, GILA outperforms any individual ILR run in isolation, thus demonstrating the power of the ensemble architecture for learning and problem solving.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2165730036",
    "type": "article"
  },
  {
    "title": "Understanding and Identifying Rhetorical Questions in Social Media",
    "doi": "https://doi.org/10.1145/3108364",
    "publication_date": "2018-01-10",
    "publication_year": 2018,
    "authors": "Suhas Ranganath; Xia Hu; Jiliang Tang; Suhang Wang; Huan Liu",
    "corresponding_authors": "",
    "abstract": "Social media provides a platform for seeking information from a large user base. Information seeking in social media, however, occurs simultaneously with users expressing their viewpoints by making statements. Rhetorical questions have the form of a question but serve the function of a statement and are an important tool employed by users to express their viewpoints. Therefore, rhetorical questions might mislead platforms assisting information seeking in social media. It becomes difficult to identify rhetorical questions as they are not syntactically different from other questions. In this article, we develop a framework to identify rhetorical questions by modeling some motivations of the users to post them. We focus on two motivations of the users drawing from linguistic theories to implicitly convey a message and to modify the strength of a statement previously made. We develop a quantitative framework from these motivations to identify rhetorical questions in social media. We evaluate the framework using two datasets of questions posted on a social media platform Twitter and demonstrate its effectiveness in identifying rhetorical questions. This is the first framework, to the best of our knowledge, to model the possible motivations for posting rhetorical questions to identify them on social media platforms.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2783008516",
    "type": "article"
  },
  {
    "title": "Discriminative and Orthogonal Subspace Constraints-Based Nonnegative Matrix Factorization",
    "doi": "https://doi.org/10.1145/3229051",
    "publication_date": "2018-11-01",
    "publication_year": 2018,
    "authors": "Xuelong Li; Guosheng Cui; Yongsheng Dong",
    "corresponding_authors": "",
    "abstract": "Nonnegative matrix factorization (NMF) is one widely used feature extraction technology in the tasks of image clustering and image classification. For the former task, various unsupervised NMF methods based on the data distribution structure information have been proposed. While for the latter task, the label information of the dataset is one very important guiding. However, most previous proposed supervised NMF methods emphasis on imposing the discriminant constraints on the coefficient matrix. When dealing with new coming samples, the transpose or the pseudoinverse of the basis matrix is used to project these samples to the low dimension space. In this way, the label influence to the basis matrix is indirect. Although, there are also some methods trying to constrain the basis matrix in NMF framework, either they only restrict within-class samples or impose improper constraint on the basis matrix. To address these problems, in this article a novel NMF framework named discriminative and orthogonal subspace constraints-based nonnegative matrix factorization (DOSNMF) is proposed. In DOSNMF, the discriminative constraints are imposed on the projected subspace instead of the directly learned representation. In this manner, the discriminative information is directly connected with the projected subspace. At the same time, an orthogonal term is incorporated in DOSNMF to adjust the orthogonality of the learned basis matrix, which can ensure the orthogonality of the learned subspace and improve the sparseness of the basis matrix at the same time. This framework can be implemented in two ways. The first way is based on the manifold learning theory. In this way, two graphs, i.e., the intrinsic graph and the penalty graph, are constructed to capture the intra-class structure and the inter-class distinctness. With this design, both the manifold structure information and the discriminative information of the dataset are utilized. For convenience, we name this method as the name of the framework, i.e., DOSNMF. The second way is based on the Fisher’s criterion, we name it Fisher’s criterion-based DOSNMF (FDOSNMF). The objective functions of DOSNMF and FDOSNMF can be easily optimized using multiplicative update (MU) rules. The new methods are tested on five datasets and compared with several supervised and unsupervised variants of NMF. The experimental results reveal the effectiveness of the proposed methods.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2899165782",
    "type": "article"
  },
  {
    "title": "Learning Facial Expressions with 3D Mesh Convolutional Neural Network",
    "doi": "https://doi.org/10.1145/3200572",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Hai Jin; Yuanfeng Lian; Jing Hua",
    "corresponding_authors": "",
    "abstract": "Making machines understand human expressions enables various useful applications in human-machine interaction. In this article, we present a novel facial expression recognition approach with 3D Mesh Convolutional Neural Networks (3DMCNN) and a visual analytics-guided 3DMCNN design and optimization scheme. From an RGBD camera, we first reconstruct a 3D face model of a subject with facial expressions and then compute the geometric properties of the surface. Instead of using regular Convolutional Neural Networks (CNNs) to learn intensities of the facial images, we convolve the geometric properties on the surface of the 3D model using 3DMCNN. We design a geodesic distance-based convolution method to overcome the difficulties raised from the irregular sampling of the face surface mesh. We further present interactive visual analytics for the purpose of designing and modifying the networks to analyze the learned features and cluster similar nodes in 3DMCNN. By removing low-activity nodes in the network, the performance of the network is greatly improved. We compare our method with the regular CNN-based method by interactively visualizing each layer of the networks and analyze the effectiveness of our method by studying representative cases. Testing on public datasets, our method achieves a higher recognition accuracy than traditional image-based CNN and other 3D CNNs. The proposed framework, including 3DMCNN and interactive visual analytics of the CNN, can be extended to other applications.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2903073752",
    "type": "article"
  },
  {
    "title": "An inference-based model of word meaning in context as a paraphrase distribution",
    "doi": "https://doi.org/10.1145/2483669.2483675",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Taesun Moon; Katrin Erk",
    "corresponding_authors": "",
    "abstract": "Graded models of word meaning in context characterize the meaning of individual usages (occurrences) without reference to dictionary senses. We introduce a novel approach that frames the task of computing word meaning in context as a probabilistic inference problem. The model represents the meaning of a word as a probability distribution over potential paraphrases, inferred using an undirected graphical model. Evaluated on paraphrasing tasks, the model achieves state-of-the-art performance.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1967475417",
    "type": "article"
  },
  {
    "title": "Planning solar array operations on the international space station",
    "doi": "https://doi.org/10.1145/1989734.1989745",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Sudhakar Y. Reddy; Jeremy Frank; Michael Iatauro; Matthew E. Boyce; Elif Kürklü; Mitchell Ai-Chang; Ari Jónsson",
    "corresponding_authors": "",
    "abstract": "Flight controllers manage the orientation and modes of eight large solar arrays that power the International Space Station (ISS). The task requires generating plans that balance complex constraints and preferences. These considerations include context-dependent constraints on viable solar array configurations, temporal limits on transitions between configurations, and preferences on which considerations have priority. The Solar Array Constraint Engine (SACE) treats this operations planning problem as a sequence of tractable constrained optimization problems. SACE uses constraint management and automated planning capabilities to reason about the constraints, to find optimal array configurations subject to these constraints and solution preferences, and to automatically generate solar array operations plans. SACE further provides flight controllers with real-time situational awareness and what-if analysis capabilities. SACE is built on the Extensible Universal Remote Operations Planning Architecture (EUROPA) model-based planning system. EUROPA facilitated SACE development by providing model-based planning, built-in constraint reasoning capability, and extensibility. This article formulates the planning problem, explains how EUROPA solves the problem, and provides performance statistics from several planning scenarios. SACE reduces a highly manual process that takes weeks to an automated process that takes tens of minutes.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1973361628",
    "type": "article"
  },
  {
    "title": "Dealing with uncertainty",
    "doi": "https://doi.org/10.1145/2508037.2508046",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Hannes Wolf; Klaus Herrmann; Kurt Rothermel",
    "corresponding_authors": "",
    "abstract": "Processes in the healthcare domain are characterized by coarsely predefined recurring procedures that are flexibly adapted by the personnel to suite-specific situations. In this setting, a workflow management system that gives guidance and documents the personnel's actions can lead to a higher quality of care, fewer mistakes, and higher efficiency. However, most existing workflow management systems enforce rigid inflexible workflows and rely on direct manual input. Both are inadequate for healthcare processes. In particular, direct manual input is not possible in most cases since (1) it would distract the personnel even in critical situations and (2) it would violate fundamental hygiene principles by requiring disinfected doctors and nurses to touch input devices. The solution could be activity recognition systems that use sensor data (e.g., audio and acceleration data) to infer the current activities by the personnel and provide input to a workflow (e.g., informing it that a certain activity is finished now). However, state-of-the-art activity recognition technologies have difficulties in providing reliable information. We describe a comprehensive framework tailored for flexible human-centric healthcare processes that improves the reliability of activity recognition data. We present a set of mechanisms that exploit the application knowledge encoded in workflows in order to reduce the uncertainty of this data, thus enabling unobtrusive robust healthcare workflows. We evaluate our work based on a real-world case study and show that the robustness of unobtrusive healthcare workflows can be increased to an absolute value of up to 91% (compared to only 12% with a classical workflow system). This is a major breakthrough that paves the way towards future IT-enabled healthcare systems.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1983939972",
    "type": "article"
  },
  {
    "title": "Probabilistic models for concurrent chatting activity recognition",
    "doi": "https://doi.org/10.1145/1889681.1889685",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Jane Yung-jen Hsu; Chia-Chun Lian; Wan-rong Jih",
    "corresponding_authors": "",
    "abstract": "Recognition of chatting activities in social interactions is useful for constructing human social networks. However, the existence of multiple people involved in multiple dialogues presents special challenges. To model the conversational dynamics of concurrent chatting behaviors, this article advocates Factorial Conditional Random Fields (FCRFs) as a model to accommodate co-temporal relationships among multiple activity states. In addition, to avoid the use of inefficient Loopy Belief Propagation (LBP) algorithm, we propose using Iterative Classification Algorithm (ICA) as the inference method for FCRFs. We designed experiments to compare our FCRFs model with two dynamic probabilistic models, Parallel Condition Random Fields (PCRFs) and Hidden Markov Models (HMMs), in learning and decoding based on auditory data. The experimental results show that FCRFs outperform PCRFs and HMMs-like models. We also discover that FCRFs using the ICA inference approach not only improves the recognition accuracy but also takes significantly less time than the LBP inference method.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1999888025",
    "type": "article"
  },
  {
    "title": "Analysis of friendship network and its role in explaining obesity",
    "doi": "https://doi.org/10.1145/2483669.2483689",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Achla Marathe; Zhengzheng Pan; Andrea Apolloni",
    "corresponding_authors": "",
    "abstract": "We employ Add Health data to show that friendship networks, constructed from mutual friendship nominations, are important in building weight perception, setting weight goals, and measuring social marginalization among adolescents and young adults. We study the relationship between individuals' perceived weight status, actual weight status, weight status relative to friends' weight status, and weight goals. This analysis helps us understand how individual weight perceptions might be formed, what these perceptions do to the weight goals, and how friends' relative weight affects weight perception and weight goals. Combining this information with individuals' friendship network helps determine the influence of social relationships on weight-related variables. Multinomial logistic regression results indicate that relative status is indeed a significant predictor of perceived status, and perceived status is a significant predictor of weight goals. We also address the issue of causality between actual weight status and social marginalization (as measured by the number of friends) and show that obesity precedes social marginalization in time rather than the other way around. This lends credence to the hypothesis that obesity leads to social marginalization not vice versa. Attributes of the friendship network can provide new insights into effective interventions for combating obesity since adolescent friendships provide an important social context for weight-related behaviors.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2025439287",
    "type": "article"
  },
  {
    "title": "Distributional phrasal paraphrase generation for statistical machine translation",
    "doi": "https://doi.org/10.1145/2483669.2483672",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Yuval Marton",
    "corresponding_authors": "Yuval Marton",
    "abstract": "Paraphrase generation has been shown useful for various natural language processing tasks, including statistical machine translation. A commonly used method for paraphrase generation is pivoting [Callison-Burch et al. 2006], which benefits from linguistic knowledge implicit in the sentence alignment of parallel texts, but has limited applicability due to its reliance on parallel texts. Distributional paraphrasing [Marton et al. 2009a] has wider applicability, is more language-independent, but doesn't benefit from any linguistic knowledge. Nevertheless, we show that using distributional paraphrasing can yield greater gains in translation tasks. We report method improvements leading to higher gains than previously published, of almost 2 B leu points, and provide implementation details, complexity analysis, and further insight into this method.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2064514235",
    "type": "article"
  },
  {
    "title": "Automatic Extraction of Behavioral Patterns for Elderly Mobility and Daily Routine Analysis",
    "doi": "https://doi.org/10.1145/3178116",
    "publication_date": "2018-06-01",
    "publication_year": 2018,
    "authors": "Chen Li; William K. Cheung; Jiming Liu; Joseph Kee‐Yin Ng",
    "corresponding_authors": "",
    "abstract": "The elderly living in smart homes can have their daily movement recorded and analyzed. As different elders can have their own living habits, a methodology that can automatically identify their daily activities and discover their daily routines will be useful for better elderly care and support. In this article, we focus on automatic detection of behavioral patterns from the trajectory data of an individual for activity identification as well as daily routine discovery. The underlying challenges lie in the need to consider longer-range dependency of the sensor triggering events and spatiotemporal variations of the behavioral patterns exhibited by humans. We propose to represent the trajectory data using a behavior-aware flow graph that is a probabilistic finite state automaton with its nodes and edges attributed with some local behavior-aware features. We identify the underlying subflows as the behavioral patterns using the kernel k -means algorithm. Given the identified activities, we propose a novel nominal matrix factorization method under a Bayesian framework with Lasso to extract highly interpretable daily routines. For empirical evaluation, the proposed methodology has been compared with a number of existing methods based on both synthetic and publicly available real smart home datasets with promising results obtained. We also discuss how the proposed unsupervised methodology can be used to support exploratory behavior analysis for elderly care.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2807500178",
    "type": "article"
  },
  {
    "title": "BayesPiles",
    "doi": "https://doi.org/10.1145/3230623",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Athanasios Vogogias; Jessie Kennedy; Daniel Archambault; Benjamin Bach; V. Anne Smith; Hannah Currant",
    "corresponding_authors": "",
    "abstract": "We address the problem of exploring, combining, and comparing large collections of scored, directed networks for understanding inferred Bayesian networks used in biology. In this field, heuristic algorithms explore the space of possible network solutions, sampling this space based on algorithm parameters and a network score that encodes the statistical fit to the data. The goal of the analyst is to guide the heuristic search and decide how to determine a final consensus network structure, usually by selecting the top-scoring network or constructing the consensus network from a collection of high-scoring networks. BayesPiles, our visualisation tool, helps with understanding the structure of the solution space and supporting the construction of a final consensus network that is representative of the underlying dataset. BayesPiles builds upon and extends MultiPiles to meet our domain requirements. We developed BayesPiles in conjunction with computational biologists who have used this tool on datasets used in their research. The biologists found our solution provides them with new insights and helps them achieve results that are representative of the underlying data.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2808255162",
    "type": "article"
  },
  {
    "title": "Understanding Event Organization at Scale in Event-Based Social Networks",
    "doi": "https://doi.org/10.1145/3243227",
    "publication_date": "2019-01-12",
    "publication_year": 2019,
    "authors": "Jason Shuo Zhang; Qin Lv",
    "corresponding_authors": "",
    "abstract": "Understanding real-world event participation behavior has been a subject of active research and can offer valuable insights for event-related recommendation and advertisement. The emergence of event-based social networks (EBSNs), which attracts online users to host/attend offline events, has enabled exciting new research in this domain. However, most existing works focus on understanding or predicting individual users’ event participation behavior or recommending events to individual users. Few studies have addressed the problem of event popularity from the event organizer’s point of view. In this work, we study the latent factors for determining event popularity using large-scale datasets collected from the popular Meetup.com EBSN in five major cities around the world. We analyze and model four contextual factors: spatial factor using location convenience, quality, popularity density, and competitiveness; group factor using group member entropy and loyalty; temporal factor using temporal preference and weekly event patterns; and semantic factor using readability, sentiment, part of speech, and text novelty. In addition, we have developed a group-based social influence propagation network to model group-specific influences on events. By combining the COntextual features and Social Influence NEtwork, our integrated prediction framework COSINE can capture the diverse influential factors of event participation and can be used by event organizers to predict/improve the popularity of their events. Detailed evaluations demonstrate that our COSINE framework achieves high accuracy for event popularity prediction in all five cities with diverse cultures and user event behaviors.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2910606926",
    "type": "article"
  },
  {
    "title": "Exploiting the Value of the Center-dark Channel Prior for Salient Object Detection",
    "doi": "https://doi.org/10.1145/3319368",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Chunbiao Zhu; Wenhao Zhang; Thomas H. Li; Shan Liu; Ge Li",
    "corresponding_authors": "",
    "abstract": "Saliency detection aims to detect the most attractive objects in images and is widely used as a foundation for various applications. In this article, we propose a novel salient object detection algorithm for RGB-D images using center-dark channel priors. First, we generate an initial saliency map based on a color saliency map and a depth saliency map of a given RGB-D image. Then, we generate a center-dark channel map based on center saliency and dark channel priors. Finally, we fuse the initial saliency map with the center dark channel map to generate the final saliency map. Extensive evaluations over four benchmark datasets demonstrate that our proposed method performs favorably against most of the state-of-the-art approaches. Besides, we further discuss the application of the proposed algorithm in small target detection and demonstrate the universal value of center-dark channel priors in the field of object detection.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2963825875",
    "type": "article"
  },
  {
    "title": "<i>XLearn</i>",
    "doi": "https://doi.org/10.1145/3368272",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Juan Ye; Simon Dobson; Franco Zambonelli",
    "corresponding_authors": "",
    "abstract": "Sensor-driven systems often need to map sensed data into meaningfully labelled activities to classify the phenomena being observed. A motivating and challenging example comes from human activity recognition in which smart home and other datasets are used to classify human activities to support applications such as ambient assisted living, health monitoring, and behavioural intervention. Building a robust and meaningful classifier needs annotated ground truth, labelled with what activities are actually being observed—and acquiring high-quality, detailed, continuous annotations remains a challenging, time-consuming, and error-prone task, despite considerable attention in the literature. In this article, we use knowledge-driven ensemble learning to develop a technique that can combine classifiers built from individually labelled datasets, even when the labels are sparse and heterogeneous. The technique both relieves individual users of the burden of annotation and allows activities to be learned individually and then transferred to a general classifier. We evaluate our approach using four third-party, real-world smart home datasets and show that it enhances activity recognition accuracies even when given only a very small amount of training data.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3000482929",
    "type": "article"
  },
  {
    "title": "Unified Generative Adversarial Networks for Multiple-Choice Oriented Machine Comprehension",
    "doi": "https://doi.org/10.1145/3372120",
    "publication_date": "2020-04-03",
    "publication_year": 2020,
    "authors": "Zhuang Liu; Keli Xiao; Bo Jin; Kaiyu Huang; Degen Huang; Zhang Yun-xia",
    "corresponding_authors": "",
    "abstract": "In this article, we address the multiple-choice machine comprehension (MC) problem in natural language processing. Existing approaches for MC are usually designed for general cases; however, we specially develop a novel method for solving the multiple-choice MC problem. We take the inspiration generative adversarial networks (GANs) and first propose an adversarial framework for multiple-choice oriented MC, named McGAN . Specifically, our approach is designed as a GAN-based method that unifies both generative and discriminative MC models. Working together, the generative model focuses on predicting relevant answer given a passage (text) and a question; the discriminative model focuses on predicting their relevancy given an answer-passage-question set. Based on the competition via adversarial training in a minimize-maximize game, the proposed method takes advantages from both models. To evaluate the performance, we test our McGAN model on three well-known datasets for multiple-choice MC. Our results show that McGAN can achieve a significant increase in accuracy compared to existing models based on all three datasets, and it consistently outperforms all tested baselines, including state-of-the-art techniques.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3029462071",
    "type": "article"
  },
  {
    "title": "Fast Distributed <i>k</i> NN Graph Construction Using Auto-tuned Locality-sensitive Hashing",
    "doi": "https://doi.org/10.1145/3408889",
    "publication_date": "2020-10-12",
    "publication_year": 2020,
    "authors": "Carlos Eiras‐Franco; David Martínez‐Rego; Leslie Kanthan; César Piñeiro; Antonio Bahamonde; Bertha Guijarro‐Berdiñas; Amparo Alonso‐Betanzos",
    "corresponding_authors": "",
    "abstract": "The k -nearest-neighbors ( k NN) graph is a popular and powerful data structure that is used in various areas of Data Science, but the high computational cost of obtaining it hinders its use on large datasets. Approximate solutions have been described in the literature using diverse techniques, among which Locality-sensitive Hashing (LSH) is a promising alternative that still has unsolved problems. We present Variable Resolution Locality-sensitive Hashing, an algorithm that addresses these problems to obtain an approximate k NN graph at a significantly reduced computational cost. Its usability is greatly enhanced by its capacity to automatically find adequate hyperparameter values, a common hindrance to LSH-based methods. Moreover, we provide an implementation in the distributed computing framework Apache Spark that takes advantage of the structure of the algorithm to efficiently distribute the computational load across multiple machines, enabling practitioners to apply this solution to very large datasets. Experimental results show that our method offers significant improvements over the state-of-the-art in the field and shows very good scalability as more machines are added to the computation.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3091805362",
    "type": "article"
  },
  {
    "title": "An online system for multiple interacting targets tracking",
    "doi": "https://doi.org/10.1145/2414425.2414443",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Xuan Song; Huijing Zhao; Jinshi Cui; Xiaowei Shao; Ryosuke Shibasaki; Hongbin Zha",
    "corresponding_authors": "",
    "abstract": "Multitarget tracking becomes significantly more challenging when the targets are in close proximity or frequently interact with each other. This article presents a promising online system to deal with these problems. The novelty of this system is that laser and vision are integrated with tracking and online learning to complement each other in one framework: when the targets do not interact with each other, the laser-based independent trackers are employed and the visual information is extracted simultaneously to train some classifiers online for “possible interacting targets”. When the targets are in close proximity, the classifiers learned online are used alongside visual information to assist in tracking. Therefore, this mode of cooperation not only deals with various tough problems encountered in tracking, but also ensures that the entire process can be completely online and automatic. Experimental results demonstrate that laser and vision fully display their respective advantages in our system, and it is easy for us to obtain a good trade-off between tracking accuracy and the time-cost factor.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2060536789",
    "type": "article"
  },
  {
    "title": "Learning image-to-class distance metric for image classification",
    "doi": "https://doi.org/10.1145/2438653.2438669",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Zhengxiang Wang; Yiqun Hu; Liang-Tien Chia",
    "corresponding_authors": "",
    "abstract": "Image-To-Class (I2C) distance is a novel distance used for image classification and has successfully handled datasets with large intra-class variances. However, it uses Euclidean distance for measuring the distance between local features in different classes, which may not be the optimal distance metric in real image classification problems. In this article, we propose a distance metric learning method to improve the performance of I2C distance by learning per-class Mahalanobis metrics in a large margin framework. Our I2C distance is adaptive to different classes by combining with the learned metric for each class. These multiple per-class metrics are learned simultaneously by forming a convex optimization problem with the constraints that the I2C distance from each training image to its belonging class should be less than the distances to other classes by a large margin. A subgradient descent method is applied to efficiently solve this optimization problem. For efficiency and scalability to large-scale problems, we also show how to simplify the method to learn a diagonal matrix for each class. We show in experiments that our learned Mahalanobis I2C distance can significantly outperform the original Euclidean I2C distance as well as other distance metric learning methods in several prevalent image datasets, and our simplified diagonal matrices can preserve the performance but significantly speed up the metric learning procedure for large-scale datasets. We also show in experiment that our method is able to correct the class imbalance problem, which usually leads the NN-based methods toward classes containing more training images.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2104376766",
    "type": "article"
  },
  {
    "title": "Causal Discovery on Discrete Data with Extensions to Mixture Model",
    "doi": "https://doi.org/10.1145/2700477",
    "publication_date": "2015-12-03",
    "publication_year": 2015,
    "authors": "Furui Liu; Laiwan Chan",
    "corresponding_authors": "",
    "abstract": "In this article, we deal with the causal discovery problem on discrete data. First, we present a causal discovery method for traditional additive noise models that identifies the causal direction by analyzing the supports of the conditional distributions. Then, we present a causal mixture model to address the problem that the function transforming cause to effect varies across the observations. We propose a novel method called Support Analysis (SA) for causal discovery with the mixture model. Experiments using synthetic and real data are presented to demonstrate the performance of our proposed algorithm.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2271150192",
    "type": "article"
  },
  {
    "title": "Querying Recurrent Convoys over Trajectory Data",
    "doi": "https://doi.org/10.1145/3400730",
    "publication_date": "2020-08-03",
    "publication_year": 2020,
    "authors": "Munkh-Erdene Yadamjav; Zhifeng Bao; Baihua Zheng; Farhana Choudhury; Hanan Samet",
    "corresponding_authors": "",
    "abstract": "Moving objects equipped with location-positioning devices continuously generate a large amount of spatio-temporal trajectory data. An interesting finding over a trajectory stream is a group of objects that are travelling together for a certain period of time. We observe that existing studies on mining co-moving objects do not consider an important correlation between co-moving objects, which is the reoccurrence of the co-moving pattern. In this study, we propose the problem of finding recurrent co-moving patterns from streaming trajectories, enabling us to discover recent co-moving patterns that are repeated within a given time period. Experimental results on real-life trajectory data verify the efficiency and effectiveness of our method.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3081481768",
    "type": "article"
  },
  {
    "title": "Contextual Anomaly Detection in Solder Paste Inspection with Multi-Task Learning",
    "doi": "https://doi.org/10.1145/3383261",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Zimu Zheng; Jie Pu; Linghui Liu; Dan Wang; Xiangming Mei; Sen Zhang; Quanyu Dai",
    "corresponding_authors": "",
    "abstract": "In this article, we study solder paste inspection (SPI), an important stage that is used in the semiconductor manufacturing industry, where abnormal boards should be detected. A highly accurate SPI can substantially reduce human expert involvement, as well as reduce the waste in disposing of the boards in good condition. A key difference today is that because of increasing demand in board customization, the number of board types increases substantially and quantity of the boards produced in each type decreases. Thus, the previous approaches where a fine-tuned model is developed for each board type are no longer viable. Intrinsically, our problem is an anomaly detection problem. A major specialty in today’s SPI is that the target tasks for prediction cannot be fully pre-determined due to context changes during the solder paste printing stage. Our experiences show that a conventional approach to first define a set of tasks and train these tasks offline will lead to low accuracy. Here, we propose a novel multi-task approach, where the performance of all target tasks is ensured simultaneously. We note that the SPI process is streamlined and automatic, allowing the SPI time for only a few seconds. We propose a fast clustering algorithm that reuses existing models to avoid retraining and fine tune in the inference phase. We evaluate our approach using 3-month data collected from production lines. We show that we can reduce 81.28% of false alarms. This can translate to annual savings of $11.3 million.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3087327842",
    "type": "article"
  },
  {
    "title": "Understanding the Long-Term Evolution of Electric Taxi Networks",
    "doi": "https://doi.org/10.1145/3393671",
    "publication_date": "2020-05-28",
    "publication_year": 2020,
    "authors": "Guang Wang; Fan Zhang; Huijun Sun; Yang Wang; Desheng Zhang",
    "corresponding_authors": "",
    "abstract": "Due to the ever-growing concerns over air pollution and energy security, more and more cities have started to replace their conventional taxi fleets with electric ones. Even though environmentally friendly, the rapid promotion of electric taxis raises problems to both taxi drivers and governments, e.g., prolonged waiting/charging time, unbalanced utilization of charging infrastructures, and inadequate taxi supply due to the long charging time. In this article, we conduct the first longitudinal measurement study to understand the long-term evolution of mobility and charging patterns by utilizing 5-year data from one of the largest electric taxi networks in the world, i.e., the Shenzhen electric taxi network in China. In particular, (1) we first perform an electric taxi contextualization about their operation and charging activities; (2) then we design a generic charging event extraction algorithm based on GPS data and charging station data, and (3) based on the contextualization and extracted charging activities, we perform a comprehensive measurement study called ePat to explore the evolution of the electric taxi network from the mobility and charging perspectives. Our ePat is based on 4.8 TB taxi GPS data, 240 GB taxi transaction data, and metadata from 117 charging stations, during an evolution process from 427 electric taxis in 2013 to 13,178 in 2018. Moreover, ePat also explores the impacts of various contexts and benefits during the evolution process. Our ePat as a comprehensive measurement of the electric taxi network mobility and charging evolution has the potential to advance the understanding of the evolution patterns of electric taxi networks and pave the way for analyzing future shared autonomous vehicles.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3112327909",
    "type": "article"
  },
  {
    "title": "Feature Grouping–based Trajectory Outlier Detection over Distributed Streams",
    "doi": "https://doi.org/10.1145/3444753",
    "publication_date": "2021-02-04",
    "publication_year": 2021,
    "authors": "Jiali Mao; Jiaye Liu; Cheqing Jin; Aoying Zhou",
    "corresponding_authors": "",
    "abstract": "Owing to a wide variety of deployment of GPS -enabled devices, tremendous amounts of trajectories have been generated in distributed stream manner. It opens up new opportunities to track and analyze the moving behaviors of the entities. In this work, we focus on the issue of outlier detection over distributed trajectory streams, where the outliers refer to a few entities whose motion behaviors are significantly different from their local neighbors. In view of skewed distribution property and evolving nature of trajectory data, and on-the-fly detection requirement over distributed streams, we first design a high-efficiency outlier detection solution. It consists of identifying abnormal trajectory fragment and exceptional fragment cluster at the remote sites and then detecting abnormal evolving object at the coordinator site. Further, given that outlier detection accuracy would be damaged due to using inappropriate proximity thresholds or a few trajectory data not having sufficient neighbors at the remote sites, we extract proximity thresholds of different regions and spatial context relationship of each region from historical data to improve the precision. Built upon this is an improved version consisting of off-line modeling phase and on-line detection phase. During the on-line phase, the proximity thresholds that are derived from historical trajectories during the off-line phase are leveraged to assist in detecting abnormal trajectory fragments and exceptional fragment clusters at the remote sites. Additionally, at the coordinator site, the detection results of some remote sites can be refined by incorporating those of other remote sites with neighborhood relationship. Extensive experimental results on real data demonstrate that our proposed methods own high detection validity, less communication cost and linear scalability for online identifying outliers over distributed trajectory streams.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3126241515",
    "type": "article"
  },
  {
    "title": "Vector-Quantization-Based Topic Modeling",
    "doi": "https://doi.org/10.1145/3450946",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Amulya Gupta; Zhu Zhang",
    "corresponding_authors": "",
    "abstract": "With the purpose of learning and utilizing explicit and dense topic embeddings, we propose three variations of novel vector-quantization-based topic models (VQ-TMs): (1) Hard VQ-TM, (2) Soft VQ-TM, and (3) Multi-View Soft VQ-TM. The model family capitalize on vector quantization techniques, embedded input documents, and viewing words as mixtures of topics. Guided by a comprehensive set of evaluation metrics, we conduct systematic quantitative and qualitative empirical studies, and demonstrate the superior performance of VQ-TMs compared to important baseline models. Through a unique case study on code generation from natural language descriptions, we further illustrate the power of VQ-TMs in downstream tasks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3158661162",
    "type": "article"
  },
  {
    "title": "Getting Closer to the Essence of Music",
    "doi": "https://doi.org/10.1145/2899004",
    "publication_date": "2016-10-03",
    "publication_year": 2016,
    "authors": "Gerhard Widmer",
    "corresponding_authors": "Gerhard Widmer",
    "abstract": "This text offers a personal and very subjective view on the current situation of Music Information Research (MIR). Motivated by the desire to build systems with a somewhat deeper understanding of music than the ones we currently have, I try to sketch a number of challenges for the next decade of MIR research, grouped around six simple truths about music that are probably generally agreed on but often ignored in everyday research.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4298053324",
    "type": "article"
  },
  {
    "title": "Shifting Capsule Networks from the Cloud to the Deep Edge",
    "doi": "https://doi.org/10.1145/3544562",
    "publication_date": "2022-06-17",
    "publication_year": 2022,
    "authors": "Miguel Costa; Diogo Costa; Tiago Gomes; Sandro Pinto",
    "corresponding_authors": "",
    "abstract": "Capsule networks (CapsNets) are an emerging trend in image processing. In contrast to a convolutional neural network, CapsNets are not vulnerable to object deformation, as the relative spatial information of the objects is preserved across the network. However, their complexity is mainly related to the capsule structure and the dynamic routing mechanism, which makes it almost unreasonable to deploy a CapsNet, in its original form, in a resource-constrained device powered by a small microcontroller (MCU). In an era where intelligence is rapidly shifting from the cloud to the edge, this high complexity imposes serious challenges to the adoption of CapsNets at the very edge. To tackle this issue, we present an API for the execution of quantized CapsNets in Arm Cortex-M and RISC-V MCUs. Our software kernels extend the Arm CMSIS-NN and RISC-V PULP-NN to support capsule operations with 8-bit integers as operands. Along with it, we propose a framework to perform post-training quantization of a CapsNet. Results show a reduction in memory footprint of almost 75%, with accuracy loss ranging from 0.07% to 0.18%. In terms of throughput, our Arm Cortex-M API enables the execution of primary capsule and capsule layers with medium-sized kernels in just 119.94 and 90.60 ms, respectively (STM32H755ZIT6U, Cortex-M7 @ 480 MHz). For the GAP-8 SoC (RISC-V RV32IMCXpulp @ 170 MHz), the latency drops to 7.02 and 38.03 ms, respectively.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3202754595",
    "type": "article"
  },
  {
    "title": "Self-Adaptive Feature Transformation Networks for Object Detection in low luminance Images",
    "doi": "https://doi.org/10.1145/3480973",
    "publication_date": "2022-01-10",
    "publication_year": 2022,
    "authors": "Shih‐Chia Huang; Quoc-Viet Hoang; Da-Wei Jaw",
    "corresponding_authors": "",
    "abstract": "Despite the recent improvement of object detection techniques, many of them fail to detect objects in low-luminance images. The blurry and dimmed nature of low-luminance images results in the extraction of vague features and failure to detect objects. In addition, many existing object detection methods are based on models trained on both sufficient- and low-luminance images, which also negatively affect the feature extraction process and detection results. In this article, we propose a framework called Self-adaptive Feature Transformation Network (SFT-Net) to effectively detect objects in low-luminance conditions. The proposed SFT-Net consists of the following three modules: (1) feature transformation module, (2) self-adaptive module, and (3) object detection module. The purpose of the feature transformation module is to enhance the extracted feature through unsupervisely learning a feature domain projection procedure. The self-adaptive module is utilized as a probabilistic module producing appropriate features either from the transformed or the original features to further boost the performance and generalization ability of the proposed framework. Finally, the object detection module is designed to accurately detect objects in both low- and sufficient- luminance images by using the appropriate features produced by the self-adaptive module. The experimental results demonstrate that the proposed SFT-Net framework significantly outperforms the state-of-the-art object detection techniques, achieving an average precision (AP) of up to 6.35 and 11.89 higher on the sufficient- and low- luminance domain, respectively.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4205317838",
    "type": "article"
  },
  {
    "title": "Federated Learning for Personalized Humor Recognition",
    "doi": "https://doi.org/10.1145/3511710",
    "publication_date": "2022-05-03",
    "publication_year": 2022,
    "authors": "Xu Guo; Han Yu; Boyang Li; Hao Wang; Pengwei Xing; Siwei Feng; Zaiqing Nie; Chunyan Miao",
    "corresponding_authors": "",
    "abstract": "Computational understanding of humor is an important topic under creative language understanding and modeling. It can play a key role in complex human-AI interactions. The challenge here is that human perception of humorous content is highly subjective. The same joke may receive different funniness ratings from different readers. This makes it highly challenging for humor recognition models to achieve personalization in practical scenarios. Existing approaches are generally designed based on the assumption that users have a consensus on whether a given text is humorous or not. Thus, they cannot handle diverse humor preferences well. In this article, we propose the FedHumor approach for the recognition of humorous content in a personalized manner through Federated Learning (FL). Extending a pre-trained language model, FedHumor guides the fine-tuning process by considering diverse distributions of humor preferences from individuals. It incorporates a diversity adaptation strategy into the FL paradigm to train a personalized humor recognition model. To the best of our knowledge, FedHumor is the first text-based personalized humor recognition model through federated learning. Extensive experiments demonstrate the advantage of FedHumor in recognizing humorous texts compared to nine state-of-the-art humor recognition approaches with superior capability for handling the diversity in humor labels produced by users with diverse preferences.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4225418320",
    "type": "article"
  },
  {
    "title": "Performance Evaluation of Aggregation-based Group Recommender Systems for Ephemeral Groups",
    "doi": "https://doi.org/10.1145/3542804",
    "publication_date": "2022-06-03",
    "publication_year": 2022,
    "authors": "Edgar Ceh-Varela; Huiping Cao; Hady W. Lauw",
    "corresponding_authors": "",
    "abstract": "Recommender Systems ( RecSys ) provide suggestions in many decision-making processes. Given that groups of people can perform many real-world activities (e.g., a group of people attending a conference looking for a place to dine), the need for recommendations for groups has increased. A wide range of Group Recommender Systems ( GRecSys ) has been developed to aggregate individual preferences to group preferences. We analyze 175 studies related to GRecSys . Previous works evaluate their systems using different types of groups (sizes and cohesiveness), and most of such works focus on testing their systems using only one type of item, called Experience Goods (EG). As a consequence, it is hard to get consistent conclusions about the performance of GRecSys . We present the aggregation strategies and aggregation functions that GRecSys commonly use to aggregate group members’ preferences. This study experimentally compares the performance (i.e., accuracy, ranking quality, and usefulness) using four metrics (Hit Ratio, Normalize Discounted Cumulative Gain, Diversity, and Coverage) of eight representative RecSys for group recommendations on ephemeral groups. Moreover, we use two different aggregation strategies, 10 different aggregation functions, and two different types of items on two types of datasets (EG and Search Goods (SG)) containing real-life datasets. The results show that the evaluation of GRecSys needs to use both EG and SG types of data, because the different characteristics of datasets lead to different performance. GRecSys using Singular Value Decomposition or Neural Collaborative Filtering methods work better than others. It is observed that the Average aggregation function is the one that produces better results.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4281685783",
    "type": "article"
  },
  {
    "title": "How Is the Stroke? Inferring Shot Influence in Badminton Matches via Long Short-term Dependencies",
    "doi": "https://doi.org/10.1145/3551391",
    "publication_date": "2022-09-23",
    "publication_year": 2022,
    "authors": "Wei‐Yao Wang; Teng-Fong Chan; Wen-Chih Peng; Hui-Kuo Yang; Chih-Chuan Wang; Yao-Chung Fan",
    "corresponding_authors": "",
    "abstract": "Identifying significant shots in a rally is important for evaluating players’ performance in badminton matches. While there are several studies that have quantified player performance in other sports, analyzing badminton data has remained untouched. In this article, we introduce a badminton language to fully describe the process of the shot, and we propose a deep-learning model composed of a novel short-term extractor and a long-term encoder for capturing a shot-by-shot sequence in a badminton rally by framing the problem as predicting a rally result. Our model incorporates an attention mechanism to enable the transparency between the action sequence and the rally result, which is essential for badminton experts to gain interpretable predictions. Experimental evaluation based on a real-world dataset demonstrates that our proposed model outperforms the strong baselines. We also conducted case studies to show the ability to enhance players’ decision-making confidence and to provide advanced insights for coaching, which benefits the badminton analysis community and bridges the gap between the field of badminton and computer science.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4297009736",
    "type": "article"
  },
  {
    "title": "COMET: Convolutional Dimension Interaction for Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3588576",
    "publication_date": "2023-03-23",
    "publication_year": 2023,
    "authors": "Zhuoyi Lin; Lei Feng; Xingzhi Guo; Yu Zhang; Rui Yin; Chee Keong Kwoh; Chi Xu",
    "corresponding_authors": "",
    "abstract": "Representation learning-based recommendation models play a dominant role among recommendation techniques. However, most of the existing methods assume both historical interactions and embedding dimensions are independent of each other, and thus regrettably ignore the high-order interaction information among historical interactions and embedding dimensions. In this article, we propose a novel representation learning-based model called COMET ( CO nvolutional di M E nsion in T eraction), which simultaneously models the high-order interaction patterns among historical interactions and embedding dimensions. To be specific, COMET stacks the embeddings of historical interactions horizontally at first, which results in two “embedding maps”. In this way, internal interactions and dimensional interactions can be exploited by convolutional neural networks (CNN) with kernels of different sizes simultaneously. A fully connected multi-layer perceptron (MLP) is then applied to obtain two interaction vectors. Lastly, the representations of users and items are enriched by the learnt interaction vectors, which can further be used to produce the final prediction. Extensive experiments and ablation studies on various public implicit feedback datasets clearly demonstrate the effectiveness and rationality of our proposed method.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4287704098",
    "type": "article"
  },
  {
    "title": "Fully Linear Graph Convolutional Networks for Semi-Supervised and Unsupervised Classification",
    "doi": "https://doi.org/10.1145/3579828",
    "publication_date": "2023-01-09",
    "publication_year": 2023,
    "authors": "Yaoming Cai; Zijia Zhang; Pedram Ghamisi; Zhihua Cai; Xiaobo Liu; Yao Ding",
    "corresponding_authors": "",
    "abstract": "This article presents FLGC, a simple yet effective fully linear graph convolutional network for semi-supervised and unsupervised learning. Instead of using gradient descent, we train FLGC based on computing a global optimal closed-form solution with a decoupled procedure, resulting in a generalized linear framework and making it easier to implement, train, and apply. We show that (1) FLGC is powerful to deal with both graph-structured data and regular data, (2) training graph convolutional models with closed-form solutions improve computational efficiency without degrading performance, and (3) FLGC acts as a natural generalization of classic linear models in the non-Euclidean domain (e.g., ridge regression and subspace clustering). Furthermore, we implement a semi-supervised FLGC and an unsupervised FLGC by introducing an initial residual strategy, enabling FLGC to aggregate long-range neighborhoods and alleviate over-smoothing. We compare our semi-supervised and unsupervised FLGCs against many state-of-the-art methods on a variety of classification and clustering benchmarks, demonstrating that the proposed FLGC models consistently outperform previous methods in terms of accuracy, robustness, and learning efficiency. The core code of our FLGC is released at https://github.com/AngryCai/FLGC .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4313889424",
    "type": "article"
  },
  {
    "title": "A Joint Entity and Relation Extraction Model based on Efficient Sampling and Explicit Interaction",
    "doi": "https://doi.org/10.1145/3604811",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Qibin Li; Nianmin Yao; Nai Zhou; Jian Zhao; Yanan Zhang",
    "corresponding_authors": "",
    "abstract": "Joint entity and relation extraction (RE) construct a framework for unifying entity recognition and relationship extraction, and the approach can exploit the dependencies between the two tasks to improve the performance of the task. However, the existing tasks still have the following two problems. First, when the model extracts entity information, the boundary is blurred. Secondly, there are mostly implicit interactions between modules, that is, the interactive information is hidden inside the model, and the implicit interactions are often insufficient in the degree of interaction and lack of interpretability. To this end, this study proposes a joint entity and relation extraction model (ESEI) based on E fficient S ampling and E xplicit I nteraction. We innovatively divide negative samples into sentences based on whether they overlap with positive samples, which improves the model’s ability to extract entity word boundary information by controlling the sampling ratio. In order to increase the explicit interaction ability between the models, we introduce a heterogeneous graph neural network (GNN) into the model, which will serve as a bridge linking the entity recognition module and the relation extraction module, and enhance the interaction between the modules through information transfer. Our method substantially improves the model’s discriminative power on entity extraction tasks and enhances the interaction between relation extraction tasks and entity extraction tasks. Experiments show that the method is effective, we validate our method on four datasets, and for joint entity and relation extraction, our model improves the F1 score on multiple datasets.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4381050529",
    "type": "article"
  },
  {
    "title": "Enabling Graph Neural Networks for Semi-Supervised Risk Prediction in Online Credit Loan Services",
    "doi": "https://doi.org/10.1145/3623401",
    "publication_date": "2023-09-21",
    "publication_year": 2023,
    "authors": "Hao Tang; Cheng Wang; Jianguo Zheng; Changjun Jiang",
    "corresponding_authors": "",
    "abstract": "Graph neural networks (GNNs) are playing exciting roles in the application scenarios where features are hidden in information associations. Fraud prediction of online credit loan services (OCLSs) is such a typical scenario. But it has another rather critical challenge, i.e., the scarcity of data labels. Fortunately, GNNs can also cope with this problem due to their good ability of semi-supervised learning by mining structure and feature information within graphs. Nevertheless, the gain of internal information is often too limited to help GNNs handle the extreme deficiency of labels with high performance beyond the basic requirement of fraud prediction in OCLSs. Therefore, adding labels from the experts, such as manually adding labels through rules, has become a logical practice. However, the existing rule engines for OCLSs have the confliction problem among continuously accumulated rules. To address this issue, we propose a Snorkel-based Semi-Supervised GNN (S3GNN). Under S3GNN, we specially design an upgraded version of the rule engines, called Graph-Oriented Snorkel (GOS), a graph-specific extension of Snorkel, a widely used weakly supervised learning framework, to design rules by subject matter experts (SMEs) and resolve confliction. In particular, in the graph of an anti-fraud scenario, each node pair may have multiple different types of edges, so we propose the Multiple Edge-Types Based Attention mechanism. In general, for the heterogeneous information and multiple relations in the graph, we first obtain the embedding of applicant nodes by aggregating the representation of attribute nodes, and then use the attention mechanism to aggregate neighbor nodes on multiple meta-paths to get ultimate applicant node embedding. We conduct experiments over the real-life data of a large financial platform. The results demonstrate that S3GNN can outperform the state-of-the-art methods, including the method of pilot platform.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386928422",
    "type": "article"
  },
  {
    "title": "EMG-Based Automatic Gesture Recognition Using Lipschitz-Regularized Neural Networks",
    "doi": "https://doi.org/10.1145/3635159",
    "publication_date": "2023-12-08",
    "publication_year": 2023,
    "authors": "Ana Neacşu; Jean‐Christophe Pesquet; Corneliu Burileanu",
    "corresponding_authors": "",
    "abstract": "This article introduces a novel approach for building a robust Automatic Gesture Recognition system based on Surface Electromyographic (sEMG) signals, acquired at the forearm level. Our main contribution is to propose new constrained learning strategies that ensure robustness against adversarial perturbations by controlling the Lipschitz constant of the classifier. We focus on nonnegative neural networks for which accurate Lipschitz bounds can be derived, and we propose different spectral norm constraints offering robustness guarantees from a theoretical viewpoint. Experimental results on four publicly available datasets highlight that a good tradeoff in terms of accuracy and performance is achieved. We then demonstrate the robustness of our models, compared with standard trained classifiers in four scenarios, considering both white-box and black-box attacks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4389487309",
    "type": "article"
  },
  {
    "title": "Integrated Image-Text Augmentation for Few-Shot Learning in Vision-Language Models",
    "doi": "https://doi.org/10.1145/3712700",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Ran Wang; Hua Zuo; Zhen Fang; Jie Lü",
    "corresponding_authors": "",
    "abstract": "Vision-language models, such as the Contrastive Language-Image Pre-Training (CLIP) model, have achieved significant success in image classification tasks. CLIP demonstrates high expressive power in few-shot learning scenarios due to its pairing of text and image encoders. However, CLIP still faces overfitting when trained with a limited number of samples. To mitigate this, image augmentation techniques have been proposed in few-shot learning tasks to prevent overfitting by enriching the dataset. Existing image augmentation methods, primarily designed for single-modal image models, focus solely on transformations within the image itself. However, for CLIP, merely increasing visual variety without considering textual content can reduce generalization ability and may even mislead the model. To address this issue, we introduce a novel image augmentation approach—Integrated Image-Text Augmentation (ITA)—for CLIP model in few-shot learning tasks. This method generates new and diverse augmented images to increase the diversity of the training data and reduce overfitting. Additionally, ITA establishes an alignment between the augmented images and their textual descriptions. Through this alignment, the model not only learns to recognize visual elements in the images but also understands the semantic connections between these elements and the text descriptions. This dual-modal approach enhances the model's flexibility and accuracy in processing few-shot learning tasks. Extensive experiments in few-shot image classification scenarios have demonstrated that ITA shows significant improvements compared to various image augmentation techniques.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406613241",
    "type": "article"
  },
  {
    "title": "MGRL4RE: A Multi-Graph Representation Learning Approach for Urban Region Embedding",
    "doi": "https://doi.org/10.1145/3712698",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Meng Chen; Zechen Li; Hongwei Jia; Xin Yu Shao; Jun Zhao; Qiang Gao; Min Yang; Yilong Yin",
    "corresponding_authors": "",
    "abstract": "Using multi-modal data to learn region representations has gained popularity for its ability to reveal diverse socioeconomic features in cities. However, many studies focus solely on semantic features from points-of-interest (POIs), neglecting the issue of spatial imbalance. This paper introduces a Multi-Graph Representation Learning framework for Region Embedding (MGRL4RE), which leverages both inter-region and intra-region correlations through two main components: multi-graph construction based on various region correlations and multi-graph representation learning. The construction module creates a multi-graph reflecting various correlations among regions, utilizing geo-tagged POIs, region data, and human mobility data. Specifically, we assess a region's importance relative to its spatial context (neighborhood) and develop spatially invariant semantic features to address spatial imbalance. Further, the representation learning module generates comprehensive and effective region representations via multi-view embedding fusion. Our extensive experiments across various downstream tasks, including land use clustering, region popularity prediction, and crime prediction, confirm that our model significantly outperforms existing state-of-the-art region embedding methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406613689",
    "type": "article"
  },
  {
    "title": "Towards Predicting Urban Land Use Changes: A Dynamic Graph Alignment Perspective",
    "doi": "https://doi.org/10.1145/3712702",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Fan Yu; Xinjiang Lu; Hao Liu; Pengfei Wang; Liang Liu; Huadóng Ma; Jingbo Zhou",
    "corresponding_authors": "",
    "abstract": "Urban land use, intrinsically linked to people’s daily activities, undergoes continuous evolution, presenting a complex interplay that remains partially understood. To bridge this gap, our study leverages fine-grained human mobility data to predict these changes, adopting a novel approach that conceptualizes “community-level” land use shifts as a regression problem and represents citywide changes through dynamic graphs. We harness recent advancements in graph neural networks (GNNs), which, despite their success in various applications, face challenges in directly predicting land use changes due to the temporal mismatch between the slow evolution of urban land and the immediacy of human mobility data. Our research stands out by introducing a temporal skeleton for dynamic GNNs to synchronize human activity graphs with urban land use changes, a dynamic heterogeneous GNN approach for integrating diverse human activity data to capture essential temporal dependencies, and a novel algorithm powered by causal inference to elucidate the primary factors influencing land use predictions at the community level, all of which contribute to a training process informed by the generated causal graph. Empirically validated on three real-world datasets, our model demonstrates a performance leap over state-of-the-art baselines, marking a pivotal step toward understanding and predicting the dynamics of urban land use.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406614269",
    "type": "article"
  },
  {
    "title": "Amalgamating Knowledge for Object Detection in Rainy Weather Conditions",
    "doi": "https://doi.org/10.1145/3712703",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Trung-Hieu Le; Shih-Chia Huang; Quoc-Viet Hoang; Zdeněk Lokaj; Zhihui Lu",
    "corresponding_authors": "",
    "abstract": "In recent years, object detection has significantly advanced by using deep learning, especially convolutional neural networks. Most of the existing methods have focused on detecting objects under favorable weather conditions and achieved impressive results. However, object detection in the presence of rain remains a crucial challenge owing to the visibility limitation. In this paper, we introduce an Amalgamating Knowledge Network (AK-Net) to deal with the problem of detecting objects hampered by rain. The proposed AK-Net obtains performance improvement by associating object detection with visibility enhancement, and it is composed of five subnetworks: rain streak removal (RSR) subnetwork, raindrop removal (RDR) subnetwork, foggy rain removal (FRR) subnetwork, feature transmission (FT) subnetwork, and object detection (OD) subnetwork. Our approach is flexible; it can adopt different object detection models to construct the OD subnetwork for the final inference of objects. The RSR, RDR, and FRR subnetworks are responsible for producing clean features from rain streak, raindrop, and foggy rain images, respectively, and offer them to the OD subnetwork through the FT subnetwork for efficient object prediction. Experimental results indicate that the mean average precision (mAP) achieved by our proposed AK-Net was up to 19.58 \\(\\%\\) and 26.91 \\(\\%\\) higher than those produced using competitive methods on published iRain and RID datasets, respectively, while preserving the fast-running time of the baseline detector.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406615007",
    "type": "article"
  },
  {
    "title": "QATCH: Automatic Evaluation of SQL-centric Tasks on Proprietary Data",
    "doi": "https://doi.org/10.1145/3712704",
    "publication_date": "2025-01-20",
    "publication_year": 2025,
    "authors": "Simone Papicchio; Paolo Papotti; Luca Cagliero",
    "corresponding_authors": "",
    "abstract": "Tabular Representation Learning (TRL) and Large Language Models (LLMs) have become established for tackling Question Answering (QA) and Semantic Parsing (SP) tasks on tabular data. State-of-the-art models are pre-trained and evaluated on large open-domain datasets. However, the performance on existing QA and SP benchmarks is not necessarily representative of that achieved on proprietary data as the characteristics of the input and the complexity of the posed queries show high variability. To tackle this challenge, our goal is to allow end-users to evaluate TRL and LLM performance on their own proprietary data. We present QATCH (Query-Aided TRL Checklist), a toolbox to automatically generate a testing checklist tailored to QA and SP. QATCH provides a testing suite highlighting models’ strengths and weaknesses on relational tables unseen at training time. The proposed toolbox relies on a SQL query generator that crafts tests of varying types and complexity including, amongst others, tests on null values, projection, selections, joins, group by, and having clauses. QATCH also supports a set of general cross-task performance metrics providing more insights into SQL-related model capabilities than currently used metrics. The empirical results, achieved by state-of-the-art TRL models and LLMs, show substantial performance differences (1) between existing benchmarks and proprietary data, (2) across queries of different complexity .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406685683",
    "type": "article"
  },
  {
    "title": "Enriching Responses with Crowd-sourced Knowledge for Task-oriented Conversational Agents",
    "doi": "https://doi.org/10.1145/3714474",
    "publication_date": "2025-01-22",
    "publication_year": 2025,
    "authors": "Ze-Xiu WEI; Lizi Liao; Xinguang Xiang; Xiaoyu Du",
    "corresponding_authors": "",
    "abstract": "Task-oriented conversational agents strive to aid users across various tasks by concentrating on generating suitable responses to guarantee successful task accomplishment. Nonetheless, several factors have a substantial influence on user contentment beyond task fulfillment, requiring further investigation. Within this work, we aim to analyze diverse behavioral patterns of conversational agents with the goal of enhancing user satisfaction. Our findings lead to the exploration of three different enriched response generation schemes: EnRG-ATT, EnRG-TIP, and EnRG-SIM. Specifically, EnRG-ATT is designed to integrate the model’s capabilities with a dual attention mechanism across two distinct modalities of external resources. It employs a pair of gates to regulate the utilization of such sources efficiently. More elegantly, we introduce EnRG-TIP, which simplifies response enrichment as a sequence prediction problem and exploits the pre-trained language model to capture user tips related to the conversation. Moreover, building on the efficiency of grounding on similar responses, EnRG-SIM further enhances response generation by inserting similar responses into the training sequences, to direct the pre-trained model’s attention towards this additional knowledge. Our comprehensive experiments demonstrate that our three proposed methods not only achieve good task completion but also generate responses that yield higher user satisfaction.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406697062",
    "type": "article"
  },
  {
    "title": "Do Large Language Models have Spatial Cognitive Abilities?",
    "doi": "https://doi.org/10.1145/3716855",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Ruoling Wu; Danhuai Guo",
    "corresponding_authors": "",
    "abstract": "Since the emergence of large language models, they have garnered significant attention from scholars and industry professionals alike. An important question that arises alongside this phenomenon is whether these large language models possess cognitive capabilities akin to humans. Spatial cognition, a crucial aspect of human cognitive capability, serves as a fundamental metric in this evaluation. This study endeavors to explore two central themes. Firstly, it seeks to ascertain whether large-scale models possess spatial cognitive capabilities. Secondly, it aims to discern optimal prompt methods for eliciting improved responses concerning spatial cognition, encompassing considerations of both result stability and accuracy. We design a series of experiments with 24 typical spatial scenes to assess whether the current array of eight popular large language models exhibits spatial cognition and examine the level of their spatial cognition proficiency. Subsequent discussions delve into strategies for enhancing the spatial cognition performance of large language models to bring them closer to human cognitive levels. Without additional prompts, the average accuracy of the eight large models in judging the three basic spatial relations (topological, direction, and distance relations) is 33.25%. After prompt optimization, the accuracy improves significantly, reaching 53.90%. Our methodological approach enabled us to systematically assess and compare these models, shedding light on their diverse capabilities in this domain. The benchmark is available at https://github.com/LLING000/SCABenchmark .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407370288",
    "type": "article"
  },
  {
    "title": "Retentive Decision Transformer with Adaptive Masking for Reinforcement Learning based Recommendation Systems",
    "doi": "https://doi.org/10.1145/3719208",
    "publication_date": "2025-02-21",
    "publication_year": 2025,
    "authors": "Siyu Wang; Xiaocong Chen; Lina Yao",
    "corresponding_authors": "",
    "abstract": "Reinforcement Learning-based Recommender Systems (RLRS) have shown promise across a spectrum of applications, from e-commerce platforms to streaming services. Yet, they grapple with challenges, notably in crafting reward functions and harnessing large pre-existing datasets within the RL framework. Recent advancements in offline RLRS provide a solution for how to address these two challenges. However, existing methods mainly rely on the transformer architecture, which, as sequence lengths increase, can introduce challenges associated with computational resources and training costs. Additionally, the prevalent methods employ fixed-length input trajectories, restricting their capacity to capture evolving user preferences. In this study, we introduce a new offline RLRS method to deal with the above problems. We reinterpret the RLRS challenge by modeling sequential decision-making as an inference task, leveraging adaptive masking configurations. This adaptive approach selectively masks input tokens, transforming the recommendation task into an inference challenge based on varying token subsets, thereby enhancing the agent’s ability to infer across diverse trajectory lengths. Furthermore, we incorporate a multi-scale segmented retention mechanism that facilitates efficient modeling of long sequences, significantly enhancing computational efficiency. Our experimental analysis, conducted on both online simulator and offline datasets, clearly demonstrates the advantages of our proposed method.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407838716",
    "type": "article"
  },
  {
    "title": "stEELlm: An LLM for Generating Semantic Annotations of Tabular Data",
    "doi": "https://doi.org/10.1145/3719206",
    "publication_date": "2025-02-21",
    "publication_year": 2025,
    "authors": "Marco Cremaschi; Fabio D’Adda; Andrea Maurino",
    "corresponding_authors": "",
    "abstract": "The capabilities of LLMs represent a pivotal step in transforming how we manage and interact with information and data. We witness an increasingly pervasive use of such models in various computational tasks. In some preliminary works, attempts to integrate Knowledge Graphs and Large Language Models (LLMs) can be identified, in particular, to perform the classic tasks related to the construction of Knowledge Graphs through semantic annotation of texts. Nowadays, tables are widely used and play a crucial role in creating, organising, and sharing information that could be used to produce factual knowledge to be integrated into a Knowledge Graph. However, table-to-KG techniques through LLM have not been extensively investigated. This paper presents stEELlm, an innovative Semantic Table Interpretation approach obtained by fine-tuning the Mixtral 8x7B model. Conducted experiments demonstrate the capabilities of our model to successfully create semantic annotations of heterogeneous datasets, a scenario where classic approaches based on heuristics tend to fail.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407839089",
    "type": "article"
  },
  {
    "title": "Automatic generation of plausible co-occurring causes for effects explanation or prediction",
    "doi": "https://doi.org/10.1145/3725855",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Roberto Pietrantuono; Stefano Russo",
    "corresponding_authors": "",
    "abstract": "In numerous contexts, ranging from systems safety assessment to finance and medical diagnosis, a relevant causal inference task is to predict unseen rare events – the so-called black swans . These are plausible, high-impact, but unexpected events for whose prediction a probabilistic-based causal inference falls short. For instance, a safety analyst needs to hypothesize potential rare co-causes that could lead to an accident, so as to manage the most unexpected failures besides the more obvious ones. Given an effect, we use abduction to support the generation of a plausible set of explanatory hypotheses for its causes. We present a generative evolutionary strategy - called Evolutionary Abduction (EVA) - for automating abductive inference by repeatedly constructing hypothetical cause-effect instances, and then automatically assessing their plausibility as well as their novelty with respect to already known instances - a mechanism mimicking the human reasoning employed whenever we need to select the best candidates from a set of hypotheses. Experiments with four datasets confirm that EVA can construct new and realistic multiple-cause hypotheses for a given effect. EVA outperforms alternative strategies based on probabilistic-based causal inference as well as state-of-the-art evolutionary algorithms, generating closer-to-real instances in most settings and datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408812762",
    "type": "article"
  },
  {
    "title": "TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for Human-Aligned LLMs",
    "doi": "https://doi.org/10.1145/3732784",
    "publication_date": "2025-04-29",
    "publication_year": 2025,
    "authors": "Shu Fei Xie; Wenlin Yao; Yong Dai; Shaobo Wang; Z N Xu; Lin Fan; Donglin Zhou; Lifeng Jin; Xinhua Feng; Pengzhi Wei; Yujie Lin; Zhichao Hu; Dong Yu; Zhengyou Zhang; Jing Nie; Yanfei Liu",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs) have shown impressive capabilities across various natural language tasks. However, evaluating their alignment with human preferences remains a challenge. To this end, we propose a comprehensive human evaluation framework to assess LLMs’ proficiency in following instructions on diverse real-world tasks. We construct a hierarchical task tree encompassing 7 major areas covering over 200 categories and over 800 tasks, which covers diverse capabilities such as question answering, reasoning, multiturn dialogue, and text generation, to evaluate LLMs in a comprehensive and in-depth manner. We also design detailed evaluation standards and processes to facilitate consistent, unbiased judgments from human evaluators. A test set of over 3,000 instances is released, spanning different difficulty levels and knowledge domains. Our work provides a standardized methodology to evaluate human alignment in LLMs for both English and Chinese. We also analyze the feasibility of automating parts of evaluation with a strong LLM (GPT-4). Our framework supports a thorough assessment of LLMs as they are integrated into real-world applications. We have made publicly available the task tree, TencentLLMEval dataset, and evaluation methodology which have been demonstrated as effective in assessing the performance of Tencent Hunyuan LLMs 1 . By doing so, we aim to facilitate the benchmarking of advances in the development of safe and human-aligned LLMs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409918512",
    "type": "article"
  },
  {
    "title": "U-Net Encapsulated Transformer for Reducing Dimensionality in Training Large Language Models",
    "doi": "https://doi.org/10.1145/3735653",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Marvin John Ignacio; Yong-Guk Kim; Hulin Jin; Seunghee Yu",
    "corresponding_authors": "",
    "abstract": "Training language models from scratch presents a critical challenge in Natural Language Processing (NLP), primarily due to the computational demands of pre-trained Large Language Models, which are predominantly trained on English corpora using extensive resources. While offering viable solutions, existing alternatives still rely heavily on high-performance hardware. This work introduces a different approach to reducing the algorithmic complexity of Transformer-based architectures through the U-Net Encapsulated Transformer (UET), which applies dimensionality reduction to token embeddings. The UET architecture enables the development of language models with significantly reduced parameter sizes for a given set of hyperparameters. Alternatively, it allows researchers to design models of comparable size but with a substantially greater number of Transformer blocks, enhancing model depth and potential capacity. This study also outlines practical methodologies for training language models in resource-constrained environments. Experimental results illustrate the potential of the UET architecture in achieving reasonable performance under resource-constrained conditions, highlighting its promise as an accessible alternative for language model development. This work could broaden the accessibility of NLP research, empowering researchers with hardware constraints to contribute to language model development.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410345129",
    "type": "article"
  },
  {
    "title": "Robust Neural Model for Searching over Incomplete Graphs",
    "doi": "https://doi.org/10.1145/3735650",
    "publication_date": "2025-05-15",
    "publication_year": 2025,
    "authors": "Radin Hamidi Rad; Ebrahim Bagheri; Mehdi Kargar; Divesh Srivastava; Jaroslaw Szlichta",
    "corresponding_authors": "",
    "abstract": "The task of searching over large keyword graphs aims to identify a subgraph where the nodes collectively cover the input query keywords. Although finding an exact solution to this problem is NP-hard, we address it by proposing a novel graph neural network representation learning technique specifically tailored for graphs with missing information. We propose a novel keyword graph representation learning method that incorporates complementary aspects of graphs: global, local, adjusted, and feature semantics. Considering these multiple aspects, our approach remains robust and resilient to missing information. We adopt and fine-tune a transformer-based model to aggregate the various features of a graph to generate rich representations, recognizing the pivotal role of keywords in this task. We show through experiments on real-world data that our method outperforms the state-of-the-art approaches and is particularly robust in the face of missing values, underscoring its ability to effectively handle incomplete graphs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410398814",
    "type": "article"
  },
  {
    "title": "Introduction to the “Best papers of WSDM 2023” special issue",
    "doi": "https://doi.org/10.1145/3736730",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Hady W. Lauw; Marc Najork; Evimaria Terzi; Panayiotis Tsaparas",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410691937",
    "type": "article"
  },
  {
    "title": "STPE-MARL: Spatio-Temporal Multi-Agent Population Evolution Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3742479",
    "publication_date": "2025-06-02",
    "publication_year": 2025,
    "authors": "Kexing Peng; Shihao Zhu; Tinghuai Ma",
    "corresponding_authors": "",
    "abstract": "Achieving joint goals efficiently in complex real-world tasks demands effective collaboration among multiple agents. Multi-agent Reinforcement Learning (MARL) faces two interrelated challenges: limited exploration leads to early convergence on suboptimal behaviors, which in turn exacerbates non-stationarity under partial observability. To address these issues, we propose a novel framework, Spatio-Temporal Multi-agent Population Evolution (STPE-MARL). By integrating Evolutionary Algorithms (EAs) with MARL, our method enhances exploration diversity and facilitates global policy optimization. We further incorporate Graph Neural Networks (GNNs) to mitigate partial observability by encoding permutation symmetry through graph-based message passing. Two GNN-based training modes, Graph Relation and Graph Decomposition, are introduced to extend agents’ receptive fields and capture spatio-temporal dependencies through time-series trajectory sampling. We evaluate STPE-MARL in two complex environments: micromanagement tasks in StarCraft II and large-scale traffic simulations in SUMO (Simulation of Urban MObility). Experimental results demonstrate that STPE-MARL significantly improves policy convergence and outperforms baseline methods, highlighting the complementary roles of EAs in exploration and GNNs in addressing observation limitations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410953390",
    "type": "article"
  },
  {
    "title": "Modeling Multi-Seasonal Multi-Behavior Dependency for Temporal Recommendation",
    "doi": "https://doi.org/10.1145/3742793",
    "publication_date": "2025-06-03",
    "publication_year": 2025,
    "authors": "Shichao Liang; Wen Wen; Yali Feng; Ruichu Cai; Zhifeng Hao",
    "corresponding_authors": "",
    "abstract": "Mining temporal patterns from user behaviors has long been investigated, but most of the existing work centers on single-type user-item interactions, such as purchase or click, which fails to take advantage of the user’s diversified interests revealed by various types of behavior. However, capturing patterns from different behavior sequences and modeling the complex inter-correlation between them are non-trivial tasks, as the high sparsity of type-related interactions, multi-seasonality of individual behaviors and time-variant dependency of multi-type activities make it really challenging. To address these challenges, we propose a novel framework that aims to model the M ulti-seasonal M ulti-behavior Dep endencies (MMDep) both within and across the multi-type behavior sequences. In the proposed model, an item co-occurrence matrix factorization strategy is introduced to alleviate the sparsity issue in type-related behavior sequences. And a temporal dependency module that incorporates multi-scale EMA mechanism is utilized to capture the multi-seasonal dependencies within individual sequences. Moreover, a cross-behavior dependency module is employed to learn the time-variant dependency among different behaviors. Extensive experiments on three real-world datasets demonstrate that the proposed MMDep performs significantly better than the state-of-the-art baselines. And it may provide some new insights and tools on how to leverage multi-behavior data for better temporal recommendation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410991392",
    "type": "article"
  },
  {
    "title": "Talking-DiSSM: Enhancing Temporal Consistency in Talking Face Video Generation with Bidirectional SSMs",
    "doi": "https://doi.org/10.1145/3742790",
    "publication_date": "2025-06-04",
    "publication_year": 2025,
    "authors": "Zhen Xiao; Xueliang Liu; Jinlin Guo; Jun He; Richang Hong; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Generating temporally smooth and high-resolution videos is a crucial objective in talking face generation tasks. Diffusion-based generative models have emerged as a prime choice for these tasks due to their ability to produce high-quality outputs. To mitigate the impact of stochasticity in the diffusion process, recent research has predominantly utilized self-attention layers to extract temporal features, ensuring temporal consistency in the generated videos. However, self-attention mechanisms have computational complexity that scales quadratically with video length, leading to high computational costs. This limitation poses significant challenges when attempting to generate longer video sequences using diffusion models. To address this challenge, we propose Talking-DiSSM, an end-to-end method for generating audio-driven talking face videos using state-space models (SSMs). This novel framework for conditional video diffusion modeling integrates bidirectional state-space models (Bi-SSM) as temporal modeling modules with linear complexity, effectively capturing complex sequential temporal information and intra-batch sequential interdependencies in videos. Additionally, we employ a simple yet effective batch-overlapped sampling strategy to process input video clips, constructing inter-batch correlations while incorporating reference face clips and landmarks as conditions to ensure stability in the generation process. Extensive experiments demonstrate that Talking-DiSSM generates temporally consistent, high-quality, and identity-preserving talking face videos synchronized with the driving audio, achieving state-of-the-art results compared to existing models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411020518",
    "type": "article"
  },
  {
    "title": "Grounding Foundation Models through Federated Transfer Learning: A General Framework",
    "doi": "https://doi.org/10.1145/3742788",
    "publication_date": "2025-06-05",
    "publication_year": 2025,
    "authors": "Yan Kang; Tao Fan; Hanlin Gu; Xiaojin Zhang; Lixin Fan; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. Recently, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated learning setting, construct a detailed taxonomy based on the FTL-FM framework to categorize state-of-the-art FTL-FM works, and comprehensively overview FTL-FM works based on the proposed taxonomy. We also establish correspondence between FTL-FM and conventional phases of adapting FM so that FM practitioners can align their research works with FTL-FM. In addition, we overview advanced efficiency-improving and privacy-preserving techniques because efficiency and privacy are critical concerns in FTL-FM. Last, we discuss opportunities and future research directions of FTL-FM.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411059404",
    "type": "article"
  },
  {
    "title": "A Federated Graph Neural Network with Differential Privacy for Cross-domain Recommender System",
    "doi": "https://doi.org/10.1145/3742791",
    "publication_date": "2025-06-06",
    "publication_year": 2025,
    "authors": "Pham Minh Thu; Jie Lü; Qian Zhang; Guangquan Zhang",
    "corresponding_authors": "",
    "abstract": "Cross-domain recommender systems, which are designed to address issues with data sparsity, tend to suffer notable challenges with safeguarding user privacy. While existing cross-domain recommendation methods incorporate privacy mechanisms, they often fall short in practice, offering only one-sided benefits and limited privacy safeguards. In this study, we propose a novel privacy-preserving cross-domain recommender system that combines federated transfer learning with differential privacy to facilitate cross-domain knowledge transfer while ensuring strong privacy protection. First, we leverage federated transfer learning, treating each domain as an independent client to protect privacy for business partners by preventing the exchange of raw data. Second, we use a graph neural network (GNN) as the encoder to learn the user and item representations. We also design a consistency loss function that maintains the invariance between local and global user representations while preventing representation collapse. Third, we introduce a privacy mechanism that applies differential privacy to the output of each aggregation layer in the GNN - the aim being to protect transferred user representations while balancing privacy with accuracy. Finally, our transfer mechanism operates without user-identifying information, establishing connections between domains by detecting latent overlapping users and subsequently performing personalized preference aggregation. This allows for efficient knowledge transfer across domains. Experiments on real-world datasets show that our approach significantly enhances recommendation accuracy while offering robust privacy protection, outperforming state-of-the-art baselines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411088796",
    "type": "article"
  },
  {
    "title": "Smart imputation, better recommendations: improving traditional Point-of-Interest recommendation through data augmentation",
    "doi": "https://doi.org/10.1145/3744347",
    "publication_date": "2025-06-10",
    "publication_year": 2025,
    "authors": "Pablo Sánchez; Alejandro Bellogín",
    "corresponding_authors": "",
    "abstract": "Data sparsity is a persistent challenge in recommender systems, specially in specific domains like Point-of-Interest (POI) recommendation, where it significantly impacts model performance. While classical recommender systems have used various imputation and data augmentation mechanisms to address data sparsity, these methods have not been extensively explored in the POI recommendation domain. In this work, we propose a generic imputation framework to study the use of data augmentation techniques to generate synthetic check-ins and analyze their effects on the POI recommendation scenario. Our main goal is to enhance the performance of various traditional recommenders by increasing the training set interactions, considering specific characteristics of the domain, such as geographical information. We apply these techniques in six different cities from a global Foursquare check-in dataset, as well as in two additional cities from the Gowalla dataset, and a separate dataset from Yelp, ensuring a comprehensive evaluation across multiple data sources. Our imputation approach evidences improvements for most models. In several cases, these improvements exceeded 100% for ranking accuracy, measured in terms of nDCG, without considerably compromising novelty or diversity. Data and code is released at https://github.com/pablosanchezp/ImputationForPOIRecsys .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411164650",
    "type": "article"
  },
  {
    "title": "Predicting Next Useful Location With Context-Awareness: The State-Of-The-Art",
    "doi": "https://doi.org/10.1145/3744653",
    "publication_date": "2025-06-13",
    "publication_year": 2025,
    "authors": "Alireza Nezhadettehad; Arkady Zaslavsky; Abdur Rakib; Siraj Ahmed Shaikh; Seng W. Loke; Guang‐Li Huang; Alireza Hassani",
    "corresponding_authors": "",
    "abstract": "Predicting the future location of mobile objects reinforces location-aware services with proactive intelligence and helps businesses and decision-makers with better planning and near real-time scheduling in different applications such as traffic congestion control, location-aware advertisements, and monitoring public health and well-being. Recent developments in smartphone and location sensors technology and the prevalence of using location-based social networks alongside the improvements in artificial intelligence and machine learning techniques provide an excellent opportunity to exploit massive amounts of historical and real-time contextual information to recognise mobility patterns and achieve more accurate and intelligent predictions. This unique survey provides a comprehensive overview of the next useful location prediction problem with context-awareness and the related studies. First, we explain the concepts of context and context-awareness and define the next location prediction problem. Then we analyse more than thirty studies in this field concerning the prediction method, the challenges addressed, the datasets and metrics used for training and evaluating the model, and the types of context incorporated. Finally, we discuss the advantages and disadvantages of different approaches, focusing on the usefulness of the predicted location and identifying the open challenges and future work on this subject.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411273378",
    "type": "article"
  },
  {
    "title": "Back-in-Time Diffusion: Unsupervised Detection of Medical Deepfakes",
    "doi": "https://doi.org/10.1145/3744656",
    "publication_date": "2025-06-13",
    "publication_year": 2025,
    "authors": "Freddie Grabovski; Lior Yasur; Guy Amit; Yisroel Mirsky",
    "corresponding_authors": "",
    "abstract": "Recent progress in generative models has made it easier for a wide audience to edit and create image content, raising concerns about the proliferation of deepfakes, especially in healthcare. Despite the availability of numerous techniques for detecting manipulated images captured by conventional cameras, their applicability to medical images is limited. This limitation stems from the distinctive forensic characteristics of medical images, a result of their imaging process. In this work we propose a novel anomaly detector for medical imagery based on diffusion models. Normally, diffusion models are used to generate images. However, we show how a similar process can be used to detect synthetic content by making a model reverse the diffusion on a suspected image. We evaluate our method on the task of detecting fake tumors injected and removed from CT and MRI scans. Our method significantly outperforms other state-of-the-art unsupervised detectors with an increased AUC of 0.9 from 0.79 for injection and of 0.96 from 0.91 for removal on average. We also explore our hypothesis using AI explainability tools and publish both our code and new medical deepfake datasets to encourage further research into this domain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411276114",
    "type": "article"
  },
  {
    "title": "Semi-Supervised Crowd Counting via Swin Transformer with Adaptive Soft Threshold and Contrastive Learning",
    "doi": "https://doi.org/10.1145/3744747",
    "publication_date": "2025-06-16",
    "publication_year": 2025,
    "authors": "Mingwei Yao; Kehua Guo; Lingyan Zhang; Xuyang Tan; Xiaokang Zhou",
    "corresponding_authors": "",
    "abstract": "Manual annotation for crowd counting remains labor-intensive and costly. Although existing semi-supervised methods partially alleviate this burden, they still face significant challenges regarding the quality of generated pseudo-labels and the utilization of unlabeled data. To address these issues, we propose a novel semi-supervised crowd counting framework, called Point-Adaptive Teacher (PAT). This framework integrates Adaptive Soft Threshold (AST) and contrastive learning to enhance pseudo-label quality and effectively leverage unlabeled data. Specifically, we employ the Swin Transformer as the backbone and develop Swin-P2PNet, which captures global contextual information through hierarchical window attention, improving the accuracy of pseudo-labels. Additionally, we design the AST that dynamically adjusts the sample loss weight by combining confidence and uncertainty predictions, thereby alleviating the effect of noise in pseudo-labels. Finally, we introduce a contrastive learning strategy requiring no extra parameters. This strategy enhances the model's ability to learn latent representations from unlabeled data. Extensive experiments have been conducted on three public datasets, namely ShanghaiTech, JHU-Crowd++, and UCF-QNRF. The results demonstrate that our method achieves performance comparable to state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411345778",
    "type": "article"
  },
  {
    "title": "Optimizing Reachability in Graph-based Recommender Systems",
    "doi": "https://doi.org/10.1145/3744658",
    "publication_date": "2025-06-18",
    "publication_year": 2025,
    "authors": "Alex Martínez; Federico Cinus; Francesco Bonchi; Jordi Vitrià",
    "corresponding_authors": "",
    "abstract": "While accuracy has long been prioritized as the primary metric for Recommender Systems (RSs), it is increasingly accepted that the system's overall quality is not solely determined by this factor. Reachability, the ease with which users can navigate the whole content catalog through recommendations, emerges as a pivotal yet under-explored concept: not only it ensures a smooth experience for users, but it also provides more equitable exposure for the items, avoiding that only a small fraction of popular items get the bulk of the attention. Despite its importance, the few existing studies analyze reachability without attempting a proper optimization. In this paper, we study the problem of optimizing the overall reachability of a RS while maintaining high-quality recommendations. We model a user browsing session as a random walk on a recommendation graph, where the links and the transition probabilities are defined based on the relevance score of the recommendation list that the user gets at every step. In this setting, reachability is modeled as the expected length of a path to reach a given item. We introduce two optimization problems, one discrete and one continuous, and characterize their theoretical properties. We then devise two algorithms that outperform non-trivial baseline methods in enhancing reachability while maintaining a high normalized Discounted Cumulative Gain (nDCG) score. Our experimental results show that, in some settings, our methods are able to improve the reachability metric by 80% while only compromising nDCG by 5%. Moreover, our empirical analysis shows that optimizing for reachability provides positive effects also on other prevalent “beyond-accuracy” metrics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411403374",
    "type": "article"
  },
  {
    "title": "An In-depth Evaluation of Large Language Models in Sentence Simplification with Error-based Human Assessment",
    "doi": "https://doi.org/10.1145/3744744",
    "publication_date": "2025-06-19",
    "publication_year": 2025,
    "authors": "X. Wu; Yuki Arase",
    "corresponding_authors": "",
    "abstract": "Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs’ simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models’ performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation’s reliability. To address these problems, this study provides in-depth insights into LLMs’ performance while ensuring the reliability of the evaluation. We design an error-based human annotation framework to assess the LLMs’ simplification capabilities. We select both closed-source and open-source LLMs, including GPT-4, Qwen2.5-72B, and Llama-3.2-3B. We believe that these models offer a representative selection across large, medium, and small sizes of LLMs. Results show that GPT-4 generally generates fewer erroneous simplification outputs compared to the current state-of-the-art. However, LLMs have their limitations, as seen in GPT-4’s struggles with lexical paraphrasing. Results show that LLMs generally generate fewer erroneous simplification outputs compared to the previous state-of-the-art. However, LLMs have their limitations, as seen in GPT-4’s and Qwen2.5-72B’s struggle with lexical paraphrasing. Furthermore, we conduct meta-evaluations on widely used automatic metrics using our human annotations. We find that these metrics lack sufficient sensitivity to assess the overall high-quality simplifications, particularly those generated by high-performance LLMs 1 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411448956",
    "type": "article"
  },
  {
    "title": "Federated Reinforcement Learning for Privacy-Preserving Sepsis Patient Treatment Model",
    "doi": "https://doi.org/10.1145/3744655",
    "publication_date": "2025-06-20",
    "publication_year": 2025,
    "authors": "S. T. Oh; Yunho Choi; Ho-Taek Joo; Kyung-Joong Kim",
    "corresponding_authors": "",
    "abstract": "Reinforcement learning (RL) for developing a patient treatment model using electronic health records has been actively studied. Although constructing the models requires considerable actual patient treatment records, the establishment of large databases poses challenges due to strict privacy regulations. Therefore, federated RL (FRL), which can train an RL model without sharing data between institutions, is being introduced. This study proposes an FRL framework where local institutions collaborate to make optimal RL models without data sharing or raw data leakage. We constructed FRL models for personalized sepsis treatment models and evaluated their performances in realistic scenarios. The reliability of the FRL framework was evaluated on basic, skewed, imbalanced, and realistic data distribution using two clinical benchmark datasets, the Medical Information Mart for Intensive Care III database and the eICU Collaborative Research Database v2.0. The performances of FRL models were comparable to those learned from the ideal setting, where all institutions agree to share their datasets to train a global treatment model. Furthermore, the FRL framework showed generalization performance on unseen data during training and showed the applicability of various federated learning algorithms. Through practical experiments using clinical data, we demonstrated the real-world applicability of the FRL framework.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411490993",
    "type": "article"
  },
  {
    "title": "Surveying Technology Fusion in IoT Networks for IDS: Exploring Datasets, Tools, Challenges, and Research Prospects",
    "doi": "https://doi.org/10.1145/3744745",
    "publication_date": "2025-06-24",
    "publication_year": 2025,
    "authors": "Mamta Rawat; Gaurav Singal",
    "corresponding_authors": "",
    "abstract": "The Internet of Things is quickly taking over the world. Nevertheless, security for the IoT is becoming a more important academic topic and commercial concern because of several factors including the diverse nature of devices, protocols in use, the sensitivity of the data they carry, and security and privacy concerns. Admitting this, there appears to be a compelling need for a comprehensive survey that encompasses the entire spectrum of intrusion detection in the IoT paradigm, from foundational concepts like types of IDS, resources, and techniques for implementing IDS, to the latest technologies that can be used to enhance the performance of IDS. This study will be helpful for academic and industrial research in different ways: first, in identifying type of IDS to be used; second, in choosing various tools such as datasets and sniffing tools, and learning techniques for implementing IDS; and finally, it suggests the use of latest enabling technologies in the IoT setting to make the process of intrusion detection more secure, efficient, trustworthy and privacy aware. We have also discussed critical challenges and research directions to help young researchers advance in their research projects.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411580723",
    "type": "article"
  },
  {
    "title": "Balancing Cooperation and Competition: Selfish Worker Coalition Formation in Spatial Crowdsourcing",
    "doi": "https://doi.org/10.1145/3748661",
    "publication_date": "2025-07-15",
    "publication_year": 2025,
    "authors": "Liang Wang; Shan Su; Rongchang Cheng; Dingqi Yang; Lianbo Ma; Fei Xiong; Bin Guo; Zexing Yu",
    "corresponding_authors": "",
    "abstract": "Spatial Crowdsourcing, which outsources location-dependent tasks to workers for physical completion, is gaining popularity. Recently, more complex tasks have emerged that require a group of workers collaborating in a coalition. Several pioneering studies have examined this issue using the server assigned tasks mode from an overall perspective, such as maximizing the total benefits of all workers. Unfortunately, maximizing the overall benefit does not necessarily align with maximizing individual benefits. In practice, crowd workers are often self-interested and autonomous, making decisions based on their personal perspectives. In this paper, under the worker selected tasks mode, we investigate an important problem: S elfish W orkers C oalition F ormation ( SWCF ) problem in SC. Here, selfish workers autonomously form coalitions to accomplish tasks to maximize their individual benefits. Achieving a stable coalition formation for SWCF problem requires balancing cooperation and competition. Firstly, we transform the SWCF problem into a hedonic coalition formation game using a devised exploited skills-based reward distribution model. Subsequently, we propose a distributed algorithm HCFTA and prove its Nash stability and performance bounds. Additionally, to enhance coalition formation efficiency, we propose a Markov blanket coloring parallel optimization algorithm MCPHCF . Extensive experiments demonstrate the superiority of the proposed methods on both synthetic and real-world datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412420807",
    "type": "article"
  },
  {
    "title": "Cross-User Federated Recommendation Unlearning",
    "doi": "https://doi.org/10.1145/3749990",
    "publication_date": "2025-07-24",
    "publication_year": 2025,
    "authors": "Yang Li; Enyue Yang; Weike Pan; Qiang Yang; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Cross-user federated recommendation (CUFR) is a promising solution for providing personalized services without collecting users’ raw data. However, most previous CUFR works mainly focus on providing accurate and privacy-preserving personalized recommendations, but overlook the fact that users can opt out at any time during the training process. In response, we study an emerging and new problem of efficiently training an unlearned model to forget the data of the clients who leave a federated system. It is challenging to simply apply or slightly modify existing machine unlearning or federated unlearning methods to CUFR because of the unique collaboration effect in recommender systems. Although a recent gradient calibration-based method (i.e., FRU) shows promising in training an unlearned model, there are still some limitations: (i) there is a potential possibility that some clients run out of the storage space, (ii) all the remaining clients need to participate in computing the new gradients, (iii) it masks the uniqueness of the local gradients, and (iv) the errors of the calibrated gradients will increase gradually with more iterations. In this paper, we propose a novel CUFR unlearning method (CUFRU). Specifically, we design a gradient transfer station (GTS) module for storing the historical gradients while enabling clients to dynamically participate in the computation of the calibrated gradients with the new gradients based on their online status. Moreover, we design a novel iteration-aware gradient calibration mechanism to strike a balance between the weights of the historical and new gradients at the different stages of the unlearning process, alleviating the calibration errors. Finally, we conduct extensive experiments on three real-world datasets to show that our CUFRU can more efficiently train an unlearned model with the competitive recommendation performance.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412627858",
    "type": "article"
  },
  {
    "title": "Scalable Multi-Instance Multi-Shape Support Vector Machine for Whole Slide Breast Histopathology",
    "doi": "https://doi.org/10.1145/3747593",
    "publication_date": "2025-08-04",
    "publication_year": 2025,
    "authors": "Hoon Seo; Y. Bai; Lodewijk Brand; Lucia Saldana Barco; Hua Wang",
    "corresponding_authors": "",
    "abstract": "Analysis of histopathological images is critical in cancer diagnosis and treatment. Due to the huge size of histopathological images and the varied number of imaging records per patient, many existing works analyze the Whole Slide Image (WSI) as a bag in which its patches are instances. However, these approaches are limited to analyzing the patches in a fixed shape, while the malignant lesions can form varied shapes. To address this challenge, in this article we propose a Multi-Instance Multi-Shape Support Vector Machine (MIMSSVM) to analyze the multiple images (instances) jointly where each instance consists of multiple patches in various shapes. In our approach, we can identify the different morphologic abnormalities of nuclei shapes from the multiple images. In addition to the multi-instance multi-shape learning capability, we derive an efficient solution algorithm to optimize the proposed model that scales well to a large number of features. Our experimental results show our new method outperforms the existing SVMs and deep learning models in histopathological classification. The proposed model also identifies the tissue segments in an image exhibiting an indication of an abnormality which provides utility in the early detection of malignant tumors. All these promising experimental results have demonstrated the effectiveness of our new method. We anticipate that our new method is of interest to biomedical engineering communities beyond WSI research and have open sourced the code of our method online. The implementation of our proposed MIMSSVM model is publicly available at https://github.com/hoonseo0409/MIMSSVM .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412928603",
    "type": "article"
  },
  {
    "title": "LKAFormer: A Lightweight Kolmogorov-Arnold Transformer Model for Image Semantic Segmentation",
    "doi": "https://doi.org/10.1145/3759254",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Shoulin Yin; Liguo Wang; Tao Chen; Huafei Huang; Jing Gao; Jianing Zhang; Meng Liu; Peng Li; Chengpei Xu",
    "corresponding_authors": "",
    "abstract": "Transformer-based semantic segmentation methods have demonstrated outstanding performance by leveraging global self-attention to effectively capture long-range dependence. However, there still exist two issues in existing works: 1) Most of them utilize the full-rank weight matrix to support the self-attention mechanism and feed-forward network in modelling long-range dependence between patches/pixels, resulting in a high computational cost during both training and inference. 2) Most of them ignore information interactions between high-level semantics and low-level structures during the image resolution recovery, which leads to the performance degradation in segmenting objects with complex boundaries. To tackle these challenges, a lightweight Kolmogorov-Arnold Transformer model (LKAFormer) is proposed for the image semantic segmentation, containing a two-stream lightweight Transformer encoder and a graph feature pyramid aggregation KAN-decoder. The former constructs a hierarchical feature cross-scale fusion pipeline to obtain sufficient semantics containing comprehensive multi-scale information via setting coarse-grained and fine-grained streams with different-size patches of images. In that pipeline, feature lightweight focusing modules model complex and long-range dependence across patches/pixels to refine image semantics with less computational costs by lightweight multi-head self-attention and lightweight feed-forward network designs. The latter leverages the learnable nonlinear transformation mechanism of the Kolmogorov-Arnold Transformer architecture to adaptively capture spatial structure dependence of distinct sub-regions of images. And then, it jointly performs the intra-scale graph fusion and cross-scale graph fusion during the image resolution recovery to enhance information interactions between high-level semantics and low-level structures, which achieves the robust boundary localization and texture refinement of segmentation objects. Finally, plentiful experiments are conducted on three challenging datasets, and the results show LKAFormer sets a new baseline in the image segmentation task in comparison with 11 methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413279514",
    "type": "article"
  },
  {
    "title": "Joint Service Migration and Resource Allocation for DNN tasks using SA-DDQN-DDPG in Vehicular Edge Computing",
    "doi": "https://doi.org/10.1145/3768152",
    "publication_date": "2025-09-17",
    "publication_year": 2025,
    "authors": "Chunlin Li; Zihao Zhang; Bingxin Wang; M.K. Lei; Sen Liu; Aoyong Li; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "With the rapid development of Vehicular Edge Computing (VEC) and Artificial Intelligence (AI), the emergence of vehicle edge intelligence meets the need for real-time vehicle intelligence applications. But the execution of deep neural networks (DNNs) requires a large amount of data input, which results in a large amount of computing resources required for the execution of DNN tasks. This also brings a certain burden to the deployment of DNN tasks and the resource allocation of edge servers. In addition, due to the high mobility of vehicles in the VEC, the backhaul delay of vehicle edge intelligent task results increases, affecting the vehicle's Quality of Experience (QoE). We propose a joint optimization strategy for service migration and resource allocation aimed at minimizing the average task completion delay. This strategy comprehensively considers service migration actions and edge server resource allocation, which is proved to be a mixed integer nonlinear programming (MINLP) problem, and hence we formulate it as an markov decision process (MDP). To solve this problem, we propose a service migration algorithm based on the self-attention mechanism-based double deep Q-network and deep deterministic policy gradient algorithm (SA-DDQN-DDPG) algorithm to solve it to obtain the optimal system service migration strategy. The experimental results show that the proposed SA-DDQN-DDPG algorithm has good performance in reducing latency. The average migration latency is reduced by 40.41%, 20.7% and 14.50% compared with always, DQN and DDQN respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414276976",
    "type": "article"
  },
  {
    "title": "Spectraformer: A Unified Random Feature Framework for Transformer",
    "doi": "https://doi.org/10.1145/3768161",
    "publication_date": "2025-09-18",
    "publication_year": 2025,
    "authors": "Duke Nguyen; Du Yin; Aditya Joshi; Flora D. Salim",
    "corresponding_authors": "",
    "abstract": "Linearization of attention using various kernel approximation and kernel learning techniques has shown promise. Past methods used a subset of combinations of component functions and weight matrices within the random feature paradigm. We identify the need for a systematic comparison of different combinations of weight matrices and component functions for attention learning in Transformer. Hence, we introduce Spectraformer , a unified framework for approximating and learning the kernel function in the attention mechanism of the Transformer. Our empirical results demonstrate, for the first time, that a random feature-based approach can achieve performance comparable to top-performing sparse and low-rank methods on the challenging Long Range Arena benchmark. Thus, we establish a new state-of-the-art for random feature-based efficient Transformers. The framework also produces many variants that offer different advantages in accuracy, training time, and memory consumption. Our code is available at: https://github.com/cruiseresearchgroup/spectraformer .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414320939",
    "type": "article"
  },
  {
    "title": "Query Performance Prediction Using Neural Query Space Proximity",
    "doi": "https://doi.org/10.1145/3762197",
    "publication_date": "2025-09-12",
    "publication_year": 2025,
    "authors": "Amin Bigdeli; Sajad Ebrahimi; Negar Arabzadeh; Sara Salamat; Shirin Seyedsalehi; Maryam Khodabakhsh; Fattane Zarrinkalam; Ebrahim Bagheri",
    "corresponding_authors": "",
    "abstract": "The varying performance of information retrieval (IR) methods, including state-of-the-art transformer-based neural retrievers, across diverse queries poses a significant challenge for achieving robust and reliable retrieval effectiveness. Query Performance Prediction (QPP) seeks to estimate the effectiveness of a retrieval method for individual queries, enabling adaptive strategies to improve retrieval outcomes, particularly for challenging queries. However, existing QPP approaches face fundamental challenges: pre-retrieval methods often rely on surface-level query features that fail to capture the nuanced relationship between queries and retrieval effectiveness, while post-retrieval methods depend heavily on the quality of retrieved documents, which can be unreliable for difficult queries. To this end, we propose the Query Space Distance-Based QPP ( QSD-QPP ) framework, which leverages the deterministic and consistent behavior of retrieval methods to estimate query performance by referencing historical queries with known effectiveness. The approach is motivated by the observation that semantically or syntactically similar queries often exhibit consistent retrieval performance, a property that can be exploited to make reliable predictions for unseen queries. QSD-QPP operates in two modes: (1) a lightweight pre-retrieval instantiation that dynamically constructs a query subspace based on embedding distances to interpolate the performance of proximate historical queries, and (2) an enriched post-retrieval instantiation that incorporates contextualized embeddings, document interactions, and historical query associations to enhance prediction accuracy. By utilizing large-scale contextualized embeddings derived from pre-trained language models, QSD-QPP efficiently identifies semantically similar queries and leverages their performance for robust predictions. By addressing the inherent limitations of prior approaches, QSD-QPP achieves a balanced trade-off between computational efficiency, prediction accuracy, and scalability. We evaluate QSD-QPP on four benchmark datasets, including MS MARCO Dev and TREC Deep Learning tracks (2019, 2020, and DL-Hard), demonstrating its superior accuracy and robustness compared to state-of-the-art baselines in both pre-retrieval and post-retrieval QPP tasks. To ensure reproducibility and encourage further research, we publicly release the implementation of our work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414596481",
    "type": "article"
  },
  {
    "title": "Visual Abstraction and Ordering in Faceted Browsing of Text Collections",
    "doi": "https://doi.org/10.1145/2089094.2089097",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "VinhTuan Thai; Pierre-Yves Rouille; Siegfried Handschuh",
    "corresponding_authors": "",
    "abstract": "Faceted navigation is a technique for the exploration and discovery of a collection of resources, which can be of various types including text documents. While being information-rich resources, documents are usually not treated as content-bearing items in faceted browsing interfaces, and yet the required clean metadata is not always available or matches users’ interest. In addition, the existing linear listing paradigm for representing result items from the faceted filtering process makes it difficult for users to traverse or compare across facet values in different orders of importance to them. In this context, we report in this article a visual support toward faceted browsing of a collection of documents based on a set of entities of interest to users. Our proposed approach involves using a multi-dimensional visualization as an alternative to the linear listing of focus items. In this visualization, visual abstraction based on a combination of a conceptual structure and the structural equivalence of documents can be simultaneously used to deal with a large number of items. Furthermore, the approach also enables visual ordering based on the importance of facet values to support prioritized, cross-facet comparisons of focus items. A user study was conducted and the results suggest that interfaces using the proposed approach can support users better in exploratory tasks and were also well-liked by the participants of the study, with the hybrid interface combining the multi-dimensional visualization with the linear listing receiving the most favorable ratings.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2016260103",
    "type": "article"
  },
  {
    "title": "A Generic Approach for Systematic Analysis of Sports Videos",
    "doi": "https://doi.org/10.1145/2168752.2168760",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Ning Zhang; Ling‐Yu Duan; Lingfang Li; Qingming Huang; Jun Du; Wen Gao; Ling Guan",
    "corresponding_authors": "",
    "abstract": "Various innovative and original works have been applied and proposed in the field of sports video analysis. However, individual works have focused on sophisticated methodologies with particular sport types and there has been a lack of scalable and holistic frameworks in this field. This article proposes a solution and presents a systematic and generic approach which is experimented on a relatively large-scale sports consortia. The system aims at the event detection scenario of an input video with an orderly sequential process. Initially, domain knowledge-independent local descriptors are extracted homogeneously from the input video sequence. Then the video representation is created by adopting a bag-of-visual-words (BoW) model. The video’s genre is first identified by applying the k-nearest neighbor (k-NN) classifiers on the initially obtained video representation, and various dissimilarity measures are assessed and evaluated analytically. Subsequently, an unsupervised probabilistic latent semantic analysis (PLSA)-based approach is employed at the same histogram-based video representation, characterizing each frame of video sequence into one of four view groups, namely closed-up-view, mid-view, long-view, and outer-field-view. Finally, a hidden conditional random field (HCRF) structured prediction model is utilized for interesting event detection. From experimental results, k-NN classifier using KL-divergence measurement demonstrates the best accuracy at 82.16% for genre categorization. Supervised SVM and unsupervised PLSA have average classification accuracies at 82.86% and 68.13%, respectively. The HCRF model achieves 92.31% accuracy using the unsupervised PLSA based label input, which is comparable with the supervised SVM based input at an accuracy of 93.08%. In general, such a systematic approach can be widely applied in processing massive videos generically.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2076424778",
    "type": "article"
  },
  {
    "title": "Reorder user's tweets",
    "doi": "https://doi.org/10.1145/2414425.2414431",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Keyi Shen; Jianmin Wu; Ya Zhang; Yiping Han; Xiaokang Yang; Li Song; Xiao Gu",
    "corresponding_authors": "",
    "abstract": "Twitter displays the tweets a user received in a reversed chronological order, which is not always the best choice. As Twitter is full of messages of very different qualities, many informative or relevant tweets might be flooded or displayed at the bottom while some nonsense buzzes might be ranked higher. In this work, we present a supervised learning method for personalized tweets reordering based on user interests. User activities on Twitter, in terms of tweeting, retweeting, and replying, are leveraged to obtain the training data for reordering models. Through exploring a rich set of social and personalized features, we model the relevance of tweets by minimizing the pairwise loss of relevant and irrelevant tweets. The tweets are then reordered according to the predicted relevance scores. Experimental results with real twitter user activities demonstrated the effectiveness of our method. The new method achieved above 30% accuracy gain compared with the default ordering in twitter based on time.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2115817283",
    "type": "article"
  },
  {
    "title": "PhC",
    "doi": "https://doi.org/10.1145/2089094.2089098",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "K. Selçuk Candan; Luigi Di; Maria Luisa Sapino",
    "corresponding_authors": "",
    "abstract": "The high-dimensional nature of the textual data complicates the design of visualization tools to support exploration of large document corpora. In this article, we first argue that the Parallel Coordinates (PC) technique, which can map multidimensional vectors onto a 2D space in such a way that elements with similar values are represented as similar poly-lines or curves in the visualization space, can be used to help users discern patterns in document collections. The inherent reduction in dimensionality during the mapping from multidimensional points to 2D lines, however, may result in visual complications. For instance, the lines that correspond to clusters of objects that are separate in the multidimensional space may overlap each other in the 2D space; the resulting increase in the number of crossings would make it hard to distinguish the individual document clusters. Such crossings of lines and overly dense regions are significant sources of visual clutter, thus avoiding them may help interpret the visualization. In this article, we note that visual clutter can be significantly reduced by adjusting the resolution of the individual term coordinates by clustering the corresponding values. Such reductions in the resolution of the individual term-coordinates, however, will lead to a certain degree of information loss and thus the appropriate resolution for the term-coordinates has to be selected carefully. Thus, in this article we propose a controlled clutter reduction approach, called Parallel hierarchical Coordinates (or PhC ), for reducing the visual clutter in PC-based visualizations of text corpora. We define visual clutter and information loss measures and provide extensive evaluations that show that the proposed PhC provides significant visual gains (i.e., multiple orders of reductions in visual clutter) with small information loss during visualization and exploration of document collections.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2143254032",
    "type": "article"
  },
  {
    "title": "ResumeVis",
    "doi": "https://doi.org/10.1145/3230707",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Chen Zhang; Hao Wang",
    "corresponding_authors": "",
    "abstract": "Massive public resume data emerging on the WWW indicates individual-related characteristics in terms of profile and career experiences. Resume Analysis (RA) provides opportunities for many applications, such as talent seeking and evaluation. Existing RA studies based on statistical analyzing have primarily focused on talent recruitment by identifying explicit attributes. However, they failed to discover the implicit semantic information, i.e., individual career progress patterns and social-relations, which are vital to comprehensive understanding of career development. Besides, how to visualize them for better human cognition is also challenging. To tackle these issues, we propose a visual analytics system ResumeVis to mine and visualize resume data. Firstly, a text-mining based approach is presented to extract semantic information. Then, a set of visualizations are devised to represent the semantic information in multiple perspectives. By interactive exploration on ResumeVis performed by domain experts, the following tasks can be accomplished: to trace individual career evolving trajectory; to mine latent social-relations among individuals; and to hold the full picture of massive resumes' collective mobility. Case studies with over 2500 online officer resumes demonstrate the effectiveness of our system. We provide a demonstration video.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2614282464",
    "type": "article"
  },
  {
    "title": "From Electromyogram to Password",
    "doi": "https://doi.org/10.1145/3078844",
    "publication_date": "2017-09-04",
    "publication_year": 2017,
    "authors": "Ruide Zhang; Ning Zhang; Changlai Du; Wenjing Lou; Y. Thomas Hou; Yuichi Kawamoto",
    "corresponding_authors": "",
    "abstract": "With the increasing popularity of augmented reality (AR) services, providing seamless human-computer interactions in the AR setting has received notable attention in the industry. Gesture control devices have recently emerged to be the next great gadgets for AR due to their unique ability to enable computer interaction with day-to-day gestures. While these AR devices are bringing revolutions to our interaction with the cyber world, it is also important to consider potential privacy leakages from these always-on wearable devices. Specifically, the coarse access control on current AR systems could lead to possible abuse of sensor data. Although the always-on gesture sensors are frequently quoted as a privacy concern, there has not been any study on information leakage of these devices. In this article, we present our study on side-channel information leakage of the most popular gesture control device, Myo. Using signals recorded from the electromyography (EMG) sensor and accelerometers on Myo, we can recover sensitive information such as passwords typed on a keyboard and PIN sequence entered through a touchscreen. EMG signal records subtle electric currents of muscle contractions. We design novel algorithms based on dynamic cumulative sum and wavelet transform to determine the exact time of finger movements. Furthermore, we adopt the Hudgins feature set in a support vector machine to classify recorded signal segments into individual fingers or numbers. We also apply coordinate transformation techniques to recover fine-grained spatial information with low-fidelity outputs from the sensor in keystroke recovery. We evaluated the information leakage using data collected from a group of volunteers. Our results show that there is severe privacy leakage from these commodity wearable sensors. Our system recovers complex passwords constructed with lowercase letters, uppercase letters, numbers, and symbols with a mean success rate of 91%.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2750678742",
    "type": "article"
  },
  {
    "title": "Secure IoT-Based, Incentive-Aware Emergency Personnel Dispatching Scheme with Weighted Fine-Grained Access Control",
    "doi": "https://doi.org/10.1145/3063716",
    "publication_date": "2017-09-13",
    "publication_year": 2017,
    "authors": "Lo‐Yao Yeh; Woei-Jiunn Tsaur; Hsin-Han Huang",
    "corresponding_authors": "",
    "abstract": "Emergency response times following a traffic accident are extremely crucial in reducing the number of traffic-related deaths. Existing emergency vehicle dispatching systems rely heavily on manual assignments. Although some technology-assisted emergency systems engage in emergency message dissemination and path planning, efficient emergency response is one of the main factors that can decrease traffic-related deaths. Obviously, effective emergency response often plays a far more important role in a successful rescue. In this article, we propose a secure IoT-based and incentive-aware emergency personnel dispatching scheme (EPDS) with weighted fine-grained access control. Our EPDS can recruit available medical personnel on-the-fly, such as physicians driving in the vicinity of the accident scene. An appropriate incentive, such as paid leave, can be offered to encourage medical personnel to join rescue missions. Furthermore, IoT-based devices are installed in vehicles or wearable on drivers to gather biometric signals from the driver, which can be used to decide precisely which divisions or physicians are needed to administer the appropriate remedy. Additionally, our scheme can cryptographically authorize the assigned rescue vehicle to control traffic to increase rescue efficacy. Our scheme also takes advantage of adjacent roadside units to organize the appropriate rescue personnel without requiring long-distance communication with a trusted traffic authority. Proof of security is provided and extensive analyses, including qualitative and quantitative analyses and simulations, show that the proposed scheme can significantly improve rescue response time and effectiveness. To the best of our knowledge, this is the first work to make use of medical personnel that are close by in emergency rescue missions.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2756386338",
    "type": "article"
  },
  {
    "title": "X-CLE <scp>a</scp> VER",
    "doi": "https://doi.org/10.1145/3205453",
    "publication_date": "2018-10-29",
    "publication_year": 2018,
    "authors": "Claudio Lucchese; Franco Maria Nardini; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Salvatore Trani",
    "corresponding_authors": "",
    "abstract": "Learning-to-Rank (LtR) solutions are commonly used in large-scale information retrieval systems such as Web search engines, which have to return highly relevant documents in response to user query within fractions of seconds. The most effective LtR algorithms adopt a gradient boosting approach to build additive ensembles of weighted regression trees. Since the required ranking effectiveness is achieved with very large ensembles, the impact on response time and query throughput of these solutions is not negligible. In this article, we propose X-CLE a VER, an iterative meta-algorithm able to build more efficient and effective ranking ensembles. X-CLE a VER interleaves the iterations of a given gradient boosting learning algorithm with pruning and re-weighting phases. First, redundant trees are removed from the given ensemble, then the weights of the remaining trees are fine-tuned by optimizing the desired ranking quality metric. We propose and analyze several pruning strategies and we assess their benefits showing that interleaving pruning and re-weighting phases during learning is more effective than applying a single post-learning optimization step. Experiments conducted using two publicly available LtR datasets show that X-CLE a VER can be successfully exploited on top of several LtR algorithms as it is effective in optimizing the effectiveness of the learnt ensembles, thus obtaining more compact forests that hence are much more efficient at scoring time.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2899500964",
    "type": "article"
  },
  {
    "title": "Visual Analytics of Heterogeneous Data Using Hypergraph Learning",
    "doi": "https://doi.org/10.1145/3200765",
    "publication_date": "2018-12-20",
    "publication_year": 2018,
    "authors": "Cong Xie; Wen Zhong; Wei Xu; Klaus Mueller",
    "corresponding_authors": "",
    "abstract": "For real-world learning tasks (e.g., classification), graph-based models are commonly used to fuse the information distributed in diverse data sources, which can be heterogeneous, redundant, and incomplete. These models represent the relations in different datasets as pairwise links. However, these links cannot deal with high-order relations which connect multiple objects (e.g., in public health datasets, more than two patient groups admitted by the same hospital in 2014). In this article, we propose a visual analytics approach for the classification on heterogeneous datasets using the hypergraph model. The hypergraph is an extension to traditional graphs in which a hyperedge connects multiple vertices instead of just two. We model various high-order relations in heterogeneous datasets as hyperedges and fuse different datasets with a unified hypergraph structure. We use the hypergraph learning algorithm for predicting missing labels in the datasets. To allow users to inject their domain knowledge into the model-learning process, we augment the traditional learning algorithm in a number of ways. In addition, we also propose a set of visualizations which enable the user to construct the hypergraph structure and the parameters of the learning model interactively during the analysis. We demonstrate the capability of our approach via two real-world cases.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2906351914",
    "type": "article"
  },
  {
    "title": "Motion-Aware Compression and Transmission of Mesh Animation Sequences",
    "doi": "https://doi.org/10.1145/3300198",
    "publication_date": "2019-04-29",
    "publication_year": 2019,
    "authors": "Bailin Yang; Luhong Zhang; Frederick W. B. Li; Xiaoheng Jiang; Zhigang Deng; Meng Wang; Mingliang Xu",
    "corresponding_authors": "",
    "abstract": "With the increasing demand in using 3D mesh data over networks, supporting effective compression and efficient transmission of meshes has caught lots of attention in recent years. This article introduces a novel compression method for 3D mesh animation sequences, supporting user-defined and progressive transmissions over networks. Our motion-aware approach starts with clustering animation frames based on their motion similarities, dividing a mesh animation sequence into fragments of varying lengths. This is done by a novel temporal clustering algorithm, which measures motion similarity based on the curvature and torsion of a space curve formed by corresponding vertices along a series of animation frames. We further segment each cluster based on mesh vertex coherence, representing topological proximity within an object under certain motion. To produce a compact representation, we perform intra-cluster compression based on Graph Fourier Transform (GFT) and Set Partitioning In Hierarchical Trees (SPIHT) coding. Optimized compression results can be achieved by applying GFT due to the proximity in vertex position and motion. We adapt SPIHT to support progressive transmission and design a mechanism to transmit mesh animation sequences with user-defined quality. Experimental results show that our method can obtain a high compression ratio while maintaining a low reconstruction error.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2920797343",
    "type": "article"
  },
  {
    "title": "Estimating and Controlling the False Discovery Rate of the PC Algorithm Using Edge-specific P-Values",
    "doi": "https://doi.org/10.1145/3351342",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Eric V. Strobl; Peter Spirtes; Shyam Visweswaran",
    "corresponding_authors": "",
    "abstract": "Many causal discovery algorithms infer graphical structure from observational data. The PC algorithm in particular estimates a completed partially directed acyclic graph (CPDAG), or an acyclic graph containing directed edges identifiable with conditional independence testing. However, few groups have investigated strategies for estimating and controlling the false discovery rate (FDR) of the edges in the CPDAG. In this article, we introduce PC with p-values (PC-p), a fast algorithm that robustly computes edge-specific p-values and then estimates and controls the FDR across the edges. PC-p specifically uses the p-values returned by many conditional independence (CI) tests to upper bound the p-values of more complex edge-specific hypothesis tests. The algorithm then estimates and controls the FDR using the bounded p-values and the Benjamini-Yekutieli FDR procedure. Modifications to the original PC algorithm also help PC-p accurately compute the upper bounds despite non-zero Type II error rates. Experiments show that PC-p yields more accurate FDR estimation and control across the edges in a variety of CPDAGs compared to alternative methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2980191562",
    "type": "article"
  },
  {
    "title": "A learning-based contrarian trading strategy via a dual-classifier model",
    "doi": "https://doi.org/10.1145/1961189.1961192",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Szu-Hao Huang; Shang‐Hong Lai; Shih-Hsien Tai",
    "corresponding_authors": "",
    "abstract": "Behavioral finance is a relatively new and developing research field which adopts cognitive psychology and emotional bias to explain the inefficient market phenomenon and some irrational trading decisions. Unlike the experts in this field who tried to reason the price anomaly and applied empirical evidence in many different financial markets, we employ the advanced binary classification algorithms, such as AdaBoost and support vector machines, to precisely model the overreaction and strengthen the portfolio compositions of the contrarian trading strategies. The novelty of this article is to discover the financial time-series patterns through a high-dimensional and nonlinear model which is constructed by integrated knowledge of finance and machine learning techniques. We propose a dual-classifier learning framework to select candidate stocks from the past results of original contrarian trading strategies based on the defined learning targets. Three different feature extraction methods, including wavelet transformation, historical return distribution, and various technical indicators, are employed to represent these learning samples in a 381-dimensional financial time-series feature space. Finally, we construct the classifier models with four different learning kernels and prove that the proposed methods could improve the returns dramatically, such as the 3-year return that improved from 26.79% to 53.75%. The experiments also demonstrate significantly higher portfolio selection accuracy, improved from 57.47% to 66.41%, than the original contrarian trading strategy. To sum up, all these experiments show that the proposed method could be extended to an effective trading system in the historical stock prices of the leading U.S. companies of S&amp;P 100 index.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1982700162",
    "type": "article"
  },
  {
    "title": "Accurate and Robust Moving-Object Segmentation for Telepresence Systems",
    "doi": "https://doi.org/10.1145/2629480",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Meiyu Huang; Yiqiang Chen; Wen Ji; Chunyan Miao",
    "corresponding_authors": "",
    "abstract": "Moving-object segmentation is the key issue of Telepresence systems. With monocular camera--based segmentation methods, desirable segmentation results are hard to obtain in challenging scenes with ambiguous color, illumination changes, and shadows. Approaches based on depth sensors often cause holes inside the object and missegmentations on the object boundary due to inaccurate and unstable estimation of depth data. This work proposes an adaptive multi-cue decision fusion method based on Kinect (which integrates a depth sensor with an RGB camera). First, the algorithm obtains an initial foreground mask based on the depth cue. Second, the algorithm introduces a postprocessing framework to refine the segmentation results, which consists of two main steps: (1) automatically adjusting the weight of two weak decisions to identify foreground holes based on the color and contrast cue separately; and (2) refining the object boundary by integrating the motion probability weighted temporal prior, color likelihood, and smoothness constraint. The extensive experiments we conducted demonstrate that our method can segment moving objects accurately and robustly in various situations in real time.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2087315237",
    "type": "article"
  },
  {
    "title": "A Combined Approach Toward Consistent Reconstructions of Indoor Spaces Based on 6D RGB-D Odometry and KinectFusion",
    "doi": "https://doi.org/10.1145/2629673",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Nadia Figueroa; Haiwei Dong; Abdulmotaleb El Saddik",
    "corresponding_authors": "",
    "abstract": "We propose a 6D RGB-D odometry approach that finds the relative camera pose between consecutive RGB-D frames by keypoint extraction and feature matching both on the RGB and depth image planes. Furthermore, we feed the estimated pose to the highly accurate KinectFusion algorithm, which uses a fast ICP (Iterative Closest Point) to fine-tune the frame-to-frame relative pose and fuse the depth data into a global implicit surface. We evaluate our method on a publicly available RGB-D SLAM benchmark dataset by Sturm et al. The experimental results show that our proposed reconstruction method solely based on visual odometry and KinectFusion outperforms the state-of-the-art RGB-D SLAM system accuracy. Moreover, our algorithm outputs a ready-to-use polygon mesh (highly suitable for creating 3D virtual worlds) without any postprocessing steps.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2089982705",
    "type": "article"
  },
  {
    "title": "Exploiting User Preference for Online Learning in Web Content Optimization Systems",
    "doi": "https://doi.org/10.1145/2493259",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Jiang Bian; Bo Long; Lihong Li; Taesup Moon; Anlei Dong; Yi Chang",
    "corresponding_authors": "",
    "abstract": "Web portal services have become an important medium to deliver digital content (e.g. news, advertisements, etc.) to Web users in a timely fashion. To attract more users to various content modules on the Web portal, it is necessary to design a recommender system that can effectively achieve Web portal content optimization by automatically estimating content item attractiveness and relevance to user interests. The state-of-the-art online learning methodology adapts dedicated pointwise models to independently estimate the attractiveness score for each candidate content item. Although such pointwise models can be easily adapted for online recommendation, there still remain a few critical problems. First, this pointwise methodology fails to use invaluable user preferences between content items. Moreover, the performance of pointwise models decreases drastically when facing the problem of sparse learning samples. To address these problems, we propose exploring a new dynamic pairwise learning methodology for Web portal content optimization in which we exploit dynamic user preferences extracted based on users' actions on portal services to compute the attractiveness scores of content items. In this article, we introduce two specific pairwise learning algorithms, a straightforward graph-based algorithm and a formalized Bayesian modeling one. Experiments on large-scale data from a commercial Web portal demonstrate the significant improvement of pairwise methodologies over the baseline pointwise models. Further analysis illustrates that our new pairwise learning approaches can benefit personalized recommendation more than pointwise models, since the data sparsity is more critical for personalized content optimization.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2166967836",
    "type": "article"
  },
  {
    "title": "Understanding, Manipulating and Searching Hand-Drawn Concept Maps",
    "doi": "https://doi.org/10.1145/2036264.2036275",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Yingying Jiang; Feng Tian; Xiaolong Zhang; Guozhong Dai; Hongan Wang",
    "corresponding_authors": "",
    "abstract": "Concept maps are an important tool to organize, represent, and share knowledge. Building a concept map involves creating text-based concepts and specifying their relationships with line-based links. Current concept map tools usually impose specific task structures for text and link construction, and may increase cognitive burden to generate and interact with concept maps. While pen-based devices (e.g., tablet PCs) offer users more freedom in drawing concept maps with a pen or stylus more naturally, the support for hand-drawn concept map creation and manipulation is still limited, largely due to the lack of methods to recognize the components and structures of hand-drawn concept maps. This article proposes a method to understand hand-drawn concept maps. Our algorithm can extract node blocks, or concept blocks, and link blocks of a hand-drawn concept map by combining dynamic programming and graph partitioning, recognize the text content of each concept node, and build a concept-map structure by relating concepts and links. We also design an algorithm for concept map retrieval based on hand-drawn queries. With our algorithms, we introduce structure-based intelligent manipulation techniques and ink-based retrieval techniques to support the management and modification of hand-drawn concept maps. Results from our evaluation study show high structure recognition accuracy in real time of our method, and good usability of intelligent manipulation and retrieval techniques.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2170737442",
    "type": "article"
  },
  {
    "title": "MeTA",
    "doi": "https://doi.org/10.1145/2700479",
    "publication_date": "2015-07-15",
    "publication_year": 2015,
    "authors": "Dario Antonelli; Elena Baralis; Giulia Bruno; Luca Cagliero; Tania Cerquitelli; Silvia Chiusano; Paolo Garza; Naeem Ahmed Mahoto",
    "corresponding_authors": "",
    "abstract": "Physicians and health care organizations always collect large amounts of data during patient care. These large and high-dimensional datasets are usually characterized by an inherent sparseness. Hence, analyzing these datasets to figure out interesting and hidden knowledge is a challenging task. This article proposes a new data mining framework based on generalized association rules to discover multiple-level correlations among patient data. Specifically, correlations among prescribed examinations, drugs, and patient profiles are discovered and analyzed at different abstraction levels. The rule extraction process is driven by a taxonomy to generalize examinations and drugs into their corresponding categories. To ease the manual inspection of the result, a worthwhile subset of rules (i.e., nonredundant generalized rules) is considered. Furthermore, rules are classified according to the involved data features (medical treatments or patient profiles) and then explored in a top-down fashion: from the small subset of high-level rules, a drill-down is performed to target more specific rules. The experiments, performed on a real diabetic patient dataset, demonstrate the effectiveness of the proposed approach in discovering interesting rule groups at different abstraction levels.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2237308128",
    "type": "article"
  },
  {
    "title": "Measuring Conditional Independence by Independent Residuals for Causal Discovery",
    "doi": "https://doi.org/10.1145/3325708",
    "publication_date": "2019-09-20",
    "publication_year": 2019,
    "authors": "Hao Zhang; Shuigeng Zhou; Jihong Guan; Jun Huan",
    "corresponding_authors": "",
    "abstract": "We investigate the relationship between conditional independence (CI) x ⫫ y | Z and the independence of two residuals x −E( x | Z )⫫ y −E( y | Z ), where x and y are two random variables and Z is a set of random variables. We show that if x , y , and Z are generated by following linear structural equation models and all external influences follow joint Gaussian distribution, then x ⫫ y | Z if and only if x −E( x | Z )⫫ y −E( y | Z ). That is, the test of x ⫫ y | Z can be relaxed to a simpler unconditional independence test of x −E( x | Z )⫫ y −E( y | Z ). Furthermore, testing x −E( x | Z )⫫ y −E( y | Z ) can be simplified by testing x −E( x | Z )⫫ y or y −E( y | Z )⫫ x . On the other side, if all these external influences follow non-Gaussian distributions and the model satisfies structural faithfulness condition, then we have x ⫫ y | Z ⇔ x −E( x | Z )⫫ y −E( y | Z ). We apply the results above to the causal discovery problem, where the causal directions are generally determined by a set of V -structures and their consistent propagations, so CI test-based methods can return a set of Markov equivalence classes. We show that in the linear non-Gaussian context, in many cases x −E( x | Z )⫫ z or y −E( y | Z )⫫ z (∀ z ∈ Z and Z is a minimal d -separator) is satisfied when x −E( x | Z )⫫ y −E( y | Z ), which implies z causes x (or y ) if z directly connects to x (or y ). Therefore, we conclude that CIs have useful information for distinguishing Markov equivalence classes. In summary, comparing with the existing discretization-based and kernel-based CI testing methods, the proposed method provides a simpler way to measure CI, which needs only one unconditional independence test and two regression operations. When being applied to causal discovery, it can find more causal relationships, which is extensively validated by experiments.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2973451064",
    "type": "article"
  },
  {
    "title": "A Traffic Density Estimation Model Based on Crowdsourcing Privacy Protection",
    "doi": "https://doi.org/10.1145/3391707",
    "publication_date": "2020-05-22",
    "publication_year": 2020,
    "authors": "Yapei Huang; Yun Tian; Zhijie Liu; Xiaowei Jin; Yanan Liu; Shifeng Zhao; Daxin Tian",
    "corresponding_authors": "",
    "abstract": "Acquiring traffic condition information is of great significance in transportation guidance, urban planning, and route recommendation. To date, traffic density data are generally acquired by road sound analysis, video data analysis, or in-vehicle network communication, which are usually financially or temporally expensive. Another way to get traffic conditions is to collect track data by crowdsourcing. However, this way lead to a greater risk of leaking users’ privacy. To avoid the risk, this article proposes a traffic density estimation model based on crowdsourcing privacy protection. First, in the acquisition process of the track data by crowdsourcing, dual servers are employed for transmission, and homomorphic encryption is carried out to encrypt the data to protect the data from being leaked during transmission. Second, sampling is implemented for randomization and anonymization to reduce the spatial continuity and temporal continuity of position data. In this way, the intermediate server cannot acquire users’ original data, and the main server cannot obtain users’ personal information. Finally, before data transmission, Laplace noising is performed on the users’ local position data to further protect the original location information. The proposed algorithm in this study realizes that only users have their original track data, and the servers involved in the work cannot infer the original track data, which ensures the real security of user privacy. The proposed algorithm was verified with the track data from the Didi Gaia Data Opening Plan. The experimental results showed that the proposed algorithm could still maintain the validity of data analysis results and the security of user data privacy after homomorphic encryption, noise addition, and sample collection, and displayed good robustness and scalability.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3033454718",
    "type": "article"
  },
  {
    "title": "An Empirical Investigation of Different Classifiers, Encoding, and Ensemble Schemes for Next Event Prediction Using Business Process Event Logs",
    "doi": "https://doi.org/10.1145/3406541",
    "publication_date": "2020-09-11",
    "publication_year": 2020,
    "authors": "Bayu Adhi Tama; Marco Comuzzi; Jonghyeon Ko",
    "corresponding_authors": "",
    "abstract": "There is a growing need for empirical benchmarks that support researchers and practitioners in selecting the best machine learning technique for given prediction tasks. In this article, we consider the next event prediction task in business process predictive monitoring, and we extend our previously published benchmark by studying the impact on the performance of different encoding windows and of using ensemble schemes. The choice of whether to use ensembles and which scheme to use often depends on the type of data and classification task. While there is a general understanding that ensembles perform well in predictive monitoring of business processes, next event prediction is a task for which no other benchmarks involving ensembles are available. The proposed benchmark helps researchers to select a high-performing individual classifier or ensemble scheme given the variability at the case level of the event log under consideration. Experimental results show that choosing an optimal number of events for feature encoding is challenging, resulting in the need to consider each event log individually when selecting an optimal value. Ensemble schemes improve the performance of low-performing classifiers in this task, such as SVM, whereas high-performing classifiers, such as tree-based classifiers, are not better off when ensemble schemes are considered.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3085263925",
    "type": "article"
  },
  {
    "title": "Latent Unexpected Recommendations",
    "doi": "https://doi.org/10.1145/3404855",
    "publication_date": "2020-09-15",
    "publication_year": 2020,
    "authors": "Pan Li; Alexander Tuzhilin",
    "corresponding_authors": "",
    "abstract": "Unexpected recommender system constitutes an important tool to tackle the problem of filter bubbles and user boredom, which aims at providing unexpected and satisfying recommendations to target users at the same time. Previous unexpected recommendation methods only focus on the straightforward relations between current recommendations and user expectations by modeling unexpectedness in the feature space, thus resulting in the loss of accuracy measures to improve unexpectedness performance. In contrast to these prior models, we propose to model unexpectedness in the latent space of user and item embeddings, which allows us to capture hidden and complex relations between new recommendations and historic purchases. In addition, we develop a novel Latent Closure (LC) method to construct a hybrid utility function and provide unexpected recommendations based on the proposed model. Extensive experiments on three real-world datasets illustrate superiority of our proposed approach over the state-of-the-art unexpected recommendation models, which leads to significant increase in unexpectedness measure without sacrificing any accuracy metric under all experimental settings in this article.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3087223341",
    "type": "article"
  },
  {
    "title": "GTAE: Graph Transformer–Based Auto-Encoders for Linguistic-Constrained Text Style Transfer",
    "doi": "https://doi.org/10.1145/3448733",
    "publication_date": "2021-06-15",
    "publication_year": 2021,
    "authors": "Yukai Shi; Sen Zhang; Chenxing Zhou; Xiaodan Liang; Xiaojun Yang; Liang Lin",
    "corresponding_authors": "",
    "abstract": "Non-parallel text style transfer has attracted increasing research interests in recent years. Despite successes in transferring the style based on the encoder-decoder framework, current approaches still lack the ability to preserve the content and even logic of original sentences, mainly due to the large unconstrained model space or too simplified assumptions on latent embedding space. Since language itself is an intelligent product of humans with certain grammars and has a limited rule-based model space by its nature, relieving this problem requires reconciling the model capacity of deep neural networks with the intrinsic model constraints from human linguistic rules. To this end, we propose a method called Graph Transformer–based Auto-Encoder, which models a sentence as a linguistic graph and performs feature extraction and style transfer at the graph level, to maximally retain the content and the linguistic structure of original sentences. Quantitative experiment results on three non-parallel text style transfer tasks show that our model outperforms state-of-the-art methods in content preservation, while achieving comparable performance on transfer accuracy and sentence naturalness.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3167683763",
    "type": "article"
  },
  {
    "title": "BATS: A Spectral Biclustering Approach to Single Document Topic Modeling and Segmentation",
    "doi": "https://doi.org/10.1145/3468268",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Qiong Wu; Adam Hare; Sirui Wang; Yuwei Tu; Zhenming Liu; Christopher G. Brinton; Yanhua Li",
    "corresponding_authors": "",
    "abstract": "Existing topic modeling and text segmentation methodologies generally require large datasets for training, limiting their capabilities when only small collections of text are available. In this work, we reexamine the inter-related problems of “topic identification” and “text segmentation” for sparse document learning, when there is a single new text of interest. In developing a methodology to handle single documents, we face two major challenges. First is sparse information : with access to only one document, we cannot train traditional topic models or deep learning algorithms. Second is significant noise : a considerable portion of words in any single document will produce only noise and not help discern topics or segments. To tackle these issues, we design an unsupervised, computationally efficient methodology called Biclustering Approach to Topic modeling and Segmentation (BATS). BATS leverages three key ideas to simultaneously identify topics and segment text: (i) a new mechanism that uses word order information to reduce sample complexity, (ii) a statistically sound graph-based biclustering technique that identifies latent structures of words and sentences, and (iii) a collection of effective heuristics that remove noise words and award important words to further improve performance. Experiments on six datasets show that our approach outperforms several state-of-the-art baselines when considering topic coherence, topic diversity, segmentation, and runtime comparison metrics.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3207617013",
    "type": "article"
  },
  {
    "title": "Simultaneous Past and Current Social Interaction-aware Trajectory Prediction for Multiple Intelligent Agents in Dynamic Scenes",
    "doi": "https://doi.org/10.1145/3466182",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Yanliang Zhu; Dongchun Ren; Yi Xu; Deheng Qian; Mingyu Fan; Xin Li; Huaxia Xia",
    "corresponding_authors": "",
    "abstract": "Trajectory prediction of multiple agents in a crowded scene is an essential component in many applications, including intelligent monitoring, autonomous robotics, and self-driving cars. Accurate agent trajectory prediction remains a significant challenge because of the complex dynamic interactions among the agents and between them and the surrounding scene. To address the challenge, we propose a decoupled attention-based spatial-temporal modeling strategy in the proposed trajectory prediction method. The past and current interactions among agents are dynamically and adaptively summarized by two separate attention-based networks and have proven powerful in improving the prediction accuracy. Moreover, it is optional in the proposed method to make use of the road map and the plan of the ego-agent for scene-compliant and accurate predictions. The road map feature is efficiently extracted by a convolutional neural network, and the features of the ego-agent’s plan is extracted by a gated recurrent network with an attention module based on the temporal characteristic. Experiments on benchmark trajectory prediction datasets demonstrate that the proposed method is effective when the ego-agent plan and the the surrounding scene information are provided and achieves state-of-the-art performance with only the observed trajectories.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3215881685",
    "type": "article"
  },
  {
    "title": "“In-Network Ensemble”: Deep Ensemble Learning with Diversified Knowledge Distillation",
    "doi": "https://doi.org/10.1145/3473464",
    "publication_date": "2021-10-31",
    "publication_year": 2021,
    "authors": "Xingjian Li; Haoyi Xiong; Zeyu Chen; Jun Huan; Chengzhong Xu; Dejing Dou",
    "corresponding_authors": "",
    "abstract": "Ensemble learning is a widely used technique to train deep convolutional neural networks (CNNs) for improved robustness and accuracy. While existing algorithms usually first train multiple diversified networks and then assemble these networks as an aggregated classifier, we propose a novel learning paradigm, namely, “In-Network Ensemble” ( INE ) that incorporates the diversity of multiple models through training a SINGLE deep neural network. Specifically, INE segments the outputs of the CNN into multiple independent classifiers, where each classifier is further fine-tuned with better accuracy through a so-called diversified knowledge distillation process . We then aggregate the fine-tuned independent classifiers using an Averaging-and-Softmax operator to obtain the final ensemble classifier. Note that, in the supervised learning settings, INE starts the CNN training from random, while, under the transfer learning settings, it also could start with a pre-trained model to incorporate the knowledge learned from additional datasets. Extensive experiments have been done using eight large-scale real-world datasets, including CIFAR, ImageNet, and Stanford Cars, among others, as well as common deep network architectures such as VGG, ResNet, and Wide ResNet. We have evaluated the method under two tasks: supervised learning and transfer learning. The results show that INE outperforms the state-of-the-art algorithms for deep ensemble learning with improved accuracy.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4200409985",
    "type": "article"
  },
  {
    "title": "Combining Sketching and Traditional Diagram Editing Tools",
    "doi": "https://doi.org/10.1145/2631925",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Gem Stapleton; Beryl Plimmer; Aidan Delaney; Peter Rodgers",
    "corresponding_authors": "",
    "abstract": "The least cognitively demanding way to create a diagram is to draw it with a pen. Yet there is also a need for more formal visualizations, that is, diagrams created using both traditional keyboard and mouse interaction. Our objective is to allow the creation of diagrams using traditional and stylus-based input. Having two diagram creation interfaces requires that changes to a diagram should be automatically rendered in the other visualization. Because sketches are imprecise, there is always the possibility that conversion between visualizations results in a lack of syntactic consistency between the two visualizations. We propose methods for converting diagrams between forms, checking them for equivalence, and rectifying inconsistencies. As a result of our theoretical contributions, we present an intelligent software system allowing users to create and edit diagrams in sketch or formal mode. Our proof-of-concept tool supports diagrams with connected and spatial syntactic elements. Two user studies show that this approach is viable and participants found the software easy to use. We conclude that supporting such diagram creation is now possible in practice.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2027508318",
    "type": "article"
  },
  {
    "title": "Check-ins in “Blau Space”",
    "doi": "https://doi.org/10.1145/2566617",
    "publication_date": "2014-09-18",
    "publication_year": 2014,
    "authors": "Kenneth Joseph; Kathleen M. Carley; Jason Hong",
    "corresponding_authors": "",
    "abstract": "Peter Blau was one of the first to define a latent social space and utilize it to provide concrete hypotheses. Blau defines social structure via social “parameters” (constraints). Actors that are closer together (more homogenous) in this social parameter space are more likely to interact. One of Blau’s most important hypotheses resulting from this work was that the consolidation of parameters could lead to isolated social groups. For example, the consolidation of race and income might lead to segregation. In the present work, we use Foursquare data from New York City to explore evidence of homogeneity along certain social parameters and consolidation that breeds social isolation in communities of locations checked in to by similar users. More specifically, we first test the extent to which communities detected via Latent Dirichlet Allocation are homogenous across a set of four social constraints—racial homophily, income homophily, personal interest homophily and physical space. Using a bootstrapping approach, we find that 14 (of 20) communities are statistically, and all but one qualitatively, homogenous along one of these social constraints, showing the relevance of Blau’s latent space model in venue communities determined via user check-in behavior. We then consider the extent to which communities with consolidated parameters, those homogenous on more than one parameter, represent socially isolated populations. We find communities homogenous on multiple parameters, including a homosexual community and a “hipster” community, that show support for Blau’s hypothesis that consolidation breeds social isolation. We consider these results in the context of mediated communication, in particular in the context of self-representation on social media.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2071462283",
    "type": "article"
  },
  {
    "title": "Anytime Algorithms for Recommendation Service Providers",
    "doi": "https://doi.org/10.1145/2835496",
    "publication_date": "2016-02-11",
    "publication_year": 2016,
    "authors": "David Ben-Shimon; Lior Rokach; Guy Shani; Bracha Shapira",
    "corresponding_authors": "",
    "abstract": "Recommender systems (RS) can now be found in many commercial Web sites, often presenting customers with a short list of additional products that they might purchase. Many commercial sites do not typically have the ability and resources to develop their own system and may outsource the RS to a third party. This had led to the growth of a recommendation as a service industry, where companies, referred to as RS providers, provide recommendation services. These companies must carefully balance the cost of building recommendation models and the payment received from the e-business, as these payments are expected to be low. In such a setting, restricting the computational time required for model building is critical for the RS provider to be profitable. In this article, we propose anytime algorithms as an attractive method for balancing computational time and the recommendation model performance, thus tackling the RS provider problem. In an anytime setting, an algorithm can be stopped after any amount of computational time, always ensuring that a valid, although suboptimal, solution will be returned. Given sufficient time, however, the algorithm should converge to an optimal solution. In this setting, it is important to evaluate the quality of the returned solution over time, monitoring quality improvement. This is significantly different from traditional evaluation methods, which mostly estimate the performance of the algorithm only after its convergence is given sufficient time. We show that the popular item-item top-N recommendation approach can be brought into the anytime framework by smartly considering the order by which item pairs are being evaluated. We experimentally show that the time-accuracy trade-off can be significantly improved for this specific problem.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2321733270",
    "type": "article"
  },
  {
    "title": "Introduction to Intelligent Music Systems and Applications",
    "doi": "https://doi.org/10.1145/2991468",
    "publication_date": "2016-10-03",
    "publication_year": 2016,
    "authors": "Markus Schedl; Yi‐Hsuan Yang; Perfecto Herrera",
    "corresponding_authors": "",
    "abstract": "Intelligent technologies have become an essential part of music systems and applications. This is evidenced by today's omnipresence of digital online music stores and streaming services, which rely on music recommenders, automatic playlist generators, and music browsing interfaces. A large amount of research leading to intelligent music applications deals with the extraction of musical and acoustic information directly from the audio signal using signal processing techniques. Other strategies exploit contextual aspects of music, not present in the signal, for example, community meta-data and trails of user interaction, as found, for instance, on social media platforms. In this editorial, we discuss the notion of “intelligent music system” and give an overview of the papers selected to this special issue.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2528157630",
    "type": "article"
  },
  {
    "title": "Learning Contextualized Music Semantics from Tags Via a Siamese Neural Network",
    "doi": "https://doi.org/10.1145/2953886",
    "publication_date": "2016-10-21",
    "publication_year": 2016,
    "authors": "Ubai Sandouk; Ke Chen",
    "corresponding_authors": "",
    "abstract": "Music information retrieval faces a challenge in modeling contextualized musical concepts formulated by a set of co-occurring tags. In this article, we investigate the suitability of our recently proposed approach based on a Siamese neural network in fighting off this challenge. By means of tag features and probabilistic topic models, the network captures contextualized semantics from tags via unsupervised learning. This leads to a distributed semantics space and a potential solution to the out of vocabulary problem, which has yet to be sufficiently addressed. We explore the nature of the resultant music-based semantics and address computational needs. We conduct experiments on three public music tag collections—namely, CAL500, MagTag5K and Million Song Dataset—and compare our approach to a number of state-of-the-art semantics learning approaches. Comparative results suggest that this approach outperforms previous approaches in terms of semantic priming and music tag completion.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W785481131",
    "type": "article"
  },
  {
    "title": "Guidelines for the Regularization of Gammas in Batch Normalization for Deep Residual Networks",
    "doi": "https://doi.org/10.1145/3643860",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Bum Jun Kim; Hyeyeon Choi; Hyeonah Jang; Sang Woo Kim",
    "corresponding_authors": "",
    "abstract": "L 2 regularization for weights in neural networks is widely used as a standard training trick. In addition to weights, the use of batch normalization involves an additional trainable parameter γ, which acts as a scaling factor. However, L 2 regularization for γ remains an undiscussed mystery and is applied in different ways depending on the library and practitioner. In this article, we study whether L 2 regularization for γ is valid. To explore this issue, we consider two approaches: (1) variance control to make the residual network behave like an identity mapping and (2) stable optimization through the improvement of effective learning rate. Through two analyses, we specify the desirable and undesirable γ to apply L 2 regularization and propose four guidelines for managing them. In several experiments, we observed that applying L 2 regularization to applicable γ increased 1% to 4% classification accuracy, whereas applying L 2 regularization to inapplicable γ decreased 1% to 3% classification accuracy, which is consistent with our four guidelines. Our proposed guidelines were further validated through various tasks and architectures, including variants of residual networks and transformers.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391436329",
    "type": "article"
  },
  {
    "title": "Multimodal Dialogue Systems via Capturing Context-aware Dependencies and Ordinal Information of Semantic Elements",
    "doi": "https://doi.org/10.1145/3645099",
    "publication_date": "2024-03-12",
    "publication_year": 2024,
    "authors": "Weidong He; Zhi Li; Hao Wang; Tong Xu; Zhefeng Wang; Baoxing Huai; Nicholas Jing Yuan; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "The topic of multimodal conversation systems has recently garnered significant attention across various industries, including travel and retail, among others. While pioneering works in this field have shown promising performance, they often focus solely on context information at the utterance level, overlooking the context-aware dependencies of multimodal semantic elements like words and images. Furthermore, the ordinal information of images, which indicates the relevance between visual context and users’ demands, remains underutilized during the integration of visual content. Additionally, the exploration of how to effectively utilize corresponding attributes provided by users when searching for desired products is still largely unexplored. To address these challenges, we propose PMATE, a P osition-aware M ultimodal di A logue system with seman T ic E lements. Specifically, to obtain semantic representations at the element level, we first unfold the multimodal historical utterances and devise a position-aware multimodal element-level encoder. This component considers all images that may be relevant to the current turn and introduces a novel position-aware image selector to choose related images before fusing the information from the two modalities. Finally, we present a knowledge-aware two-stage decoder and an attribute-enhanced image searcher for the tasks of generating textual responses and selecting image responses, respectively. We extensively evaluate our model on two large-scale multimodal dialogue datasets, and the results of our experiments demonstrate that our approach outperforms several baseline methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4392715767",
    "type": "article"
  },
  {
    "title": "A Meta-Learning Framework for Tuning Parameters of Protection Mechanisms in Trustworthy Federated Learning",
    "doi": "https://doi.org/10.1145/3652612",
    "publication_date": "2024-03-18",
    "publication_year": 2024,
    "authors": "Xiaojin Zhang; Yan Kang; Lixin Fan; Kai Chen; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Trustworthy federated learning typically leverages protection mechanisms to guarantee privacy. However, protection mechanisms inevitably introduce utility loss or efficiency reduction while protecting data privacy. Therefore, protection mechanisms and their parameters should be carefully chosen to strike an optimal tradeoff among privacy leakage , utility loss , and efficiency reduction . To this end, federated learning practitioners need tools to measure the three factors and optimize the tradeoff between them to choose the protection mechanism that is most appropriate to the application at hand. Motivated by this requirement, we propose a framework that (1) formulates trustworthy federated learning as a problem of finding a protection mechanism to optimize the tradeoff among privacy leakage, utility loss, and efficiency reduction and (2) formally defines bounded measurements of the three factors. We then propose a meta-learning algorithm to approximate this optimization problem and find optimal protection parameters for representative protection mechanisms, including randomization, homomorphic encryption, secret sharing, and compression. We further design estimation algorithms to quantify these found optimal protection parameters in a practical horizontal federated learning setting and provide a theoretical analysis of the estimation error.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4392910956",
    "type": "article"
  },
  {
    "title": "Robust Structure-Aware Graph-based Semi-Supervised Learning: Batch and Recursive Processing",
    "doi": "https://doi.org/10.1145/3653986",
    "publication_date": "2024-03-26",
    "publication_year": 2024,
    "authors": "Xu Chen",
    "corresponding_authors": "Xu Chen",
    "abstract": "Graph-based semi-supervised learning plays an important role in large scale image classification tasks. However, the problem becomes very challenging in the presence of noisy labels and outliers. Moreover, traditional robust semi-supervised learning solutions suffers from prohibitive computational burdens thus cannot be computed for streaming data. Motivated by that, we present a novel unified framework robust structure-aware semi-supervised learning called Unified RSSL (URSSL) for batch processing and recursive processing robust to both outliers and noisy labels. Particularly, URSSL applies joint semi-supervised dimensionality reduction with robust estimators and network sparse regularization simultaneously on the graph Laplacian matrix iteratively to preserve the intrinsic graph structure and ensure robustness to the compound noise. First, in order to relieve the influence from outliers, a novel semi-supervised robust dimensionality reduction is applied relying on robust estimators to suppress outliers. Meanwhile, to tackle noisy labels, the denoised graph similarity information is encoded into the network regularization. Moreover, by identifying strong relevance of dimensionality reduction and network regularization in the context of robust semi-supervised learning (RSSL), a two-step alternative optimization is derived to compute optimal solutions with guaranteed convergence. We further derive our framework to adapt to large scale semi-supervised learning particularly suitable for large scale image classification and demonstrate the model robustness under different adversarial attacks. For recursive processing, we rely on reparameterization to transform the formulation to unlock the challenging problem of robust streaming-based semi-supervised learning. Last but not least, we extend our solution into distributed solutions to resolve the challenging issue of distributed robust semi-supervised learning when images are captured by multiple cameras at different locations. Extensive experimental results demonstrate the promising performance of this framework when applied to multiple benchmark datasets with respect to state-of-the-art approaches for important applications in the areas of image classification and spam data analysis.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4393191472",
    "type": "article"
  },
  {
    "title": "Discovering Expert-Level Air Combat Knowledge via Deep Excitatory-Inhibitory Factorized Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3653979",
    "publication_date": "2024-03-27",
    "publication_year": 2024,
    "authors": "Haiyin Piao; Shengqi Yang; Hechang Chen; Junnan Li; Jin Yu; Xuanqi Peng; Xin Yang; Zhen Yang; Zhixiao Sun; Yi Chang",
    "corresponding_authors": "",
    "abstract": "Artificial Intelligence (AI) has achieved a wide range of successes in autonomous air combat decision-making recently. Previous research demonstrated that AI-enabled air combat approaches could even acquire beyond human-level capabilities. However, there remains a lack of evidence regarding two major difficulties. First, the existing methods with fixed decision intervals are mostly devoted to solving what to act but merely pay attention to when to act, which occasionally misses optimal decision opportunities. Second, the method of an expert-crafted finite maneuver library leads to a lack of tactics diversity, which is vulnerable to an opponent equipped with new tactics. In view of this, we propose a novel Deep Reinforcement Learning (DRL) and prior knowledge hybrid autonomous air combat tactics discovering algorithm, namely deep E xcitatory-i N hibitory f ACT or I zed maneu VE r ( ENACTIVE ) learning. The algorithm consists of two key modules, i.e., ENHANCE and FACTIVE. Specifically, ENHANCE learns to adjust the air combat decision-making intervals and appropriately seize key opportunities. FACTIVE factorizes maneuvers and then jointly optimizes them with significant tactics diversity increments. Extensive experimental results reveal that the proposed method outperforms state-of-the-art algorithms with a 62% winning rate and further obtains a margin of a 2.85-fold increase in terms of global tactic space coverage. It also demonstrates that a variety of discovered air combat tactics are comparable to human experts’ knowledge.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4393224853",
    "type": "article"
  },
  {
    "title": "Counterfactual Graph Convolutional Learning for Personalized Recommendation",
    "doi": "https://doi.org/10.1145/3655632",
    "publication_date": "2024-04-01",
    "publication_year": 2024,
    "authors": "Meng Jian; Yulong Bai; Xusong Fu; Jingjing Guo; Ge Shi; Lifang Wu",
    "corresponding_authors": "",
    "abstract": "Recently, recommender systems have witnessed the fast evolution of Internet services. However, it suffers hugely from inherent bias and sparsity issues in interactions. The conventional uniform embedding learning policies fail to utilize the imbalanced interaction clue and produce suboptimal representations to users and items for recommendation. Towards the issue, this work is dedicated to bias-aware embedding learning in a decomposed manner and proposes a counterfactual graph convolutional learning (CGCL) model for personalized recommendation. Instead of debiasing with uniform interaction sampling, we follow the natural interaction bias to model users’ interests with a counterfactual hypothesis. CGCL introduces bias-aware counterfactual masking on interactions to distinguish the effects between majority and minority causes on the counterfactual gap. It forms multiple counterfactual worlds to extract users’ interests in minority causes compared to the factual world. Concretely, users and items are represented with a causal decomposed embedding of majority and minority interests for recommendation. Experiments show that the proposed CGCL is superior to the state-of-the-art baselines. The performance illustrates the rationality of the counterfactual hypothesis in bias-aware embedding learning for personalized recommendation.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4393379133",
    "type": "article"
  },
  {
    "title": "A Trustworthy and Responsible Decision-Making Framework for Resource Management in Food-Energy-Water Nexus: A Control-Theoretical Approach",
    "doi": "https://doi.org/10.1145/3660640",
    "publication_date": "2024-04-23",
    "publication_year": 2024,
    "authors": "Süleyman Uslu; Davinder Kaur; Samuel J. Rivera; Arjan Durresi; Meghna Babbar‐Sebens; Jenna H. Tilt",
    "corresponding_authors": "",
    "abstract": "This paper introduces a hybrid framework for trustworthy and responsible natural resource management, aimed at building bottom-up trust to enhance cooperation among decision makers in the Food, Energy, and Water sectors. Cooperation is highly critical for the adoption and application of resource management alternatives (solutions), including those generated by AI-based recommender systems, in communities due to significant impact of these sectors on the environment and the economic productivity of affected communities. While algorithms can recommend solutions, effectively communicating and gaining community acceptance of these solutions is crucial. Our research stands out by emphasizing the collaboration between humans and machines, which is essential for addressing broader challenges related to climate change and the need for expert trade-off handling in the management of natural resources. To support future decision-making, we propose a successful control-theory model based on previous decision-making and actor behavior. We utilize control theory to depict how community decisions can be affected by how much individuals trust and accept proposed solutions on irrigation water rights and crop operations in an iterative and interactive decision support environment. This model interacts with stakeholders to collect their feedback on the acceptability of solutions, while also examining the influence of consensus levels, trust sensitivities, and the number of decision-making rounds on the acceptance of proposed solutions. Furthermore, we investigate a system of multiple decision-making and explore the impact of learning actors who adjust their trust sensitivities based on solution acceptance and the number of decision-making rounds. Additionally, our approach can be employed to evaluate and refine potential policy modifications. Although we assess potential outcomes using hypothetical actions by individuals, it is essential to emphasize our primary objective of developing a tool that accurately captures real human behavior and fosters improved collaboration in community decision-making. Ultimately, our aim is to enhance the harmony between AI-based recommender systems and human values, promoting a deeper understanding and integration between the two.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4395032750",
    "type": "article"
  },
  {
    "title": "Analyzing Robustness of Automatic Scientific Claim Verification Tools against Adversarial Rephrasing Attacks",
    "doi": "https://doi.org/10.1145/3663481",
    "publication_date": "2024-05-02",
    "publication_year": 2024,
    "authors": "Janet Layne; Qudrat E Alahy Ratul; Edoardo Serra; Sushil Jajodia",
    "corresponding_authors": "",
    "abstract": "The coronavirus pandemic has fostered an explosion of misinformation about the disease, including the risk and effectiveness of vaccination. AI tools for automatic Scientific Claim Verification (SCV) can be crucial to defeat misinformation campaigns spreading through social media channels. However, over the past years, many concerns have been raised about the robustness of AI to adversarial attacks, and the field of automatic SCV is not exempt. The risk is that such SCV tools may reinforce and legitimize the spread of fake scientific claims rather than refute them. This article investigates the problem of generating adversarial attacks for SCV tools and shows that it is far more difficult than the generic NLP adversarial attack problem. The current NLP adversarial attack generators, when applied to SCV, often generate modified claims with entirely different meaning from the original. Even when the meaning is preserved, the modification of the generated claim is too simplistic (only a single word is changed), leaving many weaknesses of the SCV tools undiscovered. We propose T5-ParEvo, an iterative evolutionary attack generator, that is able to generate more complex and creative attacks while better preserving the semantics of the original claim. Using detailed quantitative and qualitative analyses, we demonstrate the efficacy of T5-ParEvo in comparison with existing attack generators.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4396573684",
    "type": "article"
  },
  {
    "title": "Neural Methods for Data-to-text Generation",
    "doi": "https://doi.org/10.1145/3660639",
    "publication_date": "2024-05-08",
    "publication_year": 2024,
    "authors": "Mandar Sharma; Ajay Kumar Gogineni; Naren Ramakrishnan",
    "corresponding_authors": "Mandar Sharma",
    "abstract": "The neural boom that has sparked natural language processing (NLP) research throughout the last decade has similarly led to significant innovations in data-to-text (D2T) generation. This survey offers a consolidated view into the neural D2T paradigm with a structured examination of the approaches, benchmark datasets, and evaluation protocols. This survey draws boundaries separating D2T from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella. With this holistic view, we highlight promising avenues for D2T research that focus not only on the design of linguistically capable systems but also on systems that exhibit fairness and accountability.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4396736930",
    "type": "article"
  },
  {
    "title": "Fine-grained Courier Delivery Behavior Recovery with a Digital Twin Based Iterative Calibration Framework",
    "doi": "https://doi.org/10.1145/3663484",
    "publication_date": "2024-06-13",
    "publication_year": 2024,
    "authors": "Fudan Yu; Guozhen Zhang; Haotian Wang; Depeng Jin; Yong Li",
    "corresponding_authors": "",
    "abstract": "Recovering the fine-grained working process of couriers is becoming one of the essential problems for improving the express delivery systems because knowing the detailed process of how couriers accomplish their daily work facilitates the analyzing, understanding, and optimizing of the working procedure. Although coarse-grained courier trajectories and waybill delivery time data can be collected, this problem is still challenging due to noisy data with spatio-temporal biases, lacking ground truth of couriers’ fine-grained behaviors, and complex correlations between behaviors. Existing works typically focus on a single dimension of the process such as inferring the delivery time, and can only yield results of low spatio-temporal resolution, which cannot address the problem well. To bridge the gap, we propose a digital-twin-based iterative calibration system (DTRec) for fine-grained courier working process recovery. We first propose a spatio-temporal bias correction algorithm, which systematically improves existing methods in correcting waybill addresses and trajectory stay points. Second, to model the complex correlations among behaviors and inherent physical constraints, we propose an agent-based model to build the digital twin of couriers. Third, to further improve recovery performance, we design a digital-twin-based iterative calibration framework, which leverages the inconsistency between the deduction results of the digital twin and the recovery results from real-world data to improve both the agent-based model and the recovery results. Experiments show that DTRec outperforms state-of-the-art baselines by 10.8% in terms of fine-grained accuracy on real-world datasets. The system is deployed in the industrial practices in JD logistics with promising applications. The code is available at https://github.com/tsinghua-fib-lab/Courier-DTRec .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4399632713",
    "type": "article"
  },
  {
    "title": "The Social Cognition Ability Evaluation of LLMs: A Dynamic Gamified Assessment and Hierarchical Social Learning Measurement Approach",
    "doi": "https://doi.org/10.1145/3673238",
    "publication_date": "2024-06-18",
    "publication_year": 2024,
    "authors": "Qin Ni; Yangze Yu; Yiming Ma; Xin Lin; Ciping Deng; Tingjiang Wei; Mo Xuan",
    "corresponding_authors": "",
    "abstract": "Large Language Model(LLM) has shown amazing abilities in reasoning tasks, theory of mind(ToM) has been tested in many studies as part of reasoning tasks, and social learning, which is closely related to theory of mind, are still lack of investigation. However, the test methods and materials make the test results unconvincing. We propose a dynamic gamified assessment(DGA) and hierarchical social learning measurement to test ToM and social learning capacities in LLMs. The test for ToM consists of five parts. First, we extract ToM tasks from ToM experiments and then design game rules to satisfy the ToM task requirement. After that, we design ToM questions to match the game’s rules and use these to generate test materials. Finally, we go through the above steps to test the model. To assess the social learning ability, we introduce a novel set of social rules (three in total). Experiment results demonstrate that, except GPT-4, LLMs performed poorly on the ToM test but showed a certain level of social learning ability in social learning measurement.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4399777803",
    "type": "article"
  },
  {
    "title": "Gradient-Based Adversarial Training on Transformer Networks for Detecting Check-Worthy Factual Claims",
    "doi": "https://doi.org/10.1145/3689212",
    "publication_date": "2024-08-20",
    "publication_year": 2024,
    "authors": "Kevin Meng; D. Jimenez; Jacob Devasier; Sai Sandeep Naraparaju; Fatma Arslan; Daniel Obembe; Chengkai Li",
    "corresponding_authors": "",
    "abstract": "This article presents the latest developments to ClaimBuster’s claim-spotting model, which tackles the critical task of identifying check-worthy claims from large streams of information. We introduce the first adversarially regularized, transformer-based claim-spotting model, which achieves state-of-the-art results on several benchmark datasets. In addition to analyzing model performance metrics, we also quantitatively and qualitatively analyze the impact of ClaimBuster’s real-world deployment. Moreover, to help facilitate reproducibility and community engagement, we publicly release our codebase, dataset, data curation platform, API, Google Colab notebooks, and various ClaimBuster-based demo systems, at claimbuster.org .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401972929",
    "type": "article"
  },
  {
    "title": "RCCNet: A Spatial-Temporal Neural Network Model for Logistics Delivery Timely Rate Prediction",
    "doi": "https://doi.org/10.1145/3690649",
    "publication_date": "2024-08-29",
    "publication_year": 2024,
    "authors": "Jinhui Yi; Huan Yan; Haotian Wang; Jian Yuan; Yong Li",
    "corresponding_authors": "",
    "abstract": "In logistics service, the delivery timely rate is a key experience indicator, which is highly essential to the competitive advantage of express companies. Prediction on it enables intervention on couriers with low predicted results in advance, thus ensuring employee productivity and customer satisfaction. Currently, few related works focus on couriers’ level delivery timely rate prediction, and there are complex spatial correlations between couriers and road districts in the express scenario, which makes traditional real-time prediction approaches hard to utilize. To deal with this, we propose a deep spatial-temporal neural network, RCCNet to model spatial-temporal correlations. Specifically, we adopt Node2vec, which can encode the road network-based graph directly to capture spatial correlations between road districts. Further, we calculate couriers’ historical time-series similarity to build a graph and employ graph convolutional networks to capture the correlation between couriers. We also leverage historical sequential information with long short-term memory networks. We conduct experiments with real-world express datasets. Compared with other competitive baseline methods widely used in industry, the experiment results demonstrate its superior performance over multiple baselines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401991580",
    "type": "article"
  },
  {
    "title": "KGDA: A Knowledge Graph Driven Decomposition Approach for Cellular Traffic Prediction",
    "doi": "https://doi.org/10.1145/3690650",
    "publication_date": "2024-08-29",
    "publication_year": 2024,
    "authors": "Jiahui Gong; Tong Li; Huandong Wang; Yu Liu; Xing Wang; Zhendong Wang; Chao Deng; Junlan Feng; Depeng Jin; Yong Li",
    "corresponding_authors": "",
    "abstract": "Understanding and accurately predicting cellular traffic data is vital for communication operators and device users, as it facilitates efficient resource allocation and ensures superior service quality. However, large-scale cellular traffic data forecasting remains challenging due to intricate temporal variations and complex spatial relationships. This article proposes a Knowledge Graph Driven Decomposition Approach (KGDA) for precise cellular traffic prediction. The KGDA breaks down the impact of static environmental factors and dynamic autocorrelations of cellular traffic time series, enabling the capture of overall traffic changes and understanding of traffic dependence on past values. Specifically, we propose an urban knowledge graph to capture the static environmental context of base stations, mapping these entities into the same latent space while retaining static environmental knowledge. The cellular traffic is divided into a regular pattern and fluctuating residual components, with the KGDA comprising four modules: a Knowledge Graph Representation Learning model, a traffic regular pattern prediction module, a traffic residual dynamic prediction module, and an attentional fusion module. The first leverages graph neural networks to extract spatial contexts and predict regular patterns, the second utilizes the Bi-directional Long Short-Term Memory (Bi-LSTM) model to capture autocorrelations of traffic time series, and the final module integrates the patterns and residuals to produce the final prediction result. Comprehensive experiments demonstrate that our proposed model outperforms state-of-the-art models by more than 10% in forecasting cellular traffic.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401995317",
    "type": "article"
  },
  {
    "title": "User opinion-focused abstractive summarization using explainable artificial intelligence",
    "doi": "https://doi.org/10.1145/3696456",
    "publication_date": "2024-09-21",
    "publication_year": 2024,
    "authors": "Hyunho Lee; Younghoon Lee",
    "corresponding_authors": "",
    "abstract": "Recent methodologies have achieved good performance in objectively summarizing important information from fact-based datasets such as XSUM and CNN/DM. These methodologies involve abstractive summarization, extracting the core content from an input text and transforming it into natural sentences. Unlike fact-based documents, opinion-based documents require a thorough analysis of sentiment and understanding of the writer’s intention. However, existing models do not explicitly consider these factors. Therefore, in this study, we propose a novel text summarization model that is specifically designed for opinion-based documents. Specifically, we identify the sentiment distribution of the entire document and train the summarization model to focus on major opinions that conform to the intended message while randomly masking minor opinions. Experimental results show that the proposed model outperforms existing summarization models in summarizing opinion-based documents, effectively capturing and highlighting the main opinions in the generated abstractive summaries.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4402709845",
    "type": "article"
  },
  {
    "title": "Fast and Accurate Evacuation Planning Algorithm with Bayesian Optimization",
    "doi": "https://doi.org/10.1145/3704920",
    "publication_date": "2024-11-18",
    "publication_year": 2024,
    "authors": "Junpei Tokunaga; Yuki Kikukawa; Hiroyuki Ebara; Naonori Ueda",
    "corresponding_authors": "",
    "abstract": "In this work, we propose a method for generating an evacuation plan at a high speed to realize safe and swift evacuation in the event of a large-scale disaster such as an earthquake and its accompanying tsunami. Existing conventional methods have several problems. Simulation-based methods that use agents and methods that use existing time expansion networks have high computational costs, which makes it difficult for evacuation routes to be immediately changed according to the effects of disasters such as collapsed buildings and roads. Although heuristics with reduced calculation costs are also being researched, they may result in very long evacuation completion times and cannot generate optimal evacuation plans. We guarantee the optimal solution by reducing the number of maximum flow problem calculations, which constitute the bottleneck for methods using the existing time expansion network, through the use of the Bayesian optimization machine learning method. This reduces the calculation cost of the entire algorithm. The performance of our method is evaluated from the two viewpoints of the evacuation completion time, which indicates the quality of the evacuation plan, and the time required for the generation by the solution of the algorithm in computer experiments under multiple scenarios. In addition, the impact of the number of evacuees and the locations of the sinks are analyzed. We show that our method can quickly generate an optimal evacuation plan.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4404467181",
    "type": "article"
  },
  {
    "title": "Concept Drift Adaptation in Text Stream Mining Settings: A Systematic Review",
    "doi": "https://doi.org/10.1145/3704922",
    "publication_date": "2024-11-21",
    "publication_year": 2024,
    "authors": "Cristiano Mesquita Garcia; Ramón Abilio; Alessandro L. Koerich; Alceu de Souza Britto; Jean Paul Barddal",
    "corresponding_authors": "",
    "abstract": "The society produces textual data online in several ways, e.g. , via reviews and social media posts. Therefore, numerous researchers have been working on discovering patterns in textual data that can indicate peoples’ opinions, interests, etc . Most tasks regarding natural language processing are addressed using traditional machine learning methods and static datasets. This setting can lead to several problems, e.g. , outdated datasets and models, which degrade in performance over time. This is particularly true regarding concept drift, in which the data distribution changes over time. Furthermore, text streaming scenarios also exhibit further challenges, such as the high speed at which data arrives over time. Models for stream scenarios must adhere to the aforementioned constraints while learning from the stream, thus storing texts for limited periods and consuming low memory. This study presents a systematic literature review regarding concept drift adaptation in text stream scenarios. Considering well-defined criteria, we selected 48 papers published between 2018 and August 2024 to unravel aspects such as text drift categories, detection types, model update mechanisms, stream mining tasks addressed, and text representation methods and their update mechanisms. Furthermore, we discussed drift visualization and simulation and listed real-world datasets used in the selected papers. Finally, we brought forward a discussion on existing works in the area, also highlighting open challenges and future research directions for the community.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4404573142",
    "type": "review"
  },
  {
    "title": "Cascaded Alternating Refinement Transformer for Few-shot Medical Image Segmentation",
    "doi": "https://doi.org/10.1145/3709145",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Ziming Cheng; Yazhou Zhu; Shidong Wang; Tong Xin; Haofeng Zhang",
    "corresponding_authors": "",
    "abstract": "Conventional biomedical image segmentation heavily relies on substantial annotations, which demand significant human and financial resources for collection. Consequently, learning a model with excellent performance using limited medical image data becomes a challenging problem. Upliftingly, the advent of few-shot medical image segmentation (FSMIS) offers a potential solution. Although prototypical networks are commonly employed in existing FSMIS tasks, the prototypes derived from support features often induce significant bias issues caused by intra-class variations. To this end, we propose a method called Cascaded Altering Refinement Transformer (CART) to iteratively calibrate the prototypes with both support and query features. This method focuses on capturing the commonality between foreground information of the support and query features using the Alterating Refinement Transformer (ART) module, which includes two Multi-head Cross Attention (MCA) modules. Furthermore, we cascade ART modules to refine the class prototypes, resulting in representative prototypes. This process ultimately contributes to a more accurate predicted mask. Besides, to preserve more valid information in each cascaded ART module and achieve better performance, we propose a novel inference method that accumulates the predicted segmentation masks in all ART modules by applying the Rounding-Up strategy. Extensive experiments on three public medical image datasets demonstrate that our model outperforms the state-of-the-art methods, and detailed analysis also validates the reasonableness of this design. Code is available at: https://github.com/zmcheng9/CART .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4405638131",
    "type": "article"
  },
  {
    "title": "Structured coalitions in resource selection games",
    "doi": "https://doi.org/10.1145/1858948.1858952",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Michal Feldman; Moshe Tennenholtz",
    "corresponding_authors": "",
    "abstract": "We study stability against coalitional deviations in resource selection games where the coalitions have a certain structure . In particular, the agents are partitioned into coalitions, and only deviations by the prescribed coalitions are considered. This is in contrast to the classical concept of strong equilibrium according to which any subset of the agents may deviate. In resource selection games, each agent selects a resource from a set of resources, and its payoff is an increasing (or nondecreasing) function of the number of agents selecting its resource. While it has been shown that a strong equilibrium always exists in resource selection games, a closer look reveals severe limitations to the applicability of the existence result even in the simplest case of two identical resources with increasing cost functions. First, these games do not possess a super strong equilibrium in which a fruitful deviation benefits at least one deviator without hurting any other deviator. Second, a strong equilibrium may not exist when the game is played repeatedly. We prove that for any given partition, there exists a super strong equilibrium for resource selection games of identical resources with increasing cost functions. In addition, we show similar existence results for a variety of other classes of resource selection games. For the case of repeated games, we characterize partitions that guarantee the existence of a strong equilibrium. Together, our work introduces a natural concept, which turns out to lead to positive and applicable results in one of the basic domains studied in the literature.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1966186436",
    "type": "article"
  },
  {
    "title": "Evolution of state-dependent risk preferences",
    "doi": "https://doi.org/10.1145/1858948.1858954",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Patrick Roos; J. Ryan Carr; Dana Nau",
    "corresponding_authors": "",
    "abstract": "Researchers have invested much effort in constructing models of the state-dependent (sometimes risk-averse and sometimes risk-prone) nature of human decision making. An important open question is how state-dependent risk behavior can arise and remain prominent in populations. We believe that one part of the answer is the interplay between risk-taking and sequentiality of choices in populations subject to evolutionary population dynamics. To support this hypothesis, we provide simulation and analytical results for evolutionary lottery games, including results on evolutionary stability. We consider a parameterized class of imitation dynamics in which the parameter 0 ≤ α ≤ 1 yields the replicator dynamic with α = 1 and the imitate-the-better dynamic with α = 0. Our results demonstrate that for every population dynamic in this class except for the replicator dynamic, the interplay between risk-taking and sequentiality of choices allows state-dependent risk behavior to have an evolutionary advantage over expected-value maximization.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1993351496",
    "type": "article"
  },
  {
    "title": "Exploiting Multilabel Information for Noise-Resilient Feature Selection",
    "doi": "https://doi.org/10.1145/3158675",
    "publication_date": "2018-06-27",
    "publication_year": 2018,
    "authors": "Ling Jian; Jundong Li; Huan Liu",
    "corresponding_authors": "",
    "abstract": "In a conventional supervised learning paradigm, each data instance is associated with one single class label. Multilabel learning differs in the way that data instances may belong to multiple concepts simultaneously, which naturally appear in a variety of high impact domains, ranging from bioinformatics and information retrieval to multimedia analysis. It targets leveraging the multiple label information of data instances to build a predictive learning model that can classify unlabeled instances into one or multiple predefined target classes. In multilabel learning, even though each instance is associated with a rich set of class labels, the label information could be noisy and incomplete as the labeling process is both time consuming and labor expensive, leading to potential missing annotations or even erroneous annotations. The existence of noisy and missing labels could negatively affect the performance of underlying learning algorithms. More often than not, multilabeled data often has noisy, irrelevant, and redundant features of high dimensionality. The existence of these uninformative features may also deteriorate the predictive power of the learning model due to the curse of dimensionality. Feature selection, as an effective dimensionality reduction technique, has shown to be powerful in preparing high-dimensional data for numerous data mining and machine-learning tasks. However, a vast majority of existing multilabel feature selection algorithms either boil down to solving multiple single-labeled feature selection problems or directly make use of the imperfect labels to guide the selection of representative features. As a result, they may not be able to obtain discriminative features shared across multiple labels. In this article, to bridge the gap between a rich source of multilabel information and its blemish in practical usage, we propose a novel noise-resilient multilabel informed feature selection framework (MIFS) by exploiting the correlations among different labels. In particular, to reduce the negative effects of imperfect label information in obtaining label correlations, we decompose the multilabel information of data instances into a low-dimensional space and then employ the reduced label representation to guide the feature selection phase via a joint sparse regression framework. Empirical studies on both synthetic and real-world datasets demonstrate the effectiveness and efficiency of the proposed MIFS framework.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2810893494",
    "type": "article"
  },
  {
    "title": "Multifocal learning for customer problem analysis",
    "doi": "https://doi.org/10.1145/1961189.1961196",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Yong Ge; Hui Xiong; Wenjun Zhou; Siming Li; Ramendra K. Sahoo",
    "corresponding_authors": "",
    "abstract": "In this study, we formalize a multifocal learning problem, where training data are partitioned into several different focal groups and the prediction model will be learned within each focal group. The multifocal learning problem is motivated by numerous real-world learning applications. For instance, for the same type of problems encountered in a customer service center, the problem descriptions from different customers can be quite different. Experienced customers usually give more precise and focused descriptions about the problem. In contrast, inexperienced customers usually provide diverse descriptions. In this case, the examples from the same class in the training data can be naturally in different focal groups. Therefore, it is necessary to identify those natural focal groups and exploit them for learning at different focuses. Along this line, the key development challenge is how to identify those focal groups in the training data. As a case study, we exploit multifocal learning for profiling customer problems. Also, we provide an empirical study about how the performance of multifocal learning is affected by the quality of focal groups. The results on real-world customer problem logs show that multifocal learning can significantly boost the performance of many existing classification algorithms, such as Support Vector Machines (SVMs), for classifying customer problems and there is strong correlation between the quality of focal groups and the learning performance.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1971165270",
    "type": "article"
  },
  {
    "title": "Introduction to special section on CAMRa2010",
    "doi": "https://doi.org/10.1145/2414425.2414438",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Alan Said; Shlomo Berkovsky; Ernesto William De Luca",
    "corresponding_authors": "",
    "abstract": "The challenge and workshop on Context-Aware Movie Recommendation (CAMRa2010) were conducted jointly in 2010 with the Recommender Systems conference. The challenge focused on three context-aware recommendation scenarios: time-based, mood-based, and social recommendation. The participants were provided with anonymized datasets from two real-world online movie recommendation communities and competed against each other for obtaining the highest accuracy of recommendations. The datasets contained contextual features, such as tags, annotation, social relationsips, and comments, normally not available in public recommendation datasets. More than 40 teams from 21 countries participated in the challenge. Their participation was summarized by 10 papers published by the workshop, which have been extended and revised for this special section. In this preface we overview the challenge datasets, tasks, evaluation metrics, and the obtained outcomes.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2068060484",
    "type": "article"
  },
  {
    "title": "Surface Sulfur Detection via Remote Sensing and Onboard Classification",
    "doi": "https://doi.org/10.1145/2337542.2337562",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Lukas Mandrake; Umaa Rebbapragada; Kiri L. Wagstaff; David R. Thompson; Steve Chien; Daniel Tran; R. T. Pappalardo; Damhnait Gleeson; Rebecca Castaño",
    "corresponding_authors": "",
    "abstract": "Orbital remote sensing provides a powerful way to efficiently survey targets such as the Earth and other planets and moons for features of interest. One such feature of astrobiological relevance is the presence of surface sulfur deposits. These deposits have been observed to be associated with microbial activity at the Borup Fiord glacial springs in Canada, a location that may provide an analogue to other icy environments such as Europa. This article evaluates automated classifiers for detecting sulfur in remote sensing observations by the hyperion spectrometer on the EO-1 spacecraft. We determined that a data-driven machine learning solution was needed because the sulfur could not be detected by simply matching observations to sulfur lab spectra. We also evaluated several methods (manual and automated) for identifying the most relevant attributes (spectral wavelengths) needed for successful sulfur detection. Our findings include (1) the Borup Fiord sulfur deposits were best modeled as containing two sub-populations: sulfur on ice and sulfur on rock; (2) as expected, classifiers using Gaussian kernels outperformed those based on linear kernels, and should be adopted when onboard computational constraints permit; and (3) Recursive Feature Elimination selected sensible and effective features for use in the computationally constrained environment onboard EO-1. This study helped guide the selection of algorithm parameters and configuration for the classification system currently operational on EO-1. Finally, we discuss implications for a similar onboard classification system for a future Europa orbiter.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2083594659",
    "type": "article"
  },
  {
    "title": "An Unsupervised Approach to Inferring the Localness of People Using Incomplete Geotemporal Online Check-In Data",
    "doi": "https://doi.org/10.1145/3022471",
    "publication_date": "2017-08-25",
    "publication_year": 2017,
    "authors": "Chao Huang; Dong Wang; Jun Tao",
    "corresponding_authors": "",
    "abstract": "Inferring the localness of people is to classify people who are local residents in a city from people who visit the city by analyzing online check-in points that are contributed by online users. This information is critical for the urban planning, user profiling, and localized recommendation systems. Supervised learning approaches have been developed to infer the location of people in a city by assuming the availability of high-quality training datasets with complete geotemporal information. In this article, we develop an unsupervised model to accurately identify local people in a city by using the incomplete online check-in data that are publicly available. In particular, we develop an incomplete geotemporal expectation maximization (IGT-EM) scheme, which incorporates a set of hidden variables to represent the localness of people and a set of estimation parameters to represent the likelihood of venues to attract local and nonlocal people, respectively. Our solution can accurately classify local people from nonlocal nones without requiring any training data. We also implement a parallel IGT-EM algorithm by leveraging the computing power of a graphic processing unit (GPU) that consists of 2,496 cores. In the evaluation, we compare our new approach with the existing solutions through four real-world case studies using data from the New York City, Chicago, Boston, and Washington, DC. The results show that our approach can identify the local people and significantly outperform the compared baselines in estimation accuracy and execution time.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2747967272",
    "type": "article"
  },
  {
    "title": "Stopping Criterion for Active Learning with Model Stability",
    "doi": "https://doi.org/10.1145/3125645",
    "publication_date": "2017-10-25",
    "publication_year": 2017,
    "authors": "Yexun Zhang; Wenbin Cai; Wenquan Wang; Ya Zhang",
    "corresponding_authors": "",
    "abstract": "Active learning selectively labels the most informative instances, aiming to reduce the cost of data annotation. While much effort has been devoted to active sampling functions, relatively limited attention has been paid to when the learning process should stop. In this article, we focus on the stopping criterion of active learning and propose a model stability--based criterion, that is, when a model does not change with inclusion of additional training instances. The challenge lies in how to measure the model change without labeling additional instances and training new models. Inspired by the stochastic gradient update rule, we use the gradient of the loss function at each candidate example to measure its effect on model change. We propose to stop active learning when the model change brought by any of the remaining unlabeled examples is lower than a given threshold. We apply the proposed stopping criterion to two popular classifiers: logistic regression (LR) and support vector machines (SVMs). In addition, we theoretically analyze the stability and generalization ability of the model obtained by our stopping criterion. Substantial experiments on various UCI benchmark datasets and ImageNet datasets have demonstrated that the proposed approach is highly effective.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2766311212",
    "type": "article"
  },
  {
    "title": "Inferring Online Social Ties from Offline Geographical Activities",
    "doi": "https://doi.org/10.1145/3293319",
    "publication_date": "2019-01-12",
    "publication_year": 2019,
    "authors": "Hsun-Ping Hsieh; Cheng–Te Li",
    "corresponding_authors": "",
    "abstract": "As mobile devices are becoming ubiquitous nowadays, the geographical activities and interactions of human beings can be easily recorded and accessed. Each mobile individual can belong to an online social network. Unfortunately, the underlying online social relationships are hidden and only available to service providers. Acquiring the social network of mobile users would enrich lots of mobile applications, such as friend recommendation and energy-saving mobile database management. In this work, we propose to infer online social ties using purely offline geographical activities of users, such as check-in records and spatial meeting events. To tackle the problem, we devise a novel inference framework, O2O-I nf , which consists of two components, Feature Modeling and Link Inference . Feature modeling is to characterize both direct and indirect geographical interactions between nodes from co-location and graph features. Link inference aims to infer the social ties based on a small set of observed social links, and the idea is that pairs of nodes sharing similar geographical behaviors have the same tendency of linkage (i.e., either being friends or non-friends). Experiments conducted on a G owalla location-based social network and a M eetup event-based social network exhibit a satisfying performance in comparison to state-of-the-art prediction methods under the settings of offline-to-online network inference and geo-link prediction.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2910713688",
    "type": "article"
  },
  {
    "title": "Short Text Analysis Based on Dual Semantic Extension and Deep Hashing in Microblog",
    "doi": "https://doi.org/10.1145/3326166",
    "publication_date": "2019-07-31",
    "publication_year": 2019,
    "authors": "Wanqiu Cui; Junping Du; Dawei Wang; Xunpu Yuan; Feifei Kou; Liyan Zhou; Nan Zhou",
    "corresponding_authors": "",
    "abstract": "Short text analysis is a challenging task as far as the sparsity and limitation of semantics. The semantic extension approach learns the meaning of a short text by introducing external knowledge. However, for the randomness of short text descriptions in microblogs, traditional extension methods cannot accurately mine the semantics suitable for the microblog theme. Therefore, we use the prominent and refined hashtag information in microblogs as well as complex social relationships to provide implicit guidance for semantic extension of short text. Specifically, we design a deep hash model based on social and conceptual semantic extension, which consists of dual semantic extension and deep hashing representation. In the extension method, the short text is first conceptualized to achieve the construction of hashtag graph under conceptual space. Then, the associated hashtags are generated by correlation calculation based on the integration of social relationships and concepts to extend the short text. In the deep hash model, we use the semantic hashing model to encode the abundant semantic features and form a compact and meaningful binary encoding. Finally, extensive experiments demonstrate that our method can learn and represent the short texts well by using more meaningful semantic signal. It can effectively enhance and guide the semantic analysis and understanding of short text in microblogs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2970507669",
    "type": "article"
  },
  {
    "title": "Newton Methods for Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3368271",
    "publication_date": "2020-01-25",
    "publication_year": 2020,
    "authors": "Chien-Chih Wang; Kent Loong Tan; Chih‐Jen Lin",
    "corresponding_authors": "",
    "abstract": "Deep learning involves a difficult non-convex optimization problem, which is often solved by stochastic gradient (SG) methods. While SG is usually effective, it may not be robust in some situations. Recently, Newton methods have been investigated as an alternative optimization technique, but most existing studies consider only fully connected feedforward neural networks. These studies do not investigate some more commonly used networks such as Convolutional Neural Networks (CNN). One reason is that Newton methods for CNN involve complicated operations, and so far no works have conducted a thorough investigation. In this work, we give details of all building blocks, including the evaluation of function, gradient, Jacobian, and Gauss-Newton matrix-vector products. These basic components are very important not only for practical implementation but also for developing variants of Newton methods for CNN. We show that an efficient MATLAB implementation can be done in just several hundred lines of code. Preliminary experiments indicate that Newton methods are less sensitive to parameters than the stochastic gradient approach.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3007690347",
    "type": "article"
  },
  {
    "title": "Geosocial Co-Clustering",
    "doi": "https://doi.org/10.1145/3391708",
    "publication_date": "2020-06-13",
    "publication_year": 2020,
    "authors": "Jungeun Kim; Jae-Gil Lee; Byung Suk Lee; Jiajun Liu",
    "corresponding_authors": "",
    "abstract": "As location-based services using mobile devices have become globally popular these days, social network analysis (especially, community detection) increasingly benefits from combining social relationships with geographic preferences. In this regard, this article addresses the emerging problem of geosocial community detection. We first formalize the problem of geosocial co-clustering , which co-clusters the users in social networks and the locations they visited. Geosocial co-clustering detects higher-quality communities than existing approaches by improving the mapping clusterability , whereby users in the same community tend to visit locations in the same region. While geosocial co-clustering is soundly formalized as non-negative matrix tri-factorization , conventional matrix tri-factorization algorithms suffer from a significant computational overhead when handling large-scale datasets. Thus, we also develop an efficient framework for geosocial co-clustering, called GEOsocial COarsening and DEcomposition (GEOCODE) . To achieve efficient matrix tri-factorization, GEOCODE reduces the numbers of users and locations through coarsening and then decomposes the single whole matrix tri-factorization into a set of multiple smaller sub-matrix tri-factorizations. Thorough experiments conducted using real-world geosocial networks show that GEOCODE reduces the elapsed time by 19–69 times while achieving the accuracy of up to 94.8% compared with the state-of-the-art co-clustering algorithm. Furthermore, the benefit of the mapping clusterability is clearly demonstrated through a local expert recommendation application.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3034449807",
    "type": "article"
  },
  {
    "title": "STARS",
    "doi": "https://doi.org/10.1145/3397463",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Rui Liu; Runze Liu; Andrea Pugliese; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Customers of virtually all online marketplaces rely upon reviews in order to select the product or service they wish to buy. These marketplaces in turn deploy review fraud detection systems so that the integrity of reviews is preserved. A well-known problem with review fraud detection systems is their underlying assumption that the majority of reviews are honest-this assumption leads to a vulnerability where an attacker can try to generate many fake reviews of a product. In this article, we consider the case where a company wishes to fraudulently promote its product through fake reviews and propose the Sockpuppet-based Targeted Attack on Reviewing Systems (STARS for short). STARS enables an attacker to enter fake reviews for a product from multiple, apparently independent, sockpuppet accounts. We show that the STARS attack enables companies to successfully promote their product against seven recent, well-known review fraud detectors on four datasets (Amazon, Epinions, and the BitcoinAlpha and OTC exchanges) by significant margins. To protect against the STARS attack, we propose a new fraud detection algorithm called RTV. RTV introduces a new class of users (called trusted users) and also considers reviews left by verified users which were not considered in existing review fraud detectors. We show that RTV significantly mitigates the impact of the STARS attack across the four datasets listed above.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3041949805",
    "type": "article"
  },
  {
    "title": "BOXREC",
    "doi": "https://doi.org/10.1145/3408890",
    "publication_date": "2020-09-25",
    "publication_year": 2020,
    "authors": "Debopriyo Banerjee; Krothapalli Sreenivasa Rao; Shamik Sural; Niloy Ganguly",
    "corresponding_authors": "",
    "abstract": "Fashionable outfits are generally created by expert fashionistas, who use their creativity and in-depth understanding of fashion to make attractive outfits. Over the past few years, automation of outfit composition has gained much attention from the research community. Most of the existing outfit recommendation systems focus on pairwise item compatibility prediction (using visual and text features) to score an outfit combination having several items, followed by recommendation of top-n outfits or a capsule wardrobe having a collection of outfits based on user’s fashion taste. However, none of these consider a user’s preference of price range for individual clothing types or an overall shopping budget for a set of items. In this article, we propose a box recommendation framework—BOXREC—which at first collects user preferences across different item types (namely, top-wear, bottom-wear, and foot-wear) including price range of each type and a maximum shopping budget for a particular shopping session. It then generates a set of preferred outfits by retrieving all types of preferred items from the database (according to user specified preferences including price ranges), creates all possible combinations of three preferred items (belonging to distinct item types), and verifies each combination using an outfit scoring framework—BOXREC-OSF. Finally, it provides a box full of fashion items, such that different combinations of the items maximize the number of outfits suitable for an occasion while satisfying maximum shopping budget. We create an extensively annotated dataset of male fashion items across various types and categories (each having associated price) and a manually annotated positive and negative formal as well as casual outfit dataset. We consider a set of recently published pairwise compatibility prediction methods as competitors of BOXREC-OSF. Empirical results show superior performance of BOXREC-OSF over the baseline methods. We found encouraging results by performing both quantitative and qualitative analysis of the recommendations produced by BOXREC. Finally, based on user feedback corresponding to the recommendations given by BOXREC, we show that disliked or unpopular items can be a part of attractive outfits.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3088132321",
    "type": "article"
  },
  {
    "title": "Origin-Aware Location Prediction Based on Historical Vehicle Trajectories",
    "doi": "https://doi.org/10.1145/3462675",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Meng Chen; Qing-Jie Liu; Weiming Huang; Teng Zhang; Yixuan Zuo; Xiaohui Yu",
    "corresponding_authors": "",
    "abstract": "Next location prediction is of great importance for many location-based applications and provides essential intelligence to various businesses. In previous studies, a common approach to next location prediction is to learn the sequential transitions with massive historical trajectories based on conditional probability. Nevertheless, due to the time and space complexity, these methods (e.g., Markov models) only utilize the just passed locations to predict next locations, neglecting earlier passed locations in the trajectory. In this work, we seek to enhance the prediction performance by incorporating the travel time from all the passed locations in the query trajectory to each candidate next location. To this end, we propose a novel prediction method, namely the Travel Time Difference Model, which exploits the difference between the shortest travel time and the actual travel time to predict next locations. Moreover, we integrate the Travel Time Difference Model with a Sequential and Temporal Predictor to yield a joint model. The joint prediction model integrates local sequential transitions, temporal regularity, and global travel time information in the trajectory for the next location prediction problem. We have conducted extensive experiments on two real-world datasets: the vehicle passage record data and the taxi trajectory data. The experimental results demonstrate significant improvements in prediction accuracy over baseline methods.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3214905160",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2508037",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Huge amounts of search log data have been accumulated at Web search engines. Currently, a popular Web search engine may receive billions of queries and collect terabytes of records about user search behavior daily. Beside search log data, huge amounts ...",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4240453631",
    "type": "paratext"
  },
  {
    "title": "A Unified Geolocation Framework for Web Videos",
    "doi": "https://doi.org/10.1145/2533989",
    "publication_date": "2014-07-17",
    "publication_year": 2014,
    "authors": "Yicheng Song; Yongdong Zhang; Juan Cao; Jinhui Tang; Xingyu Gao; Jintao Li",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a unified geolocation framework to automatically determine where on the earth a web video was shot. We analyze different social, visual, and textual relationships from a real-world dataset and find four relationships with apparent geography clues that can be used for web video geolocation. Then, the geolocation process is formulated as an optimization problem that simultaneously takes the social, visual, and textual relationships into consideration. The optimization problem is solved by an iterative procedure, which can be interpreted as a propagation of the geography information among the web video social network. Extensive experiments on a real-world dataset clearly demonstrate the effectiveness of our proposed framework, with the geolocation accuracy higher than state-of-the-art approaches.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2081988525",
    "type": "article"
  },
  {
    "title": "Video Face Editing Using Temporal-Spatial-Smooth Warping",
    "doi": "https://doi.org/10.1145/2819000",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Xiaoyan Li; Tongliang Liu; Jiankang Deng; Dacheng Tao",
    "corresponding_authors": "",
    "abstract": "Editing faces in videos is a popular yet challenging task in computer vision and graphics that encompasses various applications, including facial attractiveness enhancement, makeup transfer, face replacement, and expression manipulation. Directly applying the existing warping methods to video face editing has the major problem of temporal incoherence in the synthesized videos, which cannot be addressed by simply employing face tracking techniques or manual interventions, as it is difficult to eliminate the subtly temporal incoherence of the facial feature point localizations in a video sequence. In this article, we propose a temporal-spatial-smooth warping (TSSW) method to achieve a high temporal coherence for video face editing. TSSW is based on two observations: (1) the control lattices are critical for generating warping surfaces and achieving the temporal coherence between consecutive video frames, and (2) the temporal coherence and spatial smoothness of the control lattices can be simultaneously and effectively preserved. Based upon these observations, we impose the temporal coherence constraint on the control lattices on two consecutive frames, as well as the spatial smoothness constraint on the control lattice on the current frame. TSSW calculates the control lattice (in either the horizontal or vertical direction) by updating the control lattice (in the corresponding direction) on its preceding frame, i.e., minimizing a novel energy function that unifies a data-driven term, a smoothness term, and feature point constraints. The contributions of this article are twofold: (1) we develop TSSW, which is robust to the subtly temporal incoherence of the facial feature point localizations and is effective to preserve the temporal coherence and spatial smoothness of the control lattices for editing faces in videos, and (2) we present a new unified video face editing framework that is capable for improving the performances of facial attractiveness enhancement, makeup transfer, face replacement, and expression manipulation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2100094703",
    "type": "article"
  },
  {
    "title": "Parameterized Decay Model for Information Retrieval",
    "doi": "https://doi.org/10.1145/2800794",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Jiaul H. Paik",
    "corresponding_authors": "Jiaul H. Paik",
    "abstract": "This article proposes a term weighting scheme for measuring query-document similarity that attempts to explicitly model the dependency between separate occurrences of a term in a document. The assumption is that, if a term appears once in a document, it is more likely to appear again in the same document. Thus, as the term appears again and again, the information content of the subsequent occurrences decreases gradually, since they are more predictable. We introduce a parameterized decay function to model this assumption, where the initial contribution of the term can be determined using any reasonable term discrimination factor. The effectiveness of the proposed model is evaluated on a number of recent web test collections of varying nature. The experimental results show that the proposed model significantly outperforms a number of well known retrieval models including a recently proposed strong Term Frequency and Inverse Document Frequency (TF-IDF) model.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2269190553",
    "type": "article"
  },
  {
    "title": "Recognition of Patient-Related Named Entities in Noisy Tele-Health Texts",
    "doi": "https://doi.org/10.1145/2651444",
    "publication_date": "2015-07-24",
    "publication_year": 2015,
    "authors": "Miyoung Kim; Ying Xu; Osmar R. Zaı̈ane; Randy Goebel",
    "corresponding_authors": "",
    "abstract": "We explore methods for effectively extracting information from clinical narratives that are captured in a public health consulting phone service called HealthLink. Our research investigates the application of state-of-the-art natural language processing and machine learning to clinical narratives to extract information of interest. The currently available data consist of dialogues constructed by nurses while consulting patients by phone. Since the data are interviews transcribed by nurses during phone conversations, they include a significant volume and variety of noise. When we extract the patient-related information from the noisy data, we have to remove or correct at least two kinds of noise: explicit noise , which includes spelling errors, unfinished sentences, omission of sentence delimiters, and variants of terms, and implicit noise , which includes non-patient information and patient's untrustworthy information. To filter explicit noise, we propose our own biomedical term detection/normalization method: it resolves misspelling, term variations, and arbitrary abbreviation of terms by nurses. In detecting temporal terms, temperature, and other types of named entities (which show patients’ personal information such as age and sex), we propose a bootstrapping-based pattern learning process to detect a variety of arbitrary variations of named entities. To address implicit noise, we propose a dependency path-based filtering method. The result of our denoising is the extraction of normalized patient information, and we visualize the named entities by constructing a graph that shows the relations between named entities. The objective of this knowledge discovery task is to identify associations between biomedical terms and to clearly expose the trends of patients’ symptoms and concern; the experimental results show that we achieve reasonable performance with our noise reduction methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2283763484",
    "type": "article"
  },
  {
    "title": "Towards Music Structural Segmentation across Genres",
    "doi": "https://doi.org/10.1145/2950066",
    "publication_date": "2016-10-21",
    "publication_year": 2016,
    "authors": "Mi Tian; M. Sandler",
    "corresponding_authors": "",
    "abstract": "This article faces the problem of how different audio features and segmentation methods work with different music genres. A new annotated corpus of Chinese traditional Jingju music is presented. We incorporate this dataset with two existing music datasets from the literature in an integrated retrieval system to evaluate existing features, structural hypotheses, and segmentation algorithms outside a Western bias. A harmonic-percussive source separation technique is introduced to the feature extraction process and brings significant improvement to the segmentation. Results show that different features capture the structural patterns of different music genres in different ways. Novelty- or homogeneity-based segmentation algorithms and timbre features can surpass the investigated alternatives for the structure analysis of Jingju due to their lack of harmonic repetition patterns. Findings indicate that the design of audio features and segmentation algorithms as well as the consideration of contextual information related to the music corpora should be accounted dependently in an effective segmentation system.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2535129843",
    "type": "article"
  },
  {
    "title": "Analyzing Trajectory Gaps to Find Possible Rendezvous Region",
    "doi": "https://doi.org/10.1145/3467977",
    "publication_date": "2022-01-18",
    "publication_year": 2022,
    "authors": "Arun Sharma; Shashi Shekhar",
    "corresponding_authors": "",
    "abstract": "Given trajectory data with gaps, we investigate methods to identify possible rendezvous regions. The problem has societal applications such as improving maritime safety and regulatory enforcement. The challenges come from two aspects. First, gaps in trajectory data make it difficult to identify regions where moving objects may have rendezvoused for nefarious reasons. Hence, traditional linear or shortest path interpolation methods may not be able to detect such activities, since objects in a rendezvous may have traveled away from their usual routes to meet. Second, user detecting a rendezvous regions involve a large number of gaps and associated trajectories, making the task computationally very expensive. In preliminary work, we proposed a more effective way of handling gaps and provided examples to illustrate potential rendezvous regions. In this article, we are providing detailed experiments with both synthetic and real-world data. Experiments on synthetic data show that the accuracy improved by 50 percent, which is substantial as compared to the baseline approach. In this article, we propose a refined algorithm Temporal Selection Search for finding a potential rendezvous region and finding an optimal temporal range to improve computational efficiency. We also incorporate two novel spatial filters: (i) a Static Ellipse Intersection Filter and (ii) a Dynamic Circle Intersection Spatial Filter. Both the baseline and proposed approaches account for every possible rendezvous pattern. We provide a theoretical evaluation of the algorithms correctness and completeness along with a time complexity analysis. Experimental results on synthetic and real-world maritime trajectory data show that the proposed approach substantially improves the area pruning effectiveness and computation time over the baseline technique. We also performed experiments based on accuracy and precision on synthetic dataset on both proposed and baseline techniques.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4205848941",
    "type": "article"
  },
  {
    "title": "Earth Imagery Segmentation on Terrain Surface with Limited Training Labels: A Semi-supervised Approach based on Physics-Guided Graph Co-Training",
    "doi": "https://doi.org/10.1145/3481043",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Wenchong He; Arpan Man Sainju; Zhe Jiang; Da Yan; Yang Zhou",
    "corresponding_authors": "",
    "abstract": "Given earth imagery with spectral features on a terrain surface, this paper studies surface segmentation based on both explanatory features and surface topology. The problem is important in many spatial and spatiotemporal applications such as flood extent mapping in hydrology. The problem is uniquely challenging for several reasons: first, the size of earth imagery on a terrain surface is often much larger than the input of popular deep convolutional neural networks; second, there exists topological structure dependency between pixel classes on the surface, and such dependency can follow an unknown and non-linear distribution; third, there are often limited training labels. Existing methods for earth imagery segmentation often divide the imagery into patches and consider the elevation as an additional feature channel. These methods do not fully incorporate the spatial topological structural constraint within and across surface patches and thus often show poor results, especially when training labels are limited. Existing methods on semi-supervised and unsupervised learning for earth imagery often focus on learning representation without explicitly incorporating surface topology. In contrast, we propose a novel framework that explicitly models the topological skeleton of a terrain surface with a contour tree from computational topology, which is guided by the physical constraint (e.g., water flow direction on terrains). Our framework consists of two neural networks: a convolutional neural network (CNN) to learn spatial contextual features on a 2D image grid, and a graph neural network (GNN) to learn the statistical distribution of physics-guided spatial topological dependency on the contour tree. The two models are co-trained via variational EM. Evaluations on the real-world flood mapping datasets show that the proposed models outperform baseline methods in classification accuracy, especially when training labels are limited.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4206678795",
    "type": "article"
  },
  {
    "title": "Efficient and Effective Similar Subtrajectory Search: A Spatial-aware Comprehension Approach",
    "doi": "https://doi.org/10.1145/3456723",
    "publication_date": "2022-04-13",
    "publication_year": 2022,
    "authors": "Liwei Deng; Hao Sun; Rui Sun; Yan Zhao; Han Su",
    "corresponding_authors": "",
    "abstract": "Although many applications take subtrajectories as basic units for analysis, there is little research on the similar subtrajectory search problem aiming to return a portion of a trajectory (i.e., subtrajectory), which is the most similar to a query trajectory. We find that in some special cases, when a grid-based metric is used, this problem can be formulated as a reading comprehension problem, which has been studied extensively in the field of natural language processing (NLP). By this formulation, we can obtain faster models with better performance than existing methods. However, due to the difference between natural language and trajectory (e.g., spatial relationship), it is impossible to directly apply NLP models to this problem. Therefore, we propose a Similar Subtrajectory Search with a Graph Neural Networks framework. This framework contains four modules including a spatial-aware grid embedding module, a trajectory embedding module, a query-context trajectory fusion module, and a span prediction module. Specifically, in the spatial-aware grid embedding module, the spatial-based grid adjacency is constructed and delivered to the graph neural network to learn spatial-aware grid embedding. The trajectory embedding module aims to model the sequential information of trajectories. The purpose of the query-context trajectory fusion module is to fuse the information of the query trajectory to each grid of the context trajectories. Finally, the span prediction module aims to predict the start and the end of a subtrajectory for the context trajectory, which is the most similar to the query trajectory. We conduct comprehensive experiments on two real world datasets, where the proposed framework outperforms the state-of-the-art baselines consistently and significantly.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4223496346",
    "type": "article"
  },
  {
    "title": "GPSClean: A Framework for Cleaning and Repairing GPS Data",
    "doi": "https://doi.org/10.1145/3469088",
    "publication_date": "2022-04-13",
    "publication_year": 2022,
    "authors": "Chenglong Fang; Feng Wang; Bin Yao; Jianqiu Xu",
    "corresponding_authors": "",
    "abstract": "The rise of GPS-equipped mobile devices has led to the emergence of big trajectory data. The collected raw data usually contain errors and anomalies information caused by device failure, sensor error, and environment influence. Low-quality data fails to support application requirements and therefore raw data will be comprehensively cleaned before usage. Existing methods are suboptimal to detect GPS data errors and do the repairing. To solve the problem, we propose a framework called GPSClean to analyze the anomalies data and develop effective methods to repair the data. There are primarily four modules in GPSClean : (i) data preprocessing, (ii) data filling, (iii) data repairing, and (iv) data conversion. For (i), we propose an approach named MDSort (Maximum Disorder Sorting) to efficiently solve the issue of data disorder. For (ii), we propose a method named NNF (Nearest Neighbor Filling) to fill missing data. For (iii), we design an approach named RCSWS (Range Constraints and Sliding Window Statistics) to repair anomalies and also improve the accuracy of data repairing by mak7ing use of driving direction. We use 45 million real trajectory data to evaluate our proposal in a prototype database system SECONDO. Experimental results show that the accuracy of RCSWS is three times higher than an alternative method SCREEN and nearly an order of magnitude higher than an alternative method EWMA.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4224050757",
    "type": "article"
  },
  {
    "title": "Utility-aware and Privacy-preserving Trajectory Synthesis Model that Resists Social Relationship Privacy Attacks",
    "doi": "https://doi.org/10.1145/3495160",
    "publication_date": "2022-05-11",
    "publication_year": 2022,
    "authors": "Zhirun Zheng; Zhetao Li; Jie Li; Hongbo Jiang; Tong Li; Bin Guo",
    "corresponding_authors": "",
    "abstract": "For academic research and business intelligence, trajectory data has been widely collected and analyzed. Releasing trajectory data to a third party may lead to serious privacy leakage, which has spawned considerable researches on trajectory privacy protection technology. However, existing work suffers from several shortcomings. They either focus on point-based location privacy, ignoring the spatio-temporal correlations among locations within a trajectory, or they protect the privacy of each user separately without considering privacy leakage of the social relationship between trajectories of different users. Besides, they fail to balance privacy protection and data utility. Motivated by these limitations, in this article, we propose S 3 T -Trajectory, which is a utility-aware and privacy-preserving trajectory synthesis model that Resists social relationship privacy attacks. Specifically, we first develop a time-dependent Markov chain based on an adaptive spatio-temporal discrete grid to efficiently and accurately capture human mobility behavior. Then, we propose three mobility feature metrics from spatio-temporal, semantic, and social dimensions. On the basis of the metrics, we construct a bi-level optimization problem to accomplish the utility-aware and privacy-preserving trajectory synthesizing. The upper-level objective guarantees data utility and the lower-level optimization problems (or upper-level constraints) provides two-layer privacy protection for S 3 T -Trajectory, i.e., resisting location inference attacks and social relationship privacy attacks. We conduct extensive experiments on large-scale real-world datasets loc-Gowalla and loc-Brightkite. The experimental results demonstrate the effectiveness and robustness of S 3 T Trajectory. Compared with the baseline models, S 3 T Trajectory achieves between 7.8% and 23.8% performance improvement in resisting social relationship privacy attacks and achieves at least 5.19% improvement regarding data utility.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4280643519",
    "type": "article"
  },
  {
    "title": "Self-supervised Discriminative Representation Learning by Fuzzy Autoencoder",
    "doi": "https://doi.org/10.1145/3555777",
    "publication_date": "2022-09-02",
    "publication_year": 2022,
    "authors": "Wenlu Yang; Hongjun Wang; Yinghui Zhang; Zehao Liu; Tianrui Li",
    "corresponding_authors": "",
    "abstract": "Representation learning based on autoencoders has received great concern for its potential ability to capture valuable latent information. Conventional autoencoders pursue minimal reconstruction error, but in most machine learning tasks such as classification and clustering, the discrimination of feature representation is also important. To address this limitation, an enhanced self-supervised discriminative fuzzy autoencoder (FAE) is innovatively proposed, which focuses on exploring information within data to guide the unsupervised training process and enhancing feature discrimination in a self-supervised manner. In FAE, fuzzy membership is applied to provide a means of self-supervised, which allows FAE can not only utilize AE’s outstanding representation learning capabilities but can also transform the original data into another space with improved discrimination. First, the objective function corresponding to FAE is proposed by reconstruction loss and clustering oriented loss simultaneously. Subsequently, Mini-Batch Gradient Descent is applied to infer the objective function and the detailed process is illustrated step by step. Finally, empirical studies on clustering tasks have demonstrated the superiority of FAE over the state of the art.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4294237762",
    "type": "article"
  },
  {
    "title": "Neural Topic Modeling via Discrete Variational Inference",
    "doi": "https://doi.org/10.1145/3570509",
    "publication_date": "2022-11-25",
    "publication_year": 2022,
    "authors": "Amulya Gupta; Zhu Zhang",
    "corresponding_authors": "",
    "abstract": "Topic models extract commonly occurring latent topics from textual data. Statistical models such as Latent Dirichlet Allocation do not produce dense topic embeddings readily integratable into neural architectures, whereas earlier neural topic models are yet to fully take advantage of the discrete nature of the topic space. To bridge this gap, we propose a novel neural topic model, Discrete-Variational-Inference-based Topic Model (DVITM), which learns dense topic embeddings homomorphic to word embeddings via discrete variational inference. The model also views words as mixtures of topics and digests embedded input text. Quantitative and qualitative evaluations empirically demonstrate the superior performance of DVITM compared to important baseline models. In the end, case studies on text generation from a discrete space and aspect-aware item recommendation are presented to further illustrate the power of our model in downstream tasks.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4309940794",
    "type": "article"
  },
  {
    "title": "Deep Reinforcement Learning for Parameter Tuning of Robot Visual Servoing",
    "doi": "https://doi.org/10.1145/3579829",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Meng Xu; Jianping Wang",
    "corresponding_authors": "",
    "abstract": "Robot visual servoing controls the motion of a robot through real-time visual observations. Kinematics is a key approach to achieving visual servoing. One key challenge of kinematics-based visual servoing is that it requires time-varying parameter configuration throughout the entire process of one task. Parameter tuning is also necessary when applying to different tasks. The existing work on parameter tuning either lacks adaptation or cannot automate the tuning of all parameters. Meanwhile, the transferability of existing methods from one task to another is low. This work develops a Deep Reinforcement Learning (DRL) framework for robot visual servoing, which can automate all parameters tuning for one task and across tasks. In visual servoing, forward kinematics focuses on motion speed, while inverse kinematics focuses on the smoothness of motion. Therefore, we develop two separate modules in the proposed DRL framework. One tunes time-varying Forward Kinematics parameters to accelerate the motion, and the other tunes the Inverse Kinematics parameters to ensure smoothness. Moreover, we customize a knowledge transfer method to generalize the proposed DRL models to various robot tasks without reconstructing the neural network. We verify the proposed method on simulated robot tasks. The experimental results show that the proposed method outperforms the state-of-the-art methods and manual parameter configuration in terms of movement speed and smoothness in one task and across tasks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4315784722",
    "type": "article"
  },
  {
    "title": "Ontology-Based Driving Simulation for Traffic Lights Optimization",
    "doi": "https://doi.org/10.1145/3579839",
    "publication_date": "2023-01-14",
    "publication_year": 2023,
    "authors": "Amirhossein Zaji; Zheng Liu; Takashi Bando; Lihua Zhao",
    "corresponding_authors": "",
    "abstract": "Traffic lights optimization is one of the principal components to lessen the traffic flow and travel time in an urban area. The present article seeks to introduce a novel procedure to design the traffic lights in a city using evolutionary-based optimization algorithms in combination with an ontology-based driving behavior simulation framework. Accordingly, an ontology-based knowledge base is introduced to provide a machine-understandable knowledge of roads and intersections, traffic rules, and driving behaviors. Then, a simulation environment is developed to inspect car behavior in real time. To optimize the traffic lights, a sine-based equation was defined for each traffic light, and the total travel time of the vehicles was considered as the cost function in the optimization algorithm. The optimization was performed with 5, 10, 15, 20, 25, and 30 vehicles in the urban areas. Based on the results, in contrast to uncontrolled intersections without traffic lights, optimized traffic lights can significantly contribute to total travel time-saving. To conclude, due to an escalation in the number of vehicles, the significance of optimized traffic lights has encountered an increase, and unoptimized traffic lights could increase total travel time even more than a city deprived of any traffic light.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4315977512",
    "type": "article"
  },
  {
    "title": "Real-time Road Network Optimization with Coordinated Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3603379",
    "publication_date": "2023-06-10",
    "publication_year": 2023,
    "authors": "Udesh Gunarathna; Hairuo Xie; Egemen Tanin; Shanika Karunasekera; Renata Borovica‐Gajic",
    "corresponding_authors": "",
    "abstract": "Dynamic road network optimization has been used for improving traffic flow in an infrequent and localized manner. The development of intelligent systems and technology provides an opportunity to improve the frequency and scale of dynamic road network optimization. However, such improvements are hindered by the high computational complexity of the existing algorithms that generate the optimization plans. We present a novel solution that integrates machine learning and road network optimization. Our solution consists of two complementary parts. The first part is an efficient algorithm that uses reinforcement learning to find the best road network configurations at real-time. The second part is a dynamic routing mechanism, which helps connected vehicles adapt to the change of the road network. Our extensive experimental results demonstrate that the proposed solution can substantially reduce the average travel time in a variety of scenarios, whilst being computationally efficient and hence applicable to real-life situations.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4380153553",
    "type": "article"
  },
  {
    "title": "Discovering Causes of Traffic Congestion via Deep Transfer Clustering",
    "doi": "https://doi.org/10.1145/3604810",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Mudan Wang; Yuan Yuan; Huan Yan; Hongjie Sui; Fan Zuo; Yue Liu; Yong Li; Depeng Jin",
    "corresponding_authors": "",
    "abstract": "Traffic congestion incurs long delay in travel time, which seriously affects our daily travel experiences. Exploring why traffic congestion occurs is significantly important to effectively address the problem of traffic congestion and improve user experience. Traditional approaches to mine the congestion causes depend on human efforts, which is time consuming and cost-intensive. Hence, we aim at discovering the known and unknown causes of traffic congestion in a systematic way. However, to achieve it, there are three challenges: (1) traffic congestion is affected by several factors with complex spatio-temporal relations; (2) there are a few samples of congestion data with known causes due to the limitation of human label; (3) more unknown congestion causes are unexplored since several factors contribute to traffic congestion. To address above challenges, we design a congestion cause discovery system consisting of two modules: (1) congestion feature extraction module, which extracts the important features distinguishing between different causes of congestion; and (2) congestion cause discovery module, which designs a deep semi-supervised learning based framework to discover the causes of traffic congestion with limited labeled data. Specifically, in pre-training stage, it first leverages a few labeled data as prior knowledge to pre-train the model. Then, in clustering stage, we propose two different clustering methods to discover the congestion causes. For the first clustering method, we extend the classic deep embedded clustering model to produce clusters via soft assignment. For the second one, we iteratively use k -means to group the latent features extracted from the pre-trained model, and use the cluster results as pseudo-labels to fine-tune the network. Extensive experiments show that the performance of our methods is superior to the state-of-the-art baselines, which demonstrates the effectiveness of the proposed cause discovery system. Additionally, our system is deployed and used in the practical production environment at Amap.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4381050537",
    "type": "article"
  },
  {
    "title": "Robust Location Prediction over Sparse Spatiotemporal Trajectory Data: Flashback to the Right Moment!",
    "doi": "https://doi.org/10.1145/3616541",
    "publication_date": "2023-08-18",
    "publication_year": 2023,
    "authors": "Bangchao Deng; Dingqi Yang; Bingqing Qu; Benjamin Fankhauser; Philippe Cudré-Mauroux",
    "corresponding_authors": "",
    "abstract": "As a fundamental problem in human mobility modeling, location prediction forecasts a user’s next location based on historical user mobility trajectories. Recurrent neural networks (RNNs) have been widely used to capture sequential patterns of user visited locations for solving location prediction problems. Due to the sparse nature of real-world user mobility trajectories, existing techniques strive to improve RNNs by incorporating spatiotemporal contexts into the recurrent hidden state passing process of RNNs using context-parameterized transition matrices or gates. However, such a scheme mismatches universal spatiotemporal mobility laws and thus cannot fully benefit from rich spatiotemporal contexts encoded in user mobility trajectories. Against this background, we propose Flashback++, a general RNN architecture designed for modeling sparse user mobility trajectories. It not only leverages rich spatiotemporal contexts to search past hidden states with high predictive power but also learns to optimally combine them via a hidden state re-weighting mechanism, which significantly improves the robustness of the models against different settings and datasets. Our extensive evaluation compares Flashback++ against a sizable collection of state-of-the-art techniques on two real-world location-based social networks datasets and one on-campus mobility dataset. Results show that Flashback++ not only consistently and significantly outperforms all baseline techniques by 20.56% to 44.36% but also achieves better robustness of location prediction performance against different model settings (different RNN architectures and numbers of hidden states to flash back), different levels of trajectory sparsity, and different train-testing splitting ratios than baselines, yielding an improvement of 31.05% to 94.60%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4385986228",
    "type": "article"
  },
  {
    "title": "Local Self-attention-based Hybrid Multiple Instance Learning for Partial Spoof Speech Detection",
    "doi": "https://doi.org/10.1145/3616540",
    "publication_date": "2023-08-19",
    "publication_year": 2023,
    "authors": "Yupeng Zhu; Yanxiang Chen; Zuxing Zhao; Xueliang Liu; Jinlin Guo",
    "corresponding_authors": "",
    "abstract": "The development of speech synthesis technology has increased the attention toward the threat of spoofed speech. Although various high-performance spoofing countermeasures have been proposed in recent years, a particular scenario is overlooked: partially spoofed audio, where spoofed utterances may contain both spoofed and bona fide segments. Currently, the research on partially spoofed speech detection is lacking. The existing methods either train with partially spoofed speech at utterance level, resulting in gradient conflicting at the segment level, or directly train with segment level data, which requires segment labels that are difficult to obtain in practice. In this study, to better detect partially spoofed speech when only utterance labels are available, we formulate partially spoofed speech detection into a multiple instance learning (MIL) problem. The typical MIL uses a pooling layer to fuse patch scores as a whole, and we propose a hybrid MIL (H-MIL) framework based on max and log-sum-exp pooling methods, which can learn better segment representations to improve partially spoofed speech detection performance. Theoretical and experimental verification shows that H-MIL can effectively relieve the gradient conflicting and gradient vanishing problems. In addition, we analyze the local correlations between segments and introduce a local self-attention mechanism to enhance segment features, which further promotes the detection performance. In our experiments, we provide not only detection results at the segment and utterance levels but also some detailed visualization analysis, including the effect of spoof ratio and cross-dataset detection. The experimental results demonstrate the effective detection performance of our method at both the utterance and segment levels, especially when dealing with low spoof ratio attacks. The results confirm that our approach can better deal with partially spoofed speech detection than previous methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4385999783",
    "type": "article"
  },
  {
    "title": "Memory Network-Based Interpreter of User Preferences in Content-Aware Recommender Systems",
    "doi": "https://doi.org/10.1145/3625239",
    "publication_date": "2023-09-21",
    "publication_year": 2023,
    "authors": "Nhu-Thuat Tran; Hady W. Lauw",
    "corresponding_authors": "",
    "abstract": "This article introduces a novel architecture for two objectives recommendation and interpretability in a unified model. We leverage textual content as a source of interpretability in content-aware recommender systems. The goal is to characterize user preferences with a set of human-understandable attributes, each is described by a single word, enabling comprehension of user interests behind item adoptions. This is achieved via a dedicated architecture, which is interpretable by design, involving two components for recommendation and interpretation. In particular, we seek an interpreter , which accepts holistic user’s representation from a recommender to output a set of activated attributes describing user preferences. Besides encoding interpretability properties such as fidelity, conciseness and diversity, the proposed memory network-based interpreter enables the generalization of user representation by discovering relevant attributes that go beyond her adopted items’ textual content. We design experiments involving both human- and functionally-grounded evaluations of interpretability. Results on four real-world datasets show that our proposed model not only discovers highly relevant attributes for interpreting user preferences, but also enjoys comparable or better recommendation accuracy than a series of baselines.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386928348",
    "type": "article"
  },
  {
    "title": "Exploring Structure Incentive Domain Adversarial Learning for Generalizable Sleep Stage Classification",
    "doi": "https://doi.org/10.1145/3625238",
    "publication_date": "2023-09-21",
    "publication_year": 2023,
    "authors": "Shuo Ma; Yingwei Zhang; Yiqiang Chen; Tao Xie; Shuchao Song; Ziyu Jia",
    "corresponding_authors": "",
    "abstract": "Sleep stage classification is crucial for sleep state monitoring and health interventions. In accordance with the standards prescribed by the American Academy of Sleep Medicine, a sleep episode follows a specific structure comprising five distinctive sleep stages that collectively form a sleep cycle. Typically, this cycle repeats about five times, providing an insightful portrayal of the subject’s physiological attributes. The progress of deep learning and advanced domain generalization methods allows automatic and even adaptive sleep stage classification. However, applying models trained with visible subject data to invisible subject data remains challenging due to significant individual differences among subjects. Motivated by the periodic category-complete structure of sleep stage classification, we propose a Structure Incentive Domain Adversarial learning (SIDA) method that combines the sleep stage classification method with domain generalization to enable cross-subject sleep stage classification. SIDA includes individual domain discriminators for each sleep stage category to decouple subject dependence differences among different categories and fine-grained learning of domain-invariant features. Furthermore, SIDA directly connects the label classifier and domain discriminators to promote the training process. Experiments on three benchmark sleep stage classification datasets demonstrate that the proposed SIDA method outperforms other state-of-the-art sleep stage classification and domain generalization methods and achieves the best cross-subject sleep stage classification results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386928368",
    "type": "article"
  },
  {
    "title": "Towards a Greener and Fairer Transportation System: A Survey of Route Recommendation Techniques",
    "doi": "https://doi.org/10.1145/3627825",
    "publication_date": "2023-10-13",
    "publication_year": 2023,
    "authors": "Aqsa Ashraf Makhdomi; Iqra Altaf Gillani",
    "corresponding_authors": "",
    "abstract": "In recent years, ride-hailing services have emerged as a popular means of transportation for the residents of urban areas. There is an inequality in the spatio-temporal distribution of demand and supply, which requires the proper recommendation of routes to drivers in order to guide them towards riders optimally. This paper provides a review of different route recommendation strategies that have been applied in ride-hailing platforms with the main focus on fairness, and environmental issues. It is important to consider the environmental aspects of route recommendation systems as the transportation sector is one of the major sources of air pollution and has reduced the life expectancy of people around the globe. Moreover, there is an unfair distribution of resources and opportunities among the drivers and riders of the platform which has affected their long-term sustainability in the market. In this paper, we highlight the critical challenges and opportunities inherent in the design of green and fair route recommendation systems and indicate some possible directions for future research.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4387618329",
    "type": "article"
  },
  {
    "title": "Out-of-distribution Detection in Time-series Domain: A Novel Seasonal Ratio Scoring Approach",
    "doi": "https://doi.org/10.1145/3630633",
    "publication_date": "2023-10-30",
    "publication_year": 2023,
    "authors": "Taha Belkhouja; Yan Yan; Janardhan Rao Doppa",
    "corresponding_authors": "",
    "abstract": "Safe deployment of time-series classifiers for real-world applications relies on the ability to detect the data that is not generated from the same distribution as training data. This task is referred to as out-of-distribution (OOD) detection. We consider the novel problem of OOD detection for the time-series domain. We discuss the unique challenges posed by time-series data and explain why prior methods from the image domain will perform poorly. Motivated by these challenges, this article proposes a novel Seasonal Ratio Scoring (SRS) approach. SRS consists of three key algorithmic steps. First, each input is decomposed into class-wise semantic component and remainder. Second, this decomposition is employed to estimate the class-wise conditional likelihoods of the input and remainder using deep generative models. The seasonal ratio score is computed from these estimates. Third, a threshold interval is identified from the in-distribution data to detect OOD examples. Experiments on diverse real-world benchmarks demonstrate that the SRS method is well-suited for time-series OOD detection when compared to baseline methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388016583",
    "type": "article"
  },
  {
    "title": "Responsible Recommendation Services with Blockchain Empowered Asynchronous Federated Learning",
    "doi": "https://doi.org/10.1145/3633520",
    "publication_date": "2023-11-23",
    "publication_year": 2023,
    "authors": "Waqar Ali; Rajesh Kumar; Xiangmin Zhou; Jie Shao",
    "corresponding_authors": "",
    "abstract": "Privacy and trust are highly demanding in practical recommendation engines. Although Federated Learning (FL) has significantly addressed privacy concerns, commercial operators are still worried about several technical challenges while bringing FL into production. In addition, classical FL has several intrinsic operational limitations such as single-point failure, data and model tampering, and heterogenic clients participating in the FL process. To address these challenges in practical recommenders, we propose a responsible recommendation generation framework based on blockchain-empowered asynchronous FL that can be adopted for any model-based recommender system. In standard FL settings, we build an additional aggregation layer in which multiple trusted nodes guided by a mediator component perform gradient aggregation to achieve an optimal model locally in a parallel fashion. The mediator partitions users into K clusters, and each cluster is represented by a cluster head. Once a cluster gets semi-global convergence, the cluster head transmits model gradients to the FL server for global aggregation. In addition the trusted cluster heads are responsible to submit the converged semi-global model to a blockchain to ensure tamper resilience. In our settings, an additional mediator component works like an independent observer that monitors the performance of each cluster head, updates a reward score, and records it into a digital ledger. Finally, evaluation results on three diversified benchmarks illustrate that the recommendation performance on selected measures is considerably comparable with the standard and federated version of a well-known neural collaborative filtering recommender.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388946128",
    "type": "article"
  },
  {
    "title": "Personalized Fashion Recommendations for Diverse Body Shapes with Contrastive Multimodal Cross-Attention Network",
    "doi": "https://doi.org/10.1145/3637217",
    "publication_date": "2023-12-11",
    "publication_year": 2023,
    "authors": "Jianghong Ma; Huiyue Sun; Dezhao Yang; Haijun Zhang",
    "corresponding_authors": "",
    "abstract": "Fashion recommendation has become a prominent focus in the realm of online shopping, with various tasks being explored to enhance the customer experience. Recent research has particularly emphasized fashion recommendation based on body shapes, yet a critical aspect of incorporating multimodal data relevance has been overlooked. In this paper, we present the Contrastive Multimodal Cross-Attention Network, a novel approach specifically designed for fashion recommendation catering to diverse body shapes. By incorporating multimodal representation learning and leveraging contrastive learning techniques, our method effectively captures both inter- and intra-sample relationships, resulting in improved accuracy in fashion recommendations tailored to individual body types. Additionally, we propose a locality-aware cross-attention module to align and understand the local preferences between body shapes and clothing items, thus enhancing the matching process. Experimental results conducted on a diverse dataset demonstrate the state-of-the-art performance achieved by our approach, reinforcing its potential to significantly enhance the personalized online shopping experience for consumers with varying body shapes and preferences.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4389572088",
    "type": "article"
  },
  {
    "title": "CORALS",
    "doi": "https://doi.org/10.1145/1869397.1869402",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Abder Rezak Benaskeur; Froduald Kabanza; Éric Beaudry",
    "corresponding_authors": "",
    "abstract": "Forces involved in modern conflicts may be exposed to a variety of threats, including coordinated raids of advanced ballistic and cruise missiles. To respond to these, a defending force will rely on a set of combat resources. Determining an efficient allocation and coordinated use of these resources, particularly in the case of multiple simultaneous attacks, is a very complex decision-making process in which a huge amount of data must be dealt with under uncertainty and time pressure. This article presents CORALS (COmbat Resource ALlocation Support), a real-time planner developed to support the command team of a naval force defending against multiple simultaneous threats. In response to such multiple threats, CORALS uses a local planner to generate a set of local plans, one for each threat considered apart, and then combines and coordinates them into a single optimized, conflict-free global plan. The coordination is performed through an iterative process of plan merging and conflict detection and resolution, which acts as a plan repair mechanism. Such an incremental plan repair approach also allows adapting previously generated plans to account for dynamic changes in the tactical situation.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2133447875",
    "type": "article"
  },
  {
    "title": "Using Clustering and Metric Learning to Improve Science Return of Remote Sensed Imagery",
    "doi": "https://doi.org/10.1145/2168752.2168765",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "David S. Hayden; Steve Chien; David R. Thompson; Rebecca Castaño",
    "corresponding_authors": "",
    "abstract": "Current and proposed remote space missions, such as the proposed aerial exploration of Titan by an aerobot, often can collect more data than can be communicated back to Earth. Autonomous selective downlink algorithms can choose informative subsets of data to improve the science value of these bandwidth-limited transmissions. This requires statistical descriptors of the data that reflect very abstract and subtle distinctions in science content. We propose a metric learning strategy that teaches algorithms how best to cluster new data based on training examples supplied by domain scientists. We demonstrate that clustering informed by metric learning produces results that more closely match multiple scientists’ labelings of aerial data than do clusterings based on random or periodic sampling. A new metric-learning strategy accommodates training sets produced by multiple scientists with different and potentially inconsistent mission objectives. Our methods are fit for current spacecraft processors (e.g., RAD750) and would further benefit from more advanced spacecraft processor architectures, such as OPERA.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2003289757",
    "type": "article"
  },
  {
    "title": "Probabilistic temporal multimedia data mining",
    "doi": "https://doi.org/10.1145/1899412.1899421",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Chidansh Bhatt; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "Existing sequence pattern mining techniques assume that the obtained events from event detectors are accurate. However, in reality, event detectors label the events from different modalities with a certain probability over a time-interval. In this article, we consider for the first time Probabilistic Temporal Multimedia (PTM) Event data to discover accurate sequence patterns. PTM event data considers the start time, end time, event label and associated probability for the sequence pattern discovery. As the existing sequence pattern mining techniques cannot work on such realistic data, we have developed a novel framework for performing sequence pattern mining on probabilistic temporal multimedia event data. We perform probability fusion to resolve the redundancy among detected events from different modalities, considering their cross-modal correlation. We propose a novel sequence pattern mining algorithm called Probabilistic Interval based Event Miner (PIE-Miner) for discovering frequent sequence patterns from interval based events. PIE-Miner has a new support counting mechanism developed for PTM data. Existing sequence pattern mining algorithms have event label level support counting mechanism, whereas we have developed event cluster level support counting mechanism. We discover the complete set of all possible temporal relationships based on Allen's interval algebra. The experimental results showed that the discovered sequence patterns are more useful than the patterns discovered with state-of-the-art sequence pattern mining algorithms.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2007368314",
    "type": "article"
  },
  {
    "title": "A SAT-based approach to cost-sensitive temporally expressive planning",
    "doi": "https://doi.org/10.1145/2542182.2542200",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Qiang Lü; Ruoyun Huang; Yixin Chen; You Xu; Weixiong Zhang; Guoliang Chen",
    "corresponding_authors": "",
    "abstract": "Complex features, such as temporal dependencies and numerical cost constraints, are hallmarks of real-world planning problems. In this article, we consider the challenging problem of cost-sensitive temporally expressive (CSTE) planning, which requires concurrency of durative actions and optimization of action costs. We first propose a scheme to translate a CSTE planning problem to a minimum cost (MinCost) satisfiability (SAT) problem and to integrate with a relaxed parallel planning semantics for handling true temporal expressiveness. Our scheme finds solution plans that optimize temporal makespan, and also minimize total action costs at the optimal makespan. We propose two approaches for solving MinCost SAT. The first is based on a transformation of a MinCost SAT problem to a weighted partial Max-SAT (WPMax-SAT), and the second, called BB-CDCL, is an integration of the branch-and-bound technique and the conflict driven clause learning (CDCL) method. We also develop a CSTE customized variable branching scheme for BB-CDCL which can significantly improve the search efficiency. Our experiments on the existing CSTE benchmark domains show that our planner compares favorably to the state-of-the-art temporally expressive planners in both efficiency and quality.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2029580091",
    "type": "article"
  },
  {
    "title": "Conceptual Imitation Learning in a Human-Robot Interaction Paradigm",
    "doi": "https://doi.org/10.1145/2089094.2089104",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Hossein Hajimirsadeghi; Majid Nili Ahmadabadi; Babak Nadjar Araabi; Hadi Moradi",
    "corresponding_authors": "",
    "abstract": "In general, imitation is imprecisely used to address different levels of social learning from high-level knowledge transfer to low-level regeneration of motor commands. However, true imitation is based on abstraction and conceptualization. This article presents a model for conceptual imitation through interaction with the teacher to abstract spatio-temporal demonstrations based on their functional meaning. Abstraction, concept acquisition, and self-organization of proto-symbols are performed through an incremental and gradual learning algorithm. In this algorithm, Hidden Markov Models (HMMs) are used to abstract perceptually similar demonstrations. However, abstract (relational) concepts emerge as a collection of HMMs irregularly scattered in the perceptual space but showing the same functionality. Performance of the proposed algorithm is evaluated in two experimental scenarios. The first one is a human-robot interaction task of imitating signs produced by hand movements. The second one is a simulated interactive task of imitating whole body motion patterns of a humanoid model. Experimental results show efficiency of our model for concept extraction, proto-symbol emergence, motion pattern recognition, prediction, and generation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2042169790",
    "type": "article"
  },
  {
    "title": "Generating targeted paraphrases for improved translation",
    "doi": "https://doi.org/10.1145/2483669.2483673",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Nitin Madnani; Bonnie J. Dorr",
    "corresponding_authors": "",
    "abstract": "Today's Statistical Machine Translation (SMT) systems require high-quality human translations for parameter tuning, in addition to large bitexts for learning the translation units. This parameter tuning usually involves generating translations at different points in the parameter space and obtaining feedback against human-authored reference translations as to how good the translations. This feedback then dictates what point in the parameter space should be explored next. To measure this feedback, it is generally considered wise to have multiple (usually 4) reference translations to avoid unfair penalization of translation hypotheses which could easily happen given the large number of ways in which a sentence can be translated from one language to another. However, this reliance on multiple reference translations creates a problem since they are labor intensive and expensive to obtain. Therefore, most current MT datasets only contain a single reference. This leads to the problem of reference sparsity. In our previously published research, we had proposed the first paraphrase-based solution to this problem and evaluated its effect on Chinese-English translation. In this article, we first present extended results for that solution on additional source languages. More importantly, we present a novel way to generate “targeted” paraphrases that yields substantially larger gains (up to 2.7 BLEU points) in translation quality when compared to our previous solution (up to 1.6 BLEU points). In addition, we further validate these improvements by supplementing with human preference judgments obtained via Amazon Mechanical Turk.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2065989126",
    "type": "article"
  },
  {
    "title": "Location-Based Parallel Tag Completion for Geo-Tagged Social Image Retrieval",
    "doi": "https://doi.org/10.1145/3001593",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Jiaming Zhang; Shuhui Wang; Qingming Huang",
    "corresponding_authors": "",
    "abstract": "Having benefited from tremendous growth of user-generated content, social annotated tags get higher importance in the organization and retrieval of large-scale image databases on Online Sharing Websites (OSW). To obtain high-quality tags from existing community contributed tags with missing information and noise, tag-based annotation or recommendation methods have been proposed for performance promotion of tag prediction. While images from OSW contain rich social attributes, they have not taken full advantage of rich social attributes and auxiliary information associated with social images to construct global information completion models. In this article, beyond the image-tag relation, we take full advantage of the ubiquitous GPS locations and image-user relationship to enhance the accuracy of tag prediction and improve the computational efficiency. For GPS locations, we define the popular geo-locations where people tend to take more images as Points of Interests (POI), which are discovered by mean shift approach. For image-user relationship, we integrate a localized prior constraint, expecting the completed tag sub-matrix in each POI to maintain consistency with users’ tagging behaviors. Based on these two key issues, we propose a unified tag matrix completion framework, which learns the image-tag relation within each POI. To solve the optimization problem, an efficient proximal sub-gradient descent algorithm is designed. The model optimization can be easily parallelized and distributed to learn the tag sub-matrix for each POI. Extensive experimental results reveal that the learned tag sub-matrix of each POI reflects the major trend of users’ tagging results with respect to different POIs and users, and the parallel learning process provides strong support for processing large-scale online image databases. To fit the response time requirement and storage limitations of Tag-based Image Retrieval (TBIR) on mobile devices, we introduce Asymmetric Locality Sensitive Hashing (ALSH) to reduce the time cost and meanwhile improve the efficiency of retrieval.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2607353660",
    "type": "article"
  },
  {
    "title": "DiffQue",
    "doi": "https://doi.org/10.1145/3337799",
    "publication_date": "2019-07-24",
    "publication_year": 2019,
    "authors": "Deepak Thukral; Adesh Kumar Pandey; Rishabh Gupta; Vikram Goyal; Tanmoy Chakraborty",
    "corresponding_authors": "",
    "abstract": "Automatic estimation of relative difficulty of a pair of questions is an important and challenging problem in community question answering (CQA) services. There are limited studies that addressed this problem. Past studies mostly leveraged expertise of users answering the questions and barely considered other properties of CQA services such as metadata of users and posts, temporal information, and textual content. In this article, we propose DiffQue, a novel system that maps this problem to a network-aided edge directionality prediction problem. DiffQue starts by constructing a novel network structure that captures different notions of difficulties among a pair of questions. It then measures the relative difficulty of two questions by predicting the direction of a (virtual) edge connecting these two questions in the network. It leverages features extracted from the network structure, metadata of users/posts, and textual description of questions and answers. Experiments on datasets obtained from two CQA sites (further divided into four datasets) with human annotated ground-truth show that DiffQue outperforms four state-of-the-art methods by a significant margin (28.77% higher F 1 score and 28.72% higher AUC than the best baseline). As opposed to the other baselines, (i) DiffQue appropriately responds to the training noise, (ii) DiffQue is capable of adapting multiple domains (CQA datasets), and (iii) DiffQue can efficiently handle the “cold start” problem that may arise due to the lack of information for newly posted questions or newly arrived users.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2963821450",
    "type": "article"
  },
  {
    "title": "Mining High-utility Temporal Patterns on Time Interval–based Data",
    "doi": "https://doi.org/10.1145/3391230",
    "publication_date": "2020-05-25",
    "publication_year": 2020,
    "authors": "Jun-Zhe Wang; Yi-Cheng Chen; Wen-Yueh Shih; Lin Yang; Yu-Shao Liu; Jiun‐Long Huang",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a novel temporal pattern mining problem, named high-utility temporal pattern mining , to fulfill the needs of various applications. Different from classical temporal pattern mining aimed at discovering frequent temporal patterns, high-utility temporal pattern mining is to find each temporal pattern whose utility is greater than or equal to the minimum-utility threshold. To facilitate efficient high-utility temporal pattern mining, several extension and pruning strategies are proposed to reduce the search space. Algorithm HUTPMiner is then proposed to efficiently mine high-utility temporal patterns with the aid of the proposed extension and pruning strategies. Experimental results show that HUTPMiner is able to prune a large number of candidates, thereby achieving high mining efficiency.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3033594068",
    "type": "article"
  },
  {
    "title": "Mapping Points of Interest Through Street View Imagery and Paid Crowdsourcing",
    "doi": "https://doi.org/10.1145/3403931",
    "publication_date": "2020-08-10",
    "publication_year": 2020,
    "authors": "Eddy Maddalena; Luis Ibáñez; Elena Simperl",
    "corresponding_authors": "",
    "abstract": "We present the Virtual City Explorer (VCE), an online crowdsourcing platform for the collection of rich geotagged information in urban environments. Compared to other volunteered geographic information approaches, which are constrained by the number and availability of mapping enthusiasts on the ground, the VCE uses digital street imagery to allow people to virtually explore a city from anywhere in the world, using a browser or a mobile phone. In addition, contributions in VCE are designed as paid microtasks—small jobs that can be carried out without any specific knowledge of the local area or previous mapping expertise in exchange for a fee. We tested the VCE in two cities to map points of interest (PoIs) in transport and mobility, using FigureEight to recruit participants. We were able to show that our platform enables crowdworkers to submit PoI location seamlessly, cover almost all of the tested areas, and discover several PoIs not reported by other approaches. This allows the VCE to complement existing approaches that leverage experts or grassroot communities.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3038425154",
    "type": "article"
  },
  {
    "title": "Forecasting Price Trend of Bulk Commodities Leveraging Cross-domain Open Data Fusion",
    "doi": "https://doi.org/10.1145/3354287",
    "publication_date": "2020-01-21",
    "publication_year": 2020,
    "authors": "Binbin Zhou; Sha Zhao; Longbiao Chen; Shijian Li; Zhaohui Wu; Gang Pan",
    "corresponding_authors": "",
    "abstract": "Forecasting price trend of bulk commodities is important in international trade, not only for markets participants to schedule production and marketing plans but also for government administrators to adjust policies. Previous studies cannot support accurate fine-grained short-term prediction, since they mainly focus on coarse-grained long-term prediction using historical data. Recently, cross-domain open data provides possibilities to conduct fine-grained price forecasting, since they can be leveraged to extract various direct and indirect factors of the price. In this article, we predict the price trend over upcoming days, by leveraging cross-domain open data fusion. More specifically, we formulate the price trend into three classes (rise, slight-change, and fall), and then we predict the specific class in which the price trend of the future day lies. We take three factors into consideration: (1) supply factor considering sources providing bulk commodities,&lt;?brk?&gt; (2) demand factor focusing on vessel transportation with reflection of short time needs, and (3) expectation factor encompassing indirect features (e.g., air quality) with latent influences. A hybrid classification framework is proposed for the price trend forecasting. Evaluation conducted on nine real-world cross-domain open datasets shows that our framework can forecast the price trend accurately, outperforming multiple state-of-the-art baselines.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3044644859",
    "type": "article"
  },
  {
    "title": "Learning Causal Relations in Multivariate Time Series Data",
    "doi": "https://doi.org/10.1145/2337542.2337561",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Zhenxing Wang; Laiwan Chan",
    "corresponding_authors": "",
    "abstract": "Many applications naturally involve time series data and the vector autoregression (VAR), and the structural VAR (SVAR) are dominant tools to investigate relations between variables in time series. In the first part of this work, we show that the SVAR method is incapable of identifying contemporaneous causal relations for Gaussian process. In addition, least squares estimators become unreliable when the scales of the problems are large and observations are limited. In the remaining part, we propose an approach to apply Bayesian network learning algorithms to identify SVARs from time series data in order to capture both temporal and contemporaneous causal relations, and avoid high-order statistical tests. The difficulty of applying Bayesian network learning algorithms to time series is that the sizes of the networks corresponding to time series tend to be large, and high-order statistical tests are required by Bayesian network learning algorithms in this case. To overcome the difficulty, we show that the search space of conditioning sets d-separating two vertices should be a subset of the Markov blankets. Based on this fact, we propose an algorithm enabling us to learn Bayesian networks locally, and make the largest order of statistical tests independent of the scales of the problems. Empirical results show that our algorithm outperforms existing methods in terms of both efficiency and accuracy.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3121988858",
    "type": "article"
  },
  {
    "title": "Flatter Is Better",
    "doi": "https://doi.org/10.1145/3437910",
    "publication_date": "2021-03-09",
    "publication_year": 2021,
    "authors": "Masoud Mansoury; Robin Burke; Bamshad Mobasher",
    "corresponding_authors": "",
    "abstract": "It is well known that explicit user ratings in recommender systems are biased toward high ratings and that users differ significantly in their usage of the rating scale. Implementers usually compensate for these issues through rating normalization or the inclusion of a user bias term in factorization models. However, these methods adjust only for the central tendency of users’ distributions. In this work, we demonstrate that a lack of flatness in rating distributions is negatively correlated with recommendation performance. We propose a rating transformation model that compensates for skew in the rating distribution as well as its central tendency by converting ratings into percentile values as a pre-processing step before recommendation generation. This transformation flattens the rating distribution, better compensates for differences in rating distributions, and improves recommendation performance. We also show that a smoothed version of this transformation can yield more intuitive results for users with very narrow rating distributions. A comprehensive set of experiments, with state-of-the-art recommendation algorithms in four real-world datasets, show improved ranking performance for these percentile transformations.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3137626050",
    "type": "article"
  },
  {
    "title": "MKEL: Multiple Kernel Ensemble Learning via Unified Ensemble Loss for Image Classification",
    "doi": "https://doi.org/10.1145/3457217",
    "publication_date": "2021-06-08",
    "publication_year": 2021,
    "authors": "Xiang‐Jun Shen; Lu Kou; Sumet Mehta; Jianming Zhang; Weifeng Liu; Jianping Fan; Zheng-Jun Zha",
    "corresponding_authors": "",
    "abstract": "In this article, a novel ensemble model, called Multiple Kernel Ensemble Learning (MKEL), is developed by introducing a unified ensemble loss. Different from the previous multiple kernel learning (MKL) methods, which attempt to seek a linear combination of basis kernels as a unified kernel, our MKEL model aims to find multiple solutions in corresponding Reproducing Kernel Hilbert Spaces (RKHSs) simultaneously. To achieve this goal, multiple individual kernel losses are integrated into a unified ensemble loss. Therefore, each model can co-optimize to learn its optimal parameters by minimizing a unified ensemble loss in multiple RKHSs. Furthermore, we apply our proposed ensemble loss into the deep network paradigm and take the sub-network as a kernel mapping from the original input space into a feature space, named Deep-MKEL (D-MKEL). Our D-MKEL model can utilize the diversified deep individual sub-networks into a whole unified network to improve the classification performance. With this unified loss design, our D-MKEL model can make our network much wider than other traditional deep kernel networks and more parameters are learned and optimized. Experimental results on several mediate UCI classification and computer vision datasets demonstrate that our MKEL model can achieve the best classification performance among comparative MKL methods, such as Simple MKL, GMKL, Spicy MKL, and Matrix-Regularized MKL. On the contrary, experimental results on large-scale CIFAR-10 and SVHN datasets concretely show the advantages and potentialities of the proposed D-MKEL approach compared to state-of-the-art deep kernel methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3169441824",
    "type": "article"
  },
  {
    "title": "Improved Fake Reviews Detection Model Based on Vertical Ensemble Tri-Training and Active Learning",
    "doi": "https://doi.org/10.1145/3450285",
    "publication_date": "2021-06-03",
    "publication_year": 2021,
    "authors": "Chunyong Yin; Haoqi Cuan; Yuhang Zhu; Zhichao Yin",
    "corresponding_authors": "",
    "abstract": "People’s increasingly frequent online activity has generated a large number of reviews, whereas fake reviews can mislead users and harm their personal interests. In addition, it is not feasible to label reviews on a large scale because of the high cost of manual labeling. Therefore, to improve the detection performance by utilizing the unlabeled reviews, this article proposes a fake reviews detection model based on vertical ensemble tri-training and active learning (VETT-AL). The model combines the features of review text with the user behavior features as feature extraction. In the VETT-AL algorithm, the iterative process is divided into two parts: vertical integration within the group and horizontal integration among the groups. The intra-group integration is to integrate three original classifiers by using the previous iterative models of the classifiers. The inter-group integration is to adopt the active learning based on entropy to select the data with the highest confidence and label it, and as the result of that, the second generation classifiers are trained by the traditional process to improve the accuracy of the label. Experimental results show that the proposed model has a good classification performance.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3171522246",
    "type": "article"
  },
  {
    "title": "<scp>Nova</scp> : Value-based Negotiation of Norms",
    "doi": "https://doi.org/10.1145/3465054",
    "publication_date": "2021-08-01",
    "publication_year": 2021,
    "authors": "Reyhan Aydoğan; Özgür Kafalı; Furkan Arslan; Catholijn M. Jonker; Munindar P. Singh",
    "corresponding_authors": "",
    "abstract": "Specifying a normative multiagent system (nMAS) is challenging, because different agents often have conflicting requirements. Whereas existing approaches can resolve clear-cut conflicts, tradeoffs might occur in practice among alternative nMAS specifications with no apparent resolution. To produce an nMAS specification that is acceptable to each agent, we model the specification process as a negotiation over a set of norms. We propose an agent-based negotiation framework, where agents’ requirements are represented as values (e.g., patient safety, privacy, and national security), and an agent revises the nMAS specification to promote its values by executing a set of norm revision rules that incorporate ontology-based reasoning. To demonstrate that our framework supports creating a transparent and accountable nMAS specification, we conduct an experiment with human participants who negotiate against our agent. Our findings show that our negotiation agent reaches better agreements (with small p -value and large effect size) faster than a baseline strategy. Moreover, participants perceive that our agent enables more collaborative and transparent negotiations than the baseline (with small p -value and large effect size in particular settings) toward reaching an agreement.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3188800054",
    "type": "article"
  },
  {
    "title": "POLLA: Enhancing the Local Structure Awareness in Long Sequence Spatial-temporal Modeling",
    "doi": "https://doi.org/10.1145/3447987",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Haoyi Zhou; Hao Peng; Jieqi Peng; Shuai Zhang; Jianxin Li",
    "corresponding_authors": "",
    "abstract": "The spatial-temporal modeling on long sequences is of great importance in many real-world applications. Recent studies have shown the potential of applying the self-attention mechanism to improve capturing the complex spatial-temporal dependencies. However, the lack of underlying structure information weakens its general performance on long sequence spatial-temporal problem. To overcome this limitation, we proposed a novel method, named the Proximity-aware Long Sequence Learning framework, and apply it to the spatial-temporal forecasting task. The model substitutes the canonical self-attention by leveraging the proximity-aware attention, which enhances local structure clues in building long-range dependencies with a linear approximation of attention scores. The relief adjacency matrix technique can utilize the historical global graph information for consistent proximity learning. Meanwhile, the reduced decoder allows for fast inference in a non-autoregressive manner. Extensive experiments are conducted on five large-scale datasets, which demonstrate that our method achieves state-of-the-art performance and validates the effectiveness brought by local structure information.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3215152557",
    "type": "article"
  },
  {
    "title": "PARP: A Parallel Traffic Condition Driven Route Planning Model on Dynamic Road Networks",
    "doi": "https://doi.org/10.1145/3459099",
    "publication_date": "2021-12-16",
    "publication_year": 2021,
    "authors": "Tianlun Dai; Bohan Li; Ziqiang Yu; Xiangrong Tong; Meng Chen; Gang Chen",
    "corresponding_authors": "",
    "abstract": "The problem of route planning on road network is essential to many Location-Based Services (LBSs). Road networks are dynamic in the sense that the weights of the edges in the corresponding graph constantly change over time, representing evolving traffic conditions. Thus, a practical route planning strategy is required to supply the continuous route optimization considering the historic, current, and future traffic condition. However, few existing works comprehensively take into account these various traffic conditions during the route planning. Moreover, the LBSs usually suffer from extensive concurrent route planning requests in rush hours, which imposes a pressing need to handle numerous queries in parallel for reducing the response time of each query. However, this issue is also not involved by most existing solutions. We therefore investigate a parallel traffic condition driven route planning model on a cluster of processors. To embed the future traffic condition into the route planning, we employ a GCN model to periodically predict the travel costs of roads within a specified time period, which facilitates the robustness of the route planning model against the varying traffic condition. To reduce the response time, a Dual-Level Path (DLP) index is proposed to support a parallel route planning algorithm with the filter-and-refine principle. The bottom level of DLP partitions the entire graph into different subgraphs, and the top level is a skeleton graph that consists of all border vertices in all subgraphs. The filter step identifies a global directional path for a given query based on the skeleton graph. In the refine step, the overall route planning for this query is decomposed into multiple sub-optimizations in the subgraphs passed through by the directional path. Since the subgraphs are independently maintained by different processors, the sub-optimizations of extensive queries can be operated in parallel. Finally, extensive evaluations are conducted to confirm the effectiveness and superiority of the proposal.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4200151208",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Urban Computing",
    "doi": "https://doi.org/10.1145/2642650",
    "publication_date": "2014-07-28",
    "publication_year": 2014,
    "authors": "Yu Zheng; Licia Capra; Ouri Wolfson; Hai Yang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2051025556",
    "type": "article"
  },
  {
    "title": "AutoLCA",
    "doi": "https://doi.org/10.1145/2505270",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "M. Shahriar Hossain; Manish Marwah; Amip Shah; Layne T. Watson; Naren Ramakrishnan",
    "corresponding_authors": "",
    "abstract": "With increasing public consciousness regarding sustainability, companies are ever more eager to introduce eco-friendly products and services. Assessing environmental footprints and designing sustainable products are challenging tasks since they require analysis of each component of a product through their life cycle. To achieve sustainable design of products, companies need to evaluate the environmental impact of their system, identify the major contributors to the footprint, and select the design alternative with the lowest environmental footprint. In this article, we formulate sustainable design as a series of clustering and classification problems, and propose a framework called AutoLCA that simplifies the effort of estimating the environmental footprint of a product bill of materials by more than an order of magnitude over current methods, which are mostly labor intensive. We apply AutoLCA to real data from a large computer manufacturer. We conduct a case study on bill of materials of four different products, perform a “hotspot” assessment analysis to identify major contributors to carbon footprint, and determine design alternatives that can reduce the carbon footprint from 1% to 36%.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2127572204",
    "type": "article"
  },
  {
    "title": "Estimating a Ranked List of Human Genetic Diseases by Associating Phenotype-Gene with Gene-Disease Bipartite Graphs",
    "doi": "https://doi.org/10.1145/2700487",
    "publication_date": "2015-07-04",
    "publication_year": 2015,
    "authors": "Md Zia Ullah; Masaki Aono; Md. Hanif Seddiqui",
    "corresponding_authors": "",
    "abstract": "With vast amounts of medical knowledge available on the Internet, it is becoming increasingly practical to help doctors in clinical diagnostics by suggesting plausible diseases predicted by applying data and text mining technologies. Recently, Genome-Wide Association Studies ( GWAS ) have proved useful as a method for exploring phenotypic associations with diseases. However, since genetic diseases are difficult to diagnose because of their low prevalence, large number, and broad diversity of symptoms, genetic disease patients are often misdiagnosed or experience long diagnostic delays. In this article, we propose a method for ranking genetic diseases for a set of clinical phenotypes. In this regard, we associate a phenotype-gene bipartite graph ( PGBG ) with a gene-disease bipartite graph ( GDBG ) by producing a phenotype-disease bipartite graph ( PDBG ), and we estimate the candidate weights of diseases. In our approach, all paths from a phenotype to a disease are explored by considering causative genes to assign a weight based on path frequency, and the phenotype is linked to the disease in a new PDBG. We introduce the Bidirectionally induced Importance Weight ( BIW ) prediction method to PDBG for approximating the weights of the edges of diseases with phenotypes by considering link information from both sides of the bipartite graph. The performance of our system is compared to that of other known related systems by estimating Normalized Discounted Cumulative Gain ( NDCG ), Mean Average Precision ( MAP ), and Kendall’s tau metrics. Further experiments are conducted with well-known TF · IDF , BM25 , and Jenson-Shannon divergence as baselines. The result shows that our proposed method outperforms the known related tool Phenomizer in terms of NDCG@10, NDCG@20, MAP@10, and MAP@20; however, it performs worse than Phenomizer in terms of Kendall’s tau-b metric at the top-10 ranks. It also turns out that our proposed method has overall better performance than the baseline methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2205534366",
    "type": "article"
  },
  {
    "title": "Topic-Aware Physical Activity Propagation with Temporal Dynamics in a Health Social Network",
    "doi": "https://doi.org/10.1145/2873066",
    "publication_date": "2016-08-23",
    "publication_year": 2016,
    "authors": "NhatHai Phan; Javid Ebrahimi; David Kil; Brigitte Piniewski; Dejing Dou",
    "corresponding_authors": "",
    "abstract": "Modeling physical activity propagation, such as activity level and intensity, is a key to preventing obesity from cascading through communities, and to helping spread wellness and healthy behavior in a social network. However, there have not been enough scientific and quantitative studies to elucidate how social communication may deliver physical activity interventions. In this work, we introduce a novel model named T opic-aware C ommunity-level P hysical Activity Propagation with T emporal Dynamics (TCPT) to analyze physical activity propagation and social influence at different granularities (i.e., individual level and community level). Given a social network, the TCPT model first integrates the correlations between the content of social communication, social influences, and temporal dynamics. Then, a hierarchical approach is utilized to detect a set of communities and their reciprocal influence strength of physical activities. The experimental evaluation shows not only the effectiveness of our approach but also the correlation of the detected communities with various health outcome measures. Our promising results pave a way for knowledge discovery in health social networks.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2507878589",
    "type": "article"
  },
  {
    "title": "DeepExpress: Heterogeneous and Coupled Sequence Modeling for Express Delivery Prediction",
    "doi": "https://doi.org/10.1145/3526087",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Siyuan Ren; Bin Guo; Longbing Cao; Ke Li; Jiaqi Liu; Zhiwen Yu",
    "corresponding_authors": "",
    "abstract": "The prediction of express delivery sequence, i.e., modeling and estimating the volumes of daily incoming and outgoing parcels for delivery, is critical for online business, logistics, and positive customer experience, and specifically for resource allocation optimization and promotional activity arrangement. A precise estimate of consumer delivery requests has to involve sequential factors such as shopping behaviors, weather conditions, events, business campaigns, and their couplings. Despite that various methods have integrated external features to enhance the effects, extant works fail to address complex feature-sequence couplings in the following aspects: weaken the inter-dependencies when processing heterogeneous data and ignore the cumulative and evolving situation of coupling relationships. To address these issues, we propose DeepExpress—a deep-learning-based express delivery sequence prediction model, which extends the classic seq2seq framework to learn feature-sequence couplings. DeepExpress leverages an express delivery seq2seq learning, a carefully designed heterogeneous feature representation, and a novel joint training attention mechanism to adaptively handle heterogeneity issues and capture feature-sequence couplings for accurate prediction. Experimental results on real-world data demonstrate that the proposed method outperforms both shallow and deep baseline models.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3195032234",
    "type": "article"
  },
  {
    "title": "Bayesian Attribute Bagging-Based Extreme Learning Machine for High-Dimensional Classification and Regression",
    "doi": "https://doi.org/10.1145/3495164",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "Yulin He; Xuan Ye; Joshua Zhexue Huang; Philippe Fournier‐Viger",
    "corresponding_authors": "",
    "abstract": "This article presents a Bayesian attribute bagging-based extreme learning machine (BAB-ELM) to handle high-dimensional classification and regression problems. First, the decision-making degree (DMD) of a condition attribute is calculated based on the Bayesian decision theory, i.e., the conditional probability of the condition attribute given the decision attribute. Second, the condition attribute with the highest DMD is put into the condition attribute group (CAG) corresponding to the specific decision attribute. Third, the bagging attribute groups (BAGs) are used to train an ensemble learning model of extreme learning machines (ELMs). Each base ELM is trained on a BAG which is composed of condition attributes that are randomly selected from the CAGs. Fourth, the information amount ratios of bagging condition attributes to all condition attributes is used as the weights to fuse the predictions of base ELMs in BAB-ELM. Exhaustive experiments have been conducted to compare the feasibility and effectiveness of BAB-ELM with seven other ELM models, i.e., ELM, ensemble-based ELM (EN-ELM), voting-based ELM (V-ELM), ensemble ELM (E-ELM), ensemble ELM based on multi-activation functions (MAF-EELM), bagging ELM, and simple ensemble ELM. Experimental results show that BAB-ELM is convergent with the increase of base ELMs and also can yield higher classification accuracy and lower regression error for high-dimensional classification and regression problems.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4220890569",
    "type": "article"
  },
  {
    "title": "Intrinsic Performance Influence-based Participant Contribution Estimation for Horizontal Federated Learning",
    "doi": "https://doi.org/10.1145/3523059",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Lin Zhang; Lixin Fan; Yong Luo; Ling‐Yu Duan",
    "corresponding_authors": "",
    "abstract": "The rapid development of modern artificial intelligence technique is mainly attributed to sufficient and high-quality data. However, in the data collection, personal privacy is at risk of being leaked. This issue can be addressed by federated learning, which is proposed to achieve efficient model training among multiple data providers without direct data access and aggregation. To encourage more parties owning high-quality data to participate in the federated learning, it is important to evaluate and reward the participant contribution in a reasonable, robust, and efficient manner. To achieve this goal, we propose a novel contribution estimation method: Intrinsic Performance Influence-based Contribution Estimation (IPICE). In particular, the class-level intrinsic performance influence is adopted as the contribution estimation criteria in IPICE, and a neural network is employed to exploit the non-linear relationship between the performance change and estimated contribution. Extensive experiments are conducted on various datasets, and the results demonstrate that IPICE is more accurate and stable than the counterpart in various data distribution settings. The computational complexity is significantly reduced in our IPICE, especially when a new party joins the federation. IPICE assigns small contributions to bad/garbage data and thus prevent them from participating and deteriorating the learning ecosystem.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4220989197",
    "type": "article"
  },
  {
    "title": "Federated Multi-task Graph Learning",
    "doi": "https://doi.org/10.1145/3527622",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Yijing Liu; Dongming Han; Jianwei Zhang; Haiyang Zhu; Mingliang Xu; Wei Chen",
    "corresponding_authors": "",
    "abstract": "Distributed processing and analysis of large-scale graph data remain challenging because of the high-level discrepancy among graphs. This study investigates a novel subproblem: the distributed multi-task learning on the graph, which jointly learns multiple analysis tasks from decentralized graphs. We propose a federated multi-task graph learning (FMTGL) framework to solve the problem within a privacy-preserving and scalable scheme. Its core is an innovative data-fusion mechanism and a low-latency distributed optimization method. The former captures multi-source data relatedness and generates universal task representation for local task analysis. The latter enables the quick update of our framework with gradients sparsification and tree-based aggregation. As a theoretical result, the proposed optimization method has a convergence rate interpolates between \\( \\mathcal {O}(1/T) \\) and \\( \\mathcal {O}(1/\\sqrt {T}) \\) , up to logarithmic terms. Unlike previous studies, our work analyzes the convergence behavior with adaptive stepsize selection and non-convex assumption. Experimental results on three graph datasets verify the effectiveness and scalability of FMTGL.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4224211339",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Collaborative Filtering by Distributed Mediation",
    "doi": "https://doi.org/10.1145/3542950",
    "publication_date": "2022-06-06",
    "publication_year": 2022,
    "authors": "Tamir Tassa; Alon Ben Horin",
    "corresponding_authors": "",
    "abstract": "Recommender systems have become very influential in our everyday decision making, e.g., helping us choose a movie from a content platform, or offering us suitable products on e-commerce websites. While most vendors who utilize recommender systems rely exclusively on training data consisting of past transactions that took place through them, it would be beneficial to base recommendations on the rating data of more than one vendor. However, enlarging the training data by means of sharing information between different vendors may jeopardize the privacy of users. We devise here secure multi-party protocols that enable the practice of Collaborative Filtering (CF) in a manner that preserves the privacy of the vendors and users. Shmueli and Tassa [ 38 ] introduced privacy-preserving protocols of CF that involved a mediator; namely, an external entity that assists in performing the computations. They demonstrated the significant advantages of mediation in that context. We take here the mediation approach into the next level by using several independent mediators. Such distributed mediation maintains all of the advantages that were identified by Shmueli and Tassa, and offers additional ones, in comparison with the single-mediator protocols: stronger security and dramatically shorter runtimes. In addition, while all prior art assumed limited and unrealistic settings, in which each user can purchase any given item through only one vendor, we consider here a general and more realistic setting, which encompasses all previously considered settings, where users can choose between different competing vendors. We demonstrate the appealing performance of our protocols through extensive experimentation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4282032145",
    "type": "article"
  },
  {
    "title": "A System for Automated Industrial Test Laboratory Scheduling",
    "doi": "https://doi.org/10.1145/3546871",
    "publication_date": "2022-08-01",
    "publication_year": 2022,
    "authors": "Philipp Danzinger; Tobias Geibinger; David Janneau; Florian Mischek; Nysret Musliu; Christian Poschalko",
    "corresponding_authors": "",
    "abstract": "Automated scheduling solutions are tremendously important for the efficient operation of industrial laboratories. The Test Laboratory Scheduling Problem (TLSP) is an extension of the well-known Resource Constrained Project Scheduling Problem (RCPSP) and captures the specific requirements of such laboratories. In addition to several new scheduling constraints, it features a grouping phase, where the jobs to be scheduled are assembled from smaller units. In this work, we introduce an innovative scheduling system that allows the efficient and flexible generation of schedules for TLSP. It features a new Constraint Programming model that covers both the grouping and the scheduling aspect, as well as a hybrid Very Large Neighborhood Search that internally uses the CP model. Our experimental results on generated and real-world benchmark instances show that good results can be obtained even compared to settings which have a good grouping already provided, including several new best known solutions for these instances. Our algorithms for TLSP have been successfully implemented in a real-world industrial test laboratory. We provide a detailed description of the deployed system as well as additional useful soft constraints supported by the solvers and general lessons learned. This includes a discussion of the choice of soft constraint weights, with an analysis on the impact and relation of different objectives to each other. Our experiments show that some soft constraints complement each other well, while others require explicit trade-offs via their relative weights.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4289223938",
    "type": "article"
  },
  {
    "title": "ONION: Online Semantic Autoencoder Hashing for Cross-Modal Retrieval",
    "doi": "https://doi.org/10.1145/3572032",
    "publication_date": "2022-11-21",
    "publication_year": 2022,
    "authors": "Donglin Zhang; Xiao‐Jun Wu; Guoqing Chen",
    "corresponding_authors": "",
    "abstract": "Cross-modal hashing (CMH) has recently received increasing attention with the merit of speed and storage in performing large-scale cross-media similarity search. However, most existing cross-media approaches utilize the batch-based mode to update hash functions, without the ability to efficiently handle the online streaming multimedia data. Online hashing can effectively address the preceding issue by using the online learning scheme to incrementally update the hash functions. Nevertheless, the existing online CMH approaches still suffer from several challenges, such as (1) how to efficiently and effectively utilize the supervision information, (2) how to learn more powerful hash functions, and (3) how to solve the binary constraints. To mitigate these limitations, we present a novel online hashing approach named ONION ( ON line semant I c aut O encoder hashi N g). Specifically, it leverages the semantic autoencoder scheme to establish the correlations between binary codes and labels, delivering the power to obtain more discriminative hash codes. Besides, the proposed ONION directly utilizes the label inner product to build the connection between existing data and newly coming data. Therefore, the optimization is less sensitive to the newly arriving data. Equipping a discrete optimization scheme designed to solve the binary constraints, the quantization errors can be dramatically reduced. Furthermore, the hash functions are learned by the proposed autoencoder strategy, making the hash functions more powerful. Extensive experiments on three large-scale databases demonstrate that the performance of our ONION is superior to several recent competitive online and offline cross-media algorithms.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4309756585",
    "type": "article"
  },
  {
    "title": "Highly Efficient Traffic Planning for Autonomous Vehicles to Cross Intersections Without a Stop",
    "doi": "https://doi.org/10.1145/3572034",
    "publication_date": "2022-12-07",
    "publication_year": 2022,
    "authors": "Jian Kang; Dan Lin",
    "corresponding_authors": "",
    "abstract": "Waiting in a long queue at traffic lights not only wastes valuable time but also pollutes the environment. With the advances in autonomous vehicles and 5G networks, the previous jamming scenarios at intersections may be turned into non-stop weaving traffic flows. Toward this vision, we propose a highly efficient traffic planning system, namely DASHX, which enables connected autonomous vehicles to cross multi-way intersections without a stop. Specifically, DASHX has a comprehensive model to represent intersections and vehicle status. It can constantly process large volumes of vehicle information, resolve scheduling conflicts, and generate optimal travel plans for all vehicles coming toward the intersection in real time. Unlike existing works that are limited to certain types of intersections and lack considerations of practicability, DASHX is universal for any type of 3D intersection and yields the near-maximum throughput while still ensuring riding comfort. To better evaluate the effectiveness of traffic scheduling systems in real-world scenarios, we developed a sophisticated open source 3D traffic simulation platform (DASHX-SIM) that can handle complicated 3D road layouts and simulate vehicles’ networking and decision-making processes. We have conducted extensive experiments, and the experimental results demonstrate the practicality, effectiveness, and efficiency of the DASHX system and the simulator.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4311808570",
    "type": "article"
  },
  {
    "title": "Variational inference with graph regularization for image annotation",
    "doi": "https://doi.org/10.1145/1899412.1899415",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Yuanlong Shao; Yuan Zhou; Deng Cai",
    "corresponding_authors": "",
    "abstract": "Image annotation is a typical area where there are multiple types of attributes associated with each individual image. In order to achieve better performance, it is important to develop effective modeling by utilizing prior knowledge. In this article, we extend the graph regularization approaches to a more general case where the regularization is imposed on the factorized variational distributions, instead of posterior distributions implicitly involved in EM-like algorithms. In this way, the problem modeling can be more flexible, and we can choose any factor in the problem domain to impose graph regularization wherever there are similarity constraints among the instances. We formulate the problem formally and show its geometrical background in manifold learning. We also design two practically effective algorithms and analyze their properties such as the convergence. Finally, we apply our approach to image annotation and show the performance improvement of our algorithm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1973314647",
    "type": "article"
  },
  {
    "title": "FolderPredictor",
    "doi": "https://doi.org/10.1145/1889681.1889689",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Xinlong Bao; Thomas G. Dietterich",
    "corresponding_authors": "",
    "abstract": "Helping computer users rapidly locate files in their folder hierarchies is a practical research problem involving both intelligent systems and user interface design. This article reports on FolderPredictor, a software system that can reduce the cost of locating files in hierarchical folders. FolderPredictor applies a cost-sensitive prediction algorithm to the user's previous file access information to predict the next folder that will be accessed. Experimental results show that, on average, FolderPredictor reduces the number of clicks spent on locating a file by 50%. Several variations of the cost-sensitive prediction algorithm are discussed. An experimental study shows that the best algorithm among them is a mixture of the most recently used (MRU) folder and the cost-sensitive predictions. Furthermore, FolderPredictor does not require users to adapt to a new interface, but rather meshes with the existing interface for opening files on the Windows platform.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1984246149",
    "type": "article"
  },
  {
    "title": "A helpfulness modeling framework for electronic word-of-mouth on consumer opinion platforms",
    "doi": "https://doi.org/10.1145/1961189.1961195",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Richong Zhang; Thomas Tran",
    "corresponding_authors": "",
    "abstract": "Electronic Word-of-Mouth (eWOM) is growing exponentially with the rapid development of electronic commerce. As a result, consumers are increasingly crowded by a huge amount of eWOM contents and therefore there is a need to automatically recommend eWOM contents that are helpful to them. Existing helpfulness assessment approaches that deterministically estimate the helpfulness of eWOM contents lack a generative formulation and are limited to the training set that has been voted by many readers. This article presents a rigorous probabilistic framework for inferring the “helpfulness” of eWOM contents which can build a “helpfulness” model from a low number of votes on eWOM contents. Furthermore, we introduce a measurement, “helpfulness” bias, as the benchmark for the “helpfulness” of eWOM documents. We also propose a model that exploits the graphical model and expectation maximization algorithm, under this probabilistic framework, to demonstrate the versatility of our framework. Our algorithm is compared experimentally to other existing helpfulness discovering algorithms and the experimental results show that our framework can effectively model the helpfulness of eWOM contents better than other approaches, and therefore indicate the capability of our framework to recommend helpful eWOMs to potential consumers.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1993097961",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on social recommender systems",
    "doi": "https://doi.org/10.1145/2414425.2414432",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Ido Guy; Li Chen; Michelle X. Zhou",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1994090921",
    "type": "article"
  },
  {
    "title": "Detecting changes in information diffusion patterns over social networks",
    "doi": "https://doi.org/10.1145/2483669.2483688",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Kazumi Saito; Masahiro Kimura; Kouzou Ohara; Hiroshi Motoda",
    "corresponding_authors": "",
    "abstract": "We addressed the problem of detecting the change in behavior of information diffusion over a social network which is caused by an unknown external situation change using a small amount of observation data in a retrospective setting. The unknown change is assumed effectively reflected in changes in the parameter values in the probabilistic information diffusion model, and the problem is reduced to detecting where in time and how long this change persisted and how big this change is. We solved this problem by searching the change pattern that maximizes the likelihood of generating the observed information diffusion sequences, and in doing so we devised a very efficient general iterative search algorithm using the derivative of the likelihood which avoids parameter value optimization during each search step. This is in contrast to the naive learning algorithm in that it has to iteratively update the patten boundaries, each requiring the parameter value optimization and thus is very inefficient. We tested this algorithm for two instances of the probabilistic information diffusion model which has different characteristics. One is of information push style and the other is of information pull style. We chose Asynchronous Independent Cascade (AsIC) model as the former and Value-weighted Voter (VwV) model as the latter. The AsIC is the model for general information diffusion with binary states and the parameter to detect its change is diffusion probability and the VwV is the model for opinion formation with multiple states and the parameter to detect its change is opinion value. The results tested on these two models using four real-world network structures confirm that the algorithm is robust enough and can efficiently identify the correct change pattern of the parameter values. Comparison with the naive method that finds the best combination of change boundaries by an exhaustive search through a set of randomly selected boundary candidates shows that the proposed algorithm far outperforms the native method both in terms of accuracy and computation time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2023340601",
    "type": "article"
  },
  {
    "title": "Virtual worlds as cultural models",
    "doi": "https://doi.org/10.1145/1858948.1858951",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "William Sims Bainbridge",
    "corresponding_authors": "William Sims Bainbridge",
    "abstract": "Thirteen gamelike virtual worlds illustrate issues that overlap social science and information science, because they embody rather clear theories of society and culture: World of Warcraft , Lord of the Rings Online , Dark Age of Camelot , Age of Conan , Pirates of the Burning Sea , A Tale in the Desert , Entropia Universe , Anarchy Online , The Matrix Online , Tabula Rasa , EVE Online , Star Trek Online, and Dungeons and Dragons Online . A fourteenth, Star Wars Galaxies , illustrates the possibility that not all virtual worlds embody clear theories. After describing the thirteen, this essay discusses their economic systems, social systems, communication challenges, and the ways in which autonomous agents and semi-autonomous secondary avatars enrich interactive complexity.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2065778018",
    "type": "article"
  },
  {
    "title": "Bootstrapping a Game with a Purpose for Commonsense Collection",
    "doi": "https://doi.org/10.1145/2337542.2337544",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Amaç Herdağdelen; Marco Baroni",
    "corresponding_authors": "",
    "abstract": "Text mining has been very successful in extracting huge amounts of commonsense knowledge from data, but the extracted knowledge tends to be extremely noisy. Manual construction of knowledge repositories, on the other hand, tends to produce high-quality data in very small amounts. We propose an architecture to combine the best of both worlds: A game with a purpose that induces humans to clean up data automatically extracted by text mining. First, a text miner trained on a set of known commonsense facts harvests many more candidate facts from corpora. Then, a simple slot-machine-with-a-purpose game presents these candidate facts to the players for verification by playing. As a result, a new dataset of high precision commonsense knowledge is created. This combined architecture is able to produce significantly better commonsense facts than the state-of-the-art text miner alone. Furthermore, we report that bootstrapping (i.e., training the text miner on the output of the game) improves the subsequent performance of the text miner.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2072734893",
    "type": "article"
  },
  {
    "title": "Using targeted paraphrasing and monolingual crowdsourcing to improve translation",
    "doi": "https://doi.org/10.1145/2483669.2483671",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Philip Resnik; Olivia Buzek; Yakov Kronrod; Chang Hu; Alexander J. Quinn; Benjamin B. Bederson",
    "corresponding_authors": "",
    "abstract": "Targeted paraphrasing is a new approach to the problem of obtaining cost-effective, reasonable quality translation, which makes use of simple and inexpensive human computations by monolingual speakers in combination with machine translation. The key insight behind the process is that it is possible to spot likely translation errors with only monolingual knowledge of the target language, and it is possible to generate alternative ways to say the same thing (i.e., paraphrases) with only monolingual knowledge of the source language. Formal evaluation demonstrates that this approach can yield substantial improvements in translation quality, and the idea has been integrated into a broader framework for monolingual collaborative translation that produces fully accurate, fully fluent translations for a majority of sentences in a real-world translation task, with no involvement of human bilingual speakers.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2117405790",
    "type": "article"
  },
  {
    "title": "Leveraging Social Bookmarks from Partially Tagged Corpus for Improved Web Page Clustering",
    "doi": "https://doi.org/10.1145/2337542.2337552",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Anusua Trivedi; Piyush Rai; Hal Daumé; Scott L. DuVall",
    "corresponding_authors": "",
    "abstract": "Automatic clustering of Web pages helps a number of information retrieval tasks, such as improving user interfaces, collection clustering, introducing diversity in search results, etc. Typically, Web page clustering algorithms use only features extracted from the page-text. However, the advent of social-bookmarking Web sites, such as StumbleUpon.com and Delicious.com, has led to a huge amount of user-generated content such as the social tag information that is associated with the Web pages. In this article, we present a subspace based feature extraction approach that leverages the social tag information to complement the page-contents of a Web page for extracting beter features, with the goal of improved clustering performance. In our approach, we consider page-text and tags as two separate views of the data, and learn a shared subspace that maximizes the correlation between the two views. Any clustering algorithm can then be applied in this subspace. We then present an extension that allows our approach to be applicable even if the Web page corpus is only partially tagged, that is, when the social tags are present for not all, but only for a small number of Web pages. We compare our subspace based approach with a number of baselines that use tag information in various other ways, and show that the subspace based approach leads to improved performance on the Web page clustering task. We also discuss some possible future work including an active learning extension that can help in choosing which Web pages to get tags for, if we only can get the social tags for only a small number of Web pages.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2154099239",
    "type": "article"
  },
  {
    "title": "DMAD",
    "doi": "https://doi.org/10.1145/3065949",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Jiaxing Shen; Jiannong Cao; Xuefeng Liu; Chisheng Zhang",
    "corresponding_authors": "",
    "abstract": "Wireless networks offer many advantages over wired local area networks such as scalability and mobility. Strategically deployed wireless networks can achieve multiple objectives like traffic offloading, network coverage, and indoor localization. To this end, various mathematical models and optimization algorithms have been proposed to find optimal deployments of access points (APs). However, wireless signals can be blocked by the human body, especially in crowded urban spaces. As a result, the real coverage of an on-site AP deployment may shrink to some degree and lead to unexpected dead spots (areas without wireless coverage). Dead spots are undesirable, since they degrade the user experience in network service continuity, on one hand, and, on the other hand paralyze some applications and services like tracking and monitoring when users are in these areas. Nevertheless, it is nontrivial for existing methods to analyze the impact of human beings on wireless coverage. Site surveys are too time consuming and labor intensive to conduct. It is also infeasible for simulation methods to predict the number of on-site people. In this article, we propose DMAD, a Data-driven Measuring of Wi-Fi Access point Deployment, which not only estimates potential dead spots of an on-site AP deployment but also quantifies their severity, using simple Wi-Fi data collected from the on-site deployment and shop profiles from the Internet. DMAD first classifies static devices and mobile devices with a decision-tree classifier. Then it locates mobile devices to grid-level locations based on shop popularities, wireless signal, and visit duration. Last, DMAD estimates the probability of dead spots for each grid during different time slots and derives their severity considering the probability and the number of potential users. The analysis of Wi-Fi data from static devices indicates that the Pearson Correlation Coefficient of wireless coverage status and the number of on-site people is over 0.7, which confirms that human beings may have a significant impact on wireless coverage. We also conduct extensive experiments in a large shopping mall in Shenzhen. The evaluation results demonstrate that DMAD can find around 70% of dead spots with a precision of over 70%.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2746471012",
    "type": "article"
  },
  {
    "title": "Strategic Attack &amp; Defense in Security Diffusion Games",
    "doi": "https://doi.org/10.1145/3357605",
    "publication_date": "2019-12-10",
    "publication_year": 2019,
    "authors": "Marcin Waniek; Tomasz Michalak; Aamena Alshamsi",
    "corresponding_authors": "",
    "abstract": "Security games model the confrontation between a defender protecting a set of targets and an attacker who tries to capture them. A variant of these games assumes security interdependence between targets, facilitating contagion of an attack. So far, only stochastic spread of an attack has been considered. In this work, we introduce a version of security games, where the attacker strategically drives the entire spread of attack and where interconnections between nodes affect their susceptibility to be captured. We find that the strategies effective in the settings without contagion or with stochastic contagion are no longer feasible when spread of attack is strategic. While in the former settings it was possible to efficiently find optimal strategies of the attacker, doing so in the latter setting turns out to be an NP-complete problem for an arbitrary network. However, for some simpler network structures, such as cliques, stars, and trees, we show that it is possible to efficiently find optimal strategies of both players. For arbitrary networks, we study and compare the efficiency of various heuristic strategies. As opposed to previous works with no or stochastic contagion, we find that centrality-based defense is often effective when spread of attack is strategic, particularly for centrality measures based on the Shapley value.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2994770585",
    "type": "article"
  },
  {
    "title": "Discovering Interesting Subpaths with Statistical Significance from Spatiotemporal Datasets",
    "doi": "https://doi.org/10.1145/3354189",
    "publication_date": "2020-01-09",
    "publication_year": 2020,
    "authors": "Yiqun Xie; Xun Zhou; Shashi Shekhar",
    "corresponding_authors": "",
    "abstract": "Given a path in a spatial or temporal framework, we aim to find all contiguous subpaths that are both interesting (e.g., abrupt changes) and statistically significant (i.e., persistent trends rather than local fluctuations). Discovering interesting subpaths can provide meaningful information for a variety of domains including Earth science, environmental science, urban planning, and the like. Existing methods are limited to detecting individual points of interest along an input path but cannot find interesting subpaths. Our preliminary work provided a Subpath Enumeration and Pruning (SEP) algorithm to detect interesting subpaths of arbitrary length. However, SEP is not effective in avoiding detections that are random variations rather than meaningful trends, which hampers clear and proper interpretations of the results. In this article, we extend our previous work by proposing a significance testing framework to eliminate these random variations. To compute the statistical significance, we first show a baseline Monte-Carlo method based on our previous work and then propose a Dynamic Search-and-Prune (D-SAP) algorithm to improve its computational efficiency. Our experiments show that the significance testing can greatly suppress the noisy detections in the output and D-SAP can greatly reduce the execution time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3005686672",
    "type": "article"
  },
  {
    "title": "Exploring Correlation Network for Cheating Detection",
    "doi": "https://doi.org/10.1145/3364221",
    "publication_date": "2020-01-17",
    "publication_year": 2020,
    "authors": "Ping Luo; Kai Shu; Junjie Wu; Li Wan; Yong Tan",
    "corresponding_authors": "",
    "abstract": "The correlation network, typically formed by computing pairwise correlations between variables, has recently become a competitive paradigm to discover insights in various application domains, such as climate prediction, financial marketing, and bioinformatics. In this study, we adopt this paradigm to detect cheating behavior hidden in business distribution channels, where falsified big deals are often made by collusive partners to obtain lower product prices—a behavior deemed to be extremely harmful to the sale ecosystem. To this end, we assume that abnormal deals are likely to occur between two partners if their purchase-volume sequences have a strong negative correlation. This seemingly intuitive rule, however, imposes several research challenges. First, existing correlation measures are usually symmetric and thus cannot distinguish the different roles of partners in cheating. Second, the tick-to-tick correspondence between two sequences might be violated due to the possible delay of purchase behavior, which should also be captured by correlation measures. Finally, the fact that any pair of sequences could be correlated may result in a number of false-positive cheating pairs, which need to be corrected in a systematic manner. To address these issues, we propose a correlation network analysis framework for cheating detection. In the framework, we adopt an asymmetric correlation measure to distinguish the two roles, namely, cheating seller and cheating buyer , in a cheating alliance. Dynamic Time Warping is employed to address the time offset between two sequences in computing the correlation. We further propose two graph-cut methods to convert the correlation network into a bipartite graph to rank cheating partners, which simultaneously helps to remove false-positive correlation pairs. Based on a 4-year real-world channel dataset from a worldwide IT company, we demonstrate the effectiveness of the proposed method in comparison to competitive baseline methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3012979415",
    "type": "article"
  },
  {
    "title": "FROST",
    "doi": "https://doi.org/10.1145/3361740",
    "publication_date": "2020-01-17",
    "publication_year": 2020,
    "authors": "Meng Wang; Hui Li; Jiangtao Cui; Sourav S. Bhowmick; Ping Liu",
    "corresponding_authors": "",
    "abstract": "The facility relocation (FR) problem, which aims to optimize the placement of facilities to accommodate the changes of users’ locations, has a broad spectrum of applications. Despite the significant progress made by existing solutions to the FR problem, they all assume each user is stationary and represented as a single point. Unfortunately, in reality, objects (e.g., people, animals) are mobile. For example, a car-sharing user picks up a vehicle from a station close to where he or she is currently located. Consequently, these efforts may fail to identify a superior solution to the FR problem. In this article, for the first time, we take into account the movement history of users and introduce a novel FR problem, called motion-fr , to address the preceding limitation. Specifically, we present a framework called frost to address it. frost comprises two exact algorithms: index based and index free . The former is designed to address the scenario when facilities and objects are known a priori , whereas the latter solves the motion-fr problem by jettisoning this assumption. Further, we extend the index-based algorithm to solve the general k - motion-fr problem, which aims to relocate k inferior facilities. We devise an approximate solution due to NP-hardness of the problem. Experimental study over both real-world and synthetic datasets demonstrates the superiority of our framework in comparison to state-of-the-art FR techniques in efficiency and effectiveness.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3013416779",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Diversity and Discovery in Recommender Systems",
    "doi": "https://doi.org/10.1145/2668113",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Pablo Castells; Jun Wang; Rubén Lara; Dell Zhang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on Diversity and Discovery in Recommender Systems Authors: Pablo Castells Universidad Autónoma de Madrid Universidad Autónoma de MadridView Profile , Jun Wang University College London University College LondonView Profile , Rubén Lara Telefónica Digital Telefónica DigitalView Profile , Dell Zhang Birkbeck, University of London Birkbeck, University of LondonView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 5Issue 4January 2015 Article No.: 52pp 1–3https://doi.org/10.1145/2668113Online:15 December 2014Publication History 4citation289DownloadsMetricsTotal Citations4Total Downloads289Last 12 Months4Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2000841954",
    "type": "article"
  },
  {
    "title": "Designing Noise-Minimal Rotorcraft Approach Trajectories",
    "doi": "https://doi.org/10.1145/2838738",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Robert A. Morris; Matthew Johnson; Kristen Brent Venable; James Lindsey",
    "corresponding_authors": "",
    "abstract": "NASA and the international aviation community are investing in the development of a commercial transportation infrastructure that includes the increased use of rotorcraft, specifically helicopters and civil tilt rotors. However, there is significant concern over the impact of noise on the communities surrounding the transportation facilities. One way to address the rotorcraft noise problem is by exploiting powerful search techniques coming from artificial intelligence to design low-noise flight profiles that can be then validated though field tests. This article investigates the use of discrete heuristic search methods to design low-noise approach trajectories for rotorcraft. Our work builds on a long research tradition in trajectory optimization using either numerical methods or discrete search. Novel features of our approach include the use of a discrete search space with a resolution that can be varied, and the coupling of search with a robust simulator to evaluate candidates. The article includes a systematic comparison of different search techniques; in particular, in the experiments, we are able to do a trade study that compares complete search algorithms such as A * with faster but approximate methods such as local search.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2343552634",
    "type": "article"
  },
  {
    "title": "Multiagent Resource Allocation for Dynamic Task Arrivals with Preemption",
    "doi": "https://doi.org/10.1145/2875441",
    "publication_date": "2016-07-15",
    "publication_year": 2016,
    "authors": "John A. Doucette; Graham Pinhey; Robin Cohen",
    "corresponding_authors": "",
    "abstract": "In this article, we present a distributed algorithm for allocating resources to tasks in multiagent systems, one that adapts well to dynamic task arrivals where new work arises at short notice. Our algorithm is designed to leverage preemption if it is available, revoking resource allocations to tasks in progress if new opportunities arise that those resources are better suited to handle. Our multiagent model assigns a task agent to each task that must be completed and a proxy agent to each resource that is available. Preemption occurs when a task agent approaches a proxy agent with a sufficiently compelling need that the proxy agent determines the newcomer derives more benefit from the proxy agent’s resource than the task agent currently using that resource. Task agents reason about which resources to request based on a learning of churn and congestion. We compare to a well-established multiagent resource allocation framework that permits preemption under more conservative assumptions and show through simulation that our model allows for improved allocations through more permissive preemption. In all, we offer a novel approach for multiagent resource allocation that is able to cope well with dynamic task arrivals.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2475215202",
    "type": "article"
  },
  {
    "title": "Driving Profiles Computation and Monitoring for Car Insurance CRM",
    "doi": "https://doi.org/10.1145/2912148",
    "publication_date": "2016-08-23",
    "publication_year": 2016,
    "authors": "Mirco Nanni; Roberto Trasarti; Anna Monreale; Valerio Grossi; Dino Pedreschi",
    "corresponding_authors": "",
    "abstract": "Customer segmentation is one of the most traditional and valued tasks in customer relationship management (CRM). In this article, we explore the problem in the context of the car insurance industry, where the mobility behavior of customers plays a key role: Different mobility needs, driving habits, and skills imply also different requirements (level of coverage provided by the insurance) and risks (of accidents). In the present work, we describe a methodology to extract several indicators describing the driving profile of customers, and we provide a clustering-oriented instantiation of the segmentation problem based on such indicators. Then, we consider the availability of a continuous flow of fresh mobility data sent by the circulating vehicles, aiming at keeping our segments constantly up to date. We tackle a major scalability issue that emerges in this context when the number of customers is large—namely, the communication bottleneck—by proposing and implementing a sophisticated distributed monitoring solution that reduces communications between vehicles and company servers to the essential. We validate the framework on a large database of real mobility data coming from GPS devices on private cars. Finally, we analyze the privacy risks that the proposed approach might involve for the users, providing and evaluating a countermeasure based on data perturbation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2509945343",
    "type": "article"
  },
  {
    "title": "Ensemble Active Learning by Contextual Bandits for AI Incubation in Manufacturing",
    "doi": "https://doi.org/10.1145/3627821",
    "publication_date": "2023-10-25",
    "publication_year": 2023,
    "authors": "Yingyan Zeng; Xiaoyu Chen; Ran Jin",
    "corresponding_authors": "",
    "abstract": "An Industrial Cyber-physical System (ICPS) provides a digital foundation for data-driven decision-making by artificial intelligence (AI) models. However, the poor data quality (e.g., inconsistent distribution, imbalanced classes) of high-speed, large-volume data streams poses significant challenges to the online deployment of offline-trained AI models. As an alternative, updating AI models online based on streaming data enables continuous improvement and resilient modeling performance. However, for a supervised learning model (i.e., a base learner), it is labor-intensive to annotate all streaming samples to update the model. Hence, a data acquisition method is needed to select the data for annotation to ensure data quality while saving annotation efforts. In the literature, active learning methods have been proposed to acquire informative samples. Different acquisition criteria were developed for exploration of under-represented regions in the input variable space or exploitation of the well-represented regions for optimal estimation of base learners. However, it remains a challenge to balance the exploration-exploitation trade-off under different online annotation scenarios. On the other hand, an acquisition criterion learned by AI adapts itself to a scenario dynamically, but the ambiguous consideration of the trade-off limits its performance in frequently changing manufacturing contexts. To overcome these limitations, we propose an ensemble active learning method by contextual bandits ( CbeAL ). CbeAL incorporates a set of active learning agents (i.e., acquisition criteria) explicitly designed for exploration or exploitation by a weighted combination of their acquisition decisions. The weight of each agent will be dynamically adjusted based on the usefulness of its decisions to improve the performance of the base learner. With adaptive and explicit consideration of both objectives, CbeAL efficiently guides the data acquisition process by selecting informative samples to reduce the human annotation efforts. Furthermore, we characterize the exploration and exploitation capability of the proposed agents theoretically. The evaluation results in a numerical simulation study and a real case study demonstrates the effectiveness and efficiency of CbeAL in manufacturing process modeling of the ICPS.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4388272453",
    "type": "article"
  },
  {
    "title": "A Camera Identity-guided Distribution Consistency Method for Unsupervised Multi-target Domain Person Re-identification",
    "doi": "https://doi.org/10.1145/3454130",
    "publication_date": "2021-06-08",
    "publication_year": 2021,
    "authors": "Jiajie Tian; Qihao Tang; Rui Li; Teng Zhu; Baopeng Zhang; Jianping Fan",
    "corresponding_authors": "",
    "abstract": "Unsupervised domain adaptation (UDA) for person re-identification (re-ID) is a challenging task due to large variations in human classes, illuminations, camera views, and so on. Currently, existing UDA methods focus on two-domain adaptation and are generally trained on one labeled source set and adapted on the other unlabeled target set. In this article, we put forward a new issue on person re-ID, namely, unsupervised multi-target domain adaptation (UMDA). It involves one labeled source set and multiple unlabeled target sets, which is more reasonable for practical real-world applications. Enabling UMDA has to learn the consistency for multiple domains, which is significantly different from the UDA problem. To ensure distribution consistency and learn the discriminative embedding, we further propose the Camera Identity-guided Distribution Consistency method that performs an alignment operation for multiple domains. The camera identities are encoded into the image semantic information to facilitate the adaptation of features. According to our knowledge, this is the first attempt on the unsupervised multi-target domain adaptation learning. Extensive experiments are executed on Market-1501, DukeMTMC-reID, MSMT17, PersonX, and CUHK03, and our method has achieved very competitive re-ID accuracy in multi-target domains against numerous state-of-the-art methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3166233593",
    "type": "article"
  },
  {
    "title": "Improving Action Recognition via Temporal and Complementary Learning",
    "doi": "https://doi.org/10.1145/3447686",
    "publication_date": "2021-06-29",
    "publication_year": 2021,
    "authors": "Nour Elmadany; Yifeng He; Ling Guan",
    "corresponding_authors": "",
    "abstract": "In this article, we study the problem of video-based action recognition. We improve the action recognition performance by finding an effective temporal and appearance representation. For capturing the temporal representation, we introduce two temporal learning techniques for improving long-term temporal information modeling, specifically Temporal Relational Network and Temporal Second-Order Pooling-based Network. Moreover, we harness the representation using complementary learning techniques, specifically Global-Local Network and Fuse-Inception Network. Performance evaluation on three datasets (UCF101, HMDB-51, and Mini-Kinetics-200) demonstrated the superiority of the proposed framework compared to the 2D Deep ConvNets-based state-of-the-art techniques.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3173340069",
    "type": "article"
  },
  {
    "title": "An Uncertainty-based Neural Network for Explainable Trajectory Segmentation",
    "doi": "https://doi.org/10.1145/3467978",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Xin Bi; Chao Zhang; Fangtong Wang; Zhixun Liu; Xiangguo Zhao; Ye Yuan; Guoren Wang",
    "corresponding_authors": "",
    "abstract": "As a variant task of time-series segmentation, trajectory segmentation is a key task in the applications of transportation pattern recognition and traffic analysis. However, segmenting trajectory is faced with challenges of implicit patterns and sparse results. Although deep neural networks have tremendous advantages in terms of high-level feature learning performance, deploying as a blackbox seriously limits the real-world applications. Providing explainable segmentations has significance for result evaluation and decision making. Thus, in this article, we address trajectory segmentation by proposing a Bayesian Encoder-Decoder Network (BED-Net) to provide accurate detection with explainability and references for the following active-learning procedures. BED-Net consists of a segmentation module based on Monte Carlo dropout and an explanation module based on uncertainty learning that provides results evaluation and visualization. Experimental results on both benchmark and real-world datasets indicate that BED-Net outperforms the rival methods and offers excellent explainability in the applications of trajectory segmentation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3216393814",
    "type": "article"
  },
  {
    "title": "Predicting Human Mobility with Reinforcement-Learning-Based Long-Term Periodicity Modeling",
    "doi": "https://doi.org/10.1145/3469860",
    "publication_date": "2021-12-16",
    "publication_year": 2021,
    "authors": "Shuo Tao; Jingang Jiang; Defu Lian; Kai Zheng; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Mobility prediction plays an important role in a wide range of location-based applications and services. However, there are three problems in the existing literature: (1) explicit high-order interactions of spatio-temporal features are not systemically modeled; (2) most existing algorithms place attention mechanisms on top of recurrent network, so they can not allow for full parallelism and are inferior to self-attention for capturing long-range dependence; (3) most literature does not make good use of long-term historical information and do not effectively model the long-term periodicity of users. To this end, we propose MoveNet and RLMoveNet. MoveNet is a self-attention-based sequential model, predicting each user’s next destination based on her most recent visits and historical trajectory. MoveNet first introduces a cross-based learning framework for modeling feature interactions. With self-attention on both the most recent visits and historical trajectory, MoveNet can use an attention mechanism to capture the user’s long-term regularity in a more efficient way. Based on MoveNet, to model long-term periodicity more effectively, we add the reinforcement learning layer and named RLMoveNet. RLMoveNet regards the human mobility prediction as a reinforcement learning problem, using the reinforcement learning layer as the regularization part to drive the model to pay attention to the behavior with periodic actions, which can help us make the algorithm more effective. We evaluate both of them with three real-world mobility datasets. MoveNet outperforms the state-of-the-art mobility predictor by around 10% in terms of accuracy, and simultaneously achieves faster convergence and over 4x training speedup. Moreover, RLMoveNet achieves higher prediction accuracy than MoveNet, which proves that modeling periodicity explicitly from the perspective of reinforcement learning is more effective.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4200028513",
    "type": "article"
  },
  {
    "title": "Customized prediction of respiratory motion with clustering from multiple patient interaction",
    "doi": "https://doi.org/10.1145/2508037.2508050",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Suk Jin Lee; Yuichi Motai; Elisabeth Weiss; Shumei S. Sun",
    "corresponding_authors": "",
    "abstract": "Information processing of radiotherapy systems has become an important research area for sophisticated radiation treatment methodology. Geometrically precise delivery of radiotherapy in the thorax and upper abdomen is compromised by respiratory motion during treatment. Accurate prediction of the respiratory motion would be beneficial for improving tumor targeting. However, a wide variety of breathing patterns can make it difficult to predict the breathing motion with explicit models. We proposed a respiratory motion predictor, that is, customized prediction with multiple patient interactions using neural network (CNN). For the preprocedure of prediction for individual patient, we construct the clustering based on breathing patterns of multiple patients using the feature selection metrics that are composed of a variety of breathing features. In the intraprocedure, the proposed CNN used neural networks (NN) for a part of the prediction and the extended Kalman filter (EKF) for a part of the correction. The prediction accuracy of the proposed method was investigated with a variety of prediction time horizons using normalized root mean squared error (NRMSE) values in comparison with the alternate recurrent neural network (RNN). We have also evaluated the prediction accuracy using the marginal value that can be used as the reference value to judge how many signals lie outside the confidence level. The experimental results showed that the proposed CNN can outperform RNN with respect to the prediction accuracy with an improvement of 50%.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2062536406",
    "type": "article"
  },
  {
    "title": "A semantic framework for intelligent matchmaking for clinical trial eligibility criteria",
    "doi": "https://doi.org/10.1145/2508037.2508052",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Yugyung Lee; Saranya Krishnamoorthy; Deendayal Dinakarpandian",
    "corresponding_authors": "",
    "abstract": "An integral step in the discovery of new treatments for medical conditions is the matching of potential subjects with appropriate clinical trials. Eligibility criteria for clinical trials are typically specified as inclusion and exclusion criteria for each study in freetext form. While this is sufficient for a human to guide a recruitment interview, it cannot be reliably and computationally construed to identify potential subjects. Standardization of the representation of eligibility criteria can enhance the efficiency and accuracy of this process. This article presents a semantic framework that facilitates intelligent matchmaking by identifying a minimal set of eligibility criteria with maximal coverage of clinical trials. In contrast to existing top-down manual standardization efforts, a bottom-up data driven approach is presented to find a canonical nonredundant representation of an arbitrary collection of clinical trial criteria. The methodology has been validated with a corpus of 709 clinical trials related to Generalized Anxiety Disorder containing 2,760 inclusion and 4,871 exclusion eligibility criteria. This corpus is well represented by a relatively small number of 126 inclusion clusters and 175 exclusion clusters, each of which corresponds to a semantically distinct criterion. Internal and external validation measures provide an objective evaluation of the method. An eligibility criteria ontology has been constructed based on the clustering. The resulting model has been incorporated into the development of the MindTrial clinical trial recruiting system. The prototype for clinical trial recruitment illustrates the effectiveness of the methodology in characterizing clinical trials and subjects and accurate matching between them.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2066742102",
    "type": "article"
  },
  {
    "title": "Two-Word Collocation Extraction Using Monolingual Word Alignment Method",
    "doi": "https://doi.org/10.1145/2036264.2036280",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Zhanyi Liu; Haifeng Wang; Hua Wu; Sheng Li",
    "corresponding_authors": "",
    "abstract": "Statistical bilingual word alignment has been well studied in the field of machine translation. This article adapts the bilingual word alignment algorithm into a monolingual scenario to extract collocations from monolingual corpus, based on the fact that the words in a collocation tend to co-occur in similar contexts as in bilingual word alignment. First, the monolingual corpus is replicated to generate a parallel corpus, in which each sentence pair consists of two identical sentences. Next, the monolingual word alignment algorithm is employed to align potentially collocated words. Finally, the aligned word pairs are ranked according to the alignment scores and candidates with higher scores are extracted as collocations. We conducted experiments on Chinese and English corpora respectively. Compared to previous approaches that use association measures to extract collocations from co-occurrence word pairs within a given window, our method achieves higher precision and recall. According to human evaluation, our method achieves precisions of 62% on a Chinese corpus and 64% on an English corpus. In particular, we can extract collocations with longer spans, achieving a higher precision of 83% on the long-span (&gt; 6 words) Chinese collocations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2077332795",
    "type": "article"
  },
  {
    "title": "Robust Video Content Analysis via Transductive Learning",
    "doi": "https://doi.org/10.1145/2168752.2168755",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Ralph Ewerth; Markus Mühling; Bernd Freisleben",
    "corresponding_authors": "",
    "abstract": "Reliable video content analysis is an essential prerequisite for effective video search. An important current research question is how to develop robust video content analysis methods that produce satisfactory results for a large variety of video sources, distribution platforms, genres, and content. The work presented in this article exploits the observation that the appearance of objects and events is often related to a particular video sequence, episode, program, or broadcast. This motivates our idea of considering the content analysis task for a single video or episode as a transductive setting: the final classification model must be optimal for the given video only, and not in general, as expected for inductive learning. For this purpose, the unlabeled video test data have to be used in the learning process. In this article, a transductive learning framework for robust video content analysis based on feature selection and ensemble classification is presented. In contrast to related transductive approaches for video analysis (e.g., for concept detection), the framework is designed in a general manner and not only for a single task. The proposed framework is applied to the following video analysis tasks: shot boundary detection, face recognition, semantic video retrieval, and semantic indexing of computer game sequences. Experimental results for diverse video analysis tasks and large test sets demonstrate that the proposed transductive framework improves the robustness of the underlying state-of-the-art approaches, whereas transductive support vector machines do not solve particular tasks in a satisfactory manner.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2112933530",
    "type": "article"
  },
  {
    "title": "Cost-Optimized Microblog Distribution over Geo-Distributed Data Centers",
    "doi": "https://doi.org/10.1145/3014431",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Han Hu; Yonggang Wen; Tat‐Seng Chua; Xuelong Li",
    "corresponding_authors": "",
    "abstract": "The unprecedent growth of microblog services poses significant challenges on network traffic and service latency to the underlay infrastructure (i.e., geo-distributed data centers). Furthermore, the dynamic evolution in microblog status generates a huge workload on data consistence maintenance. In this article, motivated by insights of cross-media analysis-based propagation patterns, we propose a novel cache strategy for microblog service systems to reduce the inter-data center traffic and consistence maintenance cost, while achieving low service latency. Specifically, we first present a microblog classification method, which utilizes the external knowledge from correlated domains, to categorize microblogs. Then we conduct a large-scale measurement on a representative online social network system to study the category-based propagation diversity on region and time scales. These insights illustrate social common habits on creating and consuming microblogs and further motivate our architecture design. Finally, we formulate the content cache problem as a constrained optimization problem. By jointly using the Lyapunov optimization framework and simplex gradient method, we find the optimal online control strategy. Extensive trace-driven experiments further demonstrate that our algorithm reduces the system cost by 24.5% against traditional approaches with the same service latency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2605633941",
    "type": "article"
  },
  {
    "title": "Modeling Topics and Behavior of Microbloggers",
    "doi": "https://doi.org/10.1145/2990507",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Tuan-Anh Hoang; Ee‐Peng Lim",
    "corresponding_authors": "",
    "abstract": "Microblogging encompasses both user-generated content and behavior. When modeling microblogging data, one has to consider personal and background topics, as well as how these topics generate the observed content and behavior. In this article, we propose the Generalized Behavior-Topic (GBT) model for simultaneously modeling background topics and users’ topical interest in microblogging data. GBT considers multiple topical communities (or realms) with different background topical interests while learning the personal topics of each user and the user’s dependence on realms to generate both content and behavior . This differentiates GBT from other previous works that consider either one realm only or content data only. By associating user behavior with the latent background and personal topics, GBT helps to model user behavior by the two types of topics. GBT also distinguishes itself from other earlier works by modeling multiple types of behavior together. Our experiments on two Twitter datasets show that GBT can effectively mine the representative topics for each realm. We also demonstrate that GBT significantly outperforms other state-of-the-art models in modeling content topics and user profiling.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2607424258",
    "type": "article"
  },
  {
    "title": "PRISM",
    "doi": "https://doi.org/10.1145/3070665",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Cunchao Tu; Zhiyuan Liu; Huanbo Luan; Maosong Sun",
    "corresponding_authors": "",
    "abstract": "Profession is an important social attribute of people. It plays a crucial role in commercial services such as personalized recommendation and targeted advertising. In practice, profession information is usually unavailable due to privacy and other reasons. In this article, we explore the task of identifying user professions according to their behaviors in social media. The task confronts the following challenges that make it non-trivial: how to incorporate heterogeneous information of user behaviors, how to effectively utilize both labeled and unlabeled data, and how to exploit community structure. To address these challenges, we present a framework called Profession Identification in Social Media. It takes advantage of both personal information and community structure of users in the following aspects: (1) We present a cascaded two-level classifier with heterogeneous personal features to measure the confidence of users belonging to different professions. (2) We present a multi-training process to take advantages of both labeled and unlabeled data to enhance classification performance. (3) We design a profession identification method synthetically considering the confidences from personal features and community structure. We collect a real-world dataset to conduct experiments, and experimental results demonstrate the significant effectiveness of our method compared with other baseline methods. By applying prediction on large-scale users, we also analyze characteristics of microblog users, finding that there are significant diversities among users of different professions in demographics, social network structures, and linguistic styles.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2746010551",
    "type": "article"
  },
  {
    "title": "Detecting Communities of Authority and Analyzing Their Influence in Dynamic Social Networks",
    "doi": "https://doi.org/10.1145/3070658",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Belkacem Chikhaoui; Mauricio Chiazzaro; Shengrui Wang; Martin Sotir",
    "corresponding_authors": "",
    "abstract": "Users in real-world social networks are organized into communities that differ from each other in terms of influence, authority, interest, size, etc. This article addresses the problems of detecting communities of authority and of estimating the influence of such communities in dynamic social networks. These are new issues that have not yet been addressed in the literature, and they are important in applications such as marketing and recommender systems. To facilitate the identification of communities of authority, our approach first detects communities sharing common interests, which we call “meta-communities,” by incorporating topic modeling based on users’ community memberships. Then, communities of authority are extracted with respect to each meta-community, using a new measure based on the betweenness centrality. To assess the influence between communities over time, we propose a new model based on the Granger causality method. Through extensive experiments on a variety of social network datasets, we empirically demonstrate the suitability of our approach for community-of-authority detection and assessment of the influence between communities over time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2749789150",
    "type": "article"
  },
  {
    "title": "On Discovery of Spatiotemporal Influence-Based Moving Clusters",
    "doi": "https://doi.org/10.1145/2631926",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "Dhaval Patel",
    "corresponding_authors": "Dhaval Patel",
    "abstract": "A moving object cluster is a set of objects that move close to each other for a long time interval. Existing works have utilized object trajectories to discover moving object clusters efficiently. In this article, we define a spatiotemporal influence-based moving cluster that captures spatiotemporal influence spread over a set of spatial objects. A spatiotemporal influence-based moving cluster is a sequence of spatial clusters, where each cluster is a set of nearby objects, such that each object in a cluster influences at least one object in the next immediate cluster and is also influenced by an object from the immediate preceding cluster. Real-life examples of spatiotemporal influence-based moving clusters include diffusion of infectious diseases and spread of innovative ideas. We study the discovery of spatiotemporal influence-based moving clusters in a database of spatiotemporal events. While the search space for discovering all spatiotemporal influence-based moving clusters is prohibitively huge, we design a method, STIMer, to efficiently retrieve the maximal answer. The algorithm STIMer adopts a top-down recursive refinement method to generate the maximal spatiotemporal influence-based moving clusters directly. Empirical studies on the real data as well as large synthetic data demonstrate the effectiveness and efficiency of our method.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1968574484",
    "type": "article"
  },
  {
    "title": "An Introduction to the Special Issue on Participatory Sensing and Crowd Intelligence",
    "doi": "https://doi.org/10.1145/2745712",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Bin Guo; Alvin Chin; Zhiwen Yu; Runhe Huang; Daqing Zhang",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessAn Introduction to the Special Issue on Participatory Sensing and Crowd Intelligence Authors: Bin Guo Northwestern Polytechnical University, China Northwestern Polytechnical University, ChinaView Profile , Alvin Chin Nokia, Beijing, China Nokia, Beijing, ChinaView Profile , Zhiwen Yu Northwestern Polytechnical University, China Northwestern Polytechnical University, ChinaView Profile , Runhe Huang Hosei University, Tokyo, Japan Hosei University, Tokyo, JapanView Profile , Daqing Zhang Institut TELECOM SudParis, France Institut TELECOM SudParis, FranceView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 6Issue 3May 2015 Article No.: 36pp 1–4https://doi.org/10.1145/2745712Published:21 April 2015Publication History 5citation311DownloadsMetricsTotal Citations5Total Downloads311Last 12 Months18Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2027416380",
    "type": "article"
  },
  {
    "title": "From RGB-D Images to RGB Images",
    "doi": "https://doi.org/10.1145/2629701",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Quanshi Zhang; Xuan Song; Xiaowei Shao; Huijing Zhao; Ryosuke Shibasaki",
    "corresponding_authors": "",
    "abstract": "Mining object-level knowledge, that is, building a comprehensive category model base, from a large set of cluttered scenes presents a considerable challenge to the field of artificial intelligence. How to initiate model learning with the least human supervision (i.e., manual labeling) and how to encode the structural knowledge are two elements of this challenge, as they largely determine the scalability and applicability of any solution. In this article, we propose a model-learning method that starts from a single-labeled object for each category, and mines further model knowledge from a number of informally captured, cluttered scenes. However, in these scenes, target objects are relatively small and have large variations in texture, scale, and rotation. Thus, to reduce the model bias normally associated with less supervised learning methods, we use the robust 3D shape in RGB-D images to guide our model learning, then apply the properly trained category models to both object detection and recognition in more conventional RGB images. In addition to model training for their own categories, the knowledge extracted from the RGB-D images can also be transferred to guide model learning for a new category, in which only RGB images without depth information in the new category are provided for training. Preliminary testing shows that the proposed method performs as well as fully supervised learning methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2043116985",
    "type": "article"
  },
  {
    "title": "Exploring Spatial Correlation for Visual Object Retrieval",
    "doi": "https://doi.org/10.1145/2641576",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Miaojing Shi; Xinghai Sun; Dacheng Tao; Chao Xu; George Baciu; Hong Liu",
    "corresponding_authors": "",
    "abstract": "Bag-of-visual-words (BOVW)-based image representation has received intense attention in recent years and has improved content-based image retrieval (CBIR) significantly. BOVW does not consider the spatial correlation between visual words in natural images and thus biases the generated visual words toward noise when the corresponding visual features are not stable. This article outlines the construction of a visual word co-occurrence matrix by exploring visual word co-occurrence extracted from small affine-invariant regions in a large collection of natural images. Based on this co-occurrence matrix, we first present a novel high-order predictor to accelerate the generation of spatially correlated visual words and a penalty tree (PTree) to continue generating the words after the prediction. Subsequently, we propose two methods of co-occurrence weighting similarity measure for image ranking: Co-Cosine and Co-TFIDF. These two new schemes down-weight the contributions of the words that are less discriminative because of frequent co-occurrences with other words. We conduct experiments on Oxford and Paris Building datasets, in which the ImageNet dataset is used to implement a large-scale evaluation. Cross-dataset evaluations between the Oxford and Paris datasets and Oxford and Holidays datasets are also provided. Thorough experimental results suggest that our method outperforms the state of the art without adding much additional cost to the BOVW model.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2052703616",
    "type": "article"
  },
  {
    "title": "Empowering Patients and Caregivers to Manage Healthcare Via Streamlined Presentation of Web Objects Selected by Modeling Learning Benefits Obtained by Similar Peers",
    "doi": "https://doi.org/10.1145/2700480",
    "publication_date": "2015-07-13",
    "publication_year": 2015,
    "authors": "John Champaign; Robin Cohen; Disney Yan Lam",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce a framework for selecting web objects (texts, videos, simulations) from a large online repository to present to patients and caregivers, in order to assist in their healthcare. Motivated by the paradigm of peer-based intelligent tutoring, we model the learning gains achieved by users when exposed to specific web objects in order to recommend those objects most likely to deliver benefit to new users. We are able to show that this streamlined presentation leads to effective knowledge gains, both through a process of simulated learning and through a user study, for the specific application of caring for children with autism. The value of our framework for peer-driven content selection of health information is emphasized through two additional roles for peers: attaching commentary to web objects and proposing subdivided objects for presentation, both of which are demonstrated to deliver effective learning gains, in simulations. In all, we are offering an opportunity for patients to navigate the deep waters of excessive online information towards effective management of healthcare, through content selection influenced by previous peer experiences.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2250547980",
    "type": "article"
  },
  {
    "title": "A Novel Continuous and Structural VAR Modeling Approach and Its Application to Reactor Noise Analysis",
    "doi": "https://doi.org/10.1145/2710025",
    "publication_date": "2015-11-26",
    "publication_year": 2015,
    "authors": "Marina Demeshko; Takashi Washio; Yoshinobu Kawahara; Yuriy Pepyolyshev",
    "corresponding_authors": "",
    "abstract": "A vector autoregressive model in discrete time domain (DVAR) is often used to analyze continuous time, multivariate, linear Markov systems through their observed time series data sampled at discrete timesteps. Based on previous studies, the DVAR model is supposed to be a noncanonical representation of the system, that is, it does not correspond to a unique system bijectively. However, in this article, we characterize the relations of the DVAR model with its corresponding Structural Vector AR (SVAR) and Continuous Time Vector AR (CTVAR) models through a finite difference method across continuous and discrete time domain. We further clarify that the DVAR model of a continuous time, multivariate, linear Markov system is canonical under a highly generic condition. Our analysis shows that we can uniquely reproduce its SVAR and CTVAR models from the DVAR model. Based on these results, we propose a novel Continuous and Structural Vector Autoregressive (CSVAR) modeling approach to derive the SVAR and the CTVAR models from their DVAR model empirically derived from the observed time series of continuous time linear Markov systems. We demonstrate its superior performance through some numerical experiments on both artificial and real-world data.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2277096186",
    "type": "article"
  },
  {
    "title": "A Crowd-Powered System for Fashion Similarity Search",
    "doi": "https://doi.org/10.1145/2897365",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Theodoros Semertzidis; Jasminko Novak; Michalis Lazaridis; Mark Melenhorst; Isabel Micheel; Dimitrios Michalopoulos; Martin Böckle; M.G. Strintzis; Petros Daras",
    "corresponding_authors": "",
    "abstract": "Driven by the needs of customers and industry, online fashion search and analytics are recently gaining much attention. As fashion is mostly expressed by visual content, the analysis of fashion images in online social networks is a rich source of possible insights on evolving trends and customer preferences. Although a plethora of visual content is available, the modeling of clothes’ physics and movement, the implicit semantics in fashion designs, and the subjectivity of their interpretation pose difficulties to fully automated solutions for fashion search and analysis. In this article, we present the design and evaluation of a crowd-powered system for fashion similarity search from Twitter, supporting trend analysis for fashion professionals. The system enables fashion similarity search based on specific human-based similarity criteria. This is achieved by implementing a novel machine--crowd workflow that supports complex tasks requiring highly subjective judgments where multiple true solutions may coexist. We discuss how this leads to a novel class of crowd-powered systems for which the output of the crowd is not used to verify the automatic analysis but is the desired outcome. Finally, we show how this kind of crowd involvement enables a novel kind of similarity search and represents a crucial factor for the acceptance of system results by the end user.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2342731808",
    "type": "article"
  },
  {
    "title": "Using the Crowd to Improve Search Result Ranking and the Search Experience",
    "doi": "https://doi.org/10.1145/2897368",
    "publication_date": "2016-07-12",
    "publication_year": 2016,
    "authors": "Yubin Kim; Kevyn Collins‐Thompson; Jaime Teevan",
    "corresponding_authors": "",
    "abstract": "Despite technological advances, algorithmic search systems still have difficulty with complex or subtle information needs. For example, scenarios requiring deep semantic interpretation are a challenge for computers. People, on the other hand, are well suited to solving such problems. As a result, there is an opportunity for humans and computers to collaborate during the course of a search in a way that takes advantage of the unique abilities of each. While search tools that rely on human intervention will never be able to respond as quickly as current search engines do, recent research suggests that there are scenarios where a search engine could take more time if it resulted in a much better experience. This article explores how crowdsourcing can be used at query time to augment key stages of the search pipeline. We first explore the use of crowdsourcing to improve search result ranking. When the crowd is used to replace or augment traditional retrieval components such as query expansion and relevance scoring, we find that we can increase robustness against failure for query expansion and improve overall precision for results filtering. However, the gains that we observe are limited and unlikely to make up for the extra cost and time that the crowd requires. We then explore ways to incorporate the crowd into the search process that more drastically alter the overall experience. We find that using crowd workers to support rich query understanding and result processing appears to be a more worthwhile way to make use of the crowd during search. Our results confirm that crowdsourcing can positively impact the search experience but suggest that significant changes to the search process may be required for crowdsourcing to fulfill its potential in search systems.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2462010759",
    "type": "article"
  },
  {
    "title": "CSM",
    "doi": "https://doi.org/10.1145/2894759",
    "publication_date": "2016-07-25",
    "publication_year": 2016,
    "authors": "Yexi Jiang; Chang-Shing Perng; Anca Sailer; Ignacio Silva-Lepe; Yang Zhou; Tao Li",
    "corresponding_authors": "",
    "abstract": "The cloud service marketplace (CSM) is an exploratory project aiming to provide “an AppStore for Services.” It is an intelligent online marketplace that facilitates service discovery and acquisition for enterprise customers. Traditional service discovery and acquisition are time-consuming. In the era of OneClick Checkout and pay-as-you-go service plans, users expect services to be purchased online efficiently and conveniently. However, as services are complex and different from software apps, the currently prevailing App Store based on keyword search is inadequate for services. In CSM, exploring and configuring services are an iterative process. Customers provide their requirements in natural language and interact with the system through questioning and answering. Learning from the input, the system can incrementally clarify users’ intention, narrow down the candidate services, and profile the configuration information for the candidates at the same time. CSM’s back end is built around the Services Knowledge Graph (SKG) and leverages data mining technologies to enable the semantic understanding of customers’ requirements. To quantitatively assess the value of CSM, empirical evaluation on real and synthetic datasets and case studies are given to demonstrate the efficacy and effectiveness of the proposed system.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2481167995",
    "type": "article"
  },
  {
    "title": "Multimodal Spatio-Temporal Prediction with Stochastic Adversarial Networks",
    "doi": "https://doi.org/10.1145/3458025",
    "publication_date": "2022-01-05",
    "publication_year": 2022,
    "authors": "Divya Saxena; Jiannong Cao",
    "corresponding_authors": "",
    "abstract": "Spatio-temporal (ST) data is a collection of multiple time series data with different spatial locations and is inherently stochastic and unpredictable. An accurate prediction over such data is an important building block for several urban applications, such as taxi demand prediction, traffic flow prediction, and so on. Existing deep learning based approaches assume that outcome is deterministic and there is only one plausible future; therefore, cannot capture the multimodal nature of future contents and dynamics. In addition, existing approaches learn spatial and temporal data separately as they assume weak correlation between them. To handle these issues, in this article, we propose a stochastic spatio-temporal generative model (named D-GAN) which adopts Generative Adversarial Networks (GANs)-based structure for more accurate ST prediction in multiple time steps. D-GAN consists of two components: (1) spatio-temporal correlation network which models spatio-temporal joint distribution of pixels and supports a stochastic sampling of latent variables for multiple plausible futures; (2) a stochastic adversarial network to jointly learn generation and variational inference of data through implicit distribution modeling. D-GAN also supports fusion of external factors through explicit objective to improve the model learning. Extensive experiments performed on two real-world datasets show that D-GAN achieves significant improvements and outperforms baseline models.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4205878841",
    "type": "article"
  },
  {
    "title": "Algorithms for Trajectory Points Clustering in Location-based Social Networks",
    "doi": "https://doi.org/10.1145/3480972",
    "publication_date": "2022-03-03",
    "publication_year": 2022,
    "authors": "Nan Han; Shaojie Qiao; Kun Yue; Jianbin Huang; Qiang He; Tingting Tang; Faliang Huang; Chunlin He; Changan Yuan",
    "corresponding_authors": "",
    "abstract": "Recent advances in localization techniques have fundamentally enhanced social networking services, allowing users to share their locations and location-related contents. This has further increased the popularity of location-based social networks (LBSNs) and produces a huge amount of trajectories composed of continuous and complex spatio-temporal points from people’s daily lives. How to accurately aggregate large-scale trajectories is an important and challenging task. Conventional clustering algorithms (e.g., k -means or k -mediods) cannot be directly employed to process trajectory data due to their serialization, triviality and redundancy. Aiming to overcome the drawbacks of traditional k -means algorithm and k -mediods, including their sensitivity to the selection of the initial k value, the cluster centers and easy convergence to a locally optimal solution, we first propose an optimized k -means algorithm (namely OKM ) to obtain k optimal initial clustering centers based on the density of trajectory points. Second, because k -means is sensitive to noisy points, we propose an improved k -mediods algorithm called IKMD based on an acceptable radius r by considering users’ geographic location in LBSNs. The value of k can be calculated based on r , and the optimal k points are selected as the initial clustering centers with high densities to reduce the cost of distance calculation. Thirdly, we thoroughly analyze the advantages of IKMD by comparing it with the commonly used clustering approaches through illustrative examples. Last, we conduct extensive experiments to evaluate the performance of IKMD against seven clustering approaches including the proposed optimized k -means algorithm, k -mediods algorithm, traditional density-based k -mediods algorithm and the state-of-the-arts trajectory clustering methods. The results demonstrate that IKMD significantly outperforms existing algorithms in the cost of distance calculation and the convergence speed. The methods proposed is proved to contribute to a larger effort targeted at advancing the study of intelligent trajectory data analytics.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4214915569",
    "type": "article"
  },
  {
    "title": "Two-Level Optimization to Reduce Waiting Time at Locks in Inland Waterway Transportation",
    "doi": "https://doi.org/10.1145/3527822",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Wided Hammedi; Sidi‐Mohammed Senouci; Philippe Brunet; Metzli Ramirez-Martinez",
    "corresponding_authors": "",
    "abstract": "Inland vessels often have to cross numerous locks before reaching their final destination, which leads to a significant delay and sometimes represents as much as half of the total travel time. The delay affects shipment costs and can affect other parts of the transport chain, adversely impacting this transportation mode’s growth. Therefore, this work presents a two-level solution to ensure a shorter waiting time at locks and improve inland waterway transport. On the one hand, the first level focuses on making infrastructural modifications by proposing an efficient Lock Automation Decision Making (Lock-ADM) method. The problem modeling consists of using a three-stage algorithm. Firstly, we calculate the optimal number of locks while minimizing the investment costs using the exact solver, CPLEX. Secondly, we measure the importance of locks in the network, and finally, we select the best locks to automate using the Genetic Algorithm (GA) metaheuristic. Based on real data, we achieved an average reduction of 33.7% in overall lock waiting time at a low cost. On the other hand, the second level proposes a Dynamic Lock Scheduling (Lock-DS) to efficiently manage vessels scheduling at locks by minimizing their waiting time and optimizing their speed. We achieve an average reduction of 69.9% in vessel waiting time and a reduction of 48.03% in total fuel consumption compared to existing scheduling methods. Automating the most important locks with Lock-ADM and managing their crossing with Lock-DS ensure shorter vessels’ waiting time and represent a significant first step towards the automation of inland navigation.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4224235340",
    "type": "article"
  },
  {
    "title": "Hierarchical Multi-agent Model for Reinforced Medical Resource Allocation with Imperfect Information",
    "doi": "https://doi.org/10.1145/3552436",
    "publication_date": "2022-07-30",
    "publication_year": 2022,
    "authors": "Qianyue Hao; Fengli Xu; Lin Chen; Pan Hui; Yong Li",
    "corresponding_authors": "",
    "abstract": "With the advent of the COVID-19 pandemic, the shortage in medical resources became increasingly more evident. Therefore, efficient strategies for medical resource allocation are urgently needed. However, conventional rule-based methods employed by public health experts have limited capability in dealing with the complex and dynamic pandemic-spreading situation. In addition, model-based optimization methods such as dynamic programming (DP) fail to work since we cannot obtain a precise model in real-world situations most of the time. Model-free reinforcement learning (RL) is a powerful tool for decision-making; however, three key challenges exist in solving this problem via RL: (1) complex situations and countless choices for decision-making in the real world; (2) imperfect information due to the latency of pandemic spreading; and (3) limitations on conducting experiments in the real world since we cannot set up pandemic outbreaks arbitrarily. In this article, we propose a hierarchical RL framework with several specially designed components. We design a decomposed action space with a corresponding training algorithm to deal with the countless choices, ensuring efficient and real-time strategies. We design a recurrent neural network–based framework to utilize the imperfect information obtained from the environment. We also design a multi-agent voting method, which modifies the decision-making process considering the randomness during model training and, thus, improves the performance. We build a pandemic-spreading simulator based on real-world data, serving as the experimental platform. We then conduct extensive experiments. The results show that our method outperforms all baselines, which reduces infections and deaths by 14.25% on average without the multi-agent voting method and up to 15.44% with it.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4288757819",
    "type": "article"
  },
  {
    "title": "Decentralized Online Learning: Take Benefits from Others’ Data without Sharing Your Own to Track Global Trend",
    "doi": "https://doi.org/10.1145/3559765",
    "publication_date": "2022-09-02",
    "publication_year": 2022,
    "authors": "Wendi Wu; Zongren Li; Yawei Zhao; Chen Yu; Peilin Zhao; Ji Liu; Kunlun He",
    "corresponding_authors": "",
    "abstract": "Decentralized online learning (online learning in decentralized networks) has been attracting more and more attention, since it is believed that decentralized online learning can help data providers cooperatively better solve their online problems without sharing their private data to a third party or other providers. Typically, the cooperation is achieved by letting the data providers exchange their models between neighbors, e.g., recommendation model. However, the best regret bound for a decentralized online learning algorithm is 𝒪( n √ T ), where n is the number of nodes (or users) and T is the number of iterations. This is clearly insignificant, since this bound can be achieved without any communication in the networks. This reminds us to ask a fundamental question: Can people really get benefit from the decentralized online learning by exchanging information? In this article, we studied when and why the communication can help the decentralized online learning to reduce the regret. Specifically, each loss function is characterized by two components: the adversarial component and the stochastic component. Under this characterization, we show that decentralized online gradient enjoys a regret bound \\( {\\mathcal {O}(\\sqrt {n^2TG^2 + n T \\sigma ^2})} \\) , where G measures the magnitude of the adversarial component in the private data (or equivalently the local loss function) and σ measures the randomness within the private data. This regret suggests that people can get benefits from the randomness in the private data by exchanging private information. Another important contribution of this article is to consider the dynamic regret—a more practical regret to track users’ interest dynamics. Empirical studies are also conducted to validate our analysis.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4294237951",
    "type": "article"
  },
  {
    "title": "Cost-sensitive Tensor-based Dual-stage Attention LSTM with Feature Selection for Data Center Server Power Forecasting",
    "doi": "https://doi.org/10.1145/3569422",
    "publication_date": "2022-10-25",
    "publication_year": 2022,
    "authors": "Ziyu Shen; Binghui Liu; Qing Zhou; Zheng Liu; Bin Xia; Yun Li",
    "corresponding_authors": "",
    "abstract": "Power forecasting has a guiding effect on power-aware scheduling strategies to reduce unnecessary power consumption in data centers. Many metrics related to power consumption can be collected in physical servers, such as the status of CPU, memory, and other components. However, most existing methods empirically exploit a small number of metrics to forecast power consumption. To this end, this article uses feature selection based on causality to explore the metrics that strongly influence the power consumption of different tasks. Moreover, we propose a tensor-based dual-stage attention LSTM to forecast the non-linear and non-periodic power consumption. In the proposed model, a multi-way delay embedding transform is utilized to convert the time series into tensors along the temporal direction. The LSTM combines with the tensor technique and the attention mechanism to capture the temporal pattern effectively. In addition, we adopt the cost-sensitive loss function to optimize the specific power forecasting problem in data centers. The experimental results demonstrate that our method can achieve up to 1.4% to 4.3% forecasting accuracy improvement compared with the state-of-the-art models.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4307380588",
    "type": "article"
  },
  {
    "title": "Diagnose Like Doctors: Weakly Supervised Fine-Grained Classification of Breast Cancer",
    "doi": "https://doi.org/10.1145/3572033",
    "publication_date": "2022-11-23",
    "publication_year": 2022,
    "authors": "Jieru Tian; Yongxin Wang; Zhen-Duo Chen; Xin Luo; Xin-Shun Xu",
    "corresponding_authors": "",
    "abstract": "Breast cancer is the most common type of cancers in women. Therefore, how to accurately and timely diagnose it becomes very important. Some computer-aided diagnosis models based on pathological images have been proposed for this task. However, there are still some issues that need to be further addressed. For example, most deep learning based models suffer from a lack of interpretability. In addition, some of them cannot fully exploit the information in medical data, e.g., hierarchical label structure and scattered distribution of target objects. To address these issues, we propose a weakly supervised fine-grained medical image classification method for breast cancer diagnosis, i.e., DLD-Net for short. It simulates the diagnostic procedures of pathologists by multiple attention-guided cropping and dropping operations, making it have good clinical interpretability. Moreover, it cannot only exploit the global information of a whole image, but also further mine the critical local information by generating and selecting critical regions from the image. In light of this, those subtle discriminating information hidden in scattered regions can be exploited. In addition, we also design a novel hierarchical cross-entropy loss to utilize the hierarchical label information in medical images, making the classification results more discriminative. Furthermore, DLD-Net is a weakly supervised network, which can be trained end-to-end without any additional region annotations. Extensive experimental results on three benchmark datasets demonstrate that DLD-Net is able to achieve good results and outperforms some state-of-the-art methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4309764771",
    "type": "article"
  },
  {
    "title": "Representation Learning of Enhanced Graphs Using Random Walk Graph Convolutional Network",
    "doi": "https://doi.org/10.1145/3582841",
    "publication_date": "2023-02-10",
    "publication_year": 2023,
    "authors": "Xing Li; Wei Wei; Ruizhi Zhang; Zhenyu Shi; Zhiming Zheng; Xiangnan Feng",
    "corresponding_authors": "",
    "abstract": "Nowadays, graph structure data has played a key role in machine learning because of its simple topological structure, and therefore, the graph representation learning methods have attracted great attention. And it turns out that the low-dimensional embedding representation obtained by graph representation learning is extremely useful in various typical tasks, such as node classification and content recommendation. However, most of the existing methods do not further dig out potential structural information on the original graph structure. Here, we propose wGCN, which utilizes random walk to obtain the node-specific mesoscopic structures (high-order local structure) of the graph and utilizes these mesoscopic structures to enhance the graph and organize the characteristic information of the nodes. Our method can effectively generate node embedding for data of previously unknown categories, which has been proven in a series of experiments conducted on many types of graph networks. And compared to baselines, our method shows the best performance on most datasets and achieves competitive results on others. It is believed that combining the mesoscopic structure to further explore the structural information of the graph will greatly improve the learning efficiency of the graph neural network.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4319966068",
    "type": "article"
  },
  {
    "title": "Empirical Review of Various Thermography-based Computer-aided Diagnostic Systems for Multiple Diseases",
    "doi": "https://doi.org/10.1145/3583778",
    "publication_date": "2023-02-16",
    "publication_year": 2023,
    "authors": "Trasha Gupta; Rajni Jindal; S. Indu",
    "corresponding_authors": "",
    "abstract": "The lifestyle led by today’s generation and its negligence towards health is highly susceptible to various diseases. Developing countries are at a higher risk of mortality due to late-stage presentation, inaccessible diagnosis, and high-cost treatment. Thermography-based technology, aided with machine learning, for screening inflammation in the human body is non-invasive and cost-wise appropriate. It requires very little equipment, especially in rural areas with limited facilities. Recently, Thermography-based monitoring has been deployed worldwide at various organizations and public gathering points as a first measure of screening COVID-19 patients. In this article, we systematically compare the state-of-the-art feature extraction approaches for analyzing thermal patterns in the human body, individually and in combination, on a platform using three publicly available Datasets of medical thermal imaging, four Feature Selection methods, and four well-known Classifiers, and analyze the results. We developed and used a two-level sampling method for training and testing the classification model. Among all the combinations considered, the classification model with Unified Feature-Sets gave the best performance for all the datasets. Also, the experimental results show that the classification accuracy improves considerably with the use of feature selection methods. We obtained the best performance with a features subset of 45, 57, and 39 features (from Unified Feature Set) with a combination of mRMR and SVM for DB-DMR-IR and DB-FOOT-IR and a combination of ReF and RF for DB-THY-IR. Also, we found that for all the feature subsets, the features obtained are relevant, non-redundant, and distinguish normal and abnormal thermal patterns with the accuracy of 94.75% on the DB-DMR-IR dataset, 93.14% on the DB-FOOT-IR dataset, and 92.06% on the DB-THY-IR dataset.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4321109049",
    "type": "article"
  },
  {
    "title": "MC <sup>2</sup> : Unsupervised Multiple Social Network Alignment",
    "doi": "https://doi.org/10.1145/3596514",
    "publication_date": "2023-05-16",
    "publication_year": 2023,
    "authors": "Li Sun; Zhongbao Zhang; Gen Li; Pengxin Ji; Sen Su; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Social network alignment, identifying social accounts of the same individual across different social networks, shows fundamental importance in a wide spectrum of applications, such as link prediction and information diffusion. Individuals more often than not join in multiple social networks, and it is in fact much too expensive or even impossible to acquiring supervision for guiding the alignment. To the best of our knowledge, few method in the literature can align multiple social networks without supervision. In this article, we propose to study the problem of unsupervised multiple social network alignment. To address this problem, we propose a novel unsupervised model of joint Matrix factorization with a diagonal Cone under orthogonal Constraint, referred to as MC 2 . Its core idea is to embed and align multiple social networks in the common subspace via an unsupervised approach. Specifically, in MC 2 model, we first design a matrix optimization to infer the common subspace from different social networks. To address the nonconvex optimization, we then design an efficient alternating algorithm by leveraging its inherent functional property. Through extensive experiments on real-world datasets, we demonstrate that the proposed MC 2 model significantly outperforms the state-of-the-art methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4376642653",
    "type": "article"
  },
  {
    "title": "Asymmetrical Attention Networks Fused Autoencoder for Debiased Recommendation",
    "doi": "https://doi.org/10.1145/3596498",
    "publication_date": "2023-05-17",
    "publication_year": 2023,
    "authors": "Yihao Zhang; Chu Zhao; Weiwen Liao; Wei Zhou; Meng Yuan",
    "corresponding_authors": "",
    "abstract": "Popularity bias is a massive challenge for autoencoder-based models, which decreases the level of personalization and hurts the fairness of recommendations. User reviews reflect their preferences and help mitigate bias or unfairness in the recommendation. However, most existing works typically incorporate user (item) reviews into a long document and then use the same module to process the document in parallel. Actually, the set of user reviews is completely different from the set of item reviews. User reviews are heterogeneous in that they reflect a variety of items purchased by users, while item reviews are only related to the item itself and are thus typically homogeneous. In this article, a novel asymmetric attention network fused with autoencoders is proposed, which jointly learns representations from the user and item reviews and implicit feedback to perform recommendations. Specifically, we design an asymmetric attentive module to capture rich representations from user and item reviews, respectively, which solves data sparsity and explainable problems. Furthermore, to further address popularity bias, we apply a noise-contrastive estimation objective to learn high-quality “de-popularity” embedding via the decoder structure. A series of extensive experiments are conducted on four benchmark datasets to show that leveraging user review information can eliminate popularity bias and improve performance compared to various state-of-the-art recommendation techniques.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4376874018",
    "type": "article"
  },
  {
    "title": "Federated Clique Percolation for Privacy-preserving Overlapping Community Detection",
    "doi": "https://doi.org/10.1145/3604807",
    "publication_date": "2023-06-19",
    "publication_year": 2023,
    "authors": "Kun Guo; Wenzhong Guo; Enjie Ye; Yutong Fang; Jiachen Zheng; Ximeng Liu; Kai Chen",
    "corresponding_authors": "",
    "abstract": "Community structure is a typical characteristic of complex networks. Finding communities in complex networks has many important applications, such as the advertisement and recommendation based on social networks and the discovery of new protein molecules in biological networks, which make it a hot topic in the field of complex network analysis. With the increasing concerns about the leakage of personal privacy, discovering communities spread across the local networks owned by multiple participants accurately while preserving each participant’s privacy has become an emerging challenge in distributed community detection. In this article, we propose a general federated graph learning model for privacy-preserving distributed graph learning and develop two federated clique percolation algorithms (CPAs) based on it to discover overlapping communities distributed across multiple participants’ local networks without disclosing any participant’s network privacy. Homomorphic encryption and hash operation are used in combination to protect the privacy of the vertices and edges of each local network. Furthermore, vertex attributes are involved in the calculation of clique similarity and clique percolation when dealing with attributed networks. The experimental results on real-world and artificial datasets demonstrate that the proposed algorithms achieve identical results to those of their stand-alone counterparts and more than 200% higher accuracy than the simple distributed CPAs without federating learning.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4381190198",
    "type": "article"
  },
  {
    "title": "Unifying Gradients to Improve Real-World Robustness for Deep Networks",
    "doi": "https://doi.org/10.1145/3617895",
    "publication_date": "2023-08-31",
    "publication_year": 2023,
    "authors": "Yingwen Wu; Sizhe Chen; Kun Fang; Xiaolin Huang",
    "corresponding_authors": "",
    "abstract": "The wide application of deep neural networks (DNNs) demands an increasing amount of attention to their real-world robustness, i.e., whether a DNN resists black-box adversarial attacks, among which score-based query attacks (SQAs) are the most threatening since they can effectively hurt a victim network with only access to model outputs. Defending against SQAs requires a slight but artful variation of outputs due to the service purpose for users, who share the same output information with SQAs. In this article, we propose a real-world defense by Unifying Gradients (UniG) of different data so that SQAs could only probe a much weaker attack direction that is similar for different samples. Since such universal attack perturbations have been validated as less aggressive than the input-specific perturbations, UniG protects real-world DNNs by indicating to attackers a twisted and less informative attack direction. We implement UniG efficiently by a Hadamard product module, which is plug-and-play. According to extensive experiments on 5 SQAs, 2 adaptive attacks and 7 defense baselines, UniG significantly improves real-world robustness without hurting clean accuracy on CIFAR10 and ImageNet. For instance, UniG maintains a model of 77.80% accuracy under a 2500-query Square attack while the state-of-the-art adversarially trained model only has 67.34% on CIFAR10. Simultaneously, UniG outperforms all compared baselines in terms of clean accuracy and achieves the smallest modification of the model output. The code is released at https://github.com/snowien/UniG-pytorch .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386326782",
    "type": "article"
  },
  {
    "title": "Inferring Real Mobility in Presence of Fake Check-ins Data",
    "doi": "https://doi.org/10.1145/3604941",
    "publication_date": "2023-09-26",
    "publication_year": 2023,
    "authors": "Qiang Gao; Hongzhu Fu; Kunpeng Zhang; Goce Trajcevski; Teng Xu; Fan Zhou",
    "corresponding_authors": "",
    "abstract": "Understanding human mobility has become an important aspect of location-based services in tasks such as personalized recommendation and individual moving pattern recognition, enabled by the large volumes of data from geo-tagged social media (GTSM). Prior studies mainly focus on analyzing human historical footprints collected by GTSM and assuming the veracity of the data, which need not hold when some users are not willing to share their real footprints due to privacy concerns—thereby affecting reliability/authenticity. In this study, we address the problem of Inferring Real Mobility (IRMo) of users, from their unreliable historical traces. Tackling IRMo is a non-trivial task due to the: (1) sparsity of check-in data; (2) suspicious counterfeit check-in behaviors; and (3) unobserved dependencies in human trajectories. To address these issues, we develop a novel Graph-enhanced Attention model called IRMoGA , which attempts to capture underlying mobility patterns and check-in correlations by exploiting the unreliable spatio-temporal data. Specifically, we incorporate the attention mechanism (rather than solely relying on traditional recursive models) to understand the regularity of human mobility, while employing a graph neural network to understand the mutual interactions from human historical check-ins and leveraging prior knowledge to alleviate the inferring bias. Our experiments conducted on four real-world datasets demonstrate the superior performance of IRMoGA over several state-of-the-art baselines, e.g., up to 39.16% improvement regarding the Recall score on Foursquare.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387055541",
    "type": "article"
  },
  {
    "title": "Nationwide Air Pollution Forecasting with Heterogeneous Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3637492",
    "publication_date": "2023-12-14",
    "publication_year": 2023,
    "authors": "Fernando Terroso-Sáenz; Juan Morales-García; Andrés Muñoz",
    "corresponding_authors": "",
    "abstract": "Nowadays, air pollution is one of the most relevant environmental problems in most urban settings. Due to the utility in operational terms of anticipating certain pollution levels, several predictors based on Graph Neural Networks (GNN) have been proposed for the last years. Most of these solutions usually encode the relationships among stations in terms of their spatial distance, but they fail when it comes to capturing other spatial and feature-based contextual factors. Besides, they assume a homogeneous setting where all the stations are able to capture the same pollutants. However, large-scale settings frequently comprise different types of stations, each one with different measurement capabilities. For that reason, the present article introduces a novel GNN framework able to capture the similarities among stations related to the land use of their locations and their primary source of pollution. Furthermore, we define a methodology to deal with heterogeneous settings on the top of the GNN architecture. Finally, the proposal has been tested with a nation-wide Spanish air-pollution dataset with very promising results.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4389736337",
    "type": "article"
  },
  {
    "title": "Reconstructing Turbulent Flows Using Spatio-temporal Physical Dynamics",
    "doi": "https://doi.org/10.1145/3637491",
    "publication_date": "2023-12-15",
    "publication_year": 2023,
    "authors": "Shengyu Chen; Tianshu Bao; Peyman Givi; Can Zheng; Xiaowei Jia",
    "corresponding_authors": "",
    "abstract": "Accurate simulation of turbulent flows is of crucial importance in many branches of science and engineering. Direct numerical simulation (DNS) provides the highest fidelity means of capturing all intricate physics of turbulent transport. However, the method is computationally expensive because of the wide range of turbulence scales that must be accounted for in such simulations. Large eddy simulation (LES) provides an alternative. In such simulations, the large scales of the flow are resolved, and the effects of small scales are modelled. Reconstruction of the DNS field from the low-resolution LES is needed for a wide variety of applications. Thus the construction of super-resolution methodologies that can provide this reconstruction has become an area of active research. In this work, a new physics-guided neural network is developed for such a reconstruction. The method leverages the partial differential equation that underlies the flow dynamics in the design of spatio-temporal model architecture. A degradation-based refinement method is also developed to enforce physical constraints and to further reduce the accumulated reconstruction errors over long periods. Detailed DNS data on two turbulent flow configurations are used to assess the performance of the model.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4389785449",
    "type": "article"
  },
  {
    "title": "Location-Specific Influence Quantification in Location-Based Social Networks",
    "doi": "https://doi.org/10.1145/3300199",
    "publication_date": "2019-04-11",
    "publication_year": 2019,
    "authors": "Ankita Likhyani; Srikanta Bedathur; P Deepak",
    "corresponding_authors": "",
    "abstract": "Location-based social networks (LBSNs) such as Foursquare offer a platform for users to share and be aware of each other’s physical movements. As a result of such a sharing of check-in information with each other, users can be influenced to visit (or check-in) at the locations visited by their friends. Quantifying such influences in these LBSNs is useful in various settings such as location promotion, personalized recommendations, mobility pattern prediction, and so forth. In this article, we develop a model to quantify the influence specific to a location between a pair of users. Specifically, we develop a framework called LoCaTe , that combines (a) a user mobility model based on kernel density estimates; (b) a model of the semantics of the location using topic models; and (c) a user correlation model that uses an exponential distribution. We further develop LoCaTe+ , an advanced model within the same framework where user correlation is quantified using a Mutually Exciting Hawkes Process. We show the applicability of LoCaTe and LoCaTe+ for location promotion and location recommendation tasks using LBSNs. Our models are validated using a long-term crawl of Foursquare data collected between January 2015 and February 2016, as well as other publicly available LBSN datasets. Our experiments demonstrate the efficacy of the LoCaTe framework in capturing location-specific influence between users. We also show that our models improve over state-of-the-art models for the task of location promotion as well as location recommendation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2935778224",
    "type": "article"
  },
  {
    "title": "Detecting Causal Relationships in Simulation Models Using Intervention-based Counterfactual Analysis",
    "doi": "https://doi.org/10.1145/3322123",
    "publication_date": "2019-09-18",
    "publication_year": 2019,
    "authors": "Benjamin Herd; Simon Miles",
    "corresponding_authors": "",
    "abstract": "Central to explanatory simulation models is their capability to not just show that but also why particular things happen. Explanation is closely related with the detection of causal relationships and is, in a simulation context, typically done by means of controlled experiments. However, for complex simulation models, conventional “blackbox” experiments may be too coarse-grained to cope with spurious relationships. We present an intervention-based causal analysis methodology that exploits the manipulability of computational models, and detects and circumvents spurious effects. The core of the methodology is a formal model that maps basic causal assumptions to causal observations and allows for the identification of combinations of assumptions that have a negative impact on observability. First, experiments indicate that the methodology can successfully deal with notoriously tricky situations involving asymmetric and symmetric overdetermination and detect fine-grained causal relationships between events in the simulation. As illustrated in the article, the methodology can be easily integrated into an existing simulation environment.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2974243576",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Advances in Causal Discovery and Inference",
    "doi": "https://doi.org/10.1145/3359995",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Jiuyong Li; Kun Zhang; Emre Kıcıman; Peng Cui",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessIntroduction to the Special Section on Advances in Causal Discovery and Inference Share on Authors: Jiuyong Li University of South Australia, Australia University of South Australia, AustraliaView Profile , Kun Zhang Carnegie Mellon University, USA Carnegie Mellon University, USAView Profile , Emre Kıcıman Microsoft Research, USA Microsoft Research, USAView Profile , Peng Cui Tsinghua University, China Tsinghua University, ChinaView Profile Authors Info & Affiliations ACM Transactions on Intelligent Systems and TechnologyVolume 10Issue 5November 2019 Article No.: 45pp 1–3https://doi.org/10.1145/3359995Published:06 November 2019 0citation182DownloadsMetricsTotal Citations0Total Downloads182Last 12 Months80Last 6 weeks14 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2985928490",
    "type": "article"
  },
  {
    "title": "Graph-based Recommendation Meets Bayes and Similarity Measures",
    "doi": "https://doi.org/10.1145/3356882",
    "publication_date": "2019-12-14",
    "publication_year": 2019,
    "authors": "Ramon Lopes; Renato Assunção; Rodrygo L. T. Santos",
    "corresponding_authors": "",
    "abstract": "Graph-based approaches provide an effective memory-based alternative to latent factor models for collaborative recommendation. Modern approaches rely on either sampling short walks or enumerating short paths starting from the target user in a user-item bipartite graph. While the effectiveness of random walk sampling heavily depends on the underlying path sampling strategy, path enumeration is sensitive to the strategy adopted for scoring each individual path. In this article, we demonstrate how both strategies can be improved through Bayesian reasoning. In particular, we propose to improve random walk sampling by exploiting distributional aspects of items’ ratings on the sampled paths. Likewise, we extend existing path enumeration approaches to leverage categorical ratings and to scale the score of each path proportionally to the affinity of pairs of users and pairs of items on the path. Experiments on several publicly available datasets demonstrate the effectiveness of our proposed approaches compared to state-of-the-art graph-based recommenders.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3016053364",
    "type": "article"
  },
  {
    "title": "BISTRO",
    "doi": "https://doi.org/10.1145/3384344",
    "publication_date": "2020-06-24",
    "publication_year": 2020,
    "authors": "Sidney Feygin; Jessica Lazarus; Edward H. Forscher; Valentine Golfier-Vetterli; Jonathan Lee; Abhishek Gupta; Rashid A. Waraich; Colin Sheppard; Alexandre M. Bayen",
    "corresponding_authors": "",
    "abstract": "The current trend toward urbanization and adoption of flexible and innovative mobility technologies will have complex and difficult-to-predict effects on urban transportation systems. Comprehensive methodological frameworks that account for the increasingly uncertain future state of the urban mobility landscape do not yet exist. Furthermore, few approaches have enabled the massive ingestion of urban data in planning tools capable of offering the flexibility of scenario-based design. This article introduces Berkeley Integrated System for Transportation Optimization (BISTRO), a new open source transportation planning decision support system that uses an agent-based simulation and optimization approach to anticipate and develop adaptive plans for possible technological disruptions and growth scenarios. The new framework was evaluated in the context of a machine learning competition hosted within Uber Technologies, Inc., in which over 400 engineers and data scientists participated. For the purposes of this competition, a benchmark model, based on the city of Sioux Falls, South Dakota, was adapted to the BISTRO framework. An important finding of this study was that in spite of rigorous analysis and testing done prior to the competition, the two top-scoring teams discovered an unbounded region of the search space, rendering the solutions largely uninterpretable for the purposes of decision-support. On the other hand, a follow-on study aimed to fix the objective function. It served to demonstrate BISTRO’s utility as a human-in-the-loop cyberphysical system: one that uses scenario-based optimization algorithms as a feedback mechanism to assist urban planners with iteratively refining objective function and constraints specification on intervention strategies. The portfolio of transportation intervention strategy alternatives eventually chosen achieves high-level regional planning goals developed through participatory stakeholder engagement practices.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3037394746",
    "type": "article"
  },
  {
    "title": "Moment-Guided Discriminative Manifold Correlation Learning on Ordinal Data",
    "doi": "https://doi.org/10.1145/3402445",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Qing Tian; Wenqiang Zhang; Meng Cao; Liping Wang; Songcan Chen; Hujun Yin",
    "corresponding_authors": "",
    "abstract": "Canonical correlation analysis (CCA) is a typical and useful learning paradigm in big data analysis for capturing correlation across multiple views of the same objects. When dealing with data with additional ordinal information, traditional CCA suffers from poor performance due to ignoring the ordinal relationships within the data. Such data is becoming increasingly common, as either temporal or sequential information is often associated with the data collection process. To incorporate the ordinal information into the objective function of CCA, the so-called ordinal discriminative CCA has been presented in the literature. Although ordinal discriminative CCA can yield better ordinal regression results, its performance deteriorates when data is corrupted with noise and outliers, as it tends to smear the order information contained in class centers. To address this issue, in this article we construct a robust manifold-preserved ordinal discriminative correlation regression (rmODCR). The robustness is achieved by replacing the traditional ( l 2 -norm) class centers with l p -norm centers, where p is efficiently estimated according to the moments of the data distributions, as well as by incorporating the manifold distribution information of the data in the objective optimization. In addition, we further extend the robust manifold-preserved ordinal discriminative correlation regression to deep convolutional architectures. Extensive experimental evaluations have demonstrated the superiority of the proposed methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3040558883",
    "type": "article"
  },
  {
    "title": "Constraint-based Scheduling for Paint Shops in the Automotive Supply Industry",
    "doi": "https://doi.org/10.1145/3430710",
    "publication_date": "2021-01-13",
    "publication_year": 2021,
    "authors": "Felix Winter; Nysret Musliu",
    "corresponding_authors": "",
    "abstract": "Factories in the automotive supply industry paint a large number of items requested by car manufacturing companies on a daily basis. As these factories face numerous constraints and optimization objectives, finding a good schedule becomes a challenging task in practice, and full-time employees are expected to manually create feasible production plans. In this study, we propose novel constraint programming models for a real-life paint shop scheduling problem. We evaluate and compare our models experimentally by performing a series of benchmark experiments using real-life instances in the industry. We also show that the decision variant of the paint shop scheduling problem is NP-complete.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3120845877",
    "type": "article"
  },
  {
    "title": "A Scale and Rotational Invariant Key-point Detector based on Sparse Coding",
    "doi": "https://doi.org/10.1145/3452009",
    "publication_date": "2021-06-15",
    "publication_year": 2021,
    "authors": "Thanh Hong-Phuoc; Ling Guan",
    "corresponding_authors": "",
    "abstract": "Most popular hand-crafted key-point detectors such as Harris corner, SIFT, SURF aim to detect corners, blobs, junctions, or other human-defined structures in images. Though being robust with some geometric transformations, unintended scenarios or non-uniform lighting variations could significantly degrade their performance. Hence, a new detector that is flexible with context change and simultaneously robust with both geometric and non-uniform illumination variations is very desirable. In this article, we propose a solution to this challenging problem by incorporating Scale and Rotation Invariant design (named SRI-SCK) into a recently developed Sparse Coding based Key-point detector (SCK). The SCK detector is flexible in different scenarios and fully invariant to affine intensity change, yet it is not designed to handle images with drastic scale and rotation changes. In SRI-SCK, the scale invariance is implemented with an image pyramid technique, while the rotation invariance is realized by combining multiple rotated versions of the dictionary used in the sparse coding step of SCK. Techniques for calculation of key-points’ characteristic scales and their sub-pixel accuracy positions are also proposed. Experimental results on three public datasets demonstrate that significantly high repeatability and matching score are achieved.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3166240918",
    "type": "article"
  },
  {
    "title": "dhCM: Dynamic and Hierarchical Event Categorization and Discovery for Social Media Stream",
    "doi": "https://doi.org/10.1145/3470888",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Jinjin Guo; Zhiguo Gong; Longbing Cao",
    "corresponding_authors": "",
    "abstract": "The online event discovery in social media based documents is useful, such as for disaster recognition and intervention. However, the diverse events incrementally identified from social media streams remain accumulated, ad hoc, and unstructured. They cannot assist users in digesting the tremendous amount of information and finding their interested events. Further, most of the existing work is challenged by jointly identifying incremental events and dynamically organizing them in an adaptive hierarchy. To address these problems, this article proposes d ynamic and h ierarchical C ategorization M odeling (dhCM) for social media stream. Instead of manually dividing the timeframe, a multimodal event miner exploits a density estimation technique to continuously capture the temporal influence between documents and incrementally identify online events in textual, temporal, and spatial spaces. At the same time, an adaptive categorization hierarchy is formed to automatically organize the documents into proper categories at multiple levels of granularities. In a nonparametric manner, dhCM accommodates the increasing complexity of data streams with automatically growing the categorization hierarchy over adaptive growth. A sequential Monte Carlo algorithm is used for the online inference of the dhCM parameters. Extensive experiments show that dhCM outperforms the state-of-the-art models in terms of term coherence, category abstraction and specialization, hierarchical affinity, and event categorization and discovery accuracy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3202445451",
    "type": "article"
  },
  {
    "title": "Causal Discovery with Confounding Cascade Nonlinear Additive Noise Models",
    "doi": "https://doi.org/10.1145/3482879",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Jie Qiao; Ruichu Cai; Kun Zhang; Zhenjie Zhang; Zhifeng Hao",
    "corresponding_authors": "",
    "abstract": "Identification of causal direction between a causal-effect pair from observed data has recently attracted much attention. Various methods based on functional causal models have been proposed to solve this problem, by assuming the causal process satisfies some (structural) constraints and showing that the reverse direction violates such constraints. The nonlinear additive noise model has been demonstrated to be effective for this purpose, but the model class does not allow any confounding or intermediate variables between a cause pair–even if each direct causal relation follows this model. However, omitting the latent causal variables is frequently encountered in practice. After the omission, the model does not necessarily follow the model constraints. As a consequence, the nonlinear additive noise model may fail to correctly discover causal direction. In this work, we propose a confounding cascade nonlinear additive noise model to represent such causal influences–each direct causal relation follows the nonlinear additive noise model but we observe only the initial cause and final effect. We further propose a method to estimate the model, including the unmeasured confounding and intermediate variables, from data under the variational auto-encoder framework. Our theoretical results show that with our model, the causal direction is identifiable under suitable technical conditions on the data generation process. Simulation results illustrate the power of the proposed method in identifying indirect causal relations across various settings, and experimental results on real data suggest that the proposed model and method greatly extend the applicability of causal discovery based on functional causal models in nonlinear cases.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3216401369",
    "type": "article"
  },
  {
    "title": "Deep Siamese Metric Learning: A Highly Scalable Approach to Searching Unordered Sets of Trajectories",
    "doi": "https://doi.org/10.1145/3465057",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Christoffer Löffler; Luca Reeb; Daniel Dzibela; Robert Marzilger; Nicolas Witt; Bjoern M. Eskofier; Christopher Mutschler",
    "corresponding_authors": "",
    "abstract": "This work proposes metric learning for fast similarity-based scene retrieval of unstructured ensembles of trajectory data from large databases. We present a novel representation learning approach using Siamese Metric Learning that approximates a distance preserving low-dimensional representation and that learns to estimate reasonable solutions to the assignment problem. To this end, we employ a Temporal Convolutional Network architecture that we extend with a gating mechanism to enable learning from sparse data, leading to solutions to the assignment problem exhibiting varying degrees of sparsity. Our experimental results on professional soccer tracking data provides insights on learned features and embeddings, as well as on generalization, sensitivity, and network architectural considerations. Our low approximation errors for learned representations and the interactive performance with retrieval times several magnitudes smaller shows that we outperform previous state of the art.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3216643861",
    "type": "article"
  },
  {
    "title": "Early prediction of the highest workload in incremental cardiopulmonary tests",
    "doi": "https://doi.org/10.1145/2508037.2508051",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Elena Baralis; Tania Cerquitelli; Silvia Chiusano; Vincenzo D’Elia; Riccardo Molinari; Davide Susta",
    "corresponding_authors": "",
    "abstract": "Incremental tests are widely used in cardiopulmonary exercise testing, both in the clinical domain and in sport sciences. The highest workload (denoted W peak ) reached in the test is key information for assessing the individual body response to the test and for analyzing possible cardiac failures and planning rehabilitation, and training sessions. Being physically very demanding, incremental tests can significantly increase the body stress on monitored individuals and may cause cardiopulmonary overload. This article presents a new approach to cardiopulmonary testing that addresses these drawbacks. During the test, our approach analyzes the individual body response to the exercise and predicts the W peak value that will be reached in the test and an evaluation of its accuracy. When the accuracy of the prediction becomes satisfactory, the test can be prematurely stopped, thus avoiding its entire execution. To predict W peak , we introduce a new index, the CardioPulmonary Efficiency Index (CPE), summarizing the cardiopulmonary response of the individual to the test. Our approach analyzes the CPE trend during the test, together with the characteristics of the individual, and predicts W peak . A K-nearest-neighbor-based classifier and an ANN-based classier are exploited for the prediction. The experimental evaluation showed that the W peak value can be predicted with a limited error from the first steps of the test.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1987924400",
    "type": "article"
  },
  {
    "title": "A conformant planner based on approximation",
    "doi": "https://doi.org/10.1145/2438653.2438671",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Vien Tran; Khoi Nguyen; Tran Cao Son; Enrico Pontelli",
    "corresponding_authors": "",
    "abstract": "This article describes the planner C p A( H ), the recipient of the Best Nonobservable Nondeterministic Planner Award in the “Uncertainty Track” of the 6 th International Planning Competition (IPC), 2008. The article presents the various techniques that help C p A( H ) to achieve the level of performance and scalability exhibited in the competition. The article also presents experimental results comparing C p A( H ) with state-of-the-art conformant planners.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2052384302",
    "type": "article"
  },
  {
    "title": "Metric Learning for Estimating Psychological Similarities",
    "doi": "https://doi.org/10.1145/2168752.2168769",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Junming Xu; Xiaojin Zhu; Timothy T. Rogers",
    "corresponding_authors": "",
    "abstract": "An important problem in cognitive psychology is to quantify the perceived similarities between stimuli. Previous work attempted to address this problem with multidimensional scaling (MDS) and its variants. However, there are several shortcomings of the MDS approaches. We propose Yada, a novel general metric-learning procedure based on two-alternative forced-choice behavioral experiments. Our method learns forward and backward nonlinear mappings between an objective space in which the stimuli are defined by the standard feature vector representation and a subjective space in which the distance between a pair of stimuli corresponds to their perceived similarity. We conduct experiments on both synthetic and real human behavioral datasets to assess the effectiveness of Yada. The results show that Yada outperforms several standard embedding and metric-learning algorithms, both in terms of likelihood and recovery error.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2141932755",
    "type": "article"
  },
  {
    "title": "Advanced Economic Control of Electricity-Based Space Heating Systems in Domestic Coalitions with Shared Intermittent Energy Resources",
    "doi": "https://doi.org/10.1145/3041216",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Athanasios Aris Panagopoulos; Sasan Maleki; Alex Rogers; Matteo Venanzi; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "Over the past few years, Domestic Heating Automation Systems (DHASs) that optimize the domestic space heating control process with minimum user input, utilizing appropriate occupancy prediction technology, have emerged as commercial products (e.g., the smart thermostats from Nest and Honeywell). At the same time, many houses are being equipped with, potentially grid-connected, Intermittent Energy Resources (IERs), such as rooftop photovoltaic systems and/or small wind turbine generators. Now, in many regions of the world, such houses can sell energy to the grid but at a lower price than the price of buying it. In this context, and given the anticipated increase in electrification of heating, the next generation DHASs need to incorporate Advanced Economic Control (AEC). Such AEC can exploit the energy buffer that heating loads provide, in order to shift the consumption of electricity-based heating systems to follow the intermittent energy generation of the house. By so doing, the energy imported from the grid can be minimized and considerable monetary gains for the household can be achieved, without affecting the occupants’ schedule. These benefits can be amplified still further in domestic coalitions, where a number of houses come together and share their IER generation to minimize their cumulative grid energy import. Given the above, in this work we extend a state-of-the-art DHAS, to propose AdaHeat+, a practical DHAS, that, for the first time, incorporates AEC. Our work is applicable to both individual houses and domestic coalitions and comes complete with an allocation mechanism to share the coalition gains. Importantly, we propose an effective heuristic heating schedule planning approach for collective AEC that (i) has a complexity that scales in a linear and parallelizable manner with the coalition size, and (ii) enables AdaHeat+ to handle the distinct preferences, in balancing heating cost and thermal discomfort, of the households. Our approach relies on stochastic IER power output predictions. In this context, we propose a simple and effective formulation for the site-specific calibration of such predictions based on adaptive Gaussian process modeling. Finally, we demonstrate the effectiveness of AdaHeat+ through real data evaluation, to show that collective AEC can improve heating cost-efficiency by up to 60%, compared to independent AEC (and even more when compared to no-AEC).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2568374434",
    "type": "article"
  },
  {
    "title": "Implicit Visual Learning",
    "doi": "https://doi.org/10.1145/2974024",
    "publication_date": "2017-01-09",
    "publication_year": 2017,
    "authors": "Yan Liu; Yang Liu; Sheng-hua Zhong; Songtao Wu",
    "corresponding_authors": "",
    "abstract": "According to consciousness involvement, human’s learning can be roughly classified into explicit learning and implicit learning. Contrasting strongly to explicit learning with clear targets and rules, such as our school study of mathematics, learning is implicit when we acquire new information without intending to do so. Research from psychology indicates that implicit learning is ubiquitous in our daily life. Moreover, implicit learning plays an important role in human visual perception. But in the past 60 years, most of the well-known machine-learning models aimed to simulate explicit learning while the work of modeling implicit learning was relatively limited, especially for computer vision applications. This article proposes a novel unsupervised computational model for implicit visual learning by exploring dissipative system, which provides a unifying macroscopic theory to connect biology with physics. We test the proposed Dissipative Implicit Learning Model (DILM) on various datasets. The experiments show that DILM not only provides a good match to human behavior but also improves the explicit machine-learning performance obviously on image classification tasks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2569446613",
    "type": "article"
  },
  {
    "title": "Multi-Hypergraph Consistent Sparse Coding",
    "doi": "https://doi.org/10.1145/3078846",
    "publication_date": "2017-07-24",
    "publication_year": 2017,
    "authors": "Xiaodong Feng; Sen Wu; Wenjun Zhou",
    "corresponding_authors": "",
    "abstract": "Sparse representation has been a powerful technique for modeling high-dimensional data. As an unsupervised technique to extract sparse representations, sparse coding encodes the original data into a new sparse code space and simultaneously learns a dictionary representing high-level semantics. Existing methods have considered local manifold within high-dimensional data using graph/hypergraph Laplacian regularization, and more from the manifold could be utilized to improve the performance. In this article, we propose to further regulate the sparse coding so that the learned sparse codes can well reconstruct the hypergraph structure. In particular, we add a novel hypergraph consistency regularization term (HC) by minimizing the reconstruction error of the hypergraph incidence or weight matrix. Moreover, we extend the HC term to multi-hypergraph consistent sparse coding (MultiCSC) and automatically select the optimal manifold structure under the multi-hypergraph learning framework. We show that the optimization of MultiCSC can be solved efficiently, and that several existing sparse coding methods can fit into the general framework of MultiCSC as special cases. As a case study, hypergraph incidence consistent sparse coding is applied to perform semi-auto image tagging, demonstrating the effectiveness of hypergraph consistency regulation. We perform further experiments using MultiCSC for image clustering, which outperforms a number of baselines.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2737859033",
    "type": "article"
  },
  {
    "title": "Rapid Low-Cost Virtual Human Bootstrapping via the Crowd",
    "doi": "https://doi.org/10.1145/2897366",
    "publication_date": "2016-03-21",
    "publication_year": 2016,
    "authors": "Michael Borish; Benjamin Lok",
    "corresponding_authors": "",
    "abstract": "Virtual human interactions provide an important avenue for training as emergent opportunities arise. In response to a new training need, we propose a framework to rapidly create experiential learning opportunities in the form of a question--answer chat interaction with virtual humans. This framework takes quickly generated case documents and breaks down the case into small tasks that can be crowdsourced by nonexperts. This framework can serve as a first step to rapidly bootstrapping new virtual humans. We have applied our framework to the task of preparing health care students and professionals to infrequent, but high-stakes, situations such as infectious diseases, cranial nerve disorders, and stroke. Our framework was utilized by medical professionals interested in providing new training experiences to students and colleagues. Over the course of two months, these professionals created seven scenarios on a diverse range of topics that included Ebola, cancer, and neurological disorders. These scenarios were developed for multiple target audiences such as medical students, residents, and fellows. As a first step, each scenario utilized our framework and crowdsourced workers to create an initial corpus over the course of two days. From these seven cases, we selected two to evaluate the quality of the resulting virtual-human corpuses. The two scenarios were compared to preexisting reference scenarios that have been in curricular use for several years. We found a reduction in author time commitment of at least 92% while creating a character that was at least 75% as accurate as its reference counterparts. The commitment reduction and accuracy achieved by our framework represents a first step towards rapid development of a virtual human. Our framework can then be combined with other creation processes for further virtual-human development in order to create a mature virtual human. As part of a virtual-human development process, our framework can help to rapidly develop new scenarios in response to emergent training opportunities.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2305554724",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Recommender System Benchmarking",
    "doi": "https://doi.org/10.1145/2870627",
    "publication_date": "2016-03-08",
    "publication_year": 2016,
    "authors": "Paolo Cremonesi; Alan Said; Domonkos Tikk; Michelle X. Zhou",
    "corresponding_authors": "",
    "abstract": "other Share on Introduction to the Special Issue on Recommender System Benchmarking Authors: Paolo Cremonesi Politecnico di Milano Politecnico di MilanoView Profile , Alan Said Recorded Future Recorded FutureView Profile , Domonkos Tikk Gravity R&D, Hungary Gravity R&D, HungaryView Profile , Michelle X. Zhou Juji JujiView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 7Issue 3April 2016 Article No.: 38pp 1–4https://doi.org/10.1145/2870627Published:08 March 2016Publication History 2citation384DownloadsMetricsTotal Citations2Total Downloads384Last 12 Months12Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2319728673",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2885506",
    "publication_date": "2016-04-01",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The design and evaluation of tag recommendation methods has historically focused on maximizing the relevance of the suggested tags for a given object, such as a movie or a song. However, relevance by itself may not be enough to guarantee recommendation ...",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4249688295",
    "type": "paratext"
  },
  {
    "title": "Energy Usage Behavior Modeling in Energy Disaggregation via Hawkes Processes",
    "doi": "https://doi.org/10.1145/3108413",
    "publication_date": "2018-01-29",
    "publication_year": 2018,
    "authors": "Liangda Li; Hongyuan Zha",
    "corresponding_authors": "",
    "abstract": "Energy disaggregation, the task of taking a whole home electricity signal and decomposing it into its component appliances, has been proved to be essential in energy conservation research. One powerful cue for breaking down the entire household’s energy consumption is user’s daily energy usage behavior, which has so far received little attention: existing works on energy disaggregation mostly ignored the relationship between the energy usages of various appliances by householders across different time slots. The major challenge in modeling such a relationship in that, with ambiguous appliance usage membership of householders, we find it difficult to appropriately model the influence between appliances, since such influence is determined by human behaviors in energy usage. To address this problem, we propose to model the influence between householders’ energy usage behaviors directly through a novel probabilistic model, which combines topic models with the Hawkes processes. The proposed model simultaneously disaggregates the whole home electricity signal into each component appliance and infers the appliance usage membership of household members and enables those two tasks to mutually benefit each other. Experimental results on both synthetic data and four real-world data sets demonstrate the effectiveness of our model, which outperforms state-of-the-art approaches in not only decomposing the entire consumed energy to each appliance in houses but also the inference of household structures. We further analyze the inferred appliance-householder assignment and the corresponding influence within the appliance usage of each householder and across different householders, which provides insight into appealing human behavior patterns in appliance usage.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2787256428",
    "type": "article"
  },
  {
    "title": "Characterizing User Skills from Application Usage Traces with Hierarchical Attention Recurrent Networks",
    "doi": "https://doi.org/10.1145/3232231",
    "publication_date": "2018-10-29",
    "publication_year": 2018,
    "authors": "Longqi Yang; Fang Chen; Hailin Jin; Matthew D. Hoffman; Deborah Estrin",
    "corresponding_authors": "",
    "abstract": "Predicting users’ proficiencies is a critical component of AI-powered personal assistants. This article introduces a novel approach for the prediction based on users’ diverse, noisy, and passively generated application usage histories. We propose a novel bi-directional recurrent neural network with hierarchical attention mechanism to extract sequential patterns and distinguish informative traces from noise. Our model is able to attend to the most discriminative actions and sessions to make more accurate and directly interpretable predictions while requiring 50× less training data than the state-of-the-art sequential learning approach. We evaluate our model with two large scale datasets collected from 68K Photoshop users: a digital design skill dataset where the user skill is determined by the quality of the end products and a software skill dataset where users self-disclose their software usage skill levels. The empirical results demonstrate our model’s superior performance compared to existing user representation learning techniques that leverage action frequencies and sequential patterns. In addition, we qualitatively illustrate the model’s significant interpretative power. The proposed approach is broadly relevant to applications that generate user time-series analytics.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2898782527",
    "type": "article"
  },
  {
    "title": "An Efficient Alternating Newton Method for Learning Factorization Machines",
    "doi": "https://doi.org/10.1145/3230710",
    "publication_date": "2018-10-29",
    "publication_year": 2018,
    "authors": "Wei-Sheng Chin; Bowen Yuan; Mengyuan Yang; Chih‐Jen Lin",
    "corresponding_authors": "",
    "abstract": "To date, factorization machines (FMs) have emerged as a powerful model in many applications. In this work, we study the training of FM with the logistic loss for binary classification, which is a nonlinear extension of the linear model with the logistic loss (i.e., logistic regression). For the training of large-scale logistic regression, Newton methods have been shown to be an effective approach, but it is difficult to apply such methods to FM because of the nonconvexity. We consider a modification of FM that is multiblock convex and propose an alternating minimization algorithm based on Newton methods. Some novel optimization techniques are introduced to reduce the running time. Our experiments demonstrate that the proposed algorithm is more efficient than stochastic gradient algorithms and coordinate descent methods. The parallelism of our method is also investigated for the acceleration in multithreading environments.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2899129884",
    "type": "article"
  },
  {
    "title": "The Effect of Pets on Happiness",
    "doi": "https://doi.org/10.1145/3200751",
    "publication_date": "2018-06-22",
    "publication_year": 2018,
    "authors": "Xuefeng Peng; Li-Kai Chi; Jiebo Luo",
    "corresponding_authors": "",
    "abstract": "From reducing stress and loneliness, to boosting productivity and overall well-being, pets are believed to play a significant role in people’s daily lives. Many traditional studies have identified that frequent interactions with pets could make individuals become healthier and more optimistic, and ultimately enjoy a happier life. However, most of those studies are not only restricted in scale, but also may carry biases by using subjective self-reports, interviews, and questionnaires as the major approaches. In this article, we leverage large-scale data collected from social media and the state-of-the-art deep learning technologies to study this phenomenon in depth and breadth. Our study includes five major steps: (1) collecting timeline posts from around 20,000 Instagram users; (2) using face detection and recognition on 2 million photos to infer users’ demographics, relationship status, and whether having children, (3) analyzing a user’s degree of happiness based on images and captions via smiling classification and textual sentiment analysis; (4) applying transfer learning techniques to retrain the final layer of the Inception v3 model for pet classification; and (5) analyzing the effects of pets on happiness in terms of multiple factors of user demographics. Our main results have demonstrated the efficacy of our proposed method with many new insights. We believe this method is also applicable to other domains as a scalable, efficient, and effective methodology for modeling and analyzing social behaviors and psychological well-being. In addition, to facilitate the research involving human faces, we also release our dataset of 700K analyzed faces.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2962805032",
    "type": "article"
  },
  {
    "title": "Privacy-aware Tag Recommendation for Accurate Image Privacy Prediction",
    "doi": "https://doi.org/10.1145/3335054",
    "publication_date": "2019-07-31",
    "publication_year": 2019,
    "authors": "Ashwini Tonge; Cornelia Caragea",
    "corresponding_authors": "",
    "abstract": "Online images’ tags are very important for indexing, sharing, and searching of images, as well as surfacing images with private or sensitive content, which needs to be protected. Social media sites such as Flickr generate these metadata from user-contributed tags. However, as the tags are at the sole discretion of users, these tags tend to be noisy and incomplete. In this article, we present a privacy-aware approach to automatic image tagging, which aims at improving the quality of user annotations, while also preserving the images’ original privacy sharing patterns. Precisely, we recommend potential tags for each target image by mining privacy-aware tags from the most similar images of the target image, which are obtained from a large collection. Experimental results show that, although the user-input tags compose noise, our privacy-aware approach is able to predict accurate tags that can improve the performance of a downstream application on image privacy prediction and outperforms an existing privacy-oblivious approach to image tagging. The results also show that, even for images that do not have any user tags, our proposed approach can recommend accurate tags. Crowd-sourcing the predicted tags exhibits the quality of our privacy-aware recommended tags. Our code, features, and the dataset used in experiments are available at: https://github.com/ashwinitonge/privacy-aware-tag-rec.git.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2966934727",
    "type": "article"
  },
  {
    "title": "Toward Accounting for Hidden Common Causes When Inferring Cause and Effect from Observational Data",
    "doi": "https://doi.org/10.1145/3309720",
    "publication_date": "2019-09-05",
    "publication_year": 2019,
    "authors": "David Heckerman",
    "corresponding_authors": "David Heckerman",
    "abstract": "Hidden common causes make it difficult to infer causal relationships from observational data. Here, we begin an investigation into a new method to account for a hidden common cause that infers its presence from the data. As with other approaches that can account for common causes, this approach is successful only in some cases. We describe such a case taken from the field of genomics, wherein one tries to identify which genomic markers causally influence a trait of interest.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2971513809",
    "type": "article"
  },
  {
    "title": "Stable Specification Search in Structural Equation Models with Latent Variables",
    "doi": "https://doi.org/10.1145/3341557",
    "publication_date": "2019-09-09",
    "publication_year": 2019,
    "authors": "Ridho Rahmadi; P. Groot; Tom Heskes",
    "corresponding_authors": "",
    "abstract": "In our previous study, we introduced stable specification search for cross-sectional data (S3C). It is an exploratory causal method that combines the concept of stability selection and multi-objective optimization to search for stable and parsimonious causal structures across the entire range of model complexities. S3C, however, is designed to model causal relations among observed variables. In this study, we extended S3C to S3C-Latent, to model linear causal relations between latent variables that are measured through observed proxies. We evaluated S3C-Latent on simulated data and compared the results to those of PC-MIMBuild, an extension of the PC algorithm, the state-of-the-art causal discovery method. The comparison shows that S3C-Latent achieved better performance. We also applied S3C-Latent to real-world data of children with attention deficit/hyperactivity disorder and data about measuring mental abilities among pupils. The results are consistent with those of previous studies.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2973228216",
    "type": "article"
  },
  {
    "title": "Special Issue on Intelligent Edge Computing for Cyber Physical and Cloud Systems",
    "doi": "https://doi.org/10.1145/3372277",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Prof. Weijia Jia; Prof. Geyong Min; Prof. Yang Xiang; Arun Kumar Sangaiah",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessSpecial Issue on Intelligent Edge Computing for Cyber Physical and Cloud Systems Share on Authors: Prof. Weijia Jia University of Macau, Macau University of Macau, MacauView Profile , Prof. Geyong Min University of Exeter, UK University of Exeter, UKView Profile , Prof. Yang Xiang Swinburne University of Technology, Australia Swinburne University of Technology, AustraliaView Profile , Dr. Arun Kumar Sangaiah VIT University, Vellore, India VIT University, Vellore, IndiaView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 10Issue 6November 2019 Article No.: 60epp 1–4https://doi.org/10.1145/3372277Online:07 December 2019Publication History 0citation561DownloadsMetricsTotal Citations0Total Downloads561Last 12 Months252Last 6 weeks10 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2996276196",
    "type": "article"
  },
  {
    "title": "Using Sub-Optimal Plan Detection to Identify Commitment Abandonment in Discrete Environments",
    "doi": "https://doi.org/10.1145/3372119",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Ramon Fraga Pereira; Nir Oren; Felipe Meneguzzi",
    "corresponding_authors": "",
    "abstract": "Assessing whether an agent has abandoned a goal or is actively pursuing it is important when multiple agents are trying to achieve joint goals, or when agents commit to achieving goals for each other. Making such a determination for a single goal by observing only plan traces is not trivial, as agents often deviate from optimal plans for various reasons, including the pursuit of multiple goals or the inability to act optimally. In this article, we develop an approach based on domain independent heuristics from automated planning, landmarks, and fact partitions to identify sub-optimal action steps—with respect to a plan—within a fully observable plan execution trace. Such capability is very important in domains where multiple agents cooperate and delegate tasks among themselves, such as through social commitments , and need to ensure that a delegating agent can infer whether or not another agent is actually progressing towards a delegated task. We demonstrate how a creditor can use our technique to determine—by observing a trace—whether a debtor is honouring a commitment. We empirically show, for a number of representative domains, that our approach infers sub-optimal action steps with very high accuracy and detects commitment abandonment in nearly all cases.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3008135457",
    "type": "article"
  },
  {
    "title": "Understand Dynamic Regret with Switching Cost for Online Decision Making",
    "doi": "https://doi.org/10.1145/3375788",
    "publication_date": "2020-04-18",
    "publication_year": 2020,
    "authors": "Yawei Zhao; Qian Zhao; Xingxing Zhang; En Zhu; Xinwang Liu; Jianping Yin",
    "corresponding_authors": "",
    "abstract": "As a metric to measure the performance of an online method, dynamic regret with switching cost has drawn much attention for online decision making problems. Although the sublinear regret has been provided in much previous research, we still have little knowledge about the relation between the dynamic regret and the switching cost . In the article, we investigate the relation for two classic online settings: Online Algorithms (OA) and Online Convex Optimization (OCO). We provide a new theoretical analysis framework that shows an interesting observation; that is, the relation between the switching cost and the dynamic regret is different for settings of OA and OCO. Specifically, the switching cost has significant impact on the dynamic regret in the setting of OA. But it does not have an impact on the dynamic regret in the setting of OCO. Furthermore, we provide a lower bound of regret for the setting of OCO, which is same with the lower bound in the case of no switching cost. It shows that the switching cost does not change the difficulty of online decision making problems in the setting of OCO.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3022895603",
    "type": "article"
  },
  {
    "title": "Knowledge-aware Attentive Wasserstein Adversarial Dialogue Response Generation",
    "doi": "https://doi.org/10.1145/3384675",
    "publication_date": "2020-05-28",
    "publication_year": 2020,
    "authors": "Yingying Zhang; Quan Fang; Shengsheng Qian; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "Natural language generation has become a fundamental task in dialogue systems. RNN-based natural response generation methods encode the dialogue context and decode it into a response. However, they tend to generate dull and simple responses. In this article, we propose a novel framework, called KAWA-DRG (Knowledge-aware Attentive Wasserstein Adversarial Dialogue Response Generation) to model conversation-specific external knowledge and the importance variances of dialogue context in a unified adversarial encoder-decoder learning framework. In KAWA-DRG, a co-attention mechanism attends to important parts within and among context utterances with word-utterance-level attention. Prior knowledge is integrated into the conditional Wasserstein auto-encoder for learning the latent variable space. The posterior and prior distribution of latent variables are generated and trained through adversarial learning. We evaluate our model on Switchboard, DailyDialog, In-Car Assistant, and Ubuntu Dialogue Corpus. Experimental results show that KAWA-DRG outperforms the existing methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3047872862",
    "type": "article"
  },
  {
    "title": "Multiple Elimination of Base Classifiers in Ensemble Learning Using Accuracy and Diversity Comparisons",
    "doi": "https://doi.org/10.1145/3405790",
    "publication_date": "2020-10-04",
    "publication_year": 2020,
    "authors": "Zohaib Jan; Brijesh Verma",
    "corresponding_authors": "",
    "abstract": "When generating ensemble classifiers, selecting the best set of classifiers from the base classifier pool is considered a combinatorial problem and an efficient classifier selection methodology must be utilized. Different researchers have used different strategies such as evolutionary algorithms, genetic algorithms, rule-based algorithms, simulated annealing, and so forth to select the best set of classifiers that can maximize overall ensemble classifier accuracy. In this article, we present a novel classifier selection approach to generate an ensemble classifier. The proposed approach selects classifiers in multiple rounds of elimination. In each round, a classifier is given a chance to be selected to become a part of the ensemble, if it can contribute to the overall ensemble accuracy or diversity; otherwise, it is put back into the pool. Each classifier is given multiple opportunities to participate in rounds of selection and they are discarded only if they have no remaining chances. The process is repeated until no classifier in the pool has any chance left to participate in the round of selection. To test the efficacy of the proposed approach, 13 benchmark datasets from the UCI repository are used and results are compared with single classifier models and existing state-of-the-art ensemble classifier approaches. Statistical significance testing is conducted to further validate the results, and an analysis is provided.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3090343122",
    "type": "article"
  },
  {
    "title": "Deep Energy Factorization Model for Demographic Prediction",
    "doi": "https://doi.org/10.1145/3426240",
    "publication_date": "2020-11-16",
    "publication_year": 2020,
    "authors": "Chih-Te Lai; Cheng–Te Li; Shou-De Lin",
    "corresponding_authors": "",
    "abstract": "Demographic information is important for various commercial and academic proposes, but in reality, few of these data are accessible for analysis and research. To solve this problem, several studies predict demographic attributes from users’ behavioral data. However, previous works suffer from different kinds of disadvantages. Handling data sparseness and defining useful features remain especially challenge tasks. In this article, we propose a novel Deep Energy Factorization Model to address these two drawbacks. The model is a designed network that performs multi-label classification and feature representation. Experiments are conducted on four datasets with four evaluation metrics. The empirical results show that our Deep Energy Factorization Model significantly outperforms state-of-the-art models.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3101169677",
    "type": "article"
  },
  {
    "title": "Using qualitative reasoning for social simulation of crowds",
    "doi": "https://doi.org/10.1145/2483669.2483687",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Natalie Fridman; Gal A. Kaminka",
    "corresponding_authors": "",
    "abstract": "The ability to model and reason about the potential violence level of a demonstration is important to the police decision making process. Unfortunately, existing knowledge regarding demonstrations is composed of partial qualitative descriptions without complete and precise numerical information. In this article we describe a first attempt to use qualitative reasoning techniques to model demonstrations. To our knowledge, such techniques have never been applied to modeling and reasoning regarding crowd behaviors, nor in particular demonstrations. We develop qualitative models consistent with the partial, qualitative social science literature, allowing us to model the interactions between different factors that influence violence in demonstrations. We then utilize qualitative simulation to predict the potential eruption of violence, at various levels, based on a description of the demographics, environmental settings, and police responses. We incrementally present and compare three such qualitative models. The results show that while two of these models fail to predict the outcomes of real-world events reported and analyzed in the literature, one model provides good results. We also examine whether a popular machine learning algorithm (decision tree learning) can be used. While the results show that the decision trees provide improved predictions, we show that the QR models can be more sensitive to changes, and can account for what-if scenarios, in contrast to decision trees. Moreover, we introduce a novel analysis algorithm that analyzes the QR simulations, to automatically determine the factors that are most important in influencing the outcome in specific real-world demonstrations. We show that the algorithm identifies factors that correspond to experts' analysis of these events.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1967092687",
    "type": "article"
  },
  {
    "title": "Video Human Motion Recognition Using a Knowledge-Based Hybrid Method Based on a Hidden Markov Model",
    "doi": "https://doi.org/10.1145/2168752.2168756",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Myunghoon Suk; Ashok Ramadass; Yohan Jin; Balakrishnan Prabhakaran",
    "corresponding_authors": "",
    "abstract": "Human motion recognition in video data has several interesting applications in fields such as gaming, senior/assisted-living environments, and surveillance. In these scenarios, we may have to consider adding new motion classes (i.e., new types of human motions to be recognized), as well as new training data (e.g., for handling different type of subjects). Hence, both the accuracy of classification and training time for the machine learning algorithms become important performance parameters in these cases. In this article, we propose a knowledge-based hybrid (KBH) method that can compute the probabilities for hidden Markov models (HMMs) associated with different human motion classes. This computation is facilitated by appropriately mixing features from two different media types (3D motion capture and 2D video). We conducted a variety of experiments comparing the proposed KBH for HMMs and the traditional Baum-Welch algorithms. With the advantage of computing the HMM parameter in a noniterative manner, the KBH method outperforms the Baum-Welch algorithm both in terms of accuracy as well as in reduced training time. Moreover, we show in additional experiments that the KBH method also outperforms the linear support vector machine (SVM).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1981165648",
    "type": "article"
  },
  {
    "title": "Audio classification with low-rank matrix representation features",
    "doi": "https://doi.org/10.1145/2542182.2542197",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Ziqiang Shi; Jiqing Han; Tieran Zheng",
    "corresponding_authors": "",
    "abstract": "In this article, a novel framework based on trace norm minimization for audio classification is proposed. In this framework, both the feature extraction and classification are obtained by solving corresponding convex optimization problem with trace norm regularization. For feature extraction, robust principle component analysis (robust PCA) via minimization a combination of the nuclear norm and the ℓ 1 -norm is used to extract low-rank matrix features which are robust to white noise and gross corruption for audio signal. These low-rank matrix features are fed to a linear classifier where the weight and bias are learned by solving similar trace norm constrained problems. For this linear classifier, most methods find the parameters, that is the weight matrix and bias in batch-mode, which makes it inefficient for large scale problems. In this article, we propose a parallel online framework using accelerated proximal gradient method. This framework has advantages in processing speed and memory cost. In addition, as a result of the regularization formulation of matrix classification, the Lipschitz constant was given explicitly, and hence the step size estimation of the general proximal gradient method was omitted, and this part of computing burden is saved in our approach. Extensive experiments on real data sets for laugh/non-laugh and applause/non-applause classification indicate that this novel framework is effective and noise robust.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1984704936",
    "type": "article"
  },
  {
    "title": "Simplifying Data Disclosure Configurations in a Cloud Computing Environment",
    "doi": "https://doi.org/10.1145/2700472",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Ron S. Hirschprung; Eran Toch; Oded Maimon",
    "corresponding_authors": "",
    "abstract": "Cloud computing offers a compelling vision of computation, enabling an unprecedented level of data distribution and sharing. Beyond improving the computing infrastructure, cloud computing enables a higher level of interoperability between information systems, simplifying tasks such as sharing documents between coworkers or enabling collaboration between an organization and its suppliers. While these abilities may result in significant benefits to users and organizations, they also present privacy challenges due to unwanted exposure of sensitive information. As information-sharing processes in cloud computing are complex and domain specific, configuring these processes can be an overwhelming and burdensome task for users. This article investigates the feasibility of configuring sharing processes through a small and representative set of canonical configuration options. For this purpose, we present a generic method, named SCON-UP (Simplified CON-figuration of User Preferences). SCON-UP simplifies configuration interfaces by using a clustering algorithm that analyzes a massive set of sharing preferences and condenses them into a small number of discrete disclosure levels. Thus, the user is provided with a usable configuration model while guaranteeing adequate privacy control. We describe the algorithm and empirically evaluate our model using data collected in two user studies (n = 121 and n = 352). Our results show that when provided with three canonical configuration options, on average, 82% of the population can be covered by at least one option. We exemplify the feasibility of discretizing sharing levels and discuss the tradeoff between coverage and simplicity in discrete configuration options.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1996234431",
    "type": "article"
  },
  {
    "title": "Mathematical description and analysis of adaptive risk choice behavior",
    "doi": "https://doi.org/10.1145/2414425.2414442",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Isamu Okada; H. Yamamoto",
    "corresponding_authors": "",
    "abstract": "Which risk should one choose when facing alternatives with different levels of risk? We discuss here adaptive processes in such risk choice behavior by generalizing the study of Roos et al. [2010]. We deal with an n -choice game in which every player sequentially chooses n times of lotteries of which there are two types: a safe lottery and a risky lottery. We analyze this model in more detail by elaborating the game. Based on the results of mathematical analysis, replicator dynamics analysis, and numerical simulations, we derived some salient features of risk choice behavior. We show that all the risk strategies can be divided into two groups: persistence and nonpersistence. We also proved that the dynamics with perturbation in which a mutation is installed is globally asymptotically stable to a unique equilibrium point for any initial population. The numerical simulations clarify that the number of persistent strategies seldom increases regardless of the increase in n , and suggest that a rarity of dominant choice strategies is widely observed in many social contexts. These facts not only go hand-in-hand with some well-known insights from prospect theory, but may also provide some theoretical hypotheses for various fields such as behavioral economics, ecology, sociology, and consumer behavioral theory.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2011972993",
    "type": "article"
  },
  {
    "title": "RECYCLE",
    "doi": "https://doi.org/10.1145/1989734.1989746",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Karen Zita Haigh; Fusun Yaman",
    "corresponding_authors": "",
    "abstract": "A workflow is a model of a process that systematically describes patterns of activity. Workflows capture a sequence of operations, their enablement conditions, and data flow dependencies among them. It is hard to design a complete and correct workflow from scratch, while it is much easier for humans to demonstrate the solution than to state the solution declaratively. This article presents RECYCLE, our approach to learning workflow models from example demonstration traces. RECYCLE captures control flow, data flow, and enablement conditions of an underlying workflow process. Unlike prior work from workflow mining and AI planning literature, (1) RECYCLE can learn from a single demonstration trace with loops, (2) RECYCLE learns both loop and conditional branch structure, and (3) RECYCLE handles data flow among actions. In this article, we describe the phases of RECYCLE's learning algorithm: substructure analysis and node abstraction. To ground the discussion, we present a simplified flight reservation system with some of the important characteristics of the real domains we worked with. We present some results from a patient transport domain.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2062408473",
    "type": "article"
  },
  {
    "title": "Geographic Information Systems and Spatial Agent-Based Model Simulations for Sustainable Development",
    "doi": "https://doi.org/10.1145/2036264.2036274",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Claudio Cioffi‐Revilla; J. Daniel Rogers; Atesmachew Hailegiorgis",
    "corresponding_authors": "",
    "abstract": "In recent years the interdisciplinary field of Computational Social Science has developed theory and methodologies for building spatial Agent-Based Social Simulation (ABSS) models of human societies that are situated in ecosystems with land cover and climate. This article explains the needs and demand for Geographic Information Systems (GIS) in these types of agent-based models, with an emphasis on models applied to Eastern Africa and Inner Asia and relevance for understanding and analyzing development issues. The models are implemented with the MASON (Multi-Agent Simulator Of Networks and Neighborhoods) system, an open-source simulation environment in the Java language and suitable for developing ABSS models with GIS for representing spatial features.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2120724742",
    "type": "article"
  },
  {
    "title": "NEAR: Neighborhood Edge AggregatoR for Graph Classification",
    "doi": "https://doi.org/10.1145/3506714",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Cheolhyeong Kim; Haeseong Moon; Hyung Ju Hwang",
    "corresponding_authors": "",
    "abstract": "Learning graph-structured data with graph neural networks (GNNs) has been recently emerging as an important field because of its wide applicability in bioinformatics, chemoinformatics, social network analysis, and data mining. Recent GNN algorithms are based on neural message passing, which enables GNNs to integrate local structures and node features recursively. However, past GNN algorithms based on 1-hop neighborhood neural message passing are exposed to a risk of loss of information on local structures and relationships. In this article, we propose Neighborhood Edge AggregatoR (NEAR), a framework that aggregates relations between the nodes in the neighborhood via edges. NEAR, which can be orthogonally combined with Graph Isomorphism Network (GIN), gives integrated information that describes which nodes in the neighborhood are connected. Therefore, NEAR can reflect additional information of a local structure of each node beyond the nodes themselves in 1-hop neighborhood. Experimental results on multiple graph classification tasks show that our algorithm makes a good improvement over other existing 1-hop based GNN-based algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2971822101",
    "type": "article"
  },
  {
    "title": "A New Similarity Space Tailored for Supervised Deep Metric Learning",
    "doi": "https://doi.org/10.1145/3559766",
    "publication_date": "2022-09-02",
    "publication_year": 2022,
    "authors": "Pedro H. Barros; Fabiane Queiroz; Flávio Figueiredo; Jefersson A. dos Santos; Heitor S. Ramos",
    "corresponding_authors": "",
    "abstract": "We propose a novel deep metric learning method. Differently from many works in this area, we define a novel latent space obtained through an autoencoder. The new space, namely S-space, is divided into different regions describing positions where pairs of objects are similar/dissimilar. We locate makers to identify these regions and estimate the similarities between objects through a kernel-based Cauchy distribution to measure the markers’ distance and the new data representation. In our approach, we simultaneously estimate the markers’ position in the S-space and represent the objects in the same space. Moreover, we propose a new regularization function to prevent similar markers from collapsing altogether. Our method emphasizes the group property (separability) while preserving instance representativity. We present evidence that our proposal can represent complex spaces, for instance, when groups of similar objects are located in disjoint regions. We compare our proposal to nine different distance metric learning approaches (four of them are based on deep learning) on 28 real-world heterogeneous datasets. According to the four quantitative metrics used, our method overcomes all of the nine strategies from the literature.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3102870107",
    "type": "article"
  },
  {
    "title": "Mining Willing-to-Pay Behavior Patterns from Payment Datasets",
    "doi": "https://doi.org/10.1145/3485848",
    "publication_date": "2022-02-06",
    "publication_year": 2022,
    "authors": "Yuting Wen; Hui-Kuo Yang; Wen-Chih Peng",
    "corresponding_authors": "",
    "abstract": "The customer base is the most valuable resource to E-commerce companies. A comprehensive understanding of customers’ preferences and behavior is crucial to developing good marketing strategies, in order to achieve optimal customer lifetime values (CLVs). For example, by exploring customer behavior patterns, given a marketing plan with a limited budget, a set of potential customers is able to be identified to maximize profit. In other words, personalized campaigns at the right time and in the right place can be treated as the last stage of consumption. Moreover, effective future purchase estimation and recommendation help guide the customer to the up-selling stage. The proposed willing-to-pay prediction model (W2P) exploits the transaction data to predict customer payment behavior based on a probabilistic graphical model, which provides semantic explanation of the estimated results and deals with the sparsity of payment data from each customer. Existing work in this domain ranks the customers by their probabilities of purchase in different conditions. However, the customer with the highest purchase probability does not necessarily spend the most. Therefore, we propose a CLV maximization algorithm based on the prediction results. In addition, we improve the model by behavioral segmentation wherein we group the customers by payment behaviors to reduce the size of the offline models and enhance the accuracy for low-frequency customers. The experiment results show that our model outperforms the state-of-the-art methods in purchase behavior prediction.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4210664898",
    "type": "article"
  },
  {
    "title": "Traveling Transporter Problem: Arranging a New Circular Route in a Public Transportation System Based on Heterogeneous Non-Monotonic Urban Data",
    "doi": "https://doi.org/10.1145/3510034",
    "publication_date": "2022-03-03",
    "publication_year": 2022,
    "authors": "Fandel Lin; Hsun-Ping Hsieh",
    "corresponding_authors": "",
    "abstract": "Hybrid computational intelligent systems that synergize learning-based inference models and route planning strategies have thrived in recent years. In this article, we focus on the non-monotonicity originated from heterogeneous urban data, as well as heuristics based on neural networks, and thereafter formulate the traveling transporter problem (TTP). TTP is a multi-criteria optimization problem and may be applied to the circular route deployment in public transportation. In particular, TTP aims to find an optimized route that maximizes passenger flow according to a neural-network-based inference model and minimizes the length of the route given several constraints, including must-visit stations and the requirement for additional ones. As a variation of the traveling salesman problem (TSP), we propose a framework that first recommends new stations’ location while considering the herding effect between stations, and thereafter combines state-of-the-art TSP solvers and a metaheuristic named Trembling Hand , which is inspired by self-efficacy for solving TTP. Precisely, the proposed Trembling Hand enhances the spatial exploration considering the structural patterns, previous actions, and aging factors. Evaluation conducted on two real-world mass transit systems, Tainan and Chicago, shows that the proposed framework can outperform other state-of-the-art methods by securing the Pareto-optimal toward the objectives of TTP among comparative methods under various constrained settings.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4214850614",
    "type": "article"
  },
  {
    "title": "A Holistic Approach for Role Inference and Action Anticipation in Human Teams",
    "doi": "https://doi.org/10.1145/3531230",
    "publication_date": "2022-05-28",
    "publication_year": 2022,
    "authors": "Junyi Dong; Qingze Huo; Silvio Ferrari",
    "corresponding_authors": "",
    "abstract": "The ability to anticipate human actions is critical to many cyber-physical systems, such as robots and autonomous vehicles. Computer vision and sensing algorithms to date have focused on extracting and predicting visual features that are explicit in the scene, such as color, appearance, actions, positions, and velocities, using video and physical measurements, such as object depth and motion. Human actions, however, are intrinsically influenced and motivated by many implicit factors such as context, human roles and interactions, past experience, and inner goals or intentions. For example, in a sport team, the team strategy, player role, and dynamic circumstances driven by the behavior of the opponents, all influence the actions of each player. This article proposes a holistic framework for incorporating visual features, as well as hidden information, such as social roles, and domain knowledge. The approach, relying on a novel dynamic Markov random field (DMRF) model, infers the instantaneous team strategy and, subsequently, the players’ roles that are temporally evolving throughout the game. The results from the DMRF inference stage are then integrated with instantaneous visual features, such as individual actions and position, in order to perform holistic action anticipation using a multi-layer perceptron (MLP). The approach is demonstrated on the team sport of volleyball, by first training the DMRF and MLP offline with past videos, and, then, by applying them to new volleyball videos online. These results show that the method is able to infer the players’ roles with an average accuracy of 86.99%, and anticipate future actions over a sequence of up to 46 frames with an average accuracy of 80.50%. Additionally, the method predicts the onset and duration of each action achieving a mean relative error of 14.57% and 15.67%, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4281964068",
    "type": "article"
  },
  {
    "title": "AggEnhance: Aggregation Enhancement by Class Interior Points in Federated Learning with Non-IID Data",
    "doi": "https://doi.org/10.1145/3544495",
    "publication_date": "2022-06-16",
    "publication_year": 2022,
    "authors": "Jinxiang Ou; Yunheng Shen; Feng Wang; Qiao Liu; Xuegong Zhang; Hairong Lv",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) is a privacy-preserving paradigm for multi-institutional collaborations, where the aggregation is an essential procedure after training on the local datasets. Conventional aggregation algorithms often apply a weighted averaging of the updates generated from distributed machines to update the global model. However, while the data distributions are non-IID, the large discrepancy between the local updates might lead to a poor averaged result and a lower convergence speed, i.e., more iterations required to achieve a certain performance. To solve this problem, this article proposes a novel method named AggEnhance for enhancing the aggregation, where we synthesize a group of reliable samples from the local models and tune the aggregated result on them. These samples, named class interior points (CIPs) in this work, bound the relevant decision boundaries that ensure the performance of aggregated result. To the best of our knowledge, this is the first work to explicitly design an enhancing method for the aggregation in prevailing FL pipelines. A series of experiments on real data demonstrate that our method has noticeable improvements of the convergence in non-IID scenarios. In particular, our approach reduces the iterations by 31.87% on average for the CIFAR10 dataset and 43.90% for the PASCAL VOC dataset. Since our method does not modify other procedures of FL pipelines, it is easy to apply to most existing FL frameworks. Furthermore, it does not require additional data transmitted from the local clients to the global server, thus holding the same security level as the original FL algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4282971512",
    "type": "article"
  },
  {
    "title": "FLAG: A Feedback-aware Local and Global Model for Heterogeneous Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3557046",
    "publication_date": "2022-08-16",
    "publication_year": 2022,
    "authors": "Mingkai He; Jing Lin; Jinwei Luo; Weike Pan; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Heterogeneous sequential recommendation that models sequences of items associated with more than one type of feedback such as examinations and purchases is an emerging topic in the research community, which is also an important problem in many real-world applications. Though there are some methods proposed to exploit different types of feedback in item sequences such as RLBL, RIB, and BINN, they are based on RNN and may not be very competitive in capturing users’ complex and dynamic preferences. And most existing advanced sequential recommendation methods such as the CNN- and attention-based methods are often designed for making use of item sequences with one single type of feedback, which thus can not be applied to the studied problem directly. As a response, we propose a novel feedback-aware local and global (FLAG) preference learning model for heterogeneous sequential recommendation. Our FLAG contains four modules, including (i) a local preference learning module for capturing a user’s short-term interest, which adopts a novel feedback-aware self-attention block to distinguish different types of feedback; (ii) a global preference learning module for modeling a user’s global preference; (iii) a local intention learning module, which takes a user’s real feedback in the next step, i.e., the user’s intention at the current step, as the query vector in a self-attention block to figure out the items that match the user’s intention well; and (iv) a prediction module for preference integration and final prediction. We then conduct extensive experiments on three public datasets and find that our FLAG significantly outperforms 13 very competitive baselines in terms of two commonly used ranking-oriented metrics in most cases. We also include ablation studies and sensitivity analysis of our FLAG to have more in-depth insights.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4291972679",
    "type": "article"
  },
  {
    "title": "A Semantically Driven Hybrid Network for Unsupervised Entity Alignment",
    "doi": "https://doi.org/10.1145/3567829",
    "publication_date": "2022-10-12",
    "publication_year": 2022,
    "authors": "Jia Li; Dandan Song; Zhijing Wu",
    "corresponding_authors": "",
    "abstract": "The major challenge in the task of entity alignment (EA) lies in the heterogeneity of the knowledge graph. The traditional solution to EA is to first map entities to the same space via knowledge embedding and then calculate the similarity between entities from different knowledge graphs. However, these methods mainly rely on manually labeled seeds of EA, which limits their applicability. Some researchers have begun using pseudo-labels rather than seeds for unsupervised EA. However, directly using pseudo-labels causes new problems, such as noise in the pseudo-labels. In this article, we propose a model called the Semantically Driven Hybrid Network (SDHN) to reduce the impact of noise in the pseudo-labels on the performance of EA models. The SDHN consists of two modules: a Teacher–Student Network (TSN) and a Rotation and Penalty (RAP) module. The TSN module reduces the impact of noise in two ways: (1) The TSN’s teacher network guides its student network to construct pseudo-labels based on semantic information instead of directly creating pseudo-labels. (2) It adaptively fuses semantic information into student networks to improve the final representation of entity embedding. Finally, the TSN enhances the performance of models of entity alignment via the RAP module. The results of experiments on multiple benchmark datasets showed that the SDHN outperforms state-of-the-art models.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4304693730",
    "type": "article"
  },
  {
    "title": "Bayesian Strategy Networks Based Soft Actor-Critic Learning",
    "doi": "https://doi.org/10.1145/3643862",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Qin Yang; Ramviyas Parasuraman",
    "corresponding_authors": "",
    "abstract": "A strategy refers to the rules that the agent chooses the available actions to achieve goals. Adopting reasonable strategies is challenging but crucial for an intelligent agent with limited resources working in hazardous, unstructured, and dynamic environments to improve the system’s utility, decrease the overall cost, and increase mission success probability. This article proposes a novel hierarchical strategy decomposition approach based on Bayesian chaining to separate an intricate policy into several simple sub-policies and organize their relationships as Bayesian strategy networks (BSN). We integrate this approach into the state-of-the-art DRL method—soft actor-critic (SAC), and build the corresponding Bayesian soft actor-critic (BSAC) model by organizing several sub-policies as a joint policy. Our method achieves the state-of-the-art performance on the standard continuous control benchmarks in the OpenAI Gym environment. The results demonstrate that the promising potential of the BSAC method significantly improves training efficiency. Furthermore, we extend the topic to the Multi-Agent systems (MAS), discussing the potential research fields and directions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391436304",
    "type": "article"
  },
  {
    "title": "FEIR: Quantifying and Reducing Envy and Inferiority for Fair Recommendation of Limited Resources",
    "doi": "https://doi.org/10.1145/3643891",
    "publication_date": "2024-02-03",
    "publication_year": 2024,
    "authors": "Nan Li; Bo Kang; Jefrey Lijffijt; Tijl De Bie",
    "corresponding_authors": "",
    "abstract": "Recommendation in settings such as e-recruitment and online dating involves distributing limited opportunities, which differs from recommending practically unlimited goods such as in e-commerce or music recommendation. This setting calls for novel approaches to quantify and enforce fairness. Indeed, typical recommender systems recommend each user their top relevant items, such that desirable items may be recommended simultaneously to more and to less qualified individuals. This is arguably unfair to the latter. Indeed, when they pursue such a desirable recommendation (e.g., by applying for a job), they are unlikely to be successful. To quantify fairness in such settings, we introduce inferiority : a novel (un)fairness measure that quantifies the competitive disadvantage of a user for their recommended items. Inferiority is complementary to envy : a previously-proposed fairness notion that quantifies the extent to which a user prefers other users’ recommendations over their own. We propose to use both inferiority and envy in combination with an accuracy-related measure called utility : the aggregated relevancy scores of the recommended items. Unfortunately, none of these three measures are differentiable, making it hard to optimize them, and restricting their immediate use to evaluation only. To remedy this, we reformulate them in the context of a probabilistic interpretation of recommender systems, resulting in differentiable versions. We show how these loss functions can be combined in a multi-objective optimization problem that we call FEIR (Fairness through Envy and Inferiority Reduction), used as a post-processing of the scores from any standard recommender system. Experiments on synthetic and real-world data show that the proposed approach effectively improves the trade-offs between inferiority, envy and utility, compared to the naive recommendation and the state-of-the-art method for the related problem of congestion alleviation in job recommendation. We discuss and enhance the practical impact of our findings on a wide range of real-world recommendation scenarios, and we offer implementations of visualization tools to render the envy and inferiority metrics more accessible.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391514801",
    "type": "article"
  },
  {
    "title": "Advancing Attribution-Based Neural Network Explainability through Relative Absolute Magnitude Layer-Wise Relevance Propagation and Multi-Component Evaluation",
    "doi": "https://doi.org/10.1145/3649458",
    "publication_date": "2024-02-26",
    "publication_year": 2024,
    "authors": "Davor Vukadin; Petar Afrić; Marin Šilić; Goran Delač",
    "corresponding_authors": "",
    "abstract": "Recent advancement in deep-neural network performance led to the development of new state-of-the-art approaches in numerous areas. However, the black-box nature of neural networks often prohibits their use in areas where model explainability and model transparency are crucial. Over the years, researchers proposed many algorithms to aid neural network understanding and provide additional information to the human expert. One of the most popular methods being Layer-Wise Relevance Propagation (LRP). This method assigns local relevance based on the pixel-wise decomposition of nonlinear classifiers. With the rise of attribution method research, there has emerged a pressing need to assess and evaluate their performance. Numerous metrics have been proposed, each assessing an individual property of attribution methods such as faithfulness, robustness or localization. Unfortunately, no single metric is deemed optimal for every case, and researchers often use several metrics to test the quality of the attribution maps. In this work, we address the shortcomings of the current LRP formulations and introduce a novel method for determining the relevance of input neurons through layer-wise relevance propagation. Furthermore, we apply this approach to the recently developed Vision Transformer architecture and evaluate its performance against existing methods on two image classification datasets, namely ImageNet and PascalVOC. Our results clearly demonstrate the advantage of our proposed method. Furthermore, we discuss the insufficiencies of current evaluation metrics for attribution-based explainability and propose a new evaluation metric that combines the notions of faithfulness, robustness and contrastiveness. We utilize this new metric to evaluate the performance of various attribution-based methods. Our code is available at: https://github.com/davor10105/relative-absolute-magnitude-propagation",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392157179",
    "type": "article"
  },
  {
    "title": "Break Out of a Pigeonhole: A Unified Framework for Examining Miscalibration, Bias, and Stereotype in Recommender Systems",
    "doi": "https://doi.org/10.1145/3650044",
    "publication_date": "2024-02-29",
    "publication_year": 2024,
    "authors": "Yongsu Ahn; Yu‐Ru Lin",
    "corresponding_authors": "",
    "abstract": "Despite the benefits of personalizing items and information tailored to users’ needs, it has been found that recommender systems tend to introduce biases that favor popular items or certain categories of items and dominant user groups. In this study, we aim to characterize the systematic errors of a recommendation system and how they manifest in various accountability issues, such as stereotypes, biases, and miscalibration. We propose a unified framework that distinguishes the sources of prediction errors into a set of key measures that quantify the various types of system-induced effects, at both the individual and collective levels. Based on our measuring framework, we examine the most widely adopted algorithms in the context of movie recommendation. Our research reveals three important findings: (1) Differences between algorithms: recommendations generated by simpler algorithms tend to be more stereotypical but less biased than those generated by more complex algorithms. (2) Disparate impact on groups and individuals: system-induced biases and stereotypes have a disproportionate effect on atypical users and minority groups (e.g., women and older users). (3) Mitigation opportunity: using structural equation modeling, we identify the interactions between user characteristics (typicality and diversity), system-induced effects, and miscalibration. We further investigate the possibility of mitigating system-induced effects by oversampling underrepresented groups and individuals, which was found to be effective in reducing stereotypes and improving recommendation quality. Our research is the first systematic examination of not only system-induced effects and miscalibration but also the stereotyping issue in recommender systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392295033",
    "type": "article"
  },
  {
    "title": "Tapestry of Time and Actions: Modeling Human Activity Sequences Using Temporal Point Process Flows",
    "doi": "https://doi.org/10.1145/3650045",
    "publication_date": "2024-02-29",
    "publication_year": 2024,
    "authors": "Vinayak Gupta; Srikanta Bedathur",
    "corresponding_authors": "",
    "abstract": "Human beings always engage in a vast range of activities and tasks that demonstrate their ability to adapt to different scenarios. These activities can range from the simplest daily routines, like walking and sitting, to multi-level complex endeavors such as cooking a four-course meal. Any human activity can be represented as a temporal sequence of actions performed to achieve a certain goal. Unlike the time series datasets extracted from electronics or machines, these action sequences are highly disparate in their nature—the time to finish a sequence of actions can vary between different persons. Therefore, understanding the dynamics of these sequences is essential for many downstream tasks such as activity length prediction, goal prediction, and next action recommendation. Existing neural network based approaches that learn a continuous-time activity sequence are limited to the presence of only visual data or are designed specifically for a particular task (i.e., limited to next action or goal prediction). In this article, we present ProActive , a neural marked temporal point process framework for modeling the continuous-time distribution of actions in an activity sequence while simultaneously addressing three high-impact problems: next action prediction, sequence goal prediction, and end-to-end sequence generation. Specifically, we utilize a self-attention module with temporal normalizing flows to model the influence and the inter-arrival times between actions in a sequence. Moreover, for time-sensitive prediction, we perform an early detection of sequence goal via a constrained margin-based optimization procedure. This in turn allows ProActive to predict the sequence goal using a limited number of actions. In addition, we propose a novel addition over the ProActive model, called ProActive++ , that can handle variations in the order of actions (i.e., different methods of achieving a given goal). We demonstrate that this variant can learn the order in which the person or actor prefers to do their actions. Extensive experiments on sequences derived from three activity recognition datasets show the significant accuracy boost of our ProActive and ProActive++ over the state of the art in terms of action and goal prediction, and the first-ever application of end-to-end action sequence generation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392295329",
    "type": "article"
  },
  {
    "title": "Learning Cross-modality Interaction for Robust Depth Perception of Autonomous Driving",
    "doi": "https://doi.org/10.1145/3650039",
    "publication_date": "2024-03-01",
    "publication_year": 2024,
    "authors": "Yunji Liang; Nengzhen Chen; Zhiwen Yu; Lei Tang; Hongkai Yu; Bin Guo; Daniel Zeng",
    "corresponding_authors": "",
    "abstract": "As one of the fundamental tasks of autonomous driving, depth perception aims to perceive physical objects in three dimensions and to judge their distances away from the ego vehicle. Although great efforts have been made for depth perception, LiDAR-based and camera-based solutions have limitations with low accuracy and poor robustness for noise input. With the integration of monocular cameras and LiDAR sensors in autonomous vehicles, in this article, we introduce a two-stream architecture to learn the modality interaction representation under the guidance of an image reconstruction task to compensate for the deficiencies of each modality in a parallel manner. Specifically, in the two-stream architecture, the multi-scale cross-modality interactions are preserved via a cascading interaction network under the guidance of the reconstruction task. Next, the shared representation of modality interaction is integrated to infer the dense depth map due to the complementarity and heterogeneity of the two modalities. We evaluated the proposed solution on the KITTI dataset and CALAR synthetic dataset. Our experimental results show that learning the coupled interaction of modalities under the guidance of an auxiliary task can lead to significant performance improvements. Furthermore, our approach is competitive against the state-of-the-art models and robust against the noisy input. The source code is available at https://github.com/tonyFengye/Code/tree/master .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392356810",
    "type": "article"
  },
  {
    "title": "Deconfounded Cross-modal Matching for Content-based Micro-video Background Music Recommendation",
    "doi": "https://doi.org/10.1145/3650042",
    "publication_date": "2024-03-06",
    "publication_year": 2024,
    "authors": "Jing Yi; Zhenzhong Chen",
    "corresponding_authors": "",
    "abstract": "Object-oriented micro-video background music recommendation is a complicated task where the matching degree between videos and background music is a major issue. However, music selections in user-generated content (UGC) are prone to selection bias caused by historical preferences of uploaders. Since historical preferences are not fully reliable and may reflect obsolete behaviors, over-reliance on them should be avoided as knowledge and interests dynamically evolve. In this article, we propose a Deconfounded Cross-Modal matching model to mitigate such bias. Specifically, uploaders’ personal preferences of music genres are identified as confounders that spuriously correlate music embeddings and background music selections, causing the learned system to over-recommend music from majority groups. To resolve such confounders, backdoor adjustment is utilized to deconfound the spurious correlation between music embeddings and prediction scores. We further utilize Monte Carlo estimator with batch-level average as the approximations to avoid integrating the entire confounder space calculated by the adjustment. Furthermore, we design a teacher–student network to utilize the matching of music videos, which is professionally generated content (PGC) with specialized matching, to better recommend content-matching background music. The PGC data are modeled by a teacher network to guide the matching of uploader-selected UGC data of student network by Kullback–Leibler–based knowledge transfer. Extensive experiments on the TT-150k-genre dataset demonstrate the effectiveness of the proposed method. The code is publicly available on https://github.com/jing-1/DecCM",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392517794",
    "type": "article"
  },
  {
    "title": "Perceiving Actions via Temporal Video Frame Pairs",
    "doi": "https://doi.org/10.1145/3652611",
    "publication_date": "2024-03-17",
    "publication_year": 2024,
    "authors": "Rongchang Li; Tianyang Xu; Xiao‐Jun Wu; Zhongwei Shen; Josef Kittler",
    "corresponding_authors": "",
    "abstract": "Video action recognition aims at classifying the action category in given videos. In general, semantic-relevant video frame pairs reflect significant action patterns such as object appearance variation and abstract temporal concepts like speed, rhythm, and so on. However, existing action recognition approaches tend to holistically extract spatiotemporal features. Though effective, there is still a risk of neglecting the crucial action features occurring across frames with a long-term temporal span. Motivated by this, in this article, we propose to perceive actions via frame pairs directly and devise a novel Nest Structure with frame pairs as basic units. Specifically, we decompose a video sequence into all possible frame pairs and hierarchically organize them according to temporal frequency and order, thus transforming the original video sequence into a Nest Structure. Through naturally decomposing actions, the proposed structure can flexibly adapt to diverse action variations such as speed or rhythm changes. Next, we devise a Temporal Pair Analysis module (TPA) to extract discriminative action patterns based on the proposed Nest Structure. The designed TPA module consists of a pair calculation part to calculate the pair features and a pair fusion part to hierarchically fuse the pair features for recognizing actions. The proposed TPA can be flexibly integrated into existing backbones, serving as a side branch to capture various action patterns from multi-level features. Extensive experiments show that the proposed TPA module can achieve consistent improvements over several typical backbones, reaching or updating CNN-based SOTA results on several challenging action recognition benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392894950",
    "type": "article"
  },
  {
    "title": "Empowering Predictive Modeling by GAN-based Causal Information Learning",
    "doi": "https://doi.org/10.1145/3652610",
    "publication_date": "2024-03-20",
    "publication_year": 2024,
    "authors": "Jinwei Zeng; Guozhen Zhang; Jian Yuan; Yong Li; Depeng Jin",
    "corresponding_authors": "",
    "abstract": "Generally speaking, we can easily specify many causal relationships in the prediction tasks of ubiquitous computing, such as human activity prediction, mobility prediction, and health prediction. However, most of the existing methods in these fields failed to take advantage of this prior causal knowledge. They typically make predictions only based on correlations in the data, which hinders the prediction performance in real-world scenarios, because a distribution shift between training data and testing data generally exists. To fill in this gap, we proposed a Generative Adversarial Network (GAN)-based Causal Information Learning prediction framework, which can effectively leverage causal information to improve the prediction performance of existing ubiquitous computing deep learning models. Specifically, faced with a unique challenge that the treatment variable, referring to the intervention that influences the target in a causal relationship, is generally continuous in ubiquitous computing, the framework employs a representation learning approach with a GAN-based deep learning model. By projecting all variables except the treatment into a latent space, it effectively minimizes confounding bias and leverages the learned latent representation for accurate predictions. In this way, it deals with the continuous treatment challenge, and in the meantime, it can be easily integrated with existing deep learning models to lift their prediction performance in practical scenarios with causal information. Extensive experiments on two large-scale real-world datasets demonstrate its superior performance over multiple state-of-the-art baselines. We also propose an analytical framework together with extensive experiments to empirically show that our framework achieves better performance gain under two conditions: when the distribution differences between the training data and the testing data are more significant and when the treatment effects are larger. Overall, this work suggests that learning causal information is a promising way to improve the prediction performance of ubiquitous computing tasks. We open both our dataset and code 1 and call for more research attention in this area.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393002646",
    "type": "article"
  },
  {
    "title": "Quintuple-based Representation Learning for Bipartite Heterogeneous Networks",
    "doi": "https://doi.org/10.1145/3653978",
    "publication_date": "2024-03-26",
    "publication_year": 2024,
    "authors": "Cangqi Zhou; Hui Chen; Jing Zhang; Qianmu Li; Dianming Hu",
    "corresponding_authors": "",
    "abstract": "Recent years have seen rapid progress in network representation learning, which removes the need for burdensome feature engineering and facilitates downstream network-based tasks. In reality, networks often exhibit heterogeneity, which means there may exist multiple types of nodes and interactions. Heterogeneous networks raise new challenges to representation learning, as the awareness of node and edge types is required. In this article, we study a basic building block of general heterogeneous networks, the heterogeneous networks with two types of nodes. Many problems can be solved by decomposing general heterogeneous networks into multiple bipartite ones. Recently, to overcome the demerits of non-metric measures used in the embedding space, metric learning-based approaches have been leveraged to tackle heterogeneous network representation learning. These approaches first generate triplets of samples, in which an anchor node, a positive counterpart, and a negative one co-exist, and then try to pull closer positive samples and push away negative ones. However, when dealing with heterogeneous networks, even the simplest two-typed ones, triplets cannot simultaneously involve both positive and negative samples from different parts of networks. To address this incompatibility of triplet-based metric learning, in this article, we propose a novel quintuple-based method for learning node representations in bipartite heterogeneous networks. Specifically, we generate quintuples that contain positive and negative samples from two different parts of networks. And we formulate two learning objectives that accommodate quintuple-based learning samples, a proximity-based loss that models the relations in quintuples by sigmoid probabilities and an angular loss that more robustly maintains similarity structures. In addition, we also parameterize feature learning by using one-dimensional convolution operators around nodes’ neighborhoods. Compared with eight methods, extensive experiments on two downstream tasks manifest the effectiveness of our approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393183640",
    "type": "article"
  },
  {
    "title": "Explainable finite mixture of mixtures of bounded asymmetric generalized Gaussian and Uniform distributions learning for energy demand management",
    "doi": "https://doi.org/10.1145/3653980",
    "publication_date": "2024-03-26",
    "publication_year": 2024,
    "authors": "Hussein Al–Bazzaz; Muhammad Azam; Manar Amayri; Nizar Bouguila",
    "corresponding_authors": "",
    "abstract": "We introduce a mixture of mixtures of bounded asymmetric generalized Gaussian and uniform distributions. Based on this framework, we propose model-based classification and model-based clustering algorithms. We develop an objective function for the minimum message length (MML) model selection criterion to discover the optimal number of clusters for the unsupervised approach of our proposed model. Given the crucial attention received by Explainable AI (XAI) in recent years, we introduce a method to interpret the predictions obtained from the proposed model in both learning settings by defining their boundaries in terms of the crucial features. Integrating Explainability within our proposed algorithm increases the credibility of the algorithm’s predictions since it would be explainable to the user’s perspective through simple If-Then statements using a small binary decision tree. In this paper, the proposed algorithm proves its reliability and superiority to several state-of-the-art machine learning algorithms within the following real-world applications: fault detection and diagnosis (FDD) in chillers, occupancy estimation and categorization of residential energy consumers.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393191404",
    "type": "article"
  },
  {
    "title": "DIRECT: Dual Interpretable Recommendation with Multi-aspect Word Attribution",
    "doi": "https://doi.org/10.1145/3663483",
    "publication_date": "2024-05-06",
    "publication_year": 2024,
    "authors": "Xuansheng Wu; Hanqin Wan; Qiaoyu Tan; Wenlin Yao; Ninghao Liu",
    "corresponding_authors": "",
    "abstract": "Recommending products to users with intuitive explanations helps improve the system in transparency, persuasiveness, and satisfaction. Existing interpretation techniques include post hoc methods and interpretable modeling. The former category could quantitatively analyze input contribution to model prediction but has limited interpretation faithfulness, while the latter could explain model internal mechanisms but may not directly attribute model predictions to input features. In this study, we propose a novel Dual Interpretable Recommendation model called DIRECT, which integrates ideas of the two interpretation categories to inherit their advantages and avoid limitations. Specifically, DIRECT makes use of item descriptions as explainable evidence for recommendation. First, similar to the post hoc interpretation, DIRECT could attribute the prediction of a user preference score to textual words of the item descriptions. The attribution of each word is related to its sentiment polarity and word importance, where a word is important if it corresponds to an item aspect that the user is interested in. Second, to improve the interpretability of embedding space, we propose to extract high-level concepts from embeddings, where each concept corresponds to an item aspect. To learn discriminative concepts, we employ a concept bottleneck layer and maximize the coding rate reduction on word-aspect embeddings by leveraging a word–word affinity graph extracted from a pre-trained language model. In this way, DIRECT simultaneously achieves faithful attribution and usable interpretation of embedding space. We also show that DIRECT achieves linear inference time complexity regarding the length of item reviews. We conduct experiments including ablation studies on five real-world datasets. Quantitative analysis, visualizations, and case studies verify the interpretability of DIRECT. Our code is available at: https://github.com/JacksonWuxs/DIRECT .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4396669082",
    "type": "article"
  },
  {
    "title": "Incremental Data Drifting: Evaluation Metrics, Data Generation, and Approach Comparison",
    "doi": "https://doi.org/10.1145/3655630",
    "publication_date": "2024-05-24",
    "publication_year": 2024,
    "authors": "Yu-Tung Pai; Nien-En Sun; Cheng–Te Li; Shou-De Lin",
    "corresponding_authors": "",
    "abstract": "Incremental data drifting is a common problem when employing a machine-learning model in industrial applications. The underlying data distribution evolves gradually, e.g., users change their buying preferences on an E-commerce website over time. The problem needs to be addressed to obtain high performance. Right now, studies regarding incremental data drifting suffer from several issues. For one thing, there is a lack of clear-defined incremental drift datasets for examination. Existing efforts use either collected real datasets or synthetic datasets that show two obvious limitations. One is in particular when and of which type of drifts the distribution undergoes is unknown, and the other is that a simple synthesized dataset cannot reflect the complex representation we would normally face in the real world. For another, there lacks a well-defined protocol to evaluate a learner’s knowledge transfer capability on an incremental drift dataset. To provide a holistic discussion on these issues, we create approaches to generate datasets with specific drift types, and define a novel protocol for evaluation. Besides, we investigate recent advances in the transfer learning field, including Domain Adaptation and Lifelong Learning, and examine how they perform in the presence of incremental data drifting. The results unfold the relationships among drift types, knowledge preservation, and learning approaches.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4398779458",
    "type": "article"
  },
  {
    "title": "Misinformation Resilient Search Rankings with Webgraph-Based Interventions",
    "doi": "https://doi.org/10.1145/3670410",
    "publication_date": "2024-06-06",
    "publication_year": 2024,
    "authors": "Peter Carragher; Evan M. Williams; Kathleen M. Carley",
    "corresponding_authors": "",
    "abstract": "The proliferation of unreliable news domains on the internet has had wide-reaching negative impacts on society. We introduce and evaluate interventions aimed at reducing traffic to unreliable news domains from search engines while maintaining traffic to reliable domains. We build these interventions on the principles of fairness (penalize sites for what is in their control), generality (label/fact-check agnostic), targeted (increase the cost of adversarial behavior), and scalability (works at webscale). We refine our methods on small-scale webdata as a testbed and then generalize the interventions to a large-scale webgraph containing 93.9M domains and 1.6B edges. We demonstrate that our methods penalize unreliable domains far more than reliable domains in both settings and we explore multiple avenues to mitigate unintended effects on both the small-scale and large-scale webgraph experiments. These results indicate the potential of our approach to reduce the spread of misinformation and foster a more reliable online information ecosystem. This research contributes to the development of targeted strategies to enhance the trustworthiness and quality of search engine results, ultimately benefiting users, and the broader digital community.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399387475",
    "type": "article"
  },
  {
    "title": "Libby-Novick Beta-Liouville Distribution for Enhanced Anomaly Detection in Proportional Data",
    "doi": "https://doi.org/10.1145/3675405",
    "publication_date": "2024-06-29",
    "publication_year": 2024,
    "authors": "Oussama Sghaier; Manar Amayri; Nizar Bouguila",
    "corresponding_authors": "",
    "abstract": "We consider the problem of anomaly detection in proportional data by investigating the Libby-Novick Beta-Liouville distribution, a novel distribution merging the salient characteristics of Liouville and Libby-Novick Beta distributions. Its main benefit, compared to the typical distributions dedicated to proportional data such as Dirichlet and Beta-Liouville, is its adaptability and explanatory power when dealing with this kind of data. Our goal is to exploit this appropriateness for modeling proportional data to achieve great performance in the anomaly detection task. First, we develop generative models, namely finite mixture models of Libby-Novick Beta-Liouville distributions. Then, we propose two discriminative techniques: Normality scores based on selecting the given distribution to approximate the softmax output vector of a deep classifier and an improved version of Support Vector Machine (SVM) by suggesting a feature mapping approach. We demonstrate the benefits of the presented approaches through a variety of experiments on both image and non-image datasets. The results demonstrate that the proposed anomaly detectors based on the Libby-Novick Beta-Liouville distribution outperform the classical distributions as well as the baseline techniques.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400146946",
    "type": "article"
  },
  {
    "title": "M2SKD: Multi-to-Single Knowledge Distillation of Real-Time Epileptic Seizure Detection for Low-Power Wearable Systems",
    "doi": "https://doi.org/10.1145/3675402",
    "publication_date": "2024-07-04",
    "publication_year": 2024,
    "authors": "Saleh Baghersalimi; Alireza Amirshahi; Farnaz Forooghifar; Tomás Teijeiro; Amir Aminifar; David Atienza",
    "corresponding_authors": "",
    "abstract": "Integrating low-power wearable systems into routine health monitoring is an ongoing challenge. Recent advances in the computation capabilities of wearables make it possible to target complex scenarios by exploiting multiple biosignals and using high-performance algorithms, such as Deep Neural Networks (DNNs). However, there is a tradeoff between the algorithms’ performance and the low-power requirements of platforms with limited resources. Besides, physically larger and multi-biosignal-based wearables bring significant discomfort to the patients. Consequently, reducing power consumption and discomfort is necessary for patients to use wearable devices continuously during everyday life. To overcome these challenges, in the context of epileptic seizure detection, we propose the Multi-to-Single Knowledge Distillation (M2SKD) approach targeting single-biosignal processing in wearable systems. The starting point is to train a highly-accurate multi-biosignal DNN, then apply M2SKD to develop a single-biosignal DNN solution for wearable systems that achieves an accuracy comparable to the original multi-biosignal DNN. To assess the practicality of our approach to real-life scenarios, we perform a comprehensive simulation experiment analysis on several edge computing platforms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400320671",
    "type": "article"
  },
  {
    "title": "DeepSneak: User GPS Trajectory Reconstruction from Federated Route Recommendation Models",
    "doi": "https://doi.org/10.1145/3670412",
    "publication_date": "2024-07-22",
    "publication_year": 2024,
    "authors": "Thirasara Ariyarathna; Meisam Mohommady; Hye-Young Paik; Salil S. Kanhere",
    "corresponding_authors": "",
    "abstract": "Decentralized machine learning, such as Federated Learning (FL), is widely adopted in many application domains. Especially in domains like recommendation systems, sharing gradients instead of private data has recently caught the research community’s attention. Personalized travel route recommendation utilizes users’ location data to recommend optimal travel routes. Location data is extremely privacy sensitive, presenting increased risks of exposing behavioural patterns and demographic attributes. FL for route recommendation can mitigate the sharing of location data. However, this paper shows that an adversary can recover the user trajectories used to train the federated recommendation models with high proximity accuracy. To this effect, we propose a novel attack called DeepSneak, which uses shared gradients obtained from global model training in FL to reconstruct private user trajectories. We formulate the attack as a regression problem and train a generative model by minimizing the distance between gradients. We validate the success of DeepSneak on two real-world trajectory datasets. The results show that we can recover the location trajectories of users with reasonable spatial and semantic accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400879975",
    "type": "article"
  },
  {
    "title": "Intermediary-Generated Bridge Network for RGB-D Cross-modal Re-identification",
    "doi": "https://doi.org/10.1145/3682066",
    "publication_date": "2024-07-29",
    "publication_year": 2024,
    "authors": "Jingjing Wu; Richang Hong; Shengeng Tang",
    "corresponding_authors": "",
    "abstract": "RGB-D cross-modal person re-identification (re-id) targets at retrieving the person of interest across RGB and depth image modalities. To cope with the modal discrepancy, some existing methods generate an auxiliary mode with either inherent properties of input modes or extra deep networks. However, such useful intermediary role included in generated mode is often overlooked in these approaches, leading to insufficient exploitation of crucial bridge knowledge. By contrast, in this article, we propose a novel approach that constructs an intermediary mode through the constraints of self-supervised intermediary learning, which is freedom from modal prior knowledge and additional module parameters. We then design a bridge network to fully mine the intermediary role of generated modality through carrying out multi-modal integration and decomposition. For one thing, this network leverages a multi-modal transformer to integrate the information of three modes via fully exploiting their heterogeneous relations with the intermediary mode as the bridge. It conducts the identification consistency constraint to promote cross-modal associations. For another, it employs circle contrastive learning to decompose the cross-modal constraint process into several subprocedures, which provides the intermediate relay during pulling two original modalities closer. Experiments on two public datasets demonstrate that the proposed method exceeds the state-of-the-arts. The effectiveness of each component in this method is verified through numerous ablation studies. Additionally, we have demonstrated the generalization ability of the proposed method through experiments.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401079043",
    "type": "article"
  },
  {
    "title": "Relation Constrained Capsule Graph Neural Networks for Non-Rigid Shape Correspondence",
    "doi": "https://doi.org/10.1145/3688851",
    "publication_date": "2024-08-16",
    "publication_year": 2024,
    "authors": "Yuanfeng Lian; Shoushuang Pei; MengFei Chen; Jing Hua",
    "corresponding_authors": "",
    "abstract": "Non-rigid 3D shape correspondence aims to establish dense correspondences between two non-rigidly deformed 3D shapes. However, the variability and symmetry of non-rigid shapes usually lead to mismatches due to shape deformation, topological changes, or data with severe noise. To finding an accurate correspondence between 3D dynamic shapes for the local deformation complexity, this article proposes a Relation Constrained Capsule Graph Network (RC-CGNet), which combines global and local features by encouraging the relation constraints between the embedding feature space and the input shape space based on the functional maps framework. Specifically, we design a Diffusion Graph Attention Network (DGANet) to segment the surface into parts with correct edge boundary between two regions. The Minimum Spanning Tree (MST) of geodesic curves among the singularities obtained from the segmented parts is added as relation constraints, which can compute isometric correspondences in both direct and symmetric directions. Besides that, the relation-and-attention constrained neural networks are designed to learn the shape correspondence via attention-aware CapsNet and functional maps under relation constraints. To improve the convergence speed and matching accuracy, we propose an optimized residual network structure based on the Nesterov Accelerated Gradient (NAG) to extract local features, and use graph convolution structure to extract global features. Moreover, a lightweight Gated Attention Module (GAM) is designed to fuse global and local features to obtain a richer feature representation. Since the capsule network has better spatial reasoning ability than the traditional convolutional neural network, our novel network architecture is a dual-route capsule network based on Routing Attention Fusion Block (RAFB), filtering low-discriminative capsules from a holistic view by exploiting geometric hierarchical relationships of semantic parts. Experiments on open datasets show that our method has excellent accuracy and wide adaptability.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401634339",
    "type": "article"
  },
  {
    "title": "Adapting to My User, Engaging with My Robot: An Adaptive Affective Architecture for a Social Assistive Robot",
    "doi": "https://doi.org/10.1145/3691348",
    "publication_date": "2024-08-31",
    "publication_year": 2024,
    "authors": "Marcos Maroto‐Gómez; Matthew Lewis; Álvaro Castro‐González; María Malfáz; Miguel Á. Salichs; Lola Cañamero",
    "corresponding_authors": "",
    "abstract": "Affective feedback from social robots is a useful technique for communicating to people whether they are interacting “well” with the robot or not. However, some users, such as people with physical or cognitive difficulties, may not be able to interact in all the desired ways. In these cases, affective feedback from the robot could be excessively negative—an “unhappy” robot, leading to an unrewarding experience for the user. This paper presents a motivation-based architecture for an autonomous multimodal social robot, that incorporates an affective feedback mechanism which generates an affective state by combining the internal needs of the robot and the social interaction quality. The balance between these two factors can dynamically change, allowing the robot to adapt its affective feedback to the user’s interaction style and capabilities. We have implemented this architecture in a simulation and in a MiRo social robot, and report experiments examining the behavior of the system in interactions with different experimental user profiles. The results show that the adaptive mechanism allows the robot to change its affective feedback to give more positive encouragement to users than in non-adaptive cases.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402088472",
    "type": "article"
  },
  {
    "title": "FastRx: Exploring Fastformer and Memory-Augmented Graph Neural Networks for Personalized Medication Recommendations",
    "doi": "https://doi.org/10.1145/3696111",
    "publication_date": "2024-09-17",
    "publication_year": 2024,
    "authors": "Tai Tan Phan; Ling Chen; Chun-Hung Chen; Wen-Chih Peng",
    "corresponding_authors": "",
    "abstract": "Personalized medication recommendations aim to suggest a set of medications based on the clinical conditions of a patient. Not only should the patient's diagnosis, procedure, and medication history be considered, but drug-drug interactions (DDIs) must also be taken into account to prevent adverse drug reactions. Although recent studies on medication recommendation have considered DDIs and patient history, personalized disease progression and prescription have not been explicitly modeled. In this work, we proposed FastRx, a Fastformer-based medication recommendation model to capture longitudinality in patient history, in combination with Graph Convolutional Networks (GCNs) to handle DDIs and co-prescribed medications in Electronic Health Records (EHRs). Our extensive experiments on the MIMIC-III dataset demonstrated superior performance of the proposed FastRx over existing state-of-the-art models for medication recommendation. The source code and data used in the experiments are available at https://github.com/pnmthaoct/FastRx .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402576122",
    "type": "article"
  },
  {
    "title": "<i>Few Images, Many Insights</i> : Illicit Content Detection Using a Limited Number of Images",
    "doi": "https://doi.org/10.1145/3696458",
    "publication_date": "2024-09-20",
    "publication_year": 2024,
    "authors": "Giuseppe Cascavilla; Gemma Catolino; Mauro Conti; Dimos Mellios; Damian A. Tamburri",
    "corresponding_authors": "",
    "abstract": "The anonymity and untraceability benefits of the dark web increased its popularity exponentially. The cost of these technical benefits is that such anonymity has created a suitable womb for illicit activity. Hence—in collaboration with cybersecurity practitioners and law-enforcement agencies—the research community provided approaches for recognizing and classifying illicit activities. Most of these approaches exploit textual content from dark web markets, whereas few used images that originated from them. This paper investigates alternative techniques for recognizing illegal activities from images. The significant contributions of our work are threefold: (a) we investigate label-agnostic learning techniques like One-Shot and Few-Shot learning that use Siamese Neural Networks (SNNs). Our approach manages to handle small-scale datasets with promising accuracy. In particular, the Siamese neural network approach reaches 90.9% on 5-Shot experiments over a 10-class dataset. (b) this study's satisfactory findings facilitate the creation of potent tools to assist authorities in identifying illicit content on the web. Moreover, our proof-of-concept approach demonstrated the ability to recognize illegal images using a limited number of files, reducing the time constraint in collecting illegal images. (c) we provide a complete labelled dataset of 3570 images from 55 different categories from dark web markets that can be used for future research activities.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402675464",
    "type": "article"
  },
  {
    "title": "GCFExplainer: Global Counterfactual Explainer for Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3698108",
    "publication_date": "2024-10-01",
    "publication_year": 2024,
    "authors": "Mert Kosan; Zexi Huang; Sourav Medya; Sayan Ranu; Ambuj K. Singh",
    "corresponding_authors": "",
    "abstract": "Graph neural networks (GNNs) find applications in various domains such as computational biology, natural language processing, and computer security. Owing to their popularity, there is an increasing need to explain GNN predictions since GNNs are black-box machine learning models. One way to address this issue involves using counterfactual reasoning where the objective is to alter the GNN prediction by minimal changes in the input graph. Existing methods for counterfactual explanation of GNNs are limited to instance-specific local reasoning. This approach has two major limitations of not being able to offer global recourse policies and overloading human cognitive ability with too much information. In this work, we study the global explainability of GNNs through global counterfactual reasoning. Specifically, we want to find a small set of representative counterfactual graphs that explains all input graphs. Towards this goal, we propose GCF Explainer , a novel algorithm powered by vertex-reinforced random walks on an edit map of graphs with a greedy summary . Extensive experiments on real graph datasets show that the global explanation from GCF Explainer provides important high-level insights of the model behavior and achieves a 46.9% gain in recourse coverage, a 9.5% reduction in recourse cost compared to the state-of-the-art local counterfactual explainers. We also demonstrate that GCF Explainer generates explanations that are more consistent with input dataset characteristics, and is robust under adversarial attacks. In addition, K-GCF Explainer , which incorporates a graph clustering component into GCF Explainer , is introduced as a more competitive extension for datasets with a clustering structure, leading to superior performance in three out of four datasets in the experiments and better scalability.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403040555",
    "type": "article"
  },
  {
    "title": "Empirical and Experimental Insights into Data Mining Techniques for Crime Prediction: A Comprehensive Survey",
    "doi": "https://doi.org/10.1145/3699515",
    "publication_date": "2024-10-07",
    "publication_year": 2024,
    "authors": "Kamal Taha",
    "corresponding_authors": "Kamal Taha",
    "abstract": "This survey paper presents a comprehensive analysis of crime prediction methodologies, exploring the various techniques and technologies utilized in this area. The paper covers the statistical methods, machine learning algorithms, and deep learning techniques employed to analyze crime data, while also examining their effectiveness and limitations. We propose a methodological taxonomy that classifies crime prediction algorithms into specific techniques. This taxonomy is structured into four tiers, including methodology category, methodology sub-category, methodology techniques, and methodology sub-techniques. Empirical and experimental evaluations are provided to rank the different techniques. The empirical evaluation assesses the crime prediction techniques based on three criteria, while the experimental evaluation ranks the algorithms that employ the same sub-technique, the different sub-techniques that employ the same technique, the different techniques that employ the same methodology sub-category, the different methodology sub-categories within the same category, and the different methodology categories. The combination of methodological taxonomy, empirical evaluations, and experimental comparisons allows for a nuanced and comprehensive understanding of crime prediction algorithms, aiding researchers in making informed decisions. Finally, the paper provides a glimpse into the future of crime prediction techniques, highlighting potential advancements and opportunities for further research in this field.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403184906",
    "type": "article"
  },
  {
    "title": "Advancing Session-Based Recommendations with Atten-Mixer+: Dynamic and Adaptive Multi-Level Intent Mining",
    "doi": "https://doi.org/10.1145/3700445",
    "publication_date": "2024-10-16",
    "publication_year": 2024,
    "authors": "Peiyan Zhang; Jiayan Guo; Chaozhuo Li; Liying Kang; Jae Boum Kim; Jie Xu; Xi Zhang; Yan Zhang; Haohan Wang; Sung Hun Kim",
    "corresponding_authors": "",
    "abstract": "Session-based recommendation (SBR) systems, traditionally reliant on complex graph neural networks (GNNs), often face challenges with marginal performance improvements despite increased model complexity. In this paper, we dissect the classical GNN-based SBR models and empirically find that the sophisticated GNN propagations might be redundant, given the readout module plays a significant role in GNN-based models. Based on this observation, we introduce Atten-Mixer+, an advanced iteration of our previously developed Multi-Level Attention Mixture Network (Atten-Mixer). Atten-Mixer+ forgoes GNN propagation in favor of a dynamic and adaptive readout process, tailored to the unique characteristics of each session. Different from the vanilla version, Atten-Mixer+ features the Adaptive Intent Scaler (AIS) layer, which dynamically determines the depth of multi-level user intent analysis, and a soft allocation approach for generating user intent queries across entire user interaction sequences. This innovative design allows Atten-Mixer+ to capture a nuanced and comprehensive understanding of user behaviors, overcoming the limitations of fixed-length analysis. Empirical evaluations on benchmark datasets highlight Atten-Mixer+'s superior efficiency and effectiveness, marking a significant step forward in the predictive accuracy of session-based recommendation systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403452582",
    "type": "article"
  },
  {
    "title": "AVENUE: <b>A</b> novel deep fake detection method based on temporal convolution network &amp; rPPG information",
    "doi": "https://doi.org/10.1145/3702232",
    "publication_date": "2024-10-28",
    "publication_year": 2024,
    "authors": "Lokendra Birla; Trishna Saikia; Puneet Gupta",
    "corresponding_authors": "",
    "abstract": "In Deep Learning (DL), an adversary creates Deepfakes by manipulating facial features to fool someone. The Deepfakes pose a security threat to anyone's privacy and a primary concern for our society. It can be detected by utilizing the texture and physiological properties of the face, like eye and lip movements; however, such methods are incompetent when Deepfakes are created using recent generative adversarial networks (GAN). Alternatively, remote Photoplethysmography (rPPG) information can be used for Deepfake detection because GANs neglect human physiological information for Deepfake generation. Such detection can be inaccurate when rPPG signals are affected by the noises induced by facial deformation and illumination variations. Furthermore, the exiting Deepfake detections are usually performed using sequential models, and such models fail to process the long sequence of temporal information. These issues are mitigated by our proposed method AVENUE , that is, \\(A\\) no \\(V\\) el d \\(E\\) epfake detectio \\(N\\) method based on temporal convol \\(U\\) tion n \\(E\\) twork &amp; rPPG information. For mitigating the noise issues in the rPPG signals, the proposed method detects and employs relatively stable clips of the input video for Deepfake detection. The stable clips are those clips that are least affected by facial deformations. Also, we use a modified Temporal convolution network to model the long sequence of Deepfake information rather than the sequential architectures. We performed the experimental result on publically available datasets of Deepfake videos. It demonstrates that our proposed method performs better than the existing rPPG-based Deepfake detection methods.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403828367",
    "type": "article"
  },
  {
    "title": "How do Large Language Models understand Genes and Cells",
    "doi": "https://doi.org/10.1145/3702234",
    "publication_date": "2024-10-29",
    "publication_year": 2024,
    "authors": "Chen Fang; Yidong Wang; Yunze Song; Qingqing Long; Lu Wang; Ling-Hui Chen; Guihai Feng; Yuanchun Zhou; Xin Li",
    "corresponding_authors": "",
    "abstract": "Researching genes and their interactions is crucial for deciphering the fundamental laws of cellular activity, advancing disease treatment, drug discovery, and more. Large language Models (LLMs), with their profound text comprehension and generation capabilities, have made significant strides across various natural science fields. However, their application in cell biology remains limited and a systematic evaluation of their performance is lacking. To address this gap, in this paper, we select seven mainstream LLMs and evaluate their performance across nine gene-related problem scenarios. Our findings indicate that LLMs possess a certain level of understanding of genes and cells, but still lag behind domain-specific models in comprehending transcriptional expression profiles. Moreover, we have improved the current method of textual representation of cells, enhancing the LLMs’ ability to tackle cell annotation tasks. We encourage cell biology researchers to leverage LLMs for problem-solving while being mindful of the associated challenges. We release our code and data at https://github.com/epang-ucas/Evaluate_LLMs_to_Genes .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403862485",
    "type": "article"
  },
  {
    "title": "Analysing the Predictability of Language Model Performance",
    "doi": "https://doi.org/10.1145/3706118",
    "publication_date": "2024-11-28",
    "publication_year": 2024,
    "authors": "Wout Schellaert; Fernando Martínez‐Plumed; José Hernández‐Orallo",
    "corresponding_authors": "",
    "abstract": "Can a language model predict for which questions another language model will answer successfully? We investigate the extent to which performance prediction is possible and dissect various factors that influence it. Our experimental setting fine-tunes DeBERTa models, which we call assessors , on the evaluation results of generative language models with up to 128 billion parameters, which we refer to as subject systems . Our analysis spans more than 100 tasks from BIG-bench. We find that the assessors can match and even exceed the subjects’ confidence in both refinement and calibration, anticipating failures at near perfect levels for some tasks. We also find that for performance prediction it can be beneficial to learn from the scores on multiple tasks or to learn from the scores of multiple subjects, but both depend on the task at hand. Lastly, we find that large and small subject systems are equally predictable, showing promise for the scalability of the predictability problem.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404817104",
    "type": "article"
  },
  {
    "title": "Unsupervised Outlier Detection with Reinforced Noise Discriminator",
    "doi": "https://doi.org/10.1145/3706117",
    "publication_date": "2024-12-02",
    "publication_year": 2024,
    "authors": "Zhengyou Zhang; Daoheng Liu; Jinwei Zhu; Youxi Wu",
    "corresponding_authors": "",
    "abstract": "Outlier detection is one of the hot topics in the field of machine learning and data mining. At present, there are many kinds of outlier detection algorithms. The accuracies of traditional outlier detection algorithms are often affected by unique parameters, and an increase in the amount of data and the dimensions of the data can seriously affect their efficiency and effectiveness. Methods based on generative adversarial networks (GANs) can solve the above problems, but they are unacceptable since the model often collapses during the training period. In this paper, to solve the problems of curse of dimensionality and model collapse, we propose a novel reinforced noise discriminator (RND) method for unsupervised outlier detection in tabular data. We consider outlier detection as a binary classification problem. Thus, we apply a learnable reinforced discriminator and generate a large number of potential outliers with a uniform distribution and potential outliers that are close to the original data that are used as a negative sample to train the discriminator, which learns the distribution of the original data to detect outliers. We empirically compare the proposed approach with ten state-of-the-art outlier detection methods on both synthetic and real-world tabular datasets. The experimental results show that RND outperforms its competitors in the majority of cases. The codes used to perform the experiments described in this paper are available at https://github.com/urlhearts/r-n-d .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404921508",
    "type": "article"
  },
  {
    "title": "Model-Free Deep Reinforcement Learning for Adaptive Supply Temperature Control in Collective Space Heating Systems",
    "doi": "https://doi.org/10.1145/3709010",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Sara Ghane; Stef Jacobs; Thomas Huybrechts; Peter Hellinckx; Siegfried Mercelis; Ivan Verhaert; Erik Mannens",
    "corresponding_authors": "",
    "abstract": "The conventional approach for controlling the supply temperature in collective space heating networks relies on a predefined heating curve determined by outdoor temperature and heat emitter type. This prioritizes thermal comfort but lacks energetic and financial optimization. This research proposes an adaptive supply temperature control in well-insulated dwellings, responsive to diverse environmental parameters. The approach considers variable electricity prices and accommodates different indoor temperature set points in dwellings. The study evaluates the effectiveness of two Deep Reinforcement Learning (DRL) algorithms, i.e. Proximal Policy Optimization (PPO) and Deep Q-Network (DQN), across various scenarios. Results reveal that DQN excels in collective space heating systems with underfloor heating in each dwelling, while PPO proves superior for radiator-based systems. Both outperform the traditional heating curve, achieving up to 13.77% (DQN) and 16.15% (PPO) cost reduction while guaranteeing thermal comfort. Additionally, the research highlights the capability of DRL-based methods to dynamically set the supply temperature based on a cloud of set points, showcasing adaptability to diverse environmental factors and addressing the growing significance of indoor heat gains in well-insulated dwellings. This innovative approach holds promise for more efficient and environmentally conscious heating strategies within collective space heating networks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405566638",
    "type": "article"
  },
  {
    "title": "Predicting the occurrence of respiratory diseases based on campus indoor air quality",
    "doi": "https://doi.org/10.1145/3709008",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Pei-En Li; Yao-Hua Ho",
    "corresponding_authors": "",
    "abstract": "Air quality is known to be strongly correlated with respiratory diseases. Indoor air quality considerably affects human health, especially in spaces such as classrooms, where students gather and interact for long periods. Most schools are located in relatively old buildings, where suitable ventilation systems are difficult to implement. The consequent lack of a standard ventilation rate increases the risk of cluster infections in classrooms. Accordingly, this paper proposes a classroom respiratory disease occurrence prediction method based on indoor air-quality data (CROP–IAQ). Early warnings provided by CROP–IAQ will enable authorities to implement measures such as ventilation and isolation that reduce the risk of cluster infections in school campuses. Data on indoor temperature, relative humidity, particulate matter (PM) concentrations (PM1.0, PM2.5, and PM10, referring to the concentrations of particles with diameters of \\(\\leq 1\\) , \\(\\leq 2.5\\) , and \\(\\leq 10\\) micrometer, respectively), carbon dioxide concentration, total volatile organic compound concentration, and luminosity in classrooms were collected using a MAPS V6.0 airbox. The air-quality data corresponding to potential cluster infections were identified from the aforementioned data and records of student epidemic prevention leaves in each class. Because most of the collected air-quality data did not correspond to potential cluster infections (that is, the dataset was imbalanced), synthetic data samples were generated using a synthetic minority oversampling technique. Four neural network models were constructed for predicting the possibility of disease occurrence and alerting authorities to classrooms at the risk of cluster infections: a convolutional neural network model, the inception model, a residual network model, and a residual network with external transformations model. The predictive capabilities of these models were only slightly improved after implementing a squeeze-and-excitation (SE) module. Experimental results indicated that the inception model with the SE module achieved the best results among the four models, with an F1 score and sensitivity of 0.72 and 0.76, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405566646",
    "type": "article"
  },
  {
    "title": "From Representation to Response: Assessing the Alignment of Large Language Models with Human Judgment Patterns",
    "doi": "https://doi.org/10.1145/3709148",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Anastasiia Hrytsyna; Rodrigo Alves",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs) are sophisticated artificial intelligence systems designed to process and understand natural language at a complex level. The recent progress of these models, culminating in chat-based LLMs, has democratized the accessibility of these sophisticated intelligent systems, showcasing how machine learning methods can help humans in daily tasks. This research addresses the growing interest in understanding the mechanisms of LLMs and in evaluating their alignment with human cognition. We introduce an innovative alignment assessment strategy in the realm of LLMs that diverges from traditional approaches, utilizing the odd-one-out triplet-based task to investigate the alignment of LLMs’ representations with human object concept mental organization. Our methodology, which incorporates image captioning and zero/few-shot learning accuracy scoring, is designed to evaluate language models’ ability to predict similarities and differences in object concepts. A comprehensive experimental evaluation was conducted, involving four captioning strategies, twenty-four LLMs across eight model families, and three scoring procedures, utilizing a significantly large dataset for enhanced understanding of LLM comprehensibility. Finally, our study explores the impact of object description comprehensiveness on model-human representation alignment and analyzes a subset of randomly selected triplets to assess how LLMs are able to represent different levels of human judgment patterns.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405638175",
    "type": "article"
  },
  {
    "title": "Adaptive Intention Learning for Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3709004",
    "publication_date": "2024-12-23",
    "publication_year": 2024,
    "authors": "Qingbo Zhang; Xiaochun Yang; Hao Chen; Bin Wang; Zhu Sun; Xiangmin Zhou",
    "corresponding_authors": "",
    "abstract": "In recent years, session-based recommender systems (SRSs) have emerged as a significant research focus within the recommendation field. Capturing user intentions to infer user interest accordingly has proven to be effective in enhancing the accuracy of SRSs. However, existing techniques assume that all sessions have the same number of intentions or that the items in one category belonging to the same session reflect the same intention. In real applications, such as e-commerce, sessions may have different numbers of intentions, and the same type of items in a session may correspond to different intentions. As a result, existing techniques cannot guarantee high-quality user interest prediction. In this paper, we propose a novel A daptive I ntention L earning N etwork (AILN) to capture an adaptive number of intentions for each session, thereby enhancing the accuracy of user interest inference. Specifically, we design an intention evaluation network (IEN) to evaluate whether a subsequence of a session corresponds to a valid intention, and an intention generation network (IGN) to learn the representation of a valid intention. By checking each subsequence of a session, IEN and IGN enable the incremental learning of a session-specific intention hierarchy (IH) to store valid intentions of the session. To reduce the cost of building the IH, we propose a pruning strategy that exploits the intention validity to avoid unnecessary evaluation. The representative intentions are selected from IH and input into a designed interest predictor to infer the user interest. Experimental results on two real-world datasets demonstrate the superiority of our proposed AILN.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405705397",
    "type": "article"
  },
  {
    "title": "FLAME: Self-Supervised Low-Resource Taxonomy Expansion Using Large Language Models",
    "doi": "https://doi.org/10.1145/3709007",
    "publication_date": "2024-12-24",
    "publication_year": 2024,
    "authors": "Sahil Mishra; Ujjwal Sudev; Tanmoy Chakraborty",
    "corresponding_authors": "",
    "abstract": "Taxonomies represent an arborescence hierarchical structure that establishes relationships among entities to convey knowledge within a specific domain. They find utility in various real-world applications, such as e-commerce search engines and recommendation systems. Consequently, there arises a necessity to enhance these taxonomies over time. However, manually curating taxonomies with neoteric data presents challenges due to limitations in available human resources and the exponential growth of data. Therefore, it becomes imperative to develop automatic taxonomy expansion methods. Traditional approaches encounter difficulties stemming from limited resources, primarily due to the small size of existing taxonomies. This scarcity of training data often leads to overfitting. In this paper, we propose FLAME ( F ine-tuning LA rge language M odels for taxonomy E xpansion), a novel approach for taxonomy expansion in low-resource environments (i.e., limited size of existing taxonomies, lack of robust representation capabilities of pre-trained language models, etc.) by harnessing the capabilities of large language models (LLMs) that are trained on extensive real-world knowledge. LLMs help compensate for the scarcity of domain-specific knowledge . Specifically, FLAME leverages prompting in few-shot settings to extract the inherent knowledge within the LLMs, ascertaining the hypernym entities within the taxonomy. Furthermore, it employs reinforcement learning to fine-tune LLMs, resulting in more accurate predictions. Experiments on four real-world benchmark datasets demonstrate the effectiveness of FLAME in real-world scenarios, achieving a remarkable improvement of 12.8% in accuracy and 5.6% in Wu &amp; Palmer metric over eleven baselines. Furthermore, we discuss the strengths and weaknesses of FLAME through an extensive case study, error analysis and ablation studies on the benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405734324",
    "type": "article"
  },
  {
    "title": "Attentive Excitation and Aggregation for Bilingual Referring Image Segmentation",
    "doi": "https://doi.org/10.1145/3446345",
    "publication_date": "2021-02-26",
    "publication_year": 2021,
    "authors": "Qianli Zhou; Tianrui Hui; Rong Wang; Hai‐Miao Hu; Si Liu",
    "corresponding_authors": "",
    "abstract": "The goal of referring image segmentation is to identify the object matched with an input natural language expression. Previous methods only support English descriptions, whereas Chinese is also broadly used around the world, which limits the potential application of this task. Therefore, we propose to extend existing datasets with Chinese descriptions and preprocessing tools for training and evaluating bilingual referring segmentation models. In addition, previous methods also lack the ability to collaboratively learn channel-wise and spatial-wise cross-modal attention to well align visual and linguistic modalities. To tackle these limitations, we propose a Linguistic Excitation module to excite image channels guided by language information and a Linguistic Aggregation module to aggregate multimodal information based on image-language relationships. Since different levels of features from the visual backbone encode rich visual information, we also propose a Cross-Level Attentive Fusion module to fuse multilevel features gated by language information. Extensive experiments on four English and Chinese benchmarks show that our bilingual referring image segmentation model outperforms previous methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3134811619",
    "type": "article"
  },
  {
    "title": "Classi-Fly: Inferring Aircraft Categories from Open Data",
    "doi": "https://doi.org/10.1145/3480969",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Martin Strohmeier; Matthew Smith; Vincent Lenders; Ivan Martinović",
    "corresponding_authors": "",
    "abstract": "In recent years, air traffic communication data has become easy to access, enabling novel research in many fields. Exploiting this new data source, a wide range of applications have emerged, from weather forecasting to stock market prediction, or the collection of intelligence about military and government movements. Typically, these applications require knowledge about the metadata of the aircraft, specifically its operator and the aircraft category. armasuisse Science + Technology , the R&amp;D agency for the Swiss Armed Forces, has been developing Classi-Fly, a novel approach to obtain metadata about aircraft based on their movement patterns. We validate Classi-Fly using several hundred thousand flights collected through open source means, in conjunction with ground truth from publicly available aircraft registries containing more than 2 million aircraft. We show that we can obtain the correct aircraft category with an accuracy of greater than 88%. In cases, where no metadata is available, this approach can be used to create the data necessary for applications working with air traffic communication. Finally, we show that it is feasible to automatically detect particular sensitive aircraft such as police and surveillance aircraft using this method.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3139257453",
    "type": "article"
  },
  {
    "title": "Mining Customers’ Changeable Electricity Consumption for Effective Load Forecasting",
    "doi": "https://doi.org/10.1145/3466684",
    "publication_date": "2021-08-01",
    "publication_year": 2021,
    "authors": "Etienne Gael Tajeuna; Mohamed Bouguessa; Shengrui Wang",
    "corresponding_authors": "",
    "abstract": "Most existing approaches for electricity load forecasting perform the task based on overall electricity consumption. However, using such a global methodology can affect load forecasting accuracy, as it does not consider the possibility that customers’ consumption behavior may change at any time. Predicting customers’ electricity consumption in the presence of unstable behaviors poses challenges to existing models. In this article, we propose a principled approach capable of handling customers’ changeable electricity consumption. We devise a network-based method that first builds and tracks clusters of customer consumption patterns over time. Then, on the evolving clusters, we develop a framework that exploits long short-term memory recurrent neural network and survival analysis techniques to forecast electricity consumption. Our experiments on real electricity consumption datasets illustrate the suitability of the proposed approach.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3191813552",
    "type": "article"
  },
  {
    "title": "TARA-Net: A Fusion Network for Detecting Takeaway Rider Accidents",
    "doi": "https://doi.org/10.1145/3457218",
    "publication_date": "2021-12-11",
    "publication_year": 2021,
    "authors": "Yifan He; Zhao Li; Lei Fu; Anhui Wang; Peng Zhang; Shuigeng Zhou; Ji Zhang; Ting Yu",
    "corresponding_authors": "",
    "abstract": "In the emerging business of food delivery, rider traffic accidents raise financial cost and social traffic burden. Although there has been much effort on traffic accident forecasting using temporal-spatial prediction models, none of the existing work studies the problem of detecting the takeaway rider accidents based on food delivery trajectory data. In this article, we aim to detect whether a takeaway rider meets an accident on a certain time period based on trajectories of food delivery and riders’ contextual information. The food delivery data has a heterogeneous information structure and carries contextual information such as weather and delivery history, and trajectory data are collected as a spatial-temporal sequence. In this article, we propose a TakeAway Rider Accident detection fusion network TARA-Net to jointly model these heterogeneous and spatial-temporal sequence data. We utilize the residual network to extract basic contextual information features and take advantage of a transformer encoder to capture trajectory features. These embedding features are concatenated into a pyramidal feed-forward neural network. We jointly train the above three components to combine the benefits of spatial-temporal trajectory data and sparse basic contextual data for early detecting traffic accidents. Furthermore, although traffic accidents rarely happen in food delivery, we propose a sampling mechanism to alleviate the imbalance of samples when training the model. We evaluate the model on a transportation mode classification dataset Geolife and a real-world Ele.me dataset with over 3 million riders. The experimental results show that the proposed model is superior to the state-of-the-art.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4200376882",
    "type": "article"
  },
  {
    "title": "Homogeneity in Web Search Results",
    "doi": "https://doi.org/10.1145/3057731",
    "publication_date": "2017-07-12",
    "publication_year": 2017,
    "authors": "Rakesh Agrawal; Behzad Golshan; Evangelos E. Papalexakis",
    "corresponding_authors": "",
    "abstract": "Access to diverse perspectives nurtures an informed citizenry. Google and Bing have emerged as the duopoly that largely arbitrates which English-language documents are seen by web searchers. We present our empirical study over the search results produced by Google and Bing that shows a large overlap. Thus, citizens may not gain different perspectives by simultaneously probing them for the same query. Fortunately, our study also shows that by mining Twitter data, one can obtain search results that are quite distinct from those produced by Google, Bing, and Bing News. Additionally, the users found those results to be quite informative. We also present two novel tools we designed for this study. One uses tensor analysis to derive low-dimensional compact representation of search results and study their behavior over time. The other uses machine learning and quantifies the similarity of results between two search engines by framing it as a prediction problem. Although these tools have different underpinnings, the analytical results obtained using them corroborate each other, which reinforces the confidence one can place in them for finding meaningful insights from big data.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2735538678",
    "type": "article"
  },
  {
    "title": "Taking the Pulse of US College Campuses with Location-Based Anonymous Mobile Apps",
    "doi": "https://doi.org/10.1145/3078843",
    "publication_date": "2017-09-04",
    "publication_year": 2017,
    "authors": "Yanqiu Wu; Tehila Minkus; Keith W. Ross",
    "corresponding_authors": "",
    "abstract": "We deploy GPS hacking in conjunction with location-based mobile apps to passively survey users in targeted geographical regions. Specifically, we investigate surveying students at different college campuses with Yik Yak, an anonymous mobile app that is popular on US college campuses. In addition to being campus centric, Yik Yak’s anonymity allows students to express themselves candidly without self-censorship. We collect nearly 1.6 million Yik Yak messages (“yaks”) from a diverse set of 45 college campuses in the United States. We use natural language processing to determine the sentiment (positive, negative, or neutral) of all of the yaks. We employ supervised machine learning to predict the gender of the authors of the yaks and then analyze how sentiment differs among the two genders on college campuses. We also use supervised machine learning to classify all the yaks into nine topics and then investigate which topics are most popular throughout the US and how topic popularity varies on the different campuses. The results in this article provide significant insight into how campus culture and student’s thinking varies among US colleges and universities.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2752136899",
    "type": "article"
  },
  {
    "title": "Multifeature Anisotropic Orthogonal Gaussian Process for Automatic Age Estimation",
    "doi": "https://doi.org/10.1145/3090311",
    "publication_date": "2017-09-04",
    "publication_year": 2017,
    "authors": "Zhifeng Li; Dihong Gong; Kai Zhu; Dacheng Tao; Xuelong Li",
    "corresponding_authors": "",
    "abstract": "Automatic age estimation is an important yet challenging problem. It has many promising applications in social media. Of the existing age estimation algorithms, the personalized approaches are among the most popular ones. However, most person-specific approaches rely heavily on the availability of training images across different ages for a single subject, which is usually difficult to satisfy in practical application of age estimation. To address this limitation, we first propose a new model called Orthogonal Gaussian Process (OGP), which is not restricted by the number of training samples per person. In addition, without sacrifice of discriminative power, OGP is much more computationally efficient than the standard Gaussian Process. Based on OGP, we then develop an effective age estimation approach, namely anisotropic OGP (A-OGP), to further reduce the estimation error. A-OGP is based on an anisotropic noise level learning scheme that contributes to better age estimation performance. To finally optimize the performance of age estimation, we propose a multifeature A-OGP fusion framework that uses multiple features combined with a random sampling method in the feature space. Extensive experiments on several public domain face aging datasets (FG-NET, MORPH Album1, and MORPH Album 2) are conducted to demonstrate the state-of-the-art estimation accuracy of our new algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2753560031",
    "type": "article"
  },
  {
    "title": "A Framework for Effectively Choosing between Alternative Candidate Partners",
    "doi": "https://doi.org/10.1145/2589482",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Shulamit Reches; Meir Kalech; Philip Hendrix",
    "corresponding_authors": "",
    "abstract": "Many multi-agent settings require that agents identify appropriate partners or teammates with whom to work on tasks. When selecting potential partners, agents may benefit from obtaining information about the alternatives, for instance, through gossip (i.e., by consulting others) or reputation systems. When information is uncertain and associated with cost, deciding on the amount of information needed is a hard optimization problem. This article defines a statistical model, the Information-Acquisition Source Utility model (IASU), by which agents, operating in an uncertain world, can determine (1) which information sources they should request for information, and (2) the amount of information to collect about potential partners from each source. To maximize the expected gain from the choice, IASU computes the utility of choosing a partner by estimating the benefit of additional information. The article presents empirical studies through a simulation domain as well as a real-world domain of restaurants. We compare the IASU model to other relevant models and show that the use of the IASU model significantly increases agents' overall utility.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2007539774",
    "type": "article"
  },
  {
    "title": "Event Extraction using Structured Learning and Rich Domain Knowledge",
    "doi": "https://doi.org/10.1145/2801131",
    "publication_date": "2015-12-04",
    "publication_year": 2015,
    "authors": "Einat Minkov",
    "corresponding_authors": "Einat Minkov",
    "abstract": "We consider the task of record extraction from text documents, where the goal is to automatically populate the fields of target relations, such as scientific seminars or corporate acquisition events. There are various inferences involved in the record-extraction process, including mention detection, unification, and field assignments. We use structured learning to find the appropriate field-value assignments. Unlike previous works, the proposed approach generates feature-rich models that enable the modeling of domain semantics and structural coherence at all levels and across fields. Given labeled examples, such an approach can, for instance, learn likely event durations and the fact that start times should come before end times. While the inference space is large, effective learning is achieved using a perceptron-style method and simple, greedy beam decoding. A main focus of this article is on practical aspects involved in implementing the proposed framework for real-world applications. We argue and demonstrate that this approach is favorable in conditions of data shift, a real-world setting in which models learned using a limited set of labeled examples are applied to examples drawn from a different data distribution. Much of the framework’s robustness is attributed to the modeling of domain knowledge. We describe design and implementation details for the case study of seminar event extraction from email announcements, and discuss design adaptations across different domains and text genres.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2267350670",
    "type": "article"
  },
  {
    "title": "Automated Generation of Counterterrorism Policies Using Multiexpert Input",
    "doi": "https://doi.org/10.1145/2716328",
    "publication_date": "2015-07-10",
    "publication_year": 2015,
    "authors": "Anshul Sawant; John P. Dickerson; Mohammad Taghi Hajiaghayi; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "The use of game theory to model conflict has been studied by several researchers, spearheaded by Schelling. Most of these efforts assume a single payoff matrix that captures players’ utilities under different assumptions about what the players will do. Our experience in counterterrorism applications is that experts disagree on these payoffs. We leverage Shapley’s notion of vector equilibria, which formulates games where there are multiple payoff matrices, but note that they are very hard to compute in practice. To effectively enumerate large numbers of equilibria with payoffs provided by multiple experts, we propose a novel combination of vector payoffs and well-supported ϵ-approximate equilibria. We develop bounds related to computation of these equilibria for some special cases and give a quasipolynomial time approximation scheme (QPTAS) for the general case when the number of players is small (which is true in many real-world applications). Leveraging this QPTAS, we give efficient algorithms to find such equilibria and experimental results showing that they work well on simulated data. We then built a policy recommendation engine based on vector equilibria, called PREVE . We use PREVE to model the terrorist group Lashkar-e-Taiba (LeT), responsible for the 2008 Mumbai attacks, as a five-player game. Specifically, we apply it to three payoff matrices provided by experts in India--Pakistan relations, analyze the equilibria generated by PREVE, and suggest counterterrorism policies that may reduce attacks by LeT. We briefly discuss these results and identify their strengths and weaknesses from a policy point of view.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2295323579",
    "type": "article"
  },
  {
    "title": "PPLib",
    "doi": "https://doi.org/10.1145/2897367",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Patrick M. de Boer; Abraham Bernstein",
    "corresponding_authors": "",
    "abstract": "Crowdsourcing is increasingly being adopted to solve simple tasks such as image labeling and object tagging, as well as more complex tasks, where crowd workers collaborate in processes with interdependent steps. For the whole range of complexity, research has yielded numerous patterns for coordinating crowd workers in order to optimize crowd accuracy, efficiency, and cost. Process designers, however, often don't know which pattern to apply to a problem at hand when designing new applications for crowdsourcing. In this article, we propose to solve this problem by systematically exploring the design space of complex crowdsourced tasks via automated recombination and auto-experimentation for an issue at hand. Specifically, we propose an approach to finding the optimal process for a given problem by defining the deep structure of the problem in terms of its abstract operators, generating all possible alternatives via the (re)combination of the abstract deep structure with concrete implementations from a Process Repository, and then establishing the best alternative via auto-experimentation. To evaluate our approach, we implemented PPLib (pronounced “People Lib”), a program library that allows for the automated recombination of known processes stored in an easily extensible Process Repository. We evaluated our work by generating and running a plethora of process candidates in two scenarios on Amazon's Mechanical Turk followed by a meta-evaluation, where we looked at the differences between the two evaluations. Our first scenario addressed the problem of text translation, where our automatic recombination produced multiple processes whose performance almost matched the benchmark established by an expert translation. In our second evaluation, we focused on text shortening; we automatically generated 41 crowd process candidates, among them variations of the well-established Find-Fix-Verify process. While Find-Fix-Verify performed well in this setting, our recombination engine produced five processes that repeatedly yielded better results. We close the article by comparing the two settings where the Recombinator was used, and empirically show that the individual processes performed differently in the two settings, which led us to contend that there is no unifying formula, hence emphasizing the necessity for recombination.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2342597251",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2753829",
    "publication_date": "2015-05-04",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Considering that the existing depth recovery approaches have different limitations when applied to Kinect depth data, in this article, we propose to integrate their effective features including adaptive support region selection, reliable depth selection,...",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4237064651",
    "type": "paratext"
  },
  {
    "title": "Reinforcement Learning for Adaptive Video Compressive Sensing",
    "doi": "https://doi.org/10.1145/3608479",
    "publication_date": "2023-07-11",
    "publication_year": 2023,
    "authors": "Sidi Lu; Xin Yuan; Aggelos K. Katsaggelos; Weisong Shi",
    "corresponding_authors": "",
    "abstract": "We apply reinforcement learning to video compressive sensing to adapt the compression ratio. Specifically, video snapshot compressive imaging (SCI), which captures high-speed video using a low-speed camera is considered in this work, in which multiple ( B ) video frames can be reconstructed from a snapshot measurement. One research gap in previous studies is how to adapt B in the video SCI system for different scenes. In this article, we fill this gap utilizing reinforcement learning (RL). An RL model, as well as various convolutional neural networks for reconstruction, are learned to achieve adaptive sensing of video SCI systems. Furthermore, the performance of an object detection network using directly the video SCI measurements without reconstruction is also used to perform RL-based adaptive video compressive sensing. Our proposed adaptive SCI method can thus be implemented in low cost and real time. Our work takes the technology one step further towards real applications of video SCI.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3160041769",
    "type": "article"
  },
  {
    "title": "Toward Balancing the Efficiency and Effectiveness in k-Facility Relocation Problem",
    "doi": "https://doi.org/10.1145/3587039",
    "publication_date": "2023-03-09",
    "publication_year": 2023,
    "authors": "Wang Hu; Hui Li; Meng Wang; Jiangtao Cui",
    "corresponding_authors": "",
    "abstract": "Facility Relocation (FR), which is an effort to reallocate the placement of facilities to adapt to the changes of urban planning, has remarkable impact on many areas. Existing solutions fail to guarantee the result quality on relocating k &gt; 1 facilities. As k -FR problem is NP-complete and is not submodular or non-decreasing, traditional greedy algorithm cannot be directly applied. We propose to transform k -FR into another facility placement problem, which is submodular and non-decreasing. We prove that the optimal solutions of both problems are equivalent. Accordingly, we present the first approximate solution toward the k -FR, FR2FP. Our extensive comparison over both FR2FP and the state-of-the-art solution shows that FR2FP, although it provides approximation guarantee, cannot necessarily given superior results. The comparison motivates us to present an advanced approximate solution, FR2FP-ex. Moreover, based on Lagrangian relaxation, we develop an algorithm that can adjust the approximation ratio. Extensive experiments verified that, FR2FP-ex demonstrates the best result quality, and it is very close to the optimal solution. In addition, we also unveil the scenarios when the state-of-the-art would fail. We further generalize the k -FR problem, considering the budget for relocation and the cost of each facility. We also present corresponding approximate solutions toward the new problem and prove the approximation ratio.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4323662816",
    "type": "article"
  },
  {
    "title": "A Discriminant Information Theoretic Learning Framework for Multi-modal Feature Representation",
    "doi": "https://doi.org/10.1145/3587253",
    "publication_date": "2023-03-10",
    "publication_year": 2023,
    "authors": "Lei Gao; Ling Guan",
    "corresponding_authors": "",
    "abstract": "As sensory and computing technology advances, multi-modal features have been playing a central role in ubiquitously representing patterns and phenomena for effective information analysis and recognition. As a result, multi-modal feature representation is becoming a progressively significant direction of academic research and real applications. Nevertheless, numerous challenges remain ahead, especially in the joint utilization of discriminatory representations and complementary representations from multi-modal features. In this article, a discriminant information theoretic learning (DITL) framework is proposed to address these challenges. By employing this proposed framework, the discrimination and complementation within the given multi-modal features are exploited jointly, resulting in a high-quality feature representation. According to characteristics of the DITL framework, the newly generated feature representation is further optimized, leading to lower computational complexity and improved system performance. To demonstrate the effectiveness and generality of DITL, we conducted experiments on several recognition examples, including both static cases, such as handwritten digit recognition, face recognition, and object recognition, and dynamic cases, such as video-based human emotion recognition and action recognition. The results show that the proposed framework outperforms state-of-the-art algorithms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4323864040",
    "type": "article"
  },
  {
    "title": "Joint Latent Space and Label Inference Estimation with Adaptive Fused Data and Label Graphs",
    "doi": "https://doi.org/10.1145/3590172",
    "publication_date": "2023-04-22",
    "publication_year": 2023,
    "authors": "A. Baradaaji; F. Dornaika",
    "corresponding_authors": "",
    "abstract": "Recently, structured computing has become an interesting topic in the world of artificial intelligence, especially in the field of machine learning, as most researchers focus on the development of graph-based semi-supervised learning models. In this article, we present a new framework for graph-based semi-supervised learning. We present a powerful method for simultaneous label inference and linear transform estimation. The targeted linear transformation is used to obtain a discriminant subspace. To improve semi-supervised learning, our framework focuses on exploiting the data structure and soft labels of the available unlabeled samples. In the iterative optimization scheme used, the prior estimation of the label increases the supervision information indirectly through an introduced informative matrix called the label graph, thus avoiding the use of hard confidence-based decisions as used in self-supervised methods. In addition, the estimation of labels and projected data is made more robust by using smoothing concepts based on hybrid graphs. For each type of smoothing, the hybrid graph is an adaptive fusion of the two graphs encoding the similarity of the data and the similarity of the labels. The proposed method leads to an improved discriminative linear transformation. Several experimental results on real image datasets confirm the effectiveness of the proposed method. They also show superior performance compared to semi-supervised methods that use integration and label inference simultaneously.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4366769452",
    "type": "article"
  },
  {
    "title": "Obfuscating the Dataset: Impacts and Applications",
    "doi": "https://doi.org/10.1145/3597936",
    "publication_date": "2023-05-23",
    "publication_year": 2023,
    "authors": "Guangsheng Yu; Xu Wang; Caijun Sun; Ping Yu; Wei Ni; Ren Ping Liu",
    "corresponding_authors": "",
    "abstract": "Obfuscating a dataset by adding random noises to protect the privacy of sensitive samples in the training dataset is crucial to prevent data leakage to untrusted parties when dataset sharing is essential. We conduct comprehensive experiments to investigate how the dataset obfuscation can affect the resultant model weights —in terms of the model accuracy, ℓ 2 -distance-based model distance, and level of data privacy—and discuss the potential applications with the proposed Privacy, Utility, and Distinguishability (PUD)-triangle diagram to visualize the requirement preferences. Our experiments are based on the popular MNIST and CIFAR-10 datasets under both independent and identically distributed (IID) and non-IID settings. Significant results include a tradeoff between the model accuracy and privacy level and a tradeoff between the model difference and privacy level. The results indicate broad application prospects for training outsourcing and guarding against attacks in federated learning both of which have been increasingly attractive in many areas, particularly learning in edge computing.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4377821114",
    "type": "article"
  },
  {
    "title": "Unsupervised Graph Representation Learning with Cluster-aware Self-training and Refining",
    "doi": "https://doi.org/10.1145/3608480",
    "publication_date": "2023-07-11",
    "publication_year": 2023,
    "authors": "Yanqiao Zhu; Yichen Xu; Feng Yu; Qiang Liu; Shu Wu",
    "corresponding_authors": "",
    "abstract": "Unsupervised graph representation learning aims to learn low-dimensional node embeddings without supervision while preserving graph topological structures and node attributive features. Previous Graph Neural Networks (GNN) require a large number of labeled nodes, which may not be accessible in real-world applications. To this end, we present a novel unsupervised graph neural network model with Cluster-aware Self-training and Refining ( CLEAR ). Specifically, in the proposed CLEAR model, we perform clustering on the node embeddings and update the model parameters by predicting the cluster assignments. To avoid degenerate solutions of clustering, we formulate the graph clustering problem as an optimal transport problem and leverage a balanced clustering strategy. Moreover, we observe that graphs often contain inter-class edges, which mislead the GNN model to aggregate noisy information from neighborhood nodes. Therefore, we propose to refine the graph topology by strengthening intra-class edges and reducing node connections between different classes based on cluster labels, which better preserves cluster structures in the embedding space. We conduct comprehensive experiments on two benchmark tasks using real-world datasets. The results demonstrate the superior performance of the proposed model over baseline methods. Notably, our model gains over 7% improvements in terms of accuracy on node clustering over state-of-the-arts.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4383982278",
    "type": "article"
  },
  {
    "title": "Argument Schemes and a Dialogue System for Explainable Planning",
    "doi": "https://doi.org/10.1145/3610301",
    "publication_date": "2023-07-21",
    "publication_year": 2023,
    "authors": "Quratul-ain Mahesar; Simon Parsons",
    "corresponding_authors": "",
    "abstract": "Artificial Intelligence (AI) is being increasingly deployed in practical applications. However, there is a major concern whether AI systems will be trusted by humans. To establish trust in AI systems, there is a need for users to understand the reasoning behind their solutions. Therefore, systems should be able to explain and justify their output. Explainable AI Planning is a field that involves explaining the outputs, i.e., solution plans produced by AI planning systems to a user. The main goal of a plan explanation is to help humans understand reasoning behind the plans that are produced by the planners. In this article, we propose an argument scheme-based approach to provide explanations in the domain of AI planning. We present novel argument schemes to create arguments that explain a plan and its key elements and a set of critical questions that allow interaction between the arguments and enable the user to obtain further information regarding the key elements of the plan. Furthermore, we present a novel dialogue system using the argument schemes and critical questions for providing interactive dialectical explanations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4385065583",
    "type": "article"
  },
  {
    "title": "Multi-agent Reinforcement Learning-based Adaptive Heterogeneous DAG Scheduling",
    "doi": "https://doi.org/10.1145/3610300",
    "publication_date": "2023-07-22",
    "publication_year": 2023,
    "authors": "A. Zhadan; Alexander Allahverdyan; Ivan Vladimirovich Kondratov; V. S. Mikheev; Ovanes Petrosian; A. B. Romanovskii; Vitaliy Kharin",
    "corresponding_authors": "",
    "abstract": "Static scheduling of computational workflow represented by a directed acyclic graph (DAG) is an important problem in many areas of computer science. The main idea and novelty of the proposed algorithm is an adaptive heuristic or graph metric that uses a different heuristic rule at each scheduling step depending on local workflow. It is also important to note that multi-agent reinforcement learning is used to determine scheduling policy based on adaptive metrics. To prove the efficiency of the approach, a comparison with the state-of-the-art DAG scheduling algorithms is provided: DONF, CPOP, HCPT, HPS, and PETS. Based on the simulation results, the proposed algorithm shows an improvement of up to 30% on specific graph topologies and an average performance gain of 5.32%, compared to the best scheduling algorithm, DONF (suitable for large-scale scheduling), on a large number of random DAGs. Another important result is that using the proposed algorithm it was possible to cover 30.01% of the proximity interval from the best scheduling algorithm to the global optimal solution. This indicates that the idea of an adaptive metric for DAG scheduling is important and requires further research and development.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4385075227",
    "type": "article"
  },
  {
    "title": "DDNAS: Discretized Differentiable Neural Architecture Search for Text Classification",
    "doi": "https://doi.org/10.1145/3610299",
    "publication_date": "2023-07-24",
    "publication_year": 2023,
    "authors": "Kuan-Chun Chen; Cheng–Te Li; Kuo‐Jung Lee",
    "corresponding_authors": "",
    "abstract": "Neural Architecture Search (NAS) has shown promising capability in learning text representation. However, existing text-based NAS neither performs a learnable fusion of neural operations to optimize the architecture nor encodes the latent hierarchical categorization behind text input. This article presents a novel NAS method, Discretized Differentiable Neural Architecture Search (DDNAS), for text representation learning and classification. With the continuous relaxation of architecture representation, DDNAS can use gradient descent to optimize the search. We also propose a novel discretization layer via mutual information maximization, which is imposed on every search node to model the latent hierarchical categorization in text representation. Extensive experiments conducted on eight diverse real datasets exhibit that DDNAS can consistently outperform the state-of-the-art NAS methods. While DDNAS relies on only three basic operations, i.e., convolution, pooling, and none, to be the candidates of NAS building blocks, its promising performance is noticeable and extensible to obtain further improvement by adding more different operations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4385199245",
    "type": "article"
  },
  {
    "title": "Attention-guided Adversarial Attack for Video Object Segmentation",
    "doi": "https://doi.org/10.1145/3617067",
    "publication_date": "2023-09-02",
    "publication_year": 2023,
    "authors": "Rui Yao; Ying Chen; Yong Zhou; Fuyuan Hu; Jiaqi Zhao; Bing Liu; Zhiwen Shao",
    "corresponding_authors": "",
    "abstract": "Video Object Segmentation (VOS) methods have made many breakthroughs with the help of the continuous development and advancement of deep learning. However, the deep learning model is vulnerable to malicious adversarial attacks, which mislead the model to make wrong decisions by adding adversarial perturbation that humans cannot perceive to the input image. Threats to deep learning models remind us that video object segmentation methods are also vulnerable to attacks, thereby threatening their security. Therefore, we study adversarial attacks on the VOS task to better identify the vulnerabilities of the VOS method, which in turn provides an opportunity to improve its robustness. In this paper, we propose an attention-guided adversarial attack method, which uses spatial attention blocks to capture features with global dependencies to construct correlations between consecutive video frames, and performs multipath aggregation to effectively integrate spatial-temporal perturbation, thereby guiding the deconvolution network to generate adversarial examples with strong attack capability. Specifically, the class loss function is designed to enable the deconvolution network to better activate noise in other regions and suppress the activation related to the object class based on the enhanced feature map of the object class. At the same time, attentional feature loss is designed to enhance the transferability against attack. The experimental results on the DAVIS dataset show that the proposed attention-guided adversarial attack method can significantly reduce the segmentation accuracy of OSVOS, and the J &amp; F mean on DAVIS 2016 can reach 73.6% drop rate. The generated adversarial examples are also highly transferable to other video object segmentation models.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386391014",
    "type": "article"
  },
  {
    "title": "Multi-aspect Understanding with Cooperative Graph Attention Networks for Medical Dialogue Information Extraction",
    "doi": "https://doi.org/10.1145/3620675",
    "publication_date": "2023-09-05",
    "publication_year": 2023,
    "authors": "Rui Lin; Jing Fan; Haifeng Wu",
    "corresponding_authors": "",
    "abstract": "Medical dialogue information extraction is an important but challenging task for Electronic Medical Records. Existing medical information extraction methods ignore the crucial information of sentence and multi-level dependency in dialogue, which limits their effectiveness for capturing essential medical information. To address these issues, we present a novel Multi-aspect Understanding with Cooperative Graph Attention Networks for Medical Dialogue Information Extraction to capture multi-aspect sentence information and multi-level dependency information from the dialogue. First, we propose the multi-aspect sentence encoder to capture various features from different perspectives. Second, we propose double graph attention networks to model the dependency features from intra-window and inter-window, respectively. Extensive experiments on a benchmark dataset have well-validated the effectiveness of the proposed method.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386440685",
    "type": "article"
  },
  {
    "title": "Dynamic Weights and Prior Reward in Policy Fusion for Compound Agent Learning",
    "doi": "https://doi.org/10.1145/3623405",
    "publication_date": "2023-09-11",
    "publication_year": 2023,
    "authors": "Meng Xu; Yechao She; Jin Yang; Jianping Wang",
    "corresponding_authors": "",
    "abstract": "In Deep Reinforcement Learning (DRL) domain, a compound learning task is often decomposed into several sub-tasks in a divide-and-conquer manner, each trained separately and then fused concurrently to achieve the original task, referred to as policy fusion. However, the state-of-the-art (SOTA) policy fusion methods treat the importance of sub-tasks equally throughout the task process, eliminating the possibility of the agent relying on different sub-tasks at various stages. To address this limitation, we propose a generic policy fusion approach, referred to as Policy Fusion Learning with Dynamic Weights and Prior Reward (PFLDWPR), to automate the time-varying selection of sub-tasks. Specifically, PFLDWPR produces a time-varying one-hot vector for sub-tasks to dynamically select a suitable sub-task and mask the rest throughout the entire task process, enabling the fused strategy to optimally guide the agent in executing the compound task. The sub-tasks with the dynamic one-hot vector are then aggregated to obtain the action policy for the original task. Moreover, we collect sub-tasks’s rewards at the pre-training stage as a prior reward, which, along with the current reward, is used to train the policy fusion network. Thus, this approach reduces fusion bias by leveraging prior experience. Experimental results under three popular learning tasks demonstrate that the proposed method significantly improves three SOTA policy fusion methods in terms of task duration, episode reward, and score difference.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386607612",
    "type": "article"
  },
  {
    "title": "Adaptive Integration of Categorical and Multi-relational Ontologies with EHR Data for Medical Concept Embedding",
    "doi": "https://doi.org/10.1145/3625224",
    "publication_date": "2023-09-26",
    "publication_year": 2023,
    "authors": "Chin Wang Cheong; Kejing Yin; William K. Cheung; Benjamin C. M. Fung; Jonathan Poon",
    "corresponding_authors": "",
    "abstract": "Representation learning has been applied to Electronic Health Records (EHR) for medical concept embedding and the downstream predictive analytics tasks with promising results. Medical ontologies can also be integrated to guide the learning so the embedding space can better align with existing medical knowledge. Yet, properly carrying out the integration is non-trivial. Medical concepts that are similar according to a medical ontology may not be necessarily close in the embedding space learned from the EHR data, as medical ontologies organize medical concepts for their own specific objectives. Any integration methodology without considering the underlying inconsistency will result in sub-optimal medical concept embedding and, in turn, degrade the performance of the downstream tasks. In this article, we propose a novel representation learning framework called ADORE ( AD aptive O ntological RE presentations) that allows the medical ontologies to adapt their structures for more robust integrating with the EHR data. ADORE first learns multiple embeddings for each category in the ontology via an attention mechanism. At the same time, it supports an adaptive integration of categorical and multi-relational ontologies in the embedding space using a category-aware graph attention network. We evaluate the performance of ADORE on a number of predictive analytics tasks using two EHR datasets. Our experimental results show that the medical concept embeddings obtained by ADORE can outperform the state-of-the-art methods for all the tasks. More importantly, it can result in clinically meaningful sub-categorization of the existing ontological categories and yield attention values that can further enhance the model interpretability.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4387055551",
    "type": "article"
  },
  {
    "title": "Human Pose Transfer with Augmented Disentangled Feature Consistency",
    "doi": "https://doi.org/10.1145/3626241",
    "publication_date": "2023-10-13",
    "publication_year": 2023,
    "authors": "Kun Wu; Chengxiang Yin; Zhengping Che; Bo Jiang; Jian Tang; Zheng Guan; Gangyi Ding",
    "corresponding_authors": "",
    "abstract": "Deep generative models have made great progress in synthesizing images with arbitrary human poses and transferring the poses of one person to others. Though many different methods have been proposed to generate images with high visual fidelity, the main challenge remains and comes from two fundamental issues: pose ambiguity and appearance inconsistency. To alleviate the current limitations and improve the quality of the synthesized images, we propose a pose transfer network with augmented D isentangled F eature C onsistency (DFC-Net) to facilitate human pose transfer. Given a pair of images containing the source and target person, DFC-Net extracts pose and static information from the source and target respectively, then synthesizes an image of the target person with the desired pose from the source. Moreover, DFC-Net leverages disentangled feature consistency losses in the adversarial training to strengthen the transfer coherence and integrates a keypoint amplifier to enhance the pose feature extraction. With the help of the disentangled feature consistency losses, we further propose a novel data augmentation scheme that introduces unpaired support data with the augmented consistency constraints to improve the generality and robustness of DFC-Net. Extensive experimental results on Mixamo-Pose and EDN-10k have demonstrated DFC-Net achieves state-of-the-art performance on pose transfer.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4387614502",
    "type": "article"
  },
  {
    "title": "Isomorphic Graph Embedding for Progressive Maximal Frequent Subgraph Mining",
    "doi": "https://doi.org/10.1145/3630635",
    "publication_date": "2023-10-27",
    "publication_year": 2023,
    "authors": "Thanh Toan Nguyen; Thành Tâm Nguyên; Thanh Hung Nguyen; Hongzhi Yin; Thanh Thi Nguyen; Jun Jo; Quoc Viet Hung Nguyen",
    "corresponding_authors": "",
    "abstract": "Maximal frequent subgraph mining (MFSM) is the task of mining only maximal frequent subgraphs, i.e., subgraphs that are not a part of other frequent subgraphs. Although many intelligent systems require MFSM, MFSM is challenging compared to frequent subgraph mining (FSM), as maximal frequent subgraphs lie in the middle of graph lattice, and FSM algorithms must explore an exponential space and an NP-hard subroutine of frequency counting. Different from prior research, which primarily focused on optimal solutions, we introduce pmMine, a progressive graph neural framework designed for MFSM in a single large graph to attain an approximate solution. The framework combines isomorphic graph embedding, non-parametric partitioning, and an efficiently top-down pattern searching strategy. The critical insight that makes pmMine work is to define the concepts of rooted subgraph and isomorphic graph embedding, in which the costly isomorphism subroutine can be efficiently performed using similarity estimation in embedding space. In addition, pmMine returns the patterns identified during the mining process in a progressive manner. We validate the efficiency and effectiveness of our technique through extensive experiments on a variety of datasets spanning various domains.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388190044",
    "type": "article"
  },
  {
    "title": "Demand-driven Urban Facility Visit Prediction",
    "doi": "https://doi.org/10.1145/3625233",
    "publication_date": "2023-11-09",
    "publication_year": 2023,
    "authors": "Yunke Zhang; Tong Li; Yuan Yuan; Fengli Xu; Fan Yang; Funing Sun; Yong Li",
    "corresponding_authors": "",
    "abstract": "Predicting citizens’ visiting behaviors to urban facilities is instrumental for city governors and planners to detect inequalities in urban opportunities and optimize the distribution of facilities and resources. Previous works predict facility visits simply using observed visit behavior, yet citizens’ intrinsic demands for facilities are not characterized explicitly, causing potential incorrect learned relations in the prediction results. In this article, to make up for this deficiency, we present a demand-driven urban facility visit prediction method that decomposes citizens’ visits to facilities into their unobservable demands and their capability to fulfill them. Demands are expressed as the function of regional demographic attributes by a neural network, and the fulfillment capability is determined by the urban region’s spatial accessibility to facilities. Extensive evaluations of datasets of three large cities confirm the efficiency and rationality of our model. Our method outperforms the best state-of-the-art model by 8.28% on average in facility visit prediction tasks. Further analyses demonstrate the reasonableness of recovered facility demands and their relationship with citizen demographics. For instance, senior citizens tend to have higher medical demands but lower shopping demands. Meanwhile, estimated capabilities and accessibilities provide deeper insights into the decaying accessibility with respect to spatial distance and facilities’ diverse functions in the urban environment. Our findings shed light on demand-driven urban data mining and demand-based urban facility planning.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388532626",
    "type": "article"
  },
  {
    "title": "Hierarchical Pruning of Deep Ensembles with Focal Diversity",
    "doi": "https://doi.org/10.1145/3633286",
    "publication_date": "2023-11-17",
    "publication_year": 2023,
    "authors": "Yanzhao Wu; Ka-Ho Chow; Wenqi Wei; Ling Liu",
    "corresponding_authors": "",
    "abstract": "Deep neural network ensembles combine the wisdom of multiple deep neural networks to improve the generalizability and robustness over individual networks. It has gained increasing popularity to study deep ensemble techniques in the deep learning community. Some mission-critical applications utilize a large number of deep neural networks to form deep ensembles to achieve desired accuracy and resilience, which introduces high time and space costs for ensemble execution. However, it still remains a critical challenge whether a small subset of the entire deep ensemble can achieve the same or better generalizability and how to effectively identify these small deep ensembles for improving the space and time efficiency of ensemble execution. This paper presents a novel deep ensemble pruning approach, which can efficiently identify smaller deep ensembles and provide higher ensemble accuracy than the entire deep ensemble of a large number of member networks. Our hierarchical ensemble pruning approach (HQ) leverages three novel ensemble pruning techniques. First, we show that the focal diversity metrics can accurately capture the complementary capacity of the member networks of an ensemble, which can guide ensemble pruning. Second, we design a focal diversity based hierarchical pruning approach, which will iteratively find high quality deep ensembles with low cost and high accuracy. Third, we develop a focal diversity consensus method to integrate multiple focal diversity metrics to refine ensemble pruning results, where smaller deep ensembles can be effectively identified to offer high accuracy, high robustness and high efficiency. Evaluated using popular benchmark datasets, we demonstrate that the proposed hierarchical ensemble pruning approach can effectively identify high quality deep ensembles with better generalizability while being more time and space efficient in ensemble decision making.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388763392",
    "type": "article"
  },
  {
    "title": "Modeling Queries with Contextual Snippets for Information Retrieval",
    "doi": "https://doi.org/10.1145/3161607",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Qin Chen; Qinmin Hu; Jimmy Xiangji Huang; Liang He",
    "corresponding_authors": "",
    "abstract": "Query expansion under the pseudo-relevance feedback (PRF) framework has been extensively studied in information retrieval. However, most expansion methods are mainly based on the statistics of single terms, which can generate plenty of irrelevant query terms and decrease retrieval performance. To alleviate this problem, we propose an approach that adapts the PRF-based contextual snippets into a context-aware topic model to enhance query representations. Specifically, instead of selecting a series of independent terms, we make full use of the query contextual information and focus on the snippets with the length of n in the PRF documents. Furthermore, we propose a context-aware topic (CAT) model to mine the topic distributions of the query-relevant snippets, namely, fine contextual snippets. In contrast to the traditional topic models that infer the topics from the whole corpus, we establish a bridge between the snippets and the corresponding PRF documents, which can be used for modeling the topics more precisely and efficiently. Finally, the topic distributions of the fine snippets are used for context-aware and topic-sensitive query representations. To evaluate the performance of our approach, we integrate the obtained queries into a topic-based hybrid retrieval model and conduct extensive experiments on various TREC collections. The experimental results show that our query-modeling approach is more effective in boosting retrieval performance compared with the state-of-the-art methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2787850647",
    "type": "article"
  },
  {
    "title": "Virtual Metering",
    "doi": "https://doi.org/10.1145/3141770",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Bingsheng Wang; Zhiqian Chen; Arnold P. Boedihardjo; Chang‐Tien Lu",
    "corresponding_authors": "",
    "abstract": "The scarcity of potable water is a critical challenge in many regions around the world. Previous studies have shown that knowledge of device-level water usage can lead to significant conservation. Although there is considerable interest in determining discriminative features via sparse coding for water disaggregation to separate whole-house consumption into its component appliances, existing methods lack a mechanism for fitting coefficient distributions and are thus unable to accurately discriminate parallel devices’ consumption. This article proposes a Bayesian discriminative sparse coding model, referred to as Virtual Metering (VM), for this disaggregation task. Mixture-of-Gammas is employed for the prior distribution of coefficients, contributing two benefits: (i) guaranteeing the coefficients’ sparseness and non-negativity, and (ii) capturing the distribution of active coefficients. The resulting method effectively adapts the bases to aggregated consumption to facilitate discriminative learning in the proposed model, and devices’ shape features are formalized and incorporated into Bayesian sparse coding to direct the learning of basis functions. Compact Gibbs Sampling (CGS) is developed to accelerate the inference process by utilizing the sparse structure of coefficients. The empirical results obtained from applying the new model to large-scale real and synthetic datasets revealed that VM significantly outperformed the benchmark methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2790515939",
    "type": "article"
  },
  {
    "title": "A Bayesian Approach to Intervention-Based Clustering",
    "doi": "https://doi.org/10.1145/3156683",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Igor Kulev; Pearl Pu; Boi Faltings",
    "corresponding_authors": "",
    "abstract": "An important task for intelligent healthcare systems is to predict the effect of a new intervention on individuals. This is especially true for medical treatments. For example, consider patients who do not respond well to a new drug or have adversary reactions. Predicting the likelihood of positive or negative response before trying the drug on the patient can potentially save his or her life. We are therefore interested in identifying distinctive subpopulations that respond differently to a given intervention. For this purpose, we have developed a novel technique, Intervention-based Clustering, based on a Bayesian mixture model. Compared to the baseline techniques, the novelty of our approach lies in its ability to model complex decision boundaries by using soft clustering, thus predicting the effect for individuals more accurately. It can also incorporate prior knowledge, making the method useful even for smaller datasets. We demonstrate how our method works by applying it to both simulated and real data. Results of our evaluation show that our model has strong predictive power and is capable of producing high-quality clusters compared to the baseline methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2792858016",
    "type": "article"
  },
  {
    "title": "Quick Bootstrapping of a Personalized Gaze Model from Real-Use Interactions",
    "doi": "https://doi.org/10.1145/3156682",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Michael Xuelin Huang; Jiajia Li; Grace Ngai; Hong Va Leong",
    "corresponding_authors": "",
    "abstract": "Understanding human visual attention is essential for understanding human cognition, which in turn benefits human--computer interaction. Recent work has demonstrated a Personalized, Auto-Calibrating Eye-tracking (PACE) system, which makes it possible to achieve accurate gaze estimation using only an off-the-shelf webcam by identifying and collecting data implicitly from user interaction events. However, this method is constrained by the need for large amounts of well-annotated data. We thus present fast-PACE, an adaptation to PACE that exploits knowledge from existing data from different users to accelerate the learning speed of the personalized model. The result is an adaptive, data-driven approach that continuously “learns” its user and recalibrates, adapts, and improves with additional usage by a user. Experimental evaluations of fast-PACE demonstrate its competitive accuracy in iris localization, validity of alignment identification between gaze and interactions, and effectiveness of gaze transfer. In general, fast-PACE achieves an initial visual error of 3.98 degrees and then steadily improves to 2.52 degrees given incremental interaction-informed data. Our performance is comparable to state-of-the-art, but without the need for explicit training or calibration. Our technique addresses the data quality and quantity problems. It therefore has the potential to enable comprehensive gaze-aware applications in the wild.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2794257028",
    "type": "article"
  },
  {
    "title": "CapVis",
    "doi": "https://doi.org/10.1145/3200767",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Haoran Liang; Ming Jiang; Ronghua Liang; Qi Zhao",
    "corresponding_authors": "",
    "abstract": "When looking at an image, humans shift their attention toward interesting regions, making sequences of eye fixations. When describing an image, they also come up with simple sentences that highlight the key elements in the scene. What is the correlation between where people look and what they describe in an image? To investigate this problem intuitively, we develop a visual analytics system, CapVis, to look into visual attention and image captioning, two types of subjective annotations that are relatively task-free and natural. Using these annotations, we propose a word-weighting scheme to extract visual and verbal saliency ranks to compare against each other. In our approach, a number of low-level and semantic-level features relevant to visual-verbal saliency consistency are proposed and visualized for a better understanding of image content. Our method also shows the different ways that a human and a computational model look at and describe images, which provides reliable information for a captioning model. Experiment also shows that the visualized feature can be integrated into a computational model to effectively predict the consistency between the two modalities on an image dataset with both types of annotations.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2903204197",
    "type": "article"
  },
  {
    "title": "ACM TIST Special Issue on Visual Analytics",
    "doi": "https://doi.org/10.1145/3277019",
    "publication_date": "2018-12-13",
    "publication_year": 2018,
    "authors": "Nan Cao; Steffen Koch; David Gotz",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on ACM TIST Special Issue on Visual Analytics Authors: Nan Cao Tongji University Tongji UniversityView Profile , Steffen Koch University of Stuttgart University of StuttgartView Profile , David Gotz University of North Carolina at Chapel Hill University of North Carolina at Chapel HillView Profile , Editor: Yingcai Wu State Key Lab of CAD8CG Zhejiang University State Key Lab of CAD8CG Zhejiang UniversityView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 10Issue 1January 2019 Article No.: 1pp 1–4https://doi.org/10.1145/3277019Published:13 December 2018Publication History 0citation404DownloadsMetricsTotal Citations0Total Downloads404Last 12 Months43Last 6 weeks10 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2905049874",
    "type": "article"
  },
  {
    "title": "A Novel Image-Centric Approach Toward Direct Volume Rendering",
    "doi": "https://doi.org/10.1145/3152875",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Naimul Khan; Riadh Ksantini; Ling Guan",
    "corresponding_authors": "",
    "abstract": "Transfer function (TF) generation is a fundamental problem in direct volume rendering (DVR). A TF maps voxels to color and opacity values to reveal inner structures. Existing TF tools are complex and unintuitive for the users who are more likely to be medical professionals than computer scientists. In this article, we propose a novel image-centric method for TF generation where instead of complex tools, the user directly manipulates volume data to generate DVR. The user’s work is further simplified by presenting only the most informative volume slices for selection. Based on the selected parts, the voxels are classified using our novel sparse nonparametric support vector machine classifier, which combines both local and near-global distributional information of the training data. The voxel classes are mapped to aesthetically pleasing and distinguishable color and opacity values using harmonic colors. Experimental results on several benchmark datasets and a detailed user survey show the effectiveness of the proposed method.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2963242516",
    "type": "article"
  },
  {
    "title": "CoFi-points",
    "doi": "https://doi.org/10.1145/3389127",
    "publication_date": "2020-05-25",
    "publication_year": 2020,
    "authors": "Lin Li; Weike Pan; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "With the explosive growth of web resources, an increasingly important task in recommender systems is to provide high-quality personalized services by learning users’ preferences from historically observed information. As an effective preference learning technology, collaborative filtering has been widely extended to model the one-class or implicit feedback data, which is known as one-class collaborative filtering (OCCF). For a long time, pairwise ranking-oriented learning scheme has been viewed as a superior solution than the pointwise scheme for OCCF due to its higher accuracy in most cases. However, we argue that with appropriate model design, pointwise preference learning can achieve comparable or even better performance than the counterpart, i.e., pairwise preference learning. In particular, we propose a new preference assumption, i.e., pointwise preference on user/item-set. Based on this new assumption, we develop a novel, simple, and flexible solution called collaborative filtering via pointwise preference learning on user/item-set (CoFi-points). Furthermore, we derive two specific algorithms of CoFi-points with respect to the involved user-set and item-set, i.e., CoFi-points(u) and CoFi-points(i), referring to preference assumptions defined on user-set and item-set, respectively. Finally, we conduct extensive empirical studies on four real-world datasets with the state-of-the-art methods, and find that our solution can achieve very promising performance with respect to several ranking-oriented evaluation metrics.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3033659671",
    "type": "article"
  },
  {
    "title": "Cut-n-Reveal",
    "doi": "https://doi.org/10.1145/3394118",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Nikhil Muralidhar; Anika Tabassum; Liangzhe Chen; Supriya Chinthavali; Naren Ramakrishnan; B. Aditya Prakash",
    "corresponding_authors": "",
    "abstract": "Recent hurricane events have caused unprecedented amounts of damage on critical infrastructure systems and have severely threatened our public safety and economic health. The most observable (and severe) impact of these hurricanes is the loss of electric power in many regions, which causes breakdowns in essential public services. Understanding power outages and how they evolve during a hurricane provides insights on how to reduce outages in the future, and how to improve the robustness of the underlying critical infrastructure systems. In this article, we propose a novel scalable segmentation with explanations framework to help experts understand such datasets. Our method, CnR (Cut-n-Reveal), first finds a segmentation of the outage sequences based on the temporal variations of the power outage failure process so as to capture major pattern changes. This temporal segmentation procedure is capable of accounting for both the spatial and temporal correlations of the underlying power outage process. We then propose a novel explanation optimization formulation to find an intuitive explanation of the segmentation such that the explanation highlights the culprit time series of the change in each segment. Through extensive experiments, we show that our method consistently outperforms competitors in multiple real datasets with ground truth. We further study real county-level power outage data from several recent hurricanes (Matthew, Harvey, Irma) and show that CnR recovers important, non-trivial, and actionable patterns for domain experts, whereas baselines typically do not give meaningful results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3040889826",
    "type": "article"
  },
  {
    "title": "From Appearance to Essence",
    "doi": "https://doi.org/10.1145/3411749",
    "publication_date": "2020-09-11",
    "publication_year": 2020,
    "authors": "Xiu Susie Fang; Quan Z. Sheng; Xianzhi Wang; Wei Emma Zhang; Anne H. H. Ngu; Jian Yang",
    "corresponding_authors": "",
    "abstract": "Truth discovery has been widely studied in recent years as a fundamental means for resolving the conflicts in multi-source data. Although many truth discovery methods have been proposed based on different considerations and intuitions, investigations show that no single method consistently outperforms the others. To select the right truth discovery method for a specific application scenario, it becomes essential to evaluate and compare the performance of different methods. A drawback of current research efforts is that they commonly assume the availability of certain ground truth for the evaluation of methods. However, the ground truth may be very limited or even impossible to obtain, rendering the evaluation biased. In this article, we present CompTruthHyp , a generic approach for comparing the performance of truth discovery methods without using ground truth. In particular, our approach calculates the probability of observations in a dataset based on the output of different methods. The probability is then ranked to reflect the performance of these methods. We review and compare 12 representative truth discovery methods and consider both single-valued and multi-valued objects. The empirical studies on both real-world and synthetic datasets demonstrate the effectiveness of our approach for comparing truth discovery methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3084552649",
    "type": "article"
  },
  {
    "title": "Human-computer Coalition Formation in Weighted Voting Games",
    "doi": "https://doi.org/10.1145/3408294",
    "publication_date": "2020-10-17",
    "publication_year": 2020,
    "authors": "Moshe Mash; Roy Fairstein; Yoram Bachrach; Kobi Gal; Yair Zick",
    "corresponding_authors": "",
    "abstract": "This article proposes a negotiation game, based on the weighted voting paradigm in cooperative game theory, where agents need to form coalitions and agree on how to share the gains. Despite the prevalence of weighted voting in the real world, there has been little work studying people’s behavior in such settings. This work addresses this gap by combining game-theoretic solution concepts with machine learning models for predicting human behavior in such domains. We present a five-player online version of a weighted voting game in which people negotiate to create coalitions. We provide an equilibrium analysis of this game and collect hundreds of instances of people’s play in the game. We show that a machine learning model with features based on solution concepts from cooperative game theory (in particular, an extension of the Deegan-Packel Index) provide a good prediction of people’s decisions to join coalitions in the game. We designed an agent that uses the prediction model to make offers to people in this game and was able to outperform other people in an extensive empirical study. These results demonstrate the benefit of incorporating concepts from cooperative game theory in the design of agents that interact with people in group decision-making settings.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3109993853",
    "type": "article"
  },
  {
    "title": "Uncovering Media Bias via Social Network Learning",
    "doi": "https://doi.org/10.1145/3422181",
    "publication_date": "2020-12-22",
    "publication_year": 2020,
    "authors": "Yiyi Zhou; Rongrong Ji; Jinsong Su; Jiaquan Yao",
    "corresponding_authors": "",
    "abstract": "It is known that media outlets, such as CNN and FOX, have intrinsic political bias that is reflected in their news reports. The computational prediction of such bias has broad application prospects. However, the prediction is difficult via directly analyzing the news content without high-level context. In contrast, social signals (e.g., the network structure of media followers) provide inspiring cues to uncover such bias. In this article, we realize the first attempt of predicting the latent bias of media outlets by analyzing their social network structures. In particular, we address two key challenges: network sparsity and label sparsity . The network sparsity refers to the partial sampling of the entire follower network in practical analysis and computing, whereas the label sparsity refers to the difficulty of annotating sufficient labels to train the prediction model. To cope with the network sparsity, we propose a hybrid sampling strategy to construct a training corpus that contains network information from micro to macro views. Based on this training corpus, a semi-supervised network embedding approach is proposed to learn low-dimensional yet effective network representations. To deal with the label sparsity, we adopt a graph-based label propagation scheme to supplement the missing links and augment label information for model training. The preceding two steps are iteratively optimized to reinforce each other. We further collect a large-scale dataset containing social networks of 10 media outlets together with about 300,000 followers and more than 5 million connections. Over this dataset, we compare our model to a range of state of the art. Superior performance gains demonstrate the merits of the proposed approach. More importantly, the experimental results and analyses confirm the validity of our approach for the computerized prediction of media bias.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3114894359",
    "type": "article"
  },
  {
    "title": "CUDIA",
    "doi": "https://doi.org/10.1145/2508037.2508047",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Yubin Park; Joydeep Ghosh",
    "corresponding_authors": "",
    "abstract": "In healthcare-related studies, individual patient or hospital data are not often publicly available due to privacy restrictions, legal issues, or reporting norms. However, such measures may be provided at a higher or more aggregated level, such as state-level, county-level summaries or averages over health zones, such as hospital referral regions (HRR) or hospital service areas (HSA). Such levels constitute partitions over the underlying individual level data, which may not match the groupings that would have been obtained if one clustered the data based on individual-level attributes. Moreover, treating aggregated values as representatives for the individuals can result in the ecological fallacy. How can one run data mining procedures on such data where different variables are available at different levels of aggregation or granularity? In this article, we seek a better utilization of variably aggregated datasets, which are possibly assembled from different sources. We propose a novel cross-level imputation technique that models the generative process of such datasets using a Bayesian directed graphical model. The imputation is based on the underlying data distribution and is shown to be unbiased. This imputation can be further utilized in a subsequent predictive modeling, yielding improved accuracies. The experimental results using a simulated dataset and the Behavioral Risk Factor Surveillance System (BRFSS) dataset are provided to illustrate the generality and capabilities of the proposed framework.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1984145285",
    "type": "article"
  },
  {
    "title": "Perspectives in semantic adaptive social web",
    "doi": "https://doi.org/10.1145/2501603",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Federica Cena; Antonina Dattolo; Pasquale Lops; Julita Vassileva",
    "corresponding_authors": "",
    "abstract": "The Social Web is now a successful reality with its quickly growing number of users and applications. Also the Semantic Web, which started with the objective of describing Web resources in a machine-processable way, is now outgrowing the research labs and is being massively exploited in many websites, incorporating high-quality user-generated content and semantic annotations. The primary goal of this special section is to showcase some recent research at the intersection of the Social Web and the Semantic Web that explores the benefits that adaptation and personalization have to offer in the Web of the future, the so-called Social Adaptive Semantic Web. We have selected two articles out of fourteen submissions based on the quality of the articles and we present the main lessons learned from the overall analysis of these submissions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2023786478",
    "type": "article"
  },
  {
    "title": "Building and using social structures",
    "doi": "https://doi.org/10.1145/2438653.2438660",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Elisabetta Erriquez; Wiebe van der Hoek; Michael Wooldridge",
    "corresponding_authors": "",
    "abstract": "This article investigates the conjecture that agents who make decisions in scenarios where trust is important can benefit from the use of a social structure , representing the social relationships that exist between agents. We propose techniques that can be used by agents to initially build and then progressively update such a structure in the light of experience. We describe an implementation of our techniques in the domain of the Agent ART testbed: we take two existing agents for this domain (“Simplet” and “Connected”) and compare their performance with versions that use our social structure (“SocialSimplet” and “SocialConnected”). We show that SocialSimplet and SocialConnected outperform their counterparts with respect to the quality of the interactions, the number of rounds won in a competition, and the total utility gained.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2165696607",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2414425",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Highly dynamic real-time microblog systems have already published petabytes of real-time human sensor data in the form of status updates. However, the lack of user adoption of geo-based features per user or per post signals that the promise of microblog ...",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4236605665",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1989734",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Where should we place sensors to efficiently monitor natural drinking water resources for contamination? Which blogs should we read to learn about the biggest stories on the Web? These problems share a fundamental challenge: How can we obtain the most ...",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4237285493",
    "type": "paratext"
  },
  {
    "title": "VSumVis: Interactive Visual Understanding and Diagnosis of Video Summarization Model",
    "doi": "https://doi.org/10.1145/3458928",
    "publication_date": "2021-06-08",
    "publication_year": 2021,
    "authors": "Guodao Sun; Hao Wu; Lin Zhu; Chaoqing Xu; Haoran Liang; Binwei Xu; Ronghua Liang",
    "corresponding_authors": "",
    "abstract": "With the rapid development of mobile Internet, the popularity of video capture devices has brought a surge in multimedia video resources. Utilizing machine learning methods combined with well-designed features, we could automatically obtain video summarization to relax video resource consumption and retrieval issues. However, there always exists a gap between the summarization obtained by the model and the ones annotated by users. How to help users understand the difference, provide insights in improving the model, and enhance the trust in the model remains challenging in the current study. To address these challenges, we propose VSumVis under a user-centered design methodology, a visual analysis system with multi-feature examination and multi-level exploration, which could help users explore and analyze video content, as well as the intrinsic relationship that existed in our video summarization model. The system contains multiple coordinated views, i.e., video view, projection view, detail view, and sequential frames view. A multi-level analysis process to integrate video events and frames are presented with clusters and nodes visualization in our system. Temporal patterns concerning the difference between the manual annotation score and the saliency score produced by our model are further investigated and distinguished with sequential frames view. Moreover, we propose a set of rich user interactions that enable an in-depth, multi-faceted analysis of the features in our video summarization model. We conduct case studies and interviews with domain experts to provide anecdotal evidence about the effectiveness of our approach. Quantitative feedback from a user study confirms the usefulness of our visual system for exploring the video summarization model.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3169343516",
    "type": "article"
  },
  {
    "title": "Modeling Complementarity in Behavior Data with Multi-Type Itemset Embedding",
    "doi": "https://doi.org/10.1145/3458724",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Daheng Wang; Qingkai Zeng; Nitesh V. Chawla; Meng Jiang",
    "corresponding_authors": "",
    "abstract": "People are looking for complementary contexts, such as team members of complementary skills for project team building and/or reading materials of complementary knowledge for effective student learning, to make their behaviors more likely to be successful. Complementarity has been revealed by behavioral sciences as one of the most important factors in decision making. Existing computational models that learn low-dimensional context representations from behavior data have poor scalability and recent network embedding methods only focus on preserving the similarity between the contexts. In this work, we formulate a behavior entry as a set of context items and propose a novel representation learning method, Multi-type Itemset Embedding , to learn the context representations preserving the itemset structures. We propose a measurement of complementarity between context items in the embedding space. Experiments demonstrate both effectiveness and efficiency of the proposed method over the state-of-the-art methods on behavior prediction and context recommendation. We discover that the complementary contexts and similar contexts are significantly different in human behaviors.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3173280177",
    "type": "article"
  },
  {
    "title": "Let Trajectories Speak Out the Traffic Bottlenecks",
    "doi": "https://doi.org/10.1145/3465058",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Hui Luo; Zhifeng Bao; Gao Cong; J. Shane Culpepper; Nguyen Lu Dang Khoa",
    "corresponding_authors": "",
    "abstract": "Traffic bottlenecks are a set of road segments that have an unacceptable level of traffic caused by a poor balance between road capacity and traffic volume. A huge volume of trajectory data which captures realtime traffic conditions in road networks provides promising new opportunities to identify the traffic bottlenecks. In this paper, we define this problem as trajectory-driven traffic bottleneck identification : Given a road network R , a trajectory database T , find a representative set of seed edges of size K of traffic bottlenecks that influence the highest number of road segments not in the seed set. We show that this problem is NP-hard and propose a framework to find the traffic bottlenecks as follows. First, a traffic spread model is defined which represents changes in traffic volume for each road segment over time. Then, the traffic diffusion probability between two connected segments and the residual ratio of traffic volume for each segment can be computed using historical trajectory data. We then propose two different algorithmic approaches to solve the problem. The first one is a best-first algorithm BF , with an approximation ratio of 1-1/ e . To further accelerate the identification process in larger datasets, we also propose a sampling-based greedy algorithm SG . Finally, comprehensive experiments using three different datasets compare and contrast various solutions, and provide insights into important efficiency and effectiveness trade-offs among the respective methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3216598902",
    "type": "article"
  },
  {
    "title": "TAML: A Traffic-aware Multi-task Learning Model for Estimating Travel Time",
    "doi": "https://doi.org/10.1145/3466686",
    "publication_date": "2021-12-11",
    "publication_year": 2021,
    "authors": "Jiajie Xu; Saijun Xu; Rui Zhou; Chengfei Liu; An Liu; Lei Zhao",
    "corresponding_authors": "",
    "abstract": "Travel time estimation has been recognized as an important research topic that can find broad applications. Existing approaches aim to explore mobility patterns via trajectory embedding for travel time estimation. Though state-of-the-art methods utilize estimated traffic condition (by explicit features such as average traffic speed) for auxiliary supervision of travel time estimation, they fail to model their mutual influence and result in inaccuracy accordingly. To this end, in this article, we propose an improved traffic-aware model, called TAML, which adopts a multi-task learning network to integrate a travel time estimator and a traffic estimator in a shared space and improves the accuracy of estimation by enhanced representation of traffic condition, such that more meaningful implicit features are fully captured. In TAML, multi-task learning is further applied for travel time estimation in multi-granularities (including road segment, sub-path, and entire path). The multiple loss functions are combined by considering the homoscedastic uncertainty of each task. Extensive experiments on two real trajectory datasets demonstrate the effectiveness of our proposed methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4200039765",
    "type": "article"
  },
  {
    "title": "Mobile Social Multimedia Analytics in the Big Data Era",
    "doi": "https://doi.org/10.1145/3040934",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Rongrong Ji; Wei Liu; Xing Xie; Yiqiang Chen; Jiebo Luo",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Mobile Social Multimedia Analytics in the Big Data Era: An Introduction to the Special Issue Editors: Rongrong Ji Xiamen University, China Xiamen University, ChinaView Profile , Wei Liu Tencent AI Lab, China Tencent AI Lab, ChinaView Profile , Xing Xie Microsoft Research Asia, China Microsoft Research Asia, ChinaView Profile , Yiqiang Chen Chinese Academy of Science, China Chinese Academy of Science, ChinaView Profile , Jiebo Luo University of Rochester, United States University of Rochester, United StatesView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 8Issue 3May 2017 Article No.: 34pp 1–3https://doi.org/10.1145/3040934Published:14 April 2017Publication History 2citation224DownloadsMetricsTotal Citations2Total Downloads224Last 12 Months11Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2605792241",
    "type": "article"
  },
  {
    "title": "ACM TIST Special Issue on Urban Intelligence",
    "doi": "https://doi.org/10.1145/3154942",
    "publication_date": "2017-11-24",
    "publication_year": 2017,
    "authors": "Bo An; Nicholas R. Jennings; Zhenhui Jessie Li",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on ACM TIST Special Issue on Urban Intelligence Editors: Bo An Nanyang Technological University Nanyang Technological UniversityView Profile , Nick Jennings Imperial College Imperial CollegeView Profile , Zhenhui Jessie Li Pennsylvania State University Pennsylvania State UniversityView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 9Issue 3May 2018 Article No.: 23pp 1–4https://doi.org/10.1145/3154942Published:24 November 2017Publication History 0citation611DownloadsMetricsTotal Citations0Total Downloads611Last 12 Months37Last 6 weeks7 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2769239359",
    "type": "article"
  },
  {
    "title": "Using Online Geotagged and Crowdsourced Data to Understand Human Offline Behavior in the City",
    "doi": "https://doi.org/10.1145/3078851",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Yingjie Zhang; Beibei Li; Jason Hong",
    "corresponding_authors": "",
    "abstract": "The pervasiveness of mobile technologies today has facilitated the creation of massive online crowdsourced and geotagged data from individual users at different locations in a city. Such ubiquitous user-generated data allow us to study the social and behavioral trajectories of individuals across both digital and physical environments. This information, combined with traditional economic and behavioral indicators in the city (e.g., store purchases, restaurant visits, parking), can help us better understand human behavior and interactions with cities. In this study, we take an economic perspective and focus on understanding human economic behavior in the city by examining the performance of local businesses based on the values learned from crowsourced and geotagged data. Specifically, we extract multiple traffic and human mobility features from publicly available data source geomapping and geo-social-tagging techniques and examine the effects of both static and dynamic features on booking volume of local restaurants. Our study is instantiated on a unique dataset of restaurant bookings from OpenTable for 3,187 restaurants in New York City from November 2013 to March 2014. Our results suggest that foot traffic can increase local popularity and business performance, while mobility and traffic from automobiles may hurt local businesses, especially the well-established chains and high-end restaurants. We also find that, on average, one or more street closure (caused by events or construction projects) nearby leads to a 4.7% decrease in the probability of a restaurant being fully booked during the dinner peak. Our study demonstrates the potential to best make use of the large volumes and diverse sources of crowdsourced and geotagged user-generated data to create matrices to predict local economic demand in a manner that is fast, cheap, accurate, and meaningful.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2779982291",
    "type": "article"
  },
  {
    "title": "Toward Scalable and Privacy-preserving Deep Neural Network via Algorithmic-Cryptographic Co-design",
    "doi": "https://doi.org/10.1145/3501809",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Jun Zhou; Longfei Zheng; Chaochao Chen; Yan Wang; Xiaolin Zheng; Bingzhe Wu; Cen Chen; Li Wang; Jianwei Yin",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have achieved remarkable progress in various real-world applications, especially when abundant training data are provided. However, data isolation has become a serious problem currently. Existing works build privacy-preserving DNN models from either algorithmic perspective or cryptographic perspective. The former mainly splits the DNN computation graph between data holders or between data holders and server, which demonstrates good scalability but suffers from accuracy loss and potential privacy risks. In contrast, the latter leverages time-consuming cryptographic techniques, which has strong privacy guarantee but poor scalability. In this article, we propose SPNN—a Scalable and Privacy-preserving deep Neural Network learning framework, from an algorithmic-cryptographic co-perspective. From algorithmic perspective, we split the computation graph of DNN models into two parts, i.e., the private-data-related computations that are performed by data holders and the rest heavy computations that are delegated to a semi-honest server with high computation ability. From cryptographic perspective, we propose using two types of cryptographic techniques, i.e., secret sharing and homomorphic encryption, for the isolated data holders to conduct private-data-related computations privately and cooperatively. Furthermore, we implement SPNN in a decentralized setting and introduce user-friendly APIs. Experimental results conducted on real-world datasets demonstrate the superiority of our proposed SPNN.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3111208380",
    "type": "article"
  },
  {
    "title": "A Foraging Strategy with Risk Response for Individual Robots in Adversarial Environments",
    "doi": "https://doi.org/10.1145/3514499",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Kai Di; Yifeng Zhou; Fuhan Yan; Jiuchuan Jiang; Shaofu Yang; Yichuan Jiang",
    "corresponding_authors": "",
    "abstract": "As an essential problem in robotics, foraging means that robots collect objects from a given environment and return them to a specified location. On many occasions, robots are required to perform foraging tasks in adversarial environments, such as battlefield rescue, where potential adversaries may damage robots with a certain probability. The longer an individual robot moves through adversarial environments, the higher the probability of being damaged by adversaries. The robot system can gain utility only when the robot brings carried objects back to a predetermined home station. Such a risk of being damaged makes returning home at different locations potentially relevant to the expected utility produced by the robot. Thus, the individual robot faces a dilemma when it responds to the potential risks in adversarial environments: whether to return the carried resources home or continue foraging tasks. In this article, two fundamental environment settings are discussed, homogeneous cases and heterogeneous cases. The former is analyzed as having both the optimal substructure property and the non-aftereffect property. Then, we present a dynamic programming (DP) algorithm that can find an optimal solution with polynomial time complexity. For the latter, it is proven that finding an optimal solution is \\( \\mathcal {NP} \\) -hard. We then propose a heuristic algorithm: A division hierarchical path planning (DHPP) algorithm that is based on the idea of dividing the foraging routes generated initially into a certain number of subroutes to dilute risks. Finally, these algorithms are extensively evaluated in simulations, concluding that in adversarial environments, they can significantly improve the productivity of an individual robot before it is damaged.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4214755794",
    "type": "article"
  },
  {
    "title": "Prior Knowledge Constrained Adaptive Graph Framework for Partial Label Learning",
    "doi": "https://doi.org/10.1145/3569421",
    "publication_date": "2022-10-25",
    "publication_year": 2022,
    "authors": "Gengyu Lyu; Songhe Feng; Shaokai Wang; Zhen Yang",
    "corresponding_authors": "",
    "abstract": "Partial label learning (PLL) aims to learn a robust multi-class classifier from the ambiguous data, where each instance is given with several candidate labels, among which only one label is real. Most existing methods usually cope with such problem by utilizing a feature similarity graph to conduct label disambiguation. However, these methods construct the feature graph by only employing original features, while the influences of latent outliers and the contributions of label space are regrettably ignored. To tackle these issues, in this article, we propose a P rior Kn O wledge Cons T rained A daptive G raph Fram E work ( POTAGE ) for partial label learning, which utilizes an adaptive graph fused with label information to accurately describe the instance relationship and guide the desired model training. Compared with the feature-induced fixed graph, the adaptive graph is deemed to be more robust and accurate to reveal the intrinsic manifold structure within the data, and the embedding label information is expected to effectively alleviate the label ambiguities and enlarge the gap of label confidences between two instances from different classes. Extensive experiments demonstrate that POTAGE achieves state-of-the-art performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4307241673",
    "type": "article"
  },
  {
    "title": "Ad-Hoc Monitoring of COVID-19 Global Research Trends for Well-Informed Policy Making",
    "doi": "https://doi.org/10.1145/3576901",
    "publication_date": "2022-12-21",
    "publication_year": 2022,
    "authors": "Souvika Sarkar; Biddut Sarker Bijoy; Syeda Jannatus Saba; Dongji Feng; Yash Mahajan; Mohammad Ruhul Amin; Sheikh Rabiul Islam; Shubhra Kanti Karmaker",
    "corresponding_authors": "",
    "abstract": "The COVID-19 pandemic has affected millions of people worldwide with severe health, economic, social, and political implications. Healthcare Policy Makers (HPMs) and medical experts are at the core of responding to this continuously evolving pandemic situation and are working hard to contain the spread and severity of this relatively unknown virus. Biomedical researchers are continually discovering new information about this virus and communicating the findings through scientific articles. As such, it is crucial for HPMs and funding agencies to monitor the COVID-19 research trend globally on a regular basis. However, given the influx of biomedical research articles, monitoring COVID-19 research trends has become more challenging than ever, especially when HPMs want on-demand guided search techniques with a set of topics of interest in mind. Unfortunately, existing topic trend modeling techniques are unable to serve this purpose as (1) traditional topic models are unsupervised, and (2) HPMs in different regions may have different topics of interest that they want to track. To address this problem, we introduce a novel computational task in this article called Ad-Hoc Topic Tracking , which is essentially a combination of zero-shot topic categorization and the spatio-temporal analysis task. We then propose multiple zero-shot classification methods to solve this task by building on state-of-the-art language understanding techniques. Next, we picked the best-performing method based on its accuracy on a separate validation dataset and then applied it to a corpus of recent biomedical research articles to track COVID-19 research endeavors across the globe using a spatio-temporal analysis. A demo website has also been developed for HPMs to create custom spatio-temporal visualizations of COVID-19 research trends. The research outcomes demonstrate that the proposed zero-shot classification methods can potentially facilitate further research on this important subject matter. At the same time, the spatio-temporal visualization tool will greatly assist HPMs and funding agencies in making well-informed policy decisions for advancing scientific research efforts.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4312043136",
    "type": "article"
  },
  {
    "title": "High-Precision Camera Localization in Scenes with Repetitive Patterns",
    "doi": "https://doi.org/10.1145/3226111",
    "publication_date": "2018-11-13",
    "publication_year": 2018,
    "authors": "Xiaobai Liu; Qian Xu; Yadong Mu; Jiadi Yang; Liang Lin; Shuicheng Yan",
    "corresponding_authors": "",
    "abstract": "This article presents a high-precision multi-modal approach for localizing moving cameras with monocular videos, which has wide potentials in many intelligent applications, including robotics, autonomous vehicles, and so on. Existing visual odometry methods often suffer from symmetric or repetitive scene patterns, e.g., windows on buildings or parking stalls. To address this issue, we introduce a robust camera localization method that contributes in two aspects. First, we formulate feature tracking, the critical step of visual odometry, as a hierarchical min-cost network flow optimization task, and we regularize the formula with flow constraints, cross-scale consistencies, and motion heuristics. The proposed regularized formula is capable of adaptively selecting distinctive features or feature combinations, which is more effective than traditional methods that detect and group repetitive patterns in a separate step. Second, we develop a joint formula for integrating dense visual odometry and sparse GPS readings in a common reference coordinate. The fusion process is guided with high-order statistics knowledge to suppress the impacts of noises, clusters, and model drifting. We evaluate the proposed camera localization method on both public video datasets and a newly created dataset that includes scenes full of repetitive patterns. Results with comparisons show that our method can achieve comparable performance to state-of-the-art methods and is particularly effective for addressing repetitive pattern issues.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2900988590",
    "type": "article"
  },
  {
    "title": "ALERA",
    "doi": "https://doi.org/10.1145/3338123",
    "publication_date": "2019-07-24",
    "publication_year": 2019,
    "authors": "Suvadeep Banerjee; Abhijit Chatterjee",
    "corresponding_authors": "",
    "abstract": "The successful deployment of autonomous real-time systems is contingent on their ability to recover from performance degradation of sensors, actuators, and other electro-mechanical subsystems with low latency. In this article, we introduce ALERA, a novel framework for real-time control law adaptation in nonlinear control systems assisted by system state encodings that generate an error signal when the code properties are violated in the presence of failures. The fundamental contributions of this methodology are twofold—first, we show that the time-domain error signal contains perturbed system parameters’ diagnostic information that can be used for quick control law adaptation to failure conditions and second, this quick adaptation is performed via reinforcement learning algorithms that relearn the control law of the perturbed system from a starting condition dictated by the diagnostic information, thus achieving significantly faster recovery. The fast (up to 80X faster than traditional reinforcement learning paradigms) performance recovery enabled by ALERA is demonstrated on an inverted pendulum balancing problem, a brake-by-wire system, and a self-balancing robot.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2963904041",
    "type": "article"
  },
  {
    "title": "Two Can Play That Game",
    "doi": "https://doi.org/10.1145/3377554",
    "publication_date": "2020-04-03",
    "publication_year": 2020,
    "authors": "Ankit Shah; Arunesh Sinha; Rajesh Ganesan; Sushil Jajodia; Hasan Çam",
    "corresponding_authors": "",
    "abstract": "Cyber-security is an important societal concern. Cyber-attacks have increased in numbers as well as in the extent of damage caused in every attack. Large organizations operate a Cyber Security Operation Center (CSOC), which forms the first line of cyber-defense. The inspection of cyber-alerts is a critical part of CSOC operations (defender or blue team). Recent work proposed a reinforcement learning (RL) based approach for the defender’s decision-making to prevent the cyber-alert queue length from growing large and overwhelming the defender. In this article, we perform a red team (adversarial) evaluation of this approach. With the recent attacks on learning-based decision-making systems, it is even more important to test the limits of the defender’s RL approach. Toward that end, we learn several adversarial alert generation policies and the best response against them for various defender’s inspection policy. Surprisingly, we find the defender’s policies to be quite robust to the best response of the attacker. In order to explain this observation, we extend the earlier defender’s RL model to a game model with adversarial RL, and show that there exist defender policies that can be robust against any adversarial policy. We also derive a competitive baseline from the game theory model and compare it to the defender’s RL approach. However, when we go further to exploit the assumptions made in the Markov Decision Process (MDP) in the defender’s RL model, we discover an attacker policy that overwhelms the defender. We use a double oracle like approach to retrain the defender with episodes from this discovered attacker policy. This made the defender robust to the discovered attacker policy and no further harmful attacker policies were discovered. Overall, the adversarial RL and double oracle approach in RL are general techniques that are applicable to other RL usage in adversarial environments.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3015592103",
    "type": "article"
  },
  {
    "title": "A Discriminative Convolutional Neural Network with Context-aware Attention",
    "doi": "https://doi.org/10.1145/3397464",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Yuxiang Zhou; Lejian Liao; Yang Gao; Heyan Huang; Xiaochi Wei",
    "corresponding_authors": "",
    "abstract": "Feature representation and feature extraction are two crucial procedures in text mining. Convolutional Neural Networks (CNN) have shown overwhelming success for text-mining tasks, since they are capable of efficiently extracting n -gram features from source data. However, vanilla CNN has its own weaknesses on feature representation and feature extraction. A certain amount of filters in CNN are inevitably duplicate and thus hinder to discriminatively represent a given text. In addition, most existing CNN models extract features in a fixed way (i.e., max pooling) that either limit the CNN to local optimum nor without considering the relation between all features, thereby unable to learn a contextual n -gram features adaptively. In this article, we propose a discriminative CNN with context-aware attention to solve the challenges of vanilla CNN. Specifically, our model mainly encourages discrimination across different filters via maximizing their earth mover distances and estimates the salience of feature candidates by considering the relation between context features. We validate carefully our findings against baselines on five benchmark datasets of classification and two datasets of summarization. The results of the experiments verify the competitive performance of our proposed model.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3044379145",
    "type": "article"
  },
  {
    "title": "高齢者の移動性と日常的日常分析のための行動パターンの自動抽出【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Li Chen; K Cheung William; Liu Jiming; Kate Joseph",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3180727414",
    "type": "article"
  },
  {
    "title": "Semiparametric Inference of the Complier Average Causal Effect with Nonignorable Missing Outcomes",
    "doi": "https://doi.org/10.1145/2668135",
    "publication_date": "2015-12-03",
    "publication_year": 2015,
    "authors": "Hua Chen; Peng Ding; Zhi Geng; Xiao‐Hua Zhou",
    "corresponding_authors": "",
    "abstract": "Noncompliance and missing data often occur in randomized trials, which complicate the inference of causal effects. When both noncompliance and missing data are present, previous papers proposed moment and maximum likelihood estimators for binary and normally distributed continuous outcomes under the latent ignorable missing data mechanism. However, the latent ignorable missing data mechanism may be violated in practice, because the missing data mechanism may depend directly on the missing outcome itself. Under noncompliance and an outcome-dependent nonignorable missing data mechanism, previous studies showed the identifiability of complier average causal effect for discrete outcomes. In this article, we study the semiparametric identifiability and estimation of complier average causal effect in randomized clinical trials with both all-or-none noncompliance and outcome-dependent nonignorable missing continuous outcomes, and propose a two-step maximum likelihood estimator in order to eliminate the infinite dimensional nuisance parameter. Our method does not need to specify a parametric form for the missing data mechanism. We also evaluate the finite sample property of our method via extensive simulation studies and sensitivity analysis, with an application to a double-blinded psychiatric clinical trial.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1563420063",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Linking Social Granularity and Functions",
    "doi": "https://doi.org/10.1145/2594452",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Qi He; Juanzi Li; Yan Rong; John Yen; Haizheng Zhang",
    "corresponding_authors": "",
    "abstract": "introduction Free Access Share on Introduction to the Special Issue on Linking Social Granularity and Functions Authors: Qi He LinkedIn LinkedInView Profile , Juanzi Li Tsinghua University Tsinghua UniversityView Profile , Rong Yan Square SquareView Profile , John Yen Pennsylvania State University Pennsylvania State UniversityView Profile , Haizheng Zhang StarMerx LLC StarMerx LLCView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 5Issue 2Article No.: 22pp 1–3https://doi.org/10.1145/2594452Published:30 April 2014Publication History 2citation322DownloadsMetricsTotal Citations2Total Downloads322Last 12 Months4Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Publisher SiteeReaderPDF",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1976320948",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on computational sustainability",
    "doi": "https://doi.org/10.1145/1989734.1989735",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Carla Gomes; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1989210333",
    "type": "article"
  },
  {
    "title": "Relational term-suggestion graphs incorporating multipartite concept and expertise networks",
    "doi": "https://doi.org/10.1145/2542182.2542201",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Jyh-Ren Shieh; Ching‐Yung Lin; Shun-Xuan Wang; Ja‐Ling Wu",
    "corresponding_authors": "",
    "abstract": "Term suggestions recommend query terms to a user based on his initial query. Suggesting adequate terms is a challenging issue. Most existing commercial search engines suggest search terms based on the frequency of prior used terms that match the leading alphabets the user types. In this article, we present a novel mechanism to construct semantic term-relation graphs to suggest relevant search terms in the semantic level. We built term-relation graphs based on multipartite networks of existing social media, especially from Wikipedia. The multipartite linkage networks of contributor-term, term-category, and term-term are extracted from Wikipedia to eventually form term relation graphs. For fusing these multipartite linkage networks, we propose to incorporate the contributor-category networks to model the expertise of the contributors. Based on our experiments, this step has demonstrated clear enhancement on the accuracy of the inferred relatedness of the term-semantic graphs. Experiments on keyword-expanded search based on 200 TREC-5 ad-hoc topics showed obvious advantage of our algorithms over existing approaches.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2018460791",
    "type": "article"
  },
  {
    "title": "Optimization-based influencing of village social networks in a counterinsurgency",
    "doi": "https://doi.org/10.1145/2483669.2483685",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Benjamin W. K. Hung; Stephan Kolitz; Asuman Ozdaglar",
    "corresponding_authors": "",
    "abstract": "This article considers the nonlethal targeting assignment problem in the counterinsurgency in Afghanistan, the problem of deciding on the people whom U.S. forces should engage through outreach, negotiations, meetings, and other interactions in order to ultimately win the support of the population in their area of operations. We propose two models: (1) the Afghan counterinsurgency (COIN) social influence model, to represent how attitudes of local leaders are affected by repeated interactions with other local leaders, insurgents, and counterinsurgents, and (2) the nonlethal targeting model, a NonLinear Programming (NLP) optimization formulation that identifies a strategy for assigning k U.S. agents to produce the greatest arithmetic mean of the expected long-term attitude of the population. We demonstrate in an experiment the merits of the optimization model in nonlethal targeting, which performs significantly better than both doctrine-based and random methods of assignment in a large network.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2036271530",
    "type": "article"
  },
  {
    "title": "An Evaluation of Gamesourced Data for Human Pose Estimation",
    "doi": "https://doi.org/10.1145/2629465",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Scott Spurlock; Richard Souvenir",
    "corresponding_authors": "",
    "abstract": "Gamesourcing has emerged as an approach for rapidly acquiring labeled data for learning-based, computer vision recognition algorithms. In this article, we present an approach for using RGB-D sensors to acquire annotated training data for human pose estimation from 2D images. Unlike other gamesourcing approaches, our method does not require a specific game, but runs alongside any gesture-based game using RGB-D sensors. The automatically generated datasets resulting from this approach contain joint estimates within a few pixel units of manually labeled data, and a gamesourced dataset created using a relatively small number of players, games, and locations performs as well as large-scale, manually annotated datasets when used as training data with recent learning-based human pose estimation methods for 2D images.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2038833414",
    "type": "article"
  },
  {
    "title": "Pattern Matching Techniques for Replacing Missing Sections of Audio Streamed across Wireless Networks",
    "doi": "https://doi.org/10.1145/2663358",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Jonathan Doherty; Kevin Curran; Paul McKevitt",
    "corresponding_authors": "",
    "abstract": "Streaming media on the Internet can be unreliable. Services such as audio-on-demand drastically increase the loads on networks; therefore, new, robust, and highly efficient coding algorithms are necessary. One method overlooked to date, which can work alongside existing audio compression schemes, is that which takes into account the semantics and natural repetition of music. Similarity detection within polyphonic audio has presented problematic challenges within the field of music information retrieval. One approach to deal with bursty errors is to use self-similarity to replace missing segments. Many existing systems exist based on packet loss and replacement on a network level, but none attempt repairs of large dropouts of 5 seconds or more. Music exhibits standard structures that can be used as a forward error correction (FEC) mechanism. FEC is an area that addresses the issue of packet loss with the onus of repair placed as much as possible on the listener's device. We have developed a server--client-based framework (SoFI) for automatic detection and replacement of large packet losses on wireless networks when receiving time-dependent streamed audio. Whenever dropouts occur, SoFI swaps audio presented to the listener between a live stream and previous sections of the audio stored locally. Objective and subjective evaluations of SoFI where subjects were presented with other simulated approaches to audio repair together with simulations of replacements including varying lengths of time in the repair give positive results.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2043810700",
    "type": "article"
  },
  {
    "title": "Metastrategies in Large-Scale Bargaining Settings",
    "doi": "https://doi.org/10.1145/2774224",
    "publication_date": "2015-10-01",
    "publication_year": 2015,
    "authors": "Daniel Hennes; Steven de Jong; Karl Tuyls; Kobi Gal",
    "corresponding_authors": "",
    "abstract": "This article presents novel methods for representing and analyzing a special class of multiagent bargaining settings that feature multiple players, large action spaces, and a relationship among players’ goals, tasks, and resources. We show how to reduce these interactions to a set of bilateral normal-form games in which the strategy space is significantly smaller than the original settings while still preserving much of their structural relationship. The method is demonstrated using the Colored Trails (CT) framework, which encompasses a broad family of games and has been used in many past studies. We define a set of heuristics (metastrategies) in multiplayer CT games that make varying assumptions about players’ strategies, such as boundedly rational play and social preferences. We show how these CT settings can be decomposed into canonical bilateral games such as the Prisoners’ Dilemma, Stag Hunt, and Ultimatum games in a way that significantly facilitates their analysis. We demonstrate the feasibility of this approach in separate CT settings involving one-shot and repeated bargaining scenarios, which are subsequently analyzed using evolutionary game-theoretic techniques. We provide a set of necessary conditions for CT games for allowing this decomposition. Our results have significance for multiagent systems researchers in mapping large multiplayer CT task settings to smaller, well-known bilateral normal-form games while preserving some of the structure of the original setting.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2080042700",
    "type": "article"
  },
  {
    "title": "Real-Time Bid Optimization for Group-Buying Ads",
    "doi": "https://doi.org/10.1145/2532441",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Raju Balakrishnan; Rushi Bhatt",
    "corresponding_authors": "",
    "abstract": "Group-buying ads seeking a minimum number of customers before the deal expiry are increasingly used by daily-deal providers. Unlike traditional web ads, the advertiser’s profits for group-buying ads depend on the time to expiry and additional customers needed to satisfy the minimum group size. Since both these quantities are time-dependent, optimal bid amounts to maximize profits change with every impression. Consequently, traditional static bidding strategies are far from optimal. Instead, bid values need to be optimized in real-time to maximize expected bidder profits. This online optimization of deal profits is made possible by the advent of ad exchanges offering real-time (spot) bidding. To this end, we propose a real-time bidding strategy for group-buying deals based on the online optimization of bid values. We derive the expected bidder profit of deals as a function of the bid amounts and dynamically vary the bids to maximize profits. Furthermore, to satisfy time constraints of the online bidding, we present methods of minimizing computation timings. Subsequently, we derive the real-time ad selection, admissibility, and real-time bidding of the traditional ads as the special cases of the proposed method. We evaluate the proposed bidding, selection, and admission strategies on a multimillion click stream of 935 ads. The proposed real-time bidding, selection, and admissibility show significant profit increases over the existing strategies. Further experiments illustrate the robustness of the bidding and acceptable computation timings.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2115496895",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue on intelligent systems for activity recognition",
    "doi": "https://doi.org/10.1145/1889681.1889682",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Daqing Zhang; Matthai Philipose; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the special issue on intelligent systems for activity recognition Authors: Daqing Zhang Institut TELECOM & Management SudParis, France Institut TELECOM & Management SudParis, FranceView Profile , Matthai Philipose Intel Research Laboratory at Seattle, USA Intel Research Laboratory at Seattle, USAView Profile , Qiang Yang Hong Kong University of Science and Technology, Hong Kong Hong Kong University of Science and Technology, Hong KongView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 2Issue 1Article No.: 1pp 1–4https://doi.org/10.1145/1889681.1889682Published:24 January 2011Publication History 2citation536DownloadsMetricsTotal Citations2Total Downloads536Last 12 Months2Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2154147539",
    "type": "article"
  },
  {
    "title": "Automated Pricing in a Multiagent Prediction Market Using a Partially Observable Stochastic Game",
    "doi": "https://doi.org/10.1145/2700488",
    "publication_date": "2015-07-29",
    "publication_year": 2015,
    "authors": "Janyl Jumadinova; Prithviraj Dasgupta",
    "corresponding_authors": "",
    "abstract": "Prediction markets offer an efficient market-based mechanism to aggregate large amounts of dispersed or distributed information from different people to predict the possible outcome of future events. Recently, automated prediction markets where software trading agents perform market operations such as trading and updating beliefs on behalf of humans have been proposed. A challenging aspect in automated prediction markets is to develop suitable techniques that can be used by automated trading agents to update the price at which they should trade securities related to an event so that they can increase their profit. This problem is nontrivial, as the decision to trade and the price at which trading should occur depends on several dynamic factors, such as incoming information related to the event for which the security is being traded, the belief-update mechanism and risk attitude of the trading agent, and the trading decision and trading prices of other agents. To address this problem, we have proposed a new behavior model for trading agents based on a game-theoretic framework called partially observable stochastic game with information (POSGI). We propose a correlated equilibrium (CE)-based solution strategy for this game that allows each agent to dynamically choose an action (to buy or sell or hold) in the prediction market. We have also performed extensive simulation experiments using the data obtained from the Intrade prediction market for four different prediction markets. Our results show that our POSGI model and CE strategy produces prices that are strongly correlated with the prices of the real prediction markets. Results comparing our CE strategy with five other strategies commonly used in similar market show that our CE strategy improves price predictions and provides higher utilities to the agents compared to other existing strategies.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2215880583",
    "type": "article"
  },
  {
    "title": "Smart Colonography for Distributed Medical Databases with Group Kernel Feature Analysis",
    "doi": "https://doi.org/10.1145/2668136",
    "publication_date": "2015-07-27",
    "publication_year": 2015,
    "authors": "Yuichi Motai; Dingkun Ma; Alen Docef; Hiroyuki Yoshida",
    "corresponding_authors": "",
    "abstract": "Computer-Aided Detection (CAD) of polyps in Computed Tomographic (CT) colonography is currently very limited since a single database at each hospital/institution doesn't provide sufficient data for training the CAD system's classification algorithm. To address this limitation, we propose to use multiple databases, (e.g., big data studies) to create multiple institution-wide databases using distributed computing technologies, which we call smart colonography. Smart colonography may be built by a larger colonography database networked through the participation of multiple institutions via distributed computing. The motivation herein is to create a distributed database that increases the detection accuracy of CAD diagnosis by covering many true-positive cases. Colonography data analysis is mutually accessible to increase the availability of resources so that the knowledge of radiologists is enhanced. In this article, we propose a scalable and efficient algorithm called Group Kernel Feature Analysis (GKFA), which can be applied to multiple cancer databases so that the overall performance of CAD is improved. The key idea behind the proposed GKFA method is to allow the feature space to be updated as the training proceeds with more data being fed from other institutions into the algorithm. Experimental results show that GKFA achieves very good classification accuracy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2248316562",
    "type": "article"
  },
  {
    "title": "Soter",
    "doi": "https://doi.org/10.1145/2700483",
    "publication_date": "2015-07-10",
    "publication_year": 2015,
    "authors": "Yanfang Ye; Tao Li; Haiyin Shen",
    "corresponding_authors": "",
    "abstract": "In recent years, crimes against children and cases of missing children have increased at a high rate. Therefore, there is an urgent need for safety support systems to prevent crimes against children or for antiloss, especially when parents are not with their children, such as to and from school. However, existing children’s tracking systems are not smart enough to provide the safety supports, as they simply locate the children’s positions without offering any notification to parents that their children may be in danger. In addition, there is limited research on children’s tracking and their antiloss. In this article, based on location histories, we introduce novel notions of children’s life patterns that capture their general lifestyles and regularities, and develop an intelligent data mining framework to learn the safe regions and safe routes of children on the cloud side. When the children may be in danger, their parents will receive automatic notifications from the cloud. We also propose an effective energy-efficient positioning scheme that leverages the location tracking accuracy of the children while keeping energy overhead low by using a hybrid global positioning system and a global system for mobile communications. To the best of our knowledge, this is the first attempt in applying data mining techniques to applications designed for children’s safety. Our proposed techniques have been incorporated into Soter , a children’s safeguard system that is used to provide cloud service for smart bracelets produced by Qihoo. The case studies on real smart bracelet users of Qihoo demonstrate the effectiveness of our proposed methods and Soter for children’s safety.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2250872537",
    "type": "article"
  },
  {
    "title": "Leveraging Human Computations to Improve Schematization of Spatial Relations from Imagery",
    "doi": "https://doi.org/10.1145/2873065",
    "publication_date": "2016-03-31",
    "publication_year": 2016,
    "authors": "Huaming Rao; Shih‐Wen Huang; Wai‐Tat Fu",
    "corresponding_authors": "",
    "abstract": "The process of generating schematic maps of salient objects from a set of pictures of an indoor environment is challenging. It has been an active area of research as it is crucial to a wide range of context- and location-aware services, as well as for general scene understanding. Although many automated systems have been developed to solve the problem, most of them either require predefining labels or expensive equipment, such as RGBD sensors or lasers, to scan the environment. In this article, we introduce a prototype system to show how human computations can be utilized to generate schematic maps from a set of pictures, without making strong assumptions or demanding extra devices. The system requires humans (crowd workers from Amazon Mechanical Turks) to do simple spatial mapping tasks in various conditions, and their data are aggregated by filtering and clustering techniques that allow salient cues to be identified in the pictures and their spatial relations to be inferred and projected on a two-dimensional map. In particular, we tested and demonstrated the effectiveness of two methods that improved the quality of the generated schematic map: (1) We encouraged humans to adopt an allocentric representations of salient objects by guiding them to perform mental rotations of these objects and (2) we sensitized human perception by guided arrows superimposed on the imagery to improve the accuracy of depth and width estimation. We demonstrated the feasibility of our system by evaluating the results of schematic maps generated from indoor pictures taken from an office building. By calculating Riemannian shape distances between the generated maps to the ground truth, we found that the generated schematic maps captured the spatial relations well. Our results showed that the combination of human computations and machine clustering could lead to more-accurate schematized maps from imagery. We also discuss how our approach may have important insights on methods that leverage human computations in other areas.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2317090216",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1889681",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The advance of GPS-enabled devices allows people to record their location histories with GPS traces, which imply human behaviors and preferences related to travel. In this article, we perform two types of travel recommendations by mining multiple users' ...",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4231019889",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2764959",
    "publication_date": "2015-05-20",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4255136483",
    "type": "paratext"
  },
  {
    "title": "Introduction to the ACM TIST special issue AI in social computing and cultural modeling",
    "doi": "https://doi.org/10.1145/1858948.1858950",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Huan Liu; Dana Nau",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2046853485",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Search and Mining User-Generated Content",
    "doi": "https://doi.org/10.1145/2337542.2337550",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "José Carlos Cortizo; Francisco M. Carrero; Iván Cantador; José A. Troyano; Paolo Rosso",
    "corresponding_authors": "",
    "abstract": "The primary goal of this special section of ACM Transactions on Intelligent Systems and Technology is to foster research in the interplay between Social Media, Data/Opinion Mining and Search, aiming to reflect the actual developments in technologies that exploit user-generated content.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2050419808",
    "type": "article"
  },
  {
    "title": "Leveraging Auxiliary Data for Learning to Rank",
    "doi": "https://doi.org/10.1145/2089094.2089113",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Ke Zhou; Jing Bai; Hongyuan Zha; Gui-Rong Xue",
    "corresponding_authors": "",
    "abstract": "In learning to rank, both the quality and quantity of the training data have significant impacts on the performance of the learned ranking functions. However, in many applications, there are usually not sufficient labeled training data for the construction of an accurate ranking model. It is therefore desirable to leverage existing training data from other tasks when learning the ranking function for a particular task, an important problem which we tackle in this article utilizing a boosting framework with transfer learning . In particular, we propose to adaptively learn transferable representations called super-features from the training data of both the target task and the auxiliary task. Those super-features and the coefficients for combining them are learned in an iterative stage-wise fashion. Unlike previous transfer learning methods, the super-features can be adaptively learned by weak learners from the data. Therefore, the proposed framework is sufficiently flexible to deal with complicated common structures among different learning tasks. We evaluate the performance of the proposed transfer learning method for two datasets from the Letor collection and one dataset collected from a commercial search engine, and we also compare our methods with several existing transfer learning methods. Our results demonstrate that the proposed method can enhance the ranking functions of the target tasks utilizing the training data from the auxiliary tasks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2082624265",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on the 2nd Asia Conference on Machine Learning (ACML 2010)",
    "doi": "https://doi.org/10.1145/2089094.2089103",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Masashi Sugiyama; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2098231662",
    "type": "article"
  },
  {
    "title": "Linking Multiple User Identities of Multiple Services from Massive Mobility Traces",
    "doi": "https://doi.org/10.1145/3439817",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Huandong Wang; Yong Li; Gang Wang; Depeng Jin",
    "corresponding_authors": "",
    "abstract": "Understanding the linkability of online user identifiers (IDs) is critical to both service providers (for business intelligence) and individual users (for assessing privacy risks). Existing methods are designed to match IDs across two services but face key challenges of matching multiple services in practice, particularly when users have multiple IDs per service. In this article, we propose a novel system to link IDs across multiple services by exploring the spatial-temporal features of user activities, of which the core idea is that the same user's online IDs are more likely to repeatedly appear at the same location. Specifically, we first utilize a contact graph to capture the “co-location” of all IDs across multiple services. Based on this graph, we propose a set-wise matching algorithm to discover candidate ID sets and use Bayesian inference to generate confidence scores for candidate ranking, which is proved to be optimal. We evaluate our system using two real-world ground-truth datasets from an Internet service provider (4 services, 815K IDs) and Twitter-Foursquare (2 services, 770 IDs). Extensive results show that our system significantly outperforms the state-of-the-art algorithms in accuracy (AUC is higher by 0.1–0.2), and it is highly robust against data quality, matching order, and number of services.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3194295794",
    "type": "article"
  },
  {
    "title": "DILSA+: Predicting Urban Dispersal Events through Deep Survival Analysis with Enhanced Urban Features",
    "doi": "https://doi.org/10.1145/3469085",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Amin Vahedian Khezerlou; Xun Zhou; Xinyi Li; W. Nick Street; Yanhua Li",
    "corresponding_authors": "",
    "abstract": "Urban dispersal events occur when an unexpectedly large number of people leave an area in a relatively short period of time. It is beneficial for the city authorities, such as law enforcement and city management, to have an advance knowledge of such events, as it can help them mitigate the safety risks and handle important challenges such as managing traffic, and so forth. Predicting dispersal events is also beneficial to Taxi drivers and/or ride-sharing services, as it will help them respond to an unexpected demand and gain competitive advantage. Large urban datasets such as detailed trip records and point of interest ( POI ) data make such predictions achievable. The related literature mainly focused on taxi demand prediction. The pattern of the demand was assumed to be repetitive and proposed methods aimed at capturing those patterns. However, dispersal events are, by definition, violations of those patterns and are, understandably, missed by the methods in the literature. We proposed a different approach in our prior work [32]. We showed that dispersal events can be predicted by learning the complex patterns of arrival and other features that precede them in time. We proposed a survival analysis formulation of this problem and proposed a two-stage framework (DILSA), where a deep learning model predicted the survival function at each point in time in the future. We used that prediction to determine the time of the dispersal event in the future, or its non-occurrence. However, DILSA is subject to a few limitations. First, based on evidence from the data, mobility patterns can vary through time at a given location. DILSA does not distinguish between different mobility patterns through time. Second, mobility patterns are also different for different locations. DILSA does not have the capability to directly distinguish between different locations based on their mobility patterns. In this article, we address these limitations by proposing a method to capture the interaction between POIs and mobility patterns and we create vector representations of locations based on their mobility patterns. We call our new method DILSA+. We conduct extensive case studies and experiments on the NYC Yellow taxi dataset from 2014 to 2016. Results show that DILSA+ can predict events in the next 5 hours with an F1-score of 0.66. It is significantly better than DILSA and the state-of-the-art deep learning approaches for taxi demand prediction.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3194471736",
    "type": "article"
  },
  {
    "title": "TLDS: A Transfer-Learning-Based Delivery Station Location Selection Pipeline",
    "doi": "https://doi.org/10.1145/3469084",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Chenyu Hou; Bin Cao; Sijie Ruan; Jing Fan",
    "corresponding_authors": "",
    "abstract": "Delivery stations play important roles in logistics systems. Well-designed delivery station planning can improve delivery efficiency significantly. However, existing delivery station locations are decided by experts, which requires much preliminary research and data collection work. It is not only time consuming but also expensive for logistics companies. Therefore, in this article, we propose a data-driven pipeline that can transfer expert knowledge among cities and automatically allocate delivery stations. Based on existing well-designed station location planning in the source city, we first train a model to learn the expert knowledge about delivery range selection for each station. Then we transfer the learned knowledge to a new city and design three strategies to select delivery stations for the new city. Due to the differences in characteristics among different cities, we adopt a transfer learning method to eliminate the domain difference so that the model can be adapted to a new city well. Finally, we conduct extensive experiments based on real-world datasets and find the proposed method can solve the problem well.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3194554490",
    "type": "article"
  },
  {
    "title": "Collaborative Local-Global Learning for Temporal Action Proposal",
    "doi": "https://doi.org/10.1145/3466181",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Yisheng Zhu; Hu Han; Guangcan Liu; Qingshan Liu",
    "corresponding_authors": "",
    "abstract": "Temporal action proposal generation is an essential and challenging task in video understanding, which aims to locate the temporal intervals that likely contain the actions of interest. Although great progress has been made, the problem is still far from being well solved. In particular, prevalent methods can handle well only the local dependencies (i.e., short-term dependencies) among adjacent frames but are generally powerless in dealing with the global dependencies (i.e., long-term dependencies) between distant frames. To tackle this issue, we propose CLGNet, a novel Collaborative Local-Global Learning Network for temporal action proposal. The majority of CLGNet is an integration of Temporal Convolution Network and Bidirectional Long Short-Term Memory, in which Temporal Convolution Network is responsible for local dependencies while Bidirectional Long Short-Term Memory takes charge of handling the global dependencies. Furthermore, an attention mechanism called the background suppression module is designed to guide our model to focus more on the actions. Extensive experiments on two benchmark datasets, THUMOS’14 and ActivityNet-1.3, show that the proposed method can outperform state-of-the-art methods, demonstrating the strong capability of modeling the actions with varying temporal durations.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3203819690",
    "type": "article"
  },
  {
    "title": "How Members of Covert Networks Conceal the Identities of Their Leaders",
    "doi": "https://doi.org/10.1145/3490462",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Marcin Waniek; Tomasz Michalak; Michael Wooldridge; Talal Rahwan",
    "corresponding_authors": "",
    "abstract": "Centrality measures are the most commonly advocated social network analysis tools for identifying leaders of covert organizations. While the literature has predominantly focused on studying the effectiveness of existing centrality measures or developing new ones, we study the problem from the opposite perspective, by focusing on how a group of leaders can avoid being identified by centrality measures as key members of a covert network. More specifically, we analyze the problem of choosing a set of edges to be added to a network to decrease the leaders’ ranking according to three fundamental centrality measures, namely, degree, closeness, and betweenness. We prove that this problem is NP-complete for each measure. Moreover, we study how the leaders can construct a network from scratch, designed specifically to keep them hidden from centrality measures. We identify a network structure that not only guarantees to hide the leaders to a certain extent but also allows them to spread their influence across the network.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3216665393",
    "type": "article"
  },
  {
    "title": "KOMPOS: Connecting Causal Knots in Large Nonlinear Time Series with Non-Parametric Regression Splines",
    "doi": "https://doi.org/10.1145/3480971",
    "publication_date": "2021-10-31",
    "publication_year": 2021,
    "authors": "Georgios Koutroulis; Leo Botler; Belgin Mutlu; Konrad Diwold; Kay Römer; Roman Kern",
    "corresponding_authors": "",
    "abstract": "Recovering causality from copious time series data beyond mere correlations has been an important contributing factor in numerous scientific fields. Most existing works assume linearity in the data that may not comply with many real-world scenarios. Moreover, it is usually not sufficient to solely infer the causal relationships. Identifying the correct time delay of cause-effect is extremely vital for further insight and effective policies in inter-disciplinary domains. To bridge this gap, we propose KOMPOS, a novel algorithmic framework that combines a powerful concept from causal discovery of additive noise models with graphical ones. We primarily build our structural causal model from multivariate adaptive regression splines with inherent additive local nonlinearities, which render the underlying causal structure more easily identifiable. In contrast to other methods, our approach is not restricted to Gaussian or non-Gaussian noise due to the non-parametric attribute of the regression method. We conduct extensive experiments on both synthetic and real-world datasets, demonstrating the superiority of the proposed algorithm over existing causal discovery methods, especially for the challenging cases of autocorrelated and non-stationary time series.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3217031555",
    "type": "article"
  },
  {
    "title": "A Distribution Separation Method Using Irrelevance Feedback Data for Information Retrieval",
    "doi": "https://doi.org/10.1145/2994608",
    "publication_date": "2017-01-12",
    "publication_year": 2017,
    "authors": "Peng Zhang; Qian Yu; Yuexian Hou; Dawei Song; Jingfei Li; Bin Hu",
    "corresponding_authors": "",
    "abstract": "In many research and application areas, such as information retrieval and machine learning, we often encounter dealing with a probability distribution that is mixed by one distribution that is relevant to our task in hand and the other that is irrelevant and that we want to get rid of. Thus, it is an essential problem to separate the irrelevant distribution from the mixture distribution. This article is focused on the application in Information Retrieval, where relevance feedback is a widely used technique to build a refined query model based on a set of feedback documents. However, in practice, the relevance feedback set, even provided by users explicitly or implicitly, is often a mixture of relevant and irrelevant documents. Consequently, the resultant query model (typically a term distribution) is often a mixture rather than a true relevance term distribution, leading to a negative impact on the retrieval performance. To tackle this problem, we recently proposed a Distribution Separation Method (DSM), which aims to approximate the true relevance distribution by separating a seed irrelevance distribution from the mixture one. While it achieved a promising performance in an empirical evaluation with simulated explicit irrelevance feedback data, it has not been deployed in the scenario where one should automatically obtain the irrelevance feedback data. In this article, we propose a substantial extension of the basic DSM from two perspectives: developing a further regularization framework and deploying DSM in the automatic irrelevance feedback scenario. Specifically, in order to avoid the output distribution of DSM drifting away from the true relevance distribution when the quality of seed irrelevant distribution (as the input to DSM) is not guaranteed, we propose a DSM regularization framework to constrain the estimation for the relevance distribution. This regularization framework includes three algorithms, each corresponding to a regularization strategy incorporated in the objective function of DSM. In addition, we exploit DSM in automatic (i.e., pseudo) irrelevance feedback, by automatically detecting the seed irrelevant documents via three different document reranking methods. We have carried out extensive experiments based on various TREC datasets, in order to systematically evaluate the proposed methods. The experimental results demonstrate the effectiveness of our proposed approaches in comparison with various strong baselines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2561605715",
    "type": "article"
  },
  {
    "title": "Iteratively Divide-and-Conquer Learning for Nonlinear Classification and Ranking",
    "doi": "https://doi.org/10.1145/3122802",
    "publication_date": "2017-10-23",
    "publication_year": 2017,
    "authors": "Ou Wu; Xue Mao; Weiming Hu",
    "corresponding_authors": "",
    "abstract": "Nonlinear classifiers (i.e., kernel support vector machines (SVMs)) are effective for nonlinear data classification. However, nonlinear classifiers are usually prohibitively expensive when dealing with large nonlinear data. Ensembles of linear classifiers have been proposed to address this inefficiency, which is called the ensemble linear classifiers for nonlinear data problem. In this article, a new iterative learning approach is introduced that involves two steps at each iteration: partitioning the data into clusters according to Gaussian mixture models with local consistency and then training basic classifiers (i.e., linear SVMs) for each cluster. The two divide-and-conquer steps are combined into a graphical model. Meanwhile, with training, each classifier is regarded as a task; clustered multitask learning is employed to capture the relatedness among different tasks and avoid overfitting in each task. In addition, two novel extensions are introduced based on the proposed approach. First, the approach is extended for quality-aware web data classification. In this problem, the types of web data vary in terms of information quality. The ignorance of the variations of information quality of web data leads to poor classification models. The proposed approach can effectively integrate quality-aware factors into web data classification. Second, the approach is extended for listwise learning to rank to construct an ensemble of linear ranking models, whereas most existing listwise ranking methods construct a solely linear ranking model. Experimental results on benchmark datasets show that our approach outperforms state-of-the-art algorithms. During prediction for nonlinear classification, it also obtains comparable classification performance to kernel SVMs, with much higher efficiency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2767131247",
    "type": "article"
  },
  {
    "title": "オンラインポートフォリオ選択のための組合せ予測復帰戦略【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Ding-jiang Huang; Yu Shunchang; Li Bin; C H Hoi Steven; Shuigeng Zhou",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3149503871",
    "type": "article"
  },
  {
    "title": "Efficient User Guidance for Validating Participatory Sensing Data",
    "doi": "https://doi.org/10.1145/3326164",
    "publication_date": "2019-07-17",
    "publication_year": 2019,
    "authors": "Phan Thanh Cong; Thành Tâm Nguyên; Hongzhi Yin; Bolong Zheng; Bela Stantić; Quoc Viet Hung Nguyen",
    "corresponding_authors": "",
    "abstract": "Participatory sensing has become a new data collection paradigm that leverages the wisdom of the crowd for big data applications without spending cost to buy dedicated sensors. It collects data from human sensors by using their own devices such as cell phone accelerometers, cameras, and GPS devices. This benefit comes with a drawback: human sensors are arbitrary and inherently uncertain due to the lack of quality guarantee. Moreover, participatory sensing data are time series that exhibit not only highly irregular dependencies on time but also high variance between sensors. To overcome these limitations, we formulate the problem of validating uncertain time series collected by participatory sensors. In this article, we approach the problem by an iterative validation process on top of a probabilistic time series model. First, we generate a series of probability distributions from raw data by tailoring a state-of-the-art dynamical model, namely &lt;u&gt;G&lt;/u&gt;eneralised &lt;u&gt;A&lt;/u&gt;uto &lt;u&gt;R&lt;/u&gt;egressive &lt;u&gt;C&lt;/u&gt;onditional &lt;u&gt;H&lt;/u&gt;eteroskedasticity (GARCH), for our joint time series setting. Second, we design a feedback process that consists of an adaptive aggregation model to unify the joint probabilistic time series and an efficient user guidance model to validate aggregated data with minimal effort. Through extensive experimentation, we demonstrate the efficiency and effectiveness of our approach on both real data and synthetic data. Highlights from our experiences include the fast running time of a probabilistic model, the robustness of an aggregation model to outliers, and the significant effort saving of a guidance model.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2962706255",
    "type": "article"
  },
  {
    "title": "Local Learning Approaches for Finding Effects of a Specified Cause and Their Causal Paths",
    "doi": "https://doi.org/10.1145/3313147",
    "publication_date": "2019-09-12",
    "publication_year": 2019,
    "authors": "Yue Liu; Zheng Cai; Chunchen Liu; Zhi Geng",
    "corresponding_authors": "",
    "abstract": "Causal networks are used to describe and to discover causal relationships among variables and data generating mechanisms. There have been many approaches for learning a global causal network of all observed variables. In many applications, we may be interested in finding what are the effects of a specified cause variable and what are the causal paths from the cause variable to its effects. Instead of learning a global causal network, we propose several local learning approaches for finding all effects (or descendants) of the specified cause variable and the causal paths from the cause variable to some effect variable of interest. We discuss the identifiability of the effects and the causal paths from observed data and prior knowledge. For the case that the causal paths are not identifiable, our approaches try to find a path set that contains the causal paths of interest.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2972323282",
    "type": "article"
  },
  {
    "title": "BiNeTClus",
    "doi": "https://doi.org/10.1145/3423067",
    "publication_date": "2020-11-13",
    "publication_year": 2020,
    "authors": "Mohamed Bouguessa; Khaled Nouri",
    "corresponding_authors": "",
    "abstract": "We investigate the problem of community detection in bipartite networks that are characterized by the presence of two types of nodes such that connections exist only between nodes of different types. While some approaches have been proposed to identify community structures in bipartite networks, there are a number of problems still to solve. In fact, the majority of the proposed approaches suffer from one or even more of the following limitations: (1) difficulty in detecting communities in the presence of many non-discriminating nodes with atypical connections that hide the community structures, (2) loss of relevant topological information due to the transformation of the bipartite network to standard plain graphs, and (3) manually specifying several input parameters, including the number of communities to be identified. To alleviate these problems, we propose BiNeTClus, a parameter-free community detection algorithm in bipartite networks that operates in two phases. The first phase focuses on identifying an initial grouping of nodes through a transactional data model capable of dealing with the situation that involves networks with many atypical connections, that is, sparsely connected nodes and nodes of one type that massively connect to all other nodes of the second type. The second phase aims to refine the clustering results of the first phase via an optimization strategy of the bipartite modularity to identify the final community structures. Our experiments on both synthetic and real networks illustrate the suitability of the proposed approach.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3110535306",
    "type": "article"
  },
  {
    "title": "A Query Optimizer for Range Queries over Multi-Attribute Trajectories",
    "doi": "https://doi.org/10.1145/3555811",
    "publication_date": "2022-09-10",
    "publication_year": 2022,
    "authors": "Jianqiu Xu; Hua Lu; Zhifeng Bao",
    "corresponding_authors": "",
    "abstract": "A multi-attribute trajectory consists of a spatio-temporal trajectory and a set of descriptive attributes. Such data enrich the representation of traditional spatio-temporal trajectories to have comprehensive knowledge of moving objects. Range query is a fundamental operator over multi-attribute trajectories. Such a query contains two predicates, spatio-temporal and attribute, and returns the objects whose locations are within a distance threshold to the query trajectory and attributes contain expected values. There are different execution plans for answering the query. To enhance the capability of a trajectory database, an optimizer is essentially required to (i) accurately estimate the cost for alternative query strategies in terms of disk accesses, (ii) build a decision-making module that automatically sorts the data in an appropriate way and selects the optimal query plan, and (iii) update the analytical models when new trajectories are arrived. The cost model supports both uniform and non-uniform spatio-temporal data distribution and incorporates attribute distribution. The optimizer is fully developed inside a database system kernel and comprehensively evaluated in terms of accuracy and effectiveness by using large real and synthetic datasets.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4296270293",
    "type": "article"
  },
  {
    "title": "3D-Guided Frontal Face Generation for Pose-Invariant Recognition",
    "doi": "https://doi.org/10.1145/3572035",
    "publication_date": "2022-11-21",
    "publication_year": 2022,
    "authors": "Hao Wu; Jianyang Gu; Xiaojin Fan; He Li; Lidong Xie; Jian Zhao",
    "corresponding_authors": "",
    "abstract": "Although deep learning techniques have achieved extraordinary accuracy in recognizing human faces, the pose variances of images captured in real-world scenarios still hinder reliable model appliance. To mitigate this gap, we propose to recognize faces via generation frontal face images with a 3D -Guided Deep P ose- I nvariant Face Recognition M odel (3D-PIM) consisted of a simulator and a refiner module. The simulator employs a 3D Morphable Model (3D MM) to fit the shape and appearance features and recover primary frontal images with less training data. The refiner further enhances the image realism on both global facial structure and local details with adversarial training, while keeping the discriminative identity information consistent with original images. An Adaptive Weighting (AW) metric is then adopted to leverage the complimentary information from recovered frontal faces and original profile faces and to obtain credible similarity scores for recognition. Extended experiments verify the superiority of the proposed “recognition via generation” framework over state-of-the-art.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4309756925",
    "type": "article"
  },
  {
    "title": "Location- and Query-Aware Modeling of Browsing and Click Behavior in Sponsored Search",
    "doi": "https://doi.org/10.1145/2534398",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Azin Ashkan; Charles L. A. Clarke",
    "corresponding_authors": "",
    "abstract": "An online advertisement’s clickthrough rate provides a fundamental measure of its quality, which is widely used in ad selection strategies. Unfortunately, ads placed in contexts where they are rarely viewed—or where users are unlikely to be interested in commercial results—may receive few clicks regardless of their quality. In this article, we model the variability of a user’s browsing behavior for the purpose of click analysis and prediction in sponsored search. Our model incorporates several important contextual factors that influence ad clickthrough rates, including the user’s query and ad placement on search engine result pages. We formally model these factors with respect to the list of ads displayed on a result page, the probability that the user will initiate browsing of this list, and the persistence of the user in browsing the list. We incorporate these factors into existing click models by augmenting them with appropriate query and location biases. Using expectation maximization, we learn the parameters of these augmented models from click signals recorded in the logs of a commercial search engine. To evaluate the performance of the models and to compare them with state-of-the-art performance, we apply standard evaluation metrics, including log-likelihood and perplexity. Our evaluation results indicate that, through the incorporation of query and location biases, significant improvements can be achieved in predicting browsing and click behavior in sponsored search. In addition, we explore the extent to which these biases actually reflect varying behavioral patterns. Our observations confirm that correlations exist between the biases and user search behavior.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2094190061",
    "type": "article"
  },
  {
    "title": "Preface to the ACM TIST Special Issue on Causal Discovery and Inference",
    "doi": "https://doi.org/10.1145/2840720",
    "publication_date": "2016-01-09",
    "publication_year": 2016,
    "authors": "Kun Zhang; Jiuyong Li; Elias Bareinboim; Bernhard Schölkopf; Judea Pearl",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Preface to the ACM TIST Special Issue on Causal Discovery and Inference Authors: Kun Zhang Max-Planck Institute for Intelligent Systems, Germany Max-Planck Institute for Intelligent Systems, GermanyView Profile , Jiuyong Li University of South Australia, Australia University of South Australia, AustraliaView Profile , Elias Bareinboim University of California, Los Angeles, CA University of California, Los Angeles, CAView Profile , Bernhard Schölkopf Max-Planck Institute for Intelligent Systems, Germany Max-Planck Institute for Intelligent Systems, GermanyView Profile , Judea Pearl University of California, Los Angeles, CA University of California, Los Angeles, CAView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 7Issue 2January 2016 Article No.: 17pp 1–3https://doi.org/10.1145/2840720Published:09 January 2016Publication History 4citation265DownloadsMetricsTotal Citations4Total Downloads265Last 12 Months26Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2254968119",
    "type": "article"
  },
  {
    "title": "Sharp Bounds on Survivor Average Causal Effects When the Outcome Is Binary and Truncated by Death",
    "doi": "https://doi.org/10.1145/2700498",
    "publication_date": "2015-11-24",
    "publication_year": 2015,
    "authors": "Na Shan; Xiaogang Dong; Ping‐Feng Xu; Jianhua Guo",
    "corresponding_authors": "",
    "abstract": "In randomized trials with follow-up, outcomes may be undefined for individuals who die before the follow-up is complete. In such settings, Frangakis and Rubin [2002] proposed the “principal stratum effect” or “Survivor Average Causal Effect” (SACE), which is a fair treatment comparison in the subpopulation that would have survived under either treatment arm. Many of the existing results for estimating the SACE are difficult to carry out in practice. In this article, when the outcome is binary, we apply the symbolic Balke-Pearl linear programming method to derive simple formulas for the sharp bounds on the SACE under the monotonicity assumption commonly used by many researchers.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2259966507",
    "type": "article"
  },
  {
    "title": "Generating Incremental Length Summary Based on Hierarchical Topic Coverage Maximization",
    "doi": "https://doi.org/10.1145/2809433",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Jintao Ye; Zhao Ming; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Document summarization is playing an important role in coping with information overload on the Web. Many summarization models have been proposed recently, but few try to adjust the summary length and sentence order according to application scenarios. With the popularity of handheld devices, presenting key information first in summaries of flexible length is of great convenience in terms of faster reading and decision-making and network consumption reduction. Targeting this problem, we introduce a novel task of generating summaries of incremental length. In particular, we require that the summaries should have the ability to automatically adjust the coverage of general-detailed information when the summary length varies. We propose a novel summarization model that incrementally maximizes topic coverage based on the document’s hierarchical topic model. In addition to the standard Rouge-1 measure, we define a new evaluation metric based on the similarity of the summaries’ topic coverage distribution in order to account for sentence order and summary length. Extensive experiments on Wikipedia pages, DUC 2007, and general noninverted writing style documents from multiple sources show the effectiveness of our proposed approach. Moreover, we carry out a user study on a mobile application scenario to show the usability of the produced summary in terms of improving judgment accuracy and speed, as well as reducing the reading burden and network traffic.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2276238675",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2611448",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Learning user interests from online social networks helps to better understand user behaviors and provides useful guidance to design user-centric applications. Apart from analyzing users' online content, it is also important to consider users' social ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4240884931",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2648782",
    "publication_date": "2014-10-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Urbanization's rapid progress has modernized many people's lives but also engendered big issues, such as traffic congestion, energy consumption, and pollution. Urban computing aims to tackle these issues by using the data that has been generated in ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4241654081",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2745393",
    "publication_date": "2015-03-11",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Coming with the popularity of multimedia sharing platforms such as Facebook and Flickr, recent years have witnessed an explosive growth of geographical tags on social multimedia content. This trend enables a wide variety of emerging applications, for ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4248165592",
    "type": "paratext"
  },
  {
    "title": "Customer Volume Prediction Using Fusion of Shared-private Dynamic Weighting over Multiple Modalities",
    "doi": "https://doi.org/10.1145/3579826",
    "publication_date": "2023-01-09",
    "publication_year": 2023,
    "authors": "Wenshan Wang; Su Yang; Weishan Zhang",
    "corresponding_authors": "",
    "abstract": "Customer volume prediction is crucial for a variety of urban applications, such as store location selection. So far, the key challenge lies in how to fuse multiple modalities from different data sources, on account of the massive amount of data accessible, for example, spatio-temporal data and satellite images. In this article, we investigate three dynamic weighting ensemble learning models to fuse spatio-temporal features and visual features for predicting customer volume in the urban commercial district of interest. Specifically, we propose the shared-private dynamic weighting model by incorporating graph neural networks, which is proposed to capture geographic dependencies (i.e., competitiveness or dependencies) between urban commercial districts in an end-to-end manner. To the best of our knowledge, it is the first work to utilize graph neural networks to model such geographic relationships. We conduct a series of experiments to demonstrate the effectiveness of the proposed models based on two real datasets. Furthermore, an elaborated visualization method is performed for knowledge discovery.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4313894131",
    "type": "article"
  },
  {
    "title": "Learning Representations of Satellite Imagery by Leveraging Point-of-Interests",
    "doi": "https://doi.org/10.1145/3589344",
    "publication_date": "2023-03-27",
    "publication_year": 2023,
    "authors": "Tong Li; Yanxin Xi; Huandong Wang; Yong Li; Sasu Tarkoma; Pan Hui",
    "corresponding_authors": "",
    "abstract": "Satellite imagery depicts the Earth’s surface remotely and provides comprehensive information for many applications, such as land use monitoring and urban planning. Existing studies on unsupervised representation learning for satellite images only take into account the images’ geographic information, ignoring human activity factors. To bridge this gap, we propose using the Point-of-Interest (POI) data to capture human factors and designing a contrastive learning-based framework to consolidate the representation of satellite imagery with POI information. Besides, we introduce a season-invariant representation learning model on satellite imagery, considering that human factors are mostly unchanging with respect to seasons. An attention model is designed at last to merge the representations from the geographic, seasonal, and POI perspectives adaptively. On the basis of real-world datasets collected from Beijing, 1 we evaluate our method for predicting socioeconomic indicators. The results show that the representation containing POI information outperforms the geographic representation in estimating commercial activity-related indicators. Our proposed attentional framework can estimate the socioeconomic indicators with R 2 of 0.874 and outperforms the baseline methods. Furthermore, we explore the differences in the representations of satellite images with varying socioeconomic statuses. Finally, we investigate the impact of geographic and POI perspective information in the representation learning process, as well as the effect of satellite imagery on various spatial resolutions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4361003566",
    "type": "article"
  },
  {
    "title": "Skin Lesion Intelligent Diagnosis in Edge Computing Networks: An FCL Approach",
    "doi": "https://doi.org/10.1145/3595186",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Yanhang Shi; Xue Li; Siguang Chen",
    "corresponding_authors": "",
    "abstract": "In recent years, automatic skin lesion diagnosis methods based on artificial intelligence have achieved great success. However, the lack of labeled data, visual similarity between skin diseases, and restriction on private data sharing remain the major challenges in skin lesion diagnosis. In this article, first, we propose a federated contrastive learning framework to break down data silos and enhance the generalizability of diagnostic model to unseen data. Subsequently, by combining data features from different participated nodes, the proposed framework can improve the performance of contrastive training. To extract discriminative features during on-device training, we propose a contrastive learning based intelligent skin lesion diagnosis scheme in edge computing networks. Specifically, a contrastive learning based dual encoder network is designed to overcome training sample scarcity by fully leveraging unlabeled samples for performance improvement. Meanwhile, we devise a maximum mean discrepancy based supervised contrastive loss function, which can efficiently explore complex intra-class and inter-class variances of samples. Finally, the diagnosis simulations demonstrate that compared with existing methods, our proposed scheme can achieve superior accuracy in both on-device training and distributed training scenarios.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4367605095",
    "type": "article"
  },
  {
    "title": "Neural Architectures for Feature Embedding in Person Re-Identification: A Comparative View",
    "doi": "https://doi.org/10.1145/3610298",
    "publication_date": "2023-07-21",
    "publication_year": 2023,
    "authors": "Javier Domínguez-Martín; María J. Gómez-Silva; Arturo de la Escalera",
    "corresponding_authors": "",
    "abstract": "Solving Person Re-Identification (Re-Id) through Deep Convolutional Neural Networks is a daunting challenge due to the small size and variety of the training data, especially in Single-Shot Re-Id, where only two images per person are available. The lack of training data causes the overfitting of the deep neural models, leading to degenerated performance. This article explores a wide assortment of neural architectures that have been commonly used for object classification and analyzes their suitability in a Re-Id model. These architectures have been trained through a Triplet Model and evaluated over two challenging Single-Shot Re-Id datasets, PRID2011 and CUHK. This comparative study is aimed at obtaining the best-performing architectures and some concluding guidance to optimize the features embedding for the Re-Identification task. The obtained results present Inception-ResNet and DenseNet as potentially useful models, especially when compared with other methods, specifically designed for solving Re-Id.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4385067299",
    "type": "article"
  },
  {
    "title": "Learning with Euler Collaborative Representation for Robust Pattern Analysis",
    "doi": "https://doi.org/10.1145/3625235",
    "publication_date": "2023-09-26",
    "publication_year": 2023,
    "authors": "Jianhang Zhou; Guancheng Wang; Shaoning Zeng; Bob Zhang",
    "corresponding_authors": "",
    "abstract": "The Collaborative Representation (CR) framework has provided various effective and efficient solutions to pattern analysis. By leveraging between discriminative coefficient coding (l 2 regularization) and the best reconstruction quality (collaboration), the CR framework can exploit discriminative patterns efficiently in high-dimensional space. Due to the limitations of its linear representation mechanism, the CR must sacrifice its superior efficiency for capturing the non-linear information with the kernel trick. Besides this, even if the coding is indispensable, there is no mechanism designed to keep the CR free from inevitable noise brought by real-world information systems. In addition, the CR only emphasizes exploiting discriminative patterns on coefficients rather than on the reconstruction. To tackle the problems of primitive CR with a unified framework, in this article we propose the Euler Collaborative Representation (E-CR) framework. Inferred from the Euler formula, in the proposed method, we map the samples to a complex space to capture discriminative and non-linear information without the high-dimensional hidden kernel space. Based on the proposed E-CR framework, we form two specific classifiers: the Euler Collaborative Representation based Classifier (E-CRC) and the Euler Probabilistic Collaborative Representation based Classifier (E-PROCRC). Furthermore, we specifically designed a robust algorithm for E-CR (termed as R-E-CR ) to deal with the inevitable noises in real-world systems. Robust iterative algorithms have been specially designed for solving E-CRC and E-PROCRC. We correspondingly present a series of theoretical proofs to ensure the completeness of the theory for the proposed robust algorithms. We evaluated E-CR and R-E-CR with various experiments to show its competitive performance and efficiency.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387055574",
    "type": "article"
  },
  {
    "title": "Interpretable Imitation Learning with Symbolic Rewards",
    "doi": "https://doi.org/10.1145/3627822",
    "publication_date": "2023-10-13",
    "publication_year": 2023,
    "authors": "Nicolas Bougie; Takashi Onishi; Yoshimasa Tsuruoka",
    "corresponding_authors": "",
    "abstract": "Sample inefficiency of deep reinforcement learning methods is a major obstacle for their use in real-world tasks as they naturally feature sparse rewards. In fact, this from-scratch approach is often impractical in environments where extreme negative outcomes are possible. Recent advances in imitation learning have improved sample efficiency by leveraging expert demonstrations. Most work along this line of research employs neural network-based approaches to recover an expert cost function. However, the complexity and lack of transparency make neural networks difficult to trust and deploy in the real world. In contrast, we present a method for extracting interpretable symbolic reward functions from expert data, which offers several advantages. First, the learned reward function can be parsed by a human to understand, verify and predict the behavior of the agent. Second, the reward function can be improved and modified by an expert. Finally, the structure of the reward function can be leveraged to extract explanations that encode richer domain knowledge than standard scalar rewards. To this end, we use an autoregressive recurrent neural network that generates hierarchical symbolic rewards represented by simple symbolic trees. The recurrent neural network is trained via risk-seeking policy gradients. We test our method in MuJoCo environments as well as a chemical plant simulator. We show that the discovered rewards can significantly accelerate the training process and achieve similar or better performance than neural network-based algorithms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387614515",
    "type": "article"
  },
  {
    "title": "“Intelligent Heuristics Are the Future of Computing”",
    "doi": "https://doi.org/10.1145/3627708",
    "publication_date": "2023-10-17",
    "publication_year": 2023,
    "authors": "Shang‐Hua Teng",
    "corresponding_authors": "Shang‐Hua Teng",
    "abstract": "Back in 1988, the partial game trees explored by computer chess programs were among the largest search structures in real-world computing. Because the game tree is too large to be fully evaluated, chess programs must make heuristic strategic decisions based on partial information, making it an illustrative subject for teaching AI search. In one of his lectures that year on AI search for games and puzzles, Professor Hans Berliner—a pioneer of computer chess programs 1 —stated: As a student in the field of the theory of computation, I was naturally perplexed but fascinated by this perspective. I had been trained to believe that “Algorithms and computational complexity theory are the foundation of computer science.” However, as it happens, my attempts to understand heuristics in computing have subsequently played a significant role in my career as a theoretical computer scientist. I have come to realize that Berliner’s postulation is a far-reaching worldview, particularly in the age of big, rich, complex, and multifaceted data and models, when computing has ubiquitous interactions with science, engineering, humanity, and society. In this article, 2 I will share some of my experiences on the subject of heuristics in computing, presenting examples of theoretical attempts to understand the behavior of heuristics on real data, as well as efforts to design practical heuristics with desirable theoretical characterizations. My hope is that these theoretical insights from past heuristics—such as spectral partitioning, multilevel methods, evolutionary algorithms, and simplex methods—can shed light on and further inspire a deeper understanding of the current and future techniques in AI and data mining.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387698781",
    "type": "article"
  },
  {
    "title": "Quantifying Levels of Influence and Causal Responsibility in Dynamic Decision Making Events",
    "doi": "https://doi.org/10.1145/3631611",
    "publication_date": "2023-11-03",
    "publication_year": 2023,
    "authors": "Yossef Saad; Joachim Meyer",
    "corresponding_authors": "",
    "abstract": "Intelligent systems support human operators’ decision-making processes, many of which are dynamic and involve temporal changes in the decision-related parameters. As we increasingly depend on automation, it becomes imperative to understand and quantify its influence on the operator’s decisions and to evaluate its implications for the human’s causal responsibility for outcomes. Past studies proposed a model for human responsibility in static decision-making processes involving intelligent systems. We present a model for dynamic, non-stationary decision-making events based on the concept of causation strength. We apply it to a test case of a dynamic binary categorization decision. The results show that for automation to influence humans significantly, it must have high detection sensitivity. However, this condition is insufficient since it is unlikely that automation, irrespective of its sensitivity, will sway humans with high detection sensitivity away from their original position. Specific combinations of automation and human detection sensitivities are required for automation to have a major influence. Moreover, the automation influence and the human causal responsibility that can be derived from it are sensitive to possible changes in the human’s detection capabilities due to fatigue or other factors, creating a “Responsibility Cliff.” This should be considered during system design and when policies and regulations are defined. This model constitutes a basis for further analyses of complex events in which human and automation sensitivity levels change over time and for evaluating human involvement in such events.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388284553",
    "type": "article"
  },
  {
    "title": "<i> E <sup>2</sup> </i> Storyline: Visualizing the Relationship with Triplet Entities and Event Discovery",
    "doi": "https://doi.org/10.1145/3633519",
    "publication_date": "2023-11-23",
    "publication_year": 2023,
    "authors": "Yunchao Wang; Guodao Sun; Zihao Zhu; Tong Li; Ling Chen; Ronghua Liang",
    "corresponding_authors": "",
    "abstract": "The narrative progression of events, evolving into a cohesive story, relies on the entity-entity relationships. Among the plethora of visualization techniques, storyline visualization has gained significant recognition for its effectiveness in offering an overview of story trends, revealing entity relationships, and facilitating visual communication. However, existing methods for storyline visualization often fall short in accurately depicting the specific relationships between entities. In this study, we present E 2 Storyline, a novel approach that emphasizes simplicity and aesthetics of layout while effectively conveying entity-entity relationships to users. To achieve this, we begin by extracting entity-entity relationships from textual data and representing them as subject-predicate-object (SPO) triplets, thereby obtaining structured data. By considering three types of design requirements, we establish new optimization objectives and model the layout problem using multi-objective optimization (MOO) techniques. The aforementioned SPO triplets, together with time and event information, are incorporated into the optimization model to ensure a straightforward and easily comprehensible storyline layout. Through a qualitative user study, we determine that a pixel-based view is the most suitable method for displaying the relationships between entities. Finally, we apply E 2 Storyline to real-world data, including movie synopses and live text commentaries. Through comprehensive case studies, we demonstrate that E 2 Storyline enables users to better extract information from stories and comprehend the relationships between entities.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388941881",
    "type": "article"
  },
  {
    "title": "Strengthening Cooperative Consensus in Multi-Robot Confrontation",
    "doi": "https://doi.org/10.1145/3639371",
    "publication_date": "2023-12-29",
    "publication_year": 2023,
    "authors": "Meng Xu; Xinhong Chen; Yechao She; Jin Yang; Guanyi Zhao; Jianping Wang",
    "corresponding_authors": "",
    "abstract": "Multi-agent reinforcement learning (MARL) has proven effective in training multi-robot confrontation, such as StarCraft and robot soccer games. However, the current joint action policies utilized in MARL have been unsuccessful in recognizing and preventing actions that often lead to failures on our side. This exacerbates the cooperation dilemma, ultimately resulting in our agents acting independently and being defeated individually by their opponents. To tackle this challenge, we propose a novel joint action policy, referred to as the consensus action policy (CAP). Specifically, CAP records the number of times each joint action has caused our side to fail in the past and computes a cooperation tendency, which is integrated with each agent’s Q -value and Nash bargaining solution to determine a joint action. The cooperation tendency promotes team cooperation by selecting joint actions that have a high tendency of cooperation and avoiding actions that may lead to team failure. Moreover, the proposed CAP policy can be extended to partially observable scenarios by combining it with Deep Q network or actor-critic–based methods. We conducted extensive experiments to compare the proposed method with seven existing joint action policies, including four commonly used methods and three state-of-the-art methods, in terms of episode rewards, winning rates, and other metrics. Our results demonstrate that this approach holds great promise for multi-robot confrontation scenarios.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4390399690",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Intelligent Visual Interfaces for Text Analysis",
    "doi": "https://doi.org/10.1145/2089094.2089095",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Shi‐Xia Liu; Michelle X. Zhou; Giuseppe Carenini; Huamin Qu",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Section on Intelligent Visual Interfaces for Text Analysis Guest Editors: Shixia Liu Microsoft Research Asia Microsoft Research AsiaView Profile , Michelle X. Zhou IBM Research – Almaden IBM Research – AlmadenView Profile , Giuseppe Carenini University of British Columbia University of British ColumbiaView Profile , Huamin Qu Hong Kong University of Science and Technology Hong Kong University of Science and TechnologyView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 3Issue 2February 2012 Article No.: 19pp 1–3https://doi.org/10.1145/2089094.2089095Published:01 February 2012Publication History 10citation353DownloadsMetricsTotal Citations10Total Downloads353Last 12 Months5Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1999678585",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on intelligent systems for health informatics",
    "doi": "https://doi.org/10.1145/2508037.2508043",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Chandan K. Reddy; Cristopher C. Yang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the special section on intelligent systems for health informatics Authors: Chandan K. Reddy Wayne State University Wayne State UniversityView Profile , Cristopher C. Yang Drexel University Drexel UniversityView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 4Issue 4Article No.: 62pp 1–3https://doi.org/10.1145/2508037.2508043Published:08 October 2013Publication History 1citation210DownloadsMetricsTotal Citations1Total Downloads210Last 12 Months2Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2050636995",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on agent communication",
    "doi": "https://doi.org/10.1145/2438653.2438654",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Amit K. Chopra; Alexander Artikis; Jamal Bentahar; Frank Dignum",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2059582083",
    "type": "article"
  },
  {
    "title": "Mondrian tree",
    "doi": "https://doi.org/10.1145/2542182.2542186",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Myungcheol Doo; Ling Liu",
    "corresponding_authors": "",
    "abstract": "With ubiquitous wireless connectivity and technological advances in mobile devices, we witness the growing demands and increasing market shares of mobile intelligent systems and technologies for real-time decision making and location-based knowledge discovery. Spatial alarms are considered as one of the fundamental capabilities for intelligent mobile location-based systems. Like time-based alarms that remind us the arrival of a future time point, spatial alarms remind us the arrival of a future spatial point. Existing approaches for scaling spatial alarm processing are focused on computing Alarm-Free Regions (A fr ) and Alarm-Free Period (A fp ) such that mobile objects traveling within an A fr can safely hibernate the alarm evaluation process for the computed A fp , to save battery power, until approaching the nearest alarm of interest. A key technical challenge in scaling spatial alarm processing is to efficiently compute A fr and A fp such that mobile objects traveling within an A fr can safely hibernate the alarm evaluation process during the computed A fp , while maintaining high accuracy. In this article we argue that on-demand computation of A fr is expensive and may not scale well for dense populations of mobile objects. Instead, we propose to maintain an index for both spatial alarms and empty regions (A fr ) such that for a given mobile user's location, we can find relevant spatial alarms and whether it is in an alarm-free region more efficiently. We also show that conventional spatial indexing methods, such as R-tree family, k -d tree, Quadtree, and Grid, are by design not well suited to index empty regions. We present Mondrian Tree – a region partitioning tree for indexing both spatial alarms and alarm-free regions. We first introduce the Mondrian Tree indexing algorithms, including index construction, search, and maintenance. Then we describe a suite of Mondrian Tree optimizations to further enhance the performance of spatial alarm processing. Our experimental evaluation shows that the Mondrian Tree index, as an intelligent technology for mobile systems, outperforms traditional index methods, such as R-tree, Quadtree, and k -d tree, for spatial alarm processing.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2065587001",
    "type": "article"
  },
  {
    "title": "Random walks down the mention graphs for event coreference resolution",
    "doi": "https://doi.org/10.1145/2508037.2508055",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Bin Chen; Jian Su; Chew Lim Tan",
    "corresponding_authors": "",
    "abstract": "Event coreference is an important task in event extraction and other natural language processing tasks. Despite its importance, it was merely discussed in previous studies. In this article, we present a global coreference resolution system dedicated to various sophisticated event coreference phenomena. First, seven resolvers are utilized to resolve different event and object coreference mention pairs with a new instance selection strategy and new linguistic features. Second, a global solution—a modified random walk partitioning—is employed for the chain formation. Being the first attempt to apply the random walk model for coreference resolution, the revised model utilizes a sampling method, termination criterion, and stopping probability to greatly improve the effectiveness of random walk model for event coreference resolution. Last but not least, the new model facilitates a convenient way to incorporate sophisticated linguistic constraints and preferences, the related object mention graph, as well as pronoun coreference information not used in previous studies for effective chain formation. In total, these techniques impose more than 20% F-score improvement over the baseline system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2080931708",
    "type": "article"
  },
  {
    "title": "Multitechnique paraphrase alignment",
    "doi": "https://doi.org/10.1145/2483669.2483677",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Houda Bouamor; Auréelien Max; Anne Vilnat",
    "corresponding_authors": "",
    "abstract": "This work uses parallel monolingual corpora for a detailed study of the task of sub-sentential paraphrase acquisition. We argue that the scarcity of this type of resource is compensated by the fact that it is the most suited type for studies on paraphrasing. We propose a large exploration of this task with experiments on two languages with five different acquisition techniques, selected for their complementarity, their combinations, as well as four monolingual corpus types of varying comparability. We report, under all conditions, a significant improvement over all techniques by validating candidate paraphrases using a maximum entropy classifier. An important result of our study is the identification of difficult-to-acquire paraphrase pairs, which are classified and quantified in a bilingual typology.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2088175415",
    "type": "article"
  },
  {
    "title": "Introduction",
    "doi": "https://doi.org/10.1145/2036264.2036265",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4230737014",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2337542",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Text mining has been very successful in extracting huge amounts of commonsense knowledge from data, but the extracted knowledge tends to be extremely noisy. Manual construction of knowledge repositories, on the other hand, tends to produce high-quality ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4236919126",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2438653",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Increasingly, software engineering involves open systems consisting of autonomous and heterogeneous participants or agents who carry out loosely coupled interactions. Accordingly, understanding and specifying communications among agents is a key ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4237936407",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2483669",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Targeted paraphrasing is a new approach to the problem of obtaining cost-effective, reasonable quality translation, which makes use of simple and inexpensive human computations by monolingual speakers in combination with machine translation. The key ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244862508",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2036264",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Despite all of the advantages of tags as an easy and flexible information management approach, tagging is a cumbersome task. A set of descriptive tags has to be manually entered by users whenever they post a resource. This process can be simplified by ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4247845092",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2542182",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In recent years, research on location predictions by mining trajectories of users has attracted a lot of attention. Existing studies on this topic mostly treat such predictions as just a type of location recommendation, that is, they predict the next ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4249701336",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2089094",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4251986556",
    "type": "paratext"
  },
  {
    "title": "Securely Computing a Ground Speed Model",
    "doi": "https://doi.org/10.1145/2998550",
    "publication_date": "2017-06-23",
    "publication_year": 2017,
    "authors": "Eyal Kolman; Benny Pinkas",
    "corresponding_authors": "",
    "abstract": "Consider a server offering risk assessment services and potential clients of these services. The risk assessment model that is run by the server is based on current and historical data of the clients. However, the clients might prefer not sharing such sensitive data with external parties such as the server, and the server might consider the possession of this data as a liability rather than an asset. Secure multi-party computation (MPC) enables one, in principle, to compute any function while hiding the inputs to the function, and would thus enable the computation of the risk assessment model while hiding the client’s data from the server. However, a direct application of a generic MPC solution to this problem is rather inefficient due to the large scale of the data and the complexity of the function. We examine a specific case of risk assessment—the ground speed model. In this model, the geographical locations of successive user-authentication attempts are compared, and a warning flag is raised if the physical speed required to move between these locations is greater than some threshold, and some other conditions, such as authentication from two related networks, do not hold. We describe a very efficient secure computation solution that is tailored for this problem. This solution demonstrates that a risk model can be applied over encrypted data with sufficient efficiency to fit the requirements of commercial systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2704240608",
    "type": "article"
  },
  {
    "title": "The Letter from Prof. Maj. Gen. (Ret.) Isaac Ben-Israel",
    "doi": "https://doi.org/10.1145/3057727",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Isaac Ben‐Israel",
    "corresponding_authors": "Isaac Ben‐Israel",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2734845838",
    "type": "article"
  },
  {
    "title": "Exploring Communication Behaviors of Users to Target Potential Users in Mobile Social Networks",
    "doi": "https://doi.org/10.1145/3022472",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Chien‐Cheng Chen; Kuo-Wei Hsu; Wen-Chih Peng",
    "corresponding_authors": "",
    "abstract": "In mobile communication services, users can communicate with each other over different telecommunication carriers. For telecom operators, how to acquire and retain users is a significant and practical task. Note that telecom operators only have their own customer profiles. For the users from other telecom operators, their information is sparse. Thus, given a set of communication logs, the main theme of our work is to identify the potential users who will possibly join the target services in the near future. Since only a limited amount of information is available, one challenging issue is how to extract features from the communication logs. In this article, we propose a Communication-Based Feature Generation (CBFG) framework that extracts features and builds models to infer the potential users. Explicitly, we construct a heterogeneous information network from the communication logs of users. Then, we extract the explicit features, which refer to those calling features of users, from the potential users’ interaction behaviors in the heterogeneous information network. Moreover, from the calling behaviors of users, one could extract the possible community structures of users. Based on the community structures, we further extract the implicit features of users. In light of both explicit and implicit features, we propose an information-gain-based method to select the effective features. According to the features selected, we utilize three popular classifiers (i.e., AdaBoost, Random Forest, and SVM) to build models to target the potential users. In addition, we have designed a sampling approach to extract training data for classifiers. To evaluate our methods, we have conducted experiments on a real dataset. The results of our experiments show that the features extracted by our proposed method can be effective for targeting the potential users.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2750317709",
    "type": "article"
  },
  {
    "title": "UMCR",
    "doi": "https://doi.org/10.1145/3102292",
    "publication_date": "2017-09-13",
    "publication_year": 2017,
    "authors": "Hao Yin; Wei Wang; Xu Zhang; Yongqiang Lyu; Geyong Min; Dongchao Guo",
    "corresponding_authors": "",
    "abstract": "Although mobile application ecosystems have experienced tremendous growth in recent years, retrieving content of mobile applications that serves a key to mobile content search engines still faces grand challenges. Compared to web content retrieval, it is much more difficult to capture content in mobile applications due to the diversity of applications and the lack of Uniform Resource Locator indices. In this study, we propose and implement a &lt;underline&gt;u&lt;/underline&gt;ser interaction-driven &lt;underline&gt;m&lt;/underline&gt;obile &lt;underline&gt;c&lt;/underline&gt;ontent &lt;underline&gt;r&lt;/underline&gt;etrieval (UMCR) system to address such issues, which is the first mobile content crawler in the current literature. UMCR is a distributed system that contains many measurement nodes, each of which combines the user interaction path traversing (UIPT) and Deep Package Inspection (DPI) together to obtain mobile content. UIPT determines the events of user interactions in various applications to capture the static content such as text and images, in which a traversal depth termination scheme and an optional cut-off component are adopted to balance the content coverage and traversing efficiency. Meanwhile, the analysis based on DPI is responsible for extracting the videos as well as digging the infrastructural information and performance metrics. In addition, a distributed traversal scheduling method is designed for UIPT tasks to improve the throughput and scalability in large-scale content retrieval. Experiments on retrieving content of 64 real mobile applications demonstrate that UMCR can handle diverse mobile applications efficiently. The scheduler can improve throughput by 3 times compared to the legacy arbitrary task assignment strategy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2754701120",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1858948",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Thirteen gamelike virtual worlds illustrate issues that overlap social science and information science, because they embody rather clear theories of society and culture: World of Warcraft, Lord of the Rings Online, Dark Age of Camelot, Age of Conan, ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4236212110",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3055535",
    "publication_date": "2017-07-17",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Information is the most critical asset of modern organizations, and accordingly it is one of the resources most coveted by adversaries. When highly sensitive data is involved, an organization may resort to air gap isolation in which there is no ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4253252978",
    "type": "paratext"
  },
  {
    "title": "Modeling Customer Experience in a Contact Center through Process Log Mining",
    "doi": "https://doi.org/10.1145/3468269",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Teng Fu; Guido Zampieri; David Hodgson; Claudio Angione; Yifeng Zeng",
    "corresponding_authors": "",
    "abstract": "The use of data mining and modeling methods in service industry is a promising avenue for optimizing current processes in a targeted manner, ultimately reducing costs and improving customer experience. However, the introduction of such tools in already established pipelines often must adapt to the way data is sampled and to its content. In this study, we tackle the challenge of characterizing and predicting customer experience having available only process log data with time-stamp information, without any ground truth feedback from the customers. As a case study, we consider the context of a contact center managed by TeleWare and analyze phone call logs relative to a two months span. We develop an approach to interpret the phone call process events registered in the logs and infer concrete points of improvement in the service management. Our approach is based on latent tree modeling and multi-class Naïve Bayes classification, which jointly allow us to infer a spectrum of customer experiences and test their predictability based on the current data sampling strategy. Moreover, such approach can overcome limitations in customer feedback collection and sharing across organizations, thus having wide applicability and being complementary to tools relying on more heavily constrained data.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3184208676",
    "type": "article"
  },
  {
    "title": "Multi-Graph Cooperative Learning Towards Distant Supervised Relation Extraction",
    "doi": "https://doi.org/10.1145/3466560",
    "publication_date": "2021-09-23",
    "publication_year": 2021,
    "authors": "Changsen Yuan; Heyan Huang; Chong Feng",
    "corresponding_authors": "",
    "abstract": "The Graph Convolutional Network (GCN) is a universal relation extraction method that can predict relations of entity pairs by capturing sentences’ syntactic features. However, existing GCN methods often use dependency parsing to generate graph matrices and learn syntactic features. The quality of the dependency parsing will directly affect the accuracy of the graph matrix and change the whole GCN’s performance. Because of the influence of noisy words and sentence length in the distant supervised dataset, using dependency parsing on sentences causes errors and leads to unreliable information. Therefore, it is difficult to obtain credible graph matrices and relational features for some special sentences. In this article, we present a Multi-Graph Cooperative Learning model (MGCL), which focuses on extracting the reliable syntactic features of relations by different graphs and harnessing them to improve the representations of sentences. We conduct experiments on a widely used real-world dataset, and the experimental results show that our model achieves the state-of-the-art performance of relation extraction.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3204214691",
    "type": "article"
  },
  {
    "title": "Fine-Grained Semantic Image Synthesis with Object-Attention Generative Adversarial Network",
    "doi": "https://doi.org/10.1145/3470008",
    "publication_date": "2021-10-31",
    "publication_year": 2021,
    "authors": "Min Wang; Congyan Lang; Liqian Liang; Songhe Feng; Tao Wang; Yutong Gao",
    "corresponding_authors": "",
    "abstract": "Semantic image synthesis is a new rising and challenging vision problem accompanied by the recent promising advances in generative adversarial networks. The existing semantic image synthesis methods only consider the global information provided by the semantic segmentation mask, such as class label, global layout, and location, so the generative models cannot capture the rich local fine-grained information of the images (e.g., object structure, contour, and texture). To address this issue, we adopt a multi-scale feature fusion algorithm to refine the generated images by learning the fine-grained information of the local objects. We propose OA-GAN, a novel object-attention generative adversarial network that allows attention-driven, multi-fusion refinement for fine-grained semantic image synthesis. Specifically, the proposed model first generates multi-scale global image features and local object features, respectively, then the local object features are fused into the global image features to improve the correlation between the local and the global. In the process of feature fusion, the global image features and the local object features are fused through the channel-spatial-wise fusion block to learn ‘what’ and ‘where’ to attend in the channel and spatial axes, respectively. The fused features are used to construct correlation filters to obtain feature response maps to determine the locations, contours, and textures of the objects. Extensive quantitative and qualitative experiments on COCO-Stuff, ADE20K and Cityscapes datasets demonstrate that our OA-GAN significantly outperforms the state-of-the-art methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4200118032",
    "type": "article"
  },
  {
    "title": "Instant Basketball Defensive Trajectory Generation",
    "doi": "https://doi.org/10.1145/3460619",
    "publication_date": "2021-12-23",
    "publication_year": 2021,
    "authors": "Wen‐Cheng Chen; Wan-Lun Tsai; Huan-Hua Chang; Min‐Chun Hu; Wei-Ta Chu",
    "corresponding_authors": "",
    "abstract": "Tactic learning in virtual reality (VR) has been proven to be effective for basketball training. Endowed with the ability of generating virtual defenders in real time according to the movement of virtual offenders controlled by the user, a VR basketball training system can bring more immersive and realistic experiences for the trainee. In this article, an autoregressive generative model for instantly producing basketball defensive trajectory is introduced. We further focus on the issue of preserving the diversity of the generated trajectories. A differentiable sampling mechanism is adopted to learn the continuous Gaussian distribution of player position. Moreover, several heuristic loss functions based on the domain knowledge of basketball are designed to make the generated trajectories assemble real situations in basketball games. We compare the proposed method with the state-of-the-art works in terms of both objective and subjective manners. The objective manner compares the average position, velocity, and acceleration of the generated defensive trajectories with the real ones to evaluate the fidelity of the results. In addition, more high-level aspects such as the empty space for offender and the defensive pressure of the generated trajectory are also considered in the objective evaluation. As for the subjective manner, visual comparison questionnaires on the proposed and other methods are thoroughly conducted. The experimental results show that the proposed method can achieve better performance than previous basketball defensive trajectory generation works in terms of different evaluation metrics.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4200131983",
    "type": "article"
  },
  {
    "title": "ACM TIST Special Issue on Deep Learning for Spatio-Temporal Data: Part 1",
    "doi": "https://doi.org/10.1145/3495188",
    "publication_date": "2021-12-16",
    "publication_year": 2021,
    "authors": "Senzhang Wang; Junbo Zhang; Yanjie Fu; Yong Li",
    "corresponding_authors": "",
    "abstract": "introduction Share on ACM TIST Special Issue on Deep Learning for Spatio-Temporal Data: Part 1 Authors: Senzhang Wang Central South University, Changsha, China Central South University, Changsha, ChinaSearch about this author , Junbo Zhang JD Intelligent Cities Research; JD iCity, JD Tech, Beijing, China JD Intelligent Cities Research; JD iCity, JD Tech, Beijing, ChinaSearch about this author , Yanjie Fu University of Central Florida, Orlando, U.S.A. University of Central Florida, Orlando, U.S.A.Search about this author , Yong Li Tsinghua University, Beijing, China Tsinghua University, Beijing, ChinaSearch about this author Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 12Issue 6December 2021 Article No.: 67pp 1–3https://doi.org/10.1145/3495188Online:16 December 2021Publication History 0citation122DownloadsMetricsTotal Citations0Total Downloads122Last 12 Months122Last 6 weeks23 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4200201633",
    "type": "article"
  },
  {
    "title": "Exploring the Risky Travel Area and Behavior of Car-hailing Service",
    "doi": "https://doi.org/10.1145/3465059",
    "publication_date": "2021-12-23",
    "publication_year": 2021,
    "authors": "Hongting Niu; Hengshu Zhu; Ying Sun; Xinjiang Lu; Jing Sun; Zhiyuan Zhao; Hui Xiong; Bo Lang",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the rapid development of car-hailing services, which provide a convenient approach for connecting passengers and local drivers using their personal vehicles. At the same time, the concern on passenger safety has gradually emerged and attracted more and more attention. While car-hailing service providers have made considerable efforts on developing real-time trajectory tracking systems and alarm mechanisms, most of them only focus on providing rescue-supporting information rather than preventing potential crimes. Recently, the newly available large-scale car-hailing order data have provided an unparalleled chance for researchers to explore the risky travel area and behavior of car-hailing services, which can be used for building an intelligent crime early warning system. To this end, in this article, we propose a Risky Area and Risky Behavior Evaluation System (RARBEs) based on the real-world car-hailing order data. In RARBEs, we first mine massive multi-source urban data and train an effective area risk prediction model, which estimates area risk at the urban block level. Then, we propose a transverse and longitudinal double detection method, which estimates behavior risk based on two aspects, including fraud trajectory recognition and fraud patterns mining. In particular, we creatively propose a bipartite graph-based algorithm to model the implicit relationship between areas and behaviors, which collaboratively adjusts area risk and behavior risk estimation based on random walk regularization. Finally, extensive experiments on multi-source real-world urban data clearly validate the effectiveness and efficiency of our system.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4200273248",
    "type": "article"
  },
  {
    "title": "An Unbiased Risk Estimator for Partial Label Learning with Augmented Classes",
    "doi": "https://doi.org/10.1145/3700137",
    "publication_date": "2024-10-14",
    "publication_year": 2024,
    "authors": "Jiayu Hu; Senlin Shu; Beibei Li; Tao Xiang; Zhongshi He",
    "corresponding_authors": "",
    "abstract": "Partial Label Learning (PLL) is a typical weakly supervised learning task, which assumes each training instance is annotated with a set of candidate labels containing the ground-truth label. Recent PLL methods adopt identification-based disambiguation to alleviate the influence of false positive labels and achieve promising performance. However, they require all classes in the test set to have appeared in the training set, ignoring the fact that new classes will keep emerging in real applications. To address this issue, in this paper, we focus on the problem of Partial Label Learning with Augmented Class (PLLAC), where one or more augmented classes are not visible in the training stage but appear in the inference stage. Specifically, we propose an unbiased risk estimator with theoretical guarantees for PLLAC, which estimates the distribution of augmented classes by differentiating the distribution of known classes from unlabeled data and can be equipped with arbitrary PLL loss functions. Besides, we provide a theoretical analysis of the estimation error bound of the estimator, which guarantees the convergence of the empirical risk minimizer to the true risk minimizer as the number of training data tends to infinity. Furthermore, we add a risk-penalty regularization term in the optimization objective to alleviate the influence of the over-fitting issue caused by negative empirical risk. Extensive experiments on benchmark, UCI and real-world datasets demonstrate the effectiveness of the proposed approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403380492",
    "type": "article"
  },
  {
    "title": "群衆を意識した経路推薦のための旅客輸送の時空間動力学のスマートトランスファモデリング【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Du Bowen; Yifeng Cui; Fu Yanjie; Runxing Zhong; Xiong Hui",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3182957721",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3295616",
    "publication_date": "2019-01-16",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The increased accessibility of urban sensor data and the popularity of social network applications is enabling the discovery of crowd mobility and personal communication patterns. However, studying the egocentric relationships of an individual can be ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4237329447",
    "type": "paratext"
  },
  {
    "title": "Local Edge Dynamics and Opinion Polarization",
    "doi": "https://doi.org/10.1145/3709006",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Nikita Bhalla; Adam Lechowicz; Cameron Musco",
    "corresponding_authors": "",
    "abstract": "The proliferation of social media platforms, recommender systems, and their joint societal impacts have prompted significant interest in opinion formation and evolution within social networks. We study how local edge dynamics can drive opinion polarization. In particular, we introduce a variant of the classic Friedkin-Johnsen opinion dynamics, augmented with a simple time-evolving network model. Edges are iteratively added or deleted according to simple rules, modeling decisions based on individual preferences and network recommendations. Via simulations on synthetic and real-world graphs, we find that the combined presence of two dynamics gives rise to high polarization: 1) confirmation bias – i.e., the preference for nodes to connect to other nodes with similar expressed opinions and 2) friend-of-friend link recommendations , which encourage new connections between closely connected nodes. We show that our model is tractable to theoretical analysis, which helps explain how these local dynamics erode connectivity across opinion groups, affecting polarization and a related measure of disagreement across edges. Finally, we validate our model against real-world data, showing that our edge dynamics drive the structure of arbitrary graphs, including random graphs, to more closely resemble real social networks. Our code and supplemental materials are available at https://github.com/adamlechowicz/opinion-polarization/ . 1",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3216173699",
    "type": "article"
  },
  {
    "title": "Internal Rehearsals for a Reconfigurable Robot to Improve Area Coverage Performance",
    "doi": "https://doi.org/10.1145/3643854",
    "publication_date": "2024-02-02",
    "publication_year": 2024,
    "authors": "S. M. Bhagya P. Samarakoon; M. A. Viraj J. Muthugala; Mohan Rajesh Elara",
    "corresponding_authors": "",
    "abstract": "Reconfigurable robots are deployed for applications demanding area coverage, such as cleaning and inspections. Reconfiguration per context, considering beyond a small set of predefined shapes, is crucial for area coverage performance. However, the existing area coverage methods of reconfigurable robots are not always effective and require improvements for ascertaining the intended goal. Therefore, this article proposes a novel coverage strategy based on internal rehearsals to improve the area coverage performance of a reconfigurable robot. In this regard, a reconfigurable robot is embodied with the cognitive ability to predict the outcomes of its actions before executing them. A genetic algorithm uses the results of the internal rehearsals to determine a set of the robot’s coverage parameters, including positioning, heading, and reconfiguration, to maximize coverage in an obstacle cluster encountered by the robot. The experimental results confirm that the proposed method can significantly improve the area coverage performance of a reconfigurable robot.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391473798",
    "type": "article"
  },
  {
    "title": "Mitigating the Impact of Inaccurate Feedback in Dynamic Learning-to-Rank: A Study of Overlooked Interesting Items",
    "doi": "https://doi.org/10.1145/3653983",
    "publication_date": "2024-03-26",
    "publication_year": 2024,
    "authors": "Chenhao Zhang; Weitong Chen; Wei Emma Zhang; Miao Xu",
    "corresponding_authors": "",
    "abstract": "Dynamic Learning-to-Rank (DLTR) is a method of updating a ranking policy in real-time based on user feedback, which may not always be accurate. Although previous DLTR work has achieved fair and unbiased DLTR under inaccurate feedback, they face the trade-off between fairness and user utility and also have limitations in the setting of feeding items. Existing DLTR works improve ranking utility by eliminating bias from inaccurate feedback on observed items, but the impact of another pervasive form of inaccurate feedback, overlooked or ignored interesting items, remains unclear. For example, users may browse the rankings too quickly to catch interesting items or miss interesting items because the snippets are not optimized enough. This phenomenon raises two questions: i) Will overlooked interesting items affect the ranking results? ii) Is it possible to improve utility without sacrificing fairness if these effects are eliminated? These questions are particularly relevant for small and medium-sized retailers who are just starting out and may have limited data, leading to the use of inaccurate feedback to update their models. In this paper, we find that inaccurate feedback in the form of overlooked interesting items has a negative impact on DLTR performance in terms of utility. To address this, we treat the overlooked interesting items as noise and propose a novel DLTR method, the Co-teaching Rank (CoTeR), that has good utility and fairness performance when inaccurate feedback is present in the form of overlooked interesting items. Our solution incorporates a co-teaching-based component with a customized loss function and data sampling strategy, as well as a mean pooling strategy to further accommodate newly added products without historical data. Through experiments, we demonstrate that CoTeRx not only enhances utilities but also preserves ranking fairness, and can smoothly handle newly introduced items.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4393183646",
    "type": "article"
  },
  {
    "title": "Popularity Bias in Correlation Graph based API Recommendation for Mashup Creation",
    "doi": "https://doi.org/10.1145/3654445",
    "publication_date": "2024-04-02",
    "publication_year": 2024,
    "authors": "Chao Yan; Weiyi Zhong; Dengshuai Zhai; Arif Ali Khan; Wenwen Gong; Yanwei Xu; Baogui Xin",
    "corresponding_authors": "",
    "abstract": "The explosive growth of the API economy in recent years has led to a dramatic increase in available APIs. Mashup development, a dominant approach for creating data-centric applications based on APIs, has experienced a surge in popularity. However, the vast array of choices poses a challenge for mashup developers when selecting appropriate API compositions to meet specific business requirements. Correlation graph-based recommendation approaches have been designed to assist developers in discovering related and compatible API compositions for mashup creation. Unfortunately, these approaches often suffer from popularity bias issues, leading to an inequality in API usage and potential disruptions to the entire API ecosystem. To address these challenges, our research begins with a theoretical analysis of the popularity bias introduced by correlation graph-based API recommendation approaches. Subsequently, we empirically validate the presence of popularity bias in API recommendations through a data-driven study. Finally, we introduce the p opularity b ias aware w eb A PI r ecommendation ( PB-WAR ) approach to mitigate popularity bias in correlation graph-based API recommendations. Experimental results over a real world dataset demonstrate that PB-WAR offers the optimal trade-off between accuracy and debiasing performance compared to other competitive methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4393520081",
    "type": "article"
  },
  {
    "title": "Fair Projections as a Means Towards Balanced Recommendations",
    "doi": "https://doi.org/10.1145/3664929",
    "publication_date": "2024-05-14",
    "publication_year": 2024,
    "authors": "Aris Anagnostopoulos; Luca Becchetti; Matteo Böhm; Adriano Fazzone; Stefano Leonardi; Cristina Menghini; Chris Schwiegelshohn",
    "corresponding_authors": "",
    "abstract": "The goal of recommender systems is to provide to users suggestions that match their interests, with the eventual goal of increasing their satisfaction, as measured by the number of transactions (clicks, purchases, and so forth). Often, this leads to providing recommendations that are of a particular type. For some contexts (e.g., browsing videos for information) this may be undesirable, as it may enforce the creation of filter bubbles. This is because of the existence of underlying bias in the input data of prior user actions. Reducing hidden bias in the data and ensuring fairness in algorithmic data analysis has recently received significant attention. In this article, we consider both the densest subgraph and the \\(k\\) -clustering problem, two primitives that are being used by some recommender systems. We are given a coloring on the nodes, respectively the points, and aim to compute a fair solution \\(S\\) , consisting of a subgraph or a clustering, such that none of the colors is disparately impacted by the solution. Unfortunately, introducing fair solutions typically makes these problems substantially more difficult. Unlike the unconstrained densest subgraph problem, which is solvable in polynomial time, the fair densest subgraph problem is NP-hard even to approximate, which means that with the standard computational model it is probably impossible to solve (or even approximate it sufficiently well) in polynomial time. For \\(k\\) -clustering, the fairness constraints make the problem very similar to capacitated clustering, which is a notoriously hard problem to even approximate. Despite such negative premises, we are able to provide positive results in important use cases. In particular, we are able to prove that a suitable spectral embedding allows recovery of an almost optimal, fair, dense subgraph hidden in the input data, whenever one is present, a result that is further supported by experimental evidence. We also show a polynomial-time, \\(2\\) -approximation algorithm to the problem of fair densest subgraph, assuming that there exist only two colors and both colors occur equally often in the graph. This result turns out to be optimal assuming the small set expansion hypothesis. For fair \\(k\\) -clustering, we show that we can recover high quality fair clusterings effectively and efficiently. For the special case of \\(k\\) -median and \\(k\\) -center, we offer additional, fast and simple approximation algorithms as well as new hardness results. The above theoretical findings drive the design of heuristics, which we experimentally evaluate on a scenario based on real data, in which our aim is to strike a good balance between diversity and highly correlated items from Amazon co-purchasing graphs and Facebook contacts. We additionally evaluated our algorithmic solutions for the fair \\(k\\) -median problem through experiments on various real-world datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396891781",
    "type": "article"
  },
  {
    "title": "Model-Agnostic Adaptive Testing for Intelligent Education Systems via Meta-learned Gradient Embeddings",
    "doi": "https://doi.org/10.1145/3660642",
    "publication_date": "2024-05-23",
    "publication_year": 2024,
    "authors": "Haoyang Bi; Qi Liu; Han Wu; Weidong He; Zhenya Huang; Yu Yin; Haiping Ma; Yu Su; Shijin Wang; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "The field of education has undergone a significant revolution with the advent of intelligent systems and technology, which aim to personalize the learning experience, catering to the unique needs and abilities of individual learners. In this pursuit, a fundamental challenge is designing proper test for assessing the students’ cognitive status on knowledge and skills accurately and efficiently. One promising approach, referred to as Computerized Adaptive Testing (CAT), is to administrate computer-automated tests that alternately select the next item for each examinee and estimate their cognitive states given their responses to the selected items. Nevertheless, existing CAT systems suffer from inflexibility in item selection and ineffectiveness in cognitive state estimation, respectively. In this article, we propose a Model-Agnostic adaptive testing framework via Meta-leaned Gradient Embeddings, MAMGE for short, improving both item selection and cognitive state estimation simultaneously. For item selection, we design a Gradient Embedding-based Item Selector (GEIS) which incorporates the concept of gradient embeddings to represent items and selects the best ones that are both informative and representative. For cognitive state estimation, we propose a Meta-learned Cognitive State Estimator (MCSE) to automatically control the estimation process by learning to learn a proper initialization and dynamically inferred updates. Both MCSE and GEIS are inherently model-agnostic, and the two modules have an ingenious connection via meta-learned gradient embeddings. Finally, extensive experiments evaluate the effectiveness and flexibility of MAMGE.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4398232793",
    "type": "article"
  },
  {
    "title": "Improving Faithfulness and Factuality with Contrastive Learning in Explainable Recommendation",
    "doi": "https://doi.org/10.1145/3653984",
    "publication_date": "2024-05-25",
    "publication_year": 2024,
    "authors": "Haojie Zhuang; Wei Emma Zhang; Weitong Chen; Jian Yang; Quan Z. Sheng",
    "corresponding_authors": "",
    "abstract": "Recommender systems have become increasingly important in navigating the vast amount of information and options available in various domains. By tailoring and personalizing recommendations to user preferences and interests, these systems improve the user experience, efficiency and satisfaction. With a growing demand for transparency and understanding of recommendation outputs, explainable recommender systems have gained growing attention in recent years. Additionally, as user reviews could be considered the rationales behind why the user likes (or dislikes) the products, generating informative and reliable reviews alongside recommendations has thus emerged as a research focus in explainable recommendation. However, the model-generated reviews might contain factual inconsistent contents (i.e., the hallucination issue), which would thus compromise the recommendation rationales. To address this issue, we propose a contrastive learning framework to improve the faithfulness and factuality in explainable recommendation in this paper. We further develop different strategies of generating positive and negative examples for contrastive learning, such as back-translation or synonym substitution for positive examples, and editing positive examples or utilizing model-generated texts for negative examples. Our proposed method optimizes the model to distinguish faithful explanations (i.e., positive examples) and unfaithful ones with factual errors (i.e., negative examples), which thus drives the model to generate faithful reviews as explanations while avoiding inconsistent contents. Extensive experiments and analysis on three benchmark datasets show that our proposed model outperforms other review generation baselines in faithfulness and factuality. In addition, the proposed contrastive learning component could be easily incorporated into other explainable recommender systems in a plug-and-play manner.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399021912",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving and Diversity-Aware Trust-based Team Formation in Online Social Networks",
    "doi": "https://doi.org/10.1145/3670411",
    "publication_date": "2024-06-05",
    "publication_year": 2024,
    "authors": "Yash Mahajan; Jin-Hee Cho; Ing-Ray Chen",
    "corresponding_authors": "",
    "abstract": "As online social networks (OSNs) become more prevalent, a new paradigm for problem-solving through crowd-sourcing has emerged. By leveraging the OSN platforms, users can post a problem to be solved and then form a team to collaborate and solve the problem. A common concern in OSNs is how to form effective collaborative teams, as various tasks are completed through online collaborative networks. A team’s diversity in expertise has received high attention to producing high team performance in developing team formation (TF) algorithms. However, the effect of team diversity on performance under different types of tasks has not been extensively studied. Another important issue is how to balance the need to preserve individuals’ privacy with the need to maximize performance through active collaboration, as these two goals may conflict with each other. This research has not been actively studied in the literature. In this work, we develop a team formation (TF) algorithm in the context of OSNs that can maximize team performance and preserve team members’ privacy under different types of tasks. Our proposed PR iv A cy- D iversity- A ware T eam F ormation framework, called PRADA-TF , is based on trust relationships between users in OSNs where trust is measured based on a user’s expertise and privacy preference levels. The PRADA-TF algorithm considers the team members’ domain expertise, privacy preferences, and the team’s expertise diversity in the process of team formation. Our approach employs game-theoretic principles Mechanism Design to motivate self-interested individuals within a team formation context, positioning the mechanism designer as the pivotal team leader responsible for assembling the team. We use two real-world datasets (i.e., Netscience and IMDb) to generate different semi-synthetic datasets for constructing trust networks using a belief model (i.e., Subjective Logic) and identifying trustworthy users as candidate team members. We evaluate the effectiveness of our proposed PRADA-TF scheme in four variants against three baseline methods in the literature. Our analysis focuses on three performance metrics for studying OSNs: social welfare, privacy loss, and team diversity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399364170",
    "type": "article"
  },
  {
    "title": "Ranking the Transferability of Adversarial Examples",
    "doi": "https://doi.org/10.1145/3670409",
    "publication_date": "2024-06-05",
    "publication_year": 2024,
    "authors": "Moshe Levy; Guy Amit; Yuval Elovici; Yisroel Mirsky",
    "corresponding_authors": "",
    "abstract": "Adversarial transferability in blackbox scenarios presents a unique challenge: while attackers can employ surrogate models to craft adversarial examples, they lack assurance on whether these examples will successfully compromise the target model. Until now, the prevalent method to ascertain success has been trial and error—testing crafted samples directly on the victim model. This approach, however, risks detection with every attempt, forcing attackers to either perfect their first try or face exposure. Our paper introduces a ranking strategy that refines the transfer attack process, enabling the attacker to estimate the likelihood of success without repeated trials on the victim’s system. By leveraging a set of diverse surrogate models, our method can predict transferability of adversarial examples. This strategy can be used to either select the best sample to use in an attack or the best perturbation to apply to a specific sample. Using our strategy, we were able to raise the transferability of adversarial examples from a mere 20%—akin to random selection—up to near upper-bound levels, with some scenarios even witnessing a 100% success rate. This substantial improvement not only sheds light on the shared susceptibilities across diverse architectures but also demonstrates that attackers can forego the detectable trial-and-error tactics raising increasing the threat of surrogate-based attacks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399364791",
    "type": "article"
  },
  {
    "title": "Special Issue on Responsible Recommender Systems Part 1",
    "doi": "https://doi.org/10.1145/3663528",
    "publication_date": "2024-06-15",
    "publication_year": 2024,
    "authors": "Lina Yao; Julian McAuley; Xianzhi Wang; Dietmar Jannach",
    "corresponding_authors": "",
    "abstract": "introduction Free Access Share on Just AcceptedSpecial Issue on Responsible Recommender Systems Part 1 Authors: Lina Yao CSIRO's Data61 and University of New South Wales, Australia CSIRO's Data61 and University of New South Wales, Australia 0000-0002-4149-839XSearch about this author , Julian McAuley University of California, USA University of California, USASearch about this author , Xianzhi Wang University of Technology Sydney, Australia University of Technology Sydney, Australia 0000-0001-9582-3445Search about this author , Dietmar Jannach University of Klagenfurt, Austria University of Klagenfurt, Austria 0000-0002-4698-8507Search about this author Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyAccepted on April 2024https://doi.org/10.1145/3663528Online AM:15 June 2024Publication History 0citation5DownloadsMetricsTotal Citations0Total Downloads5Last 12 Months5Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Publisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399702003",
    "type": "article"
  },
  {
    "title": "Explaining Neural News Recommendation with Attributions onto Reading Histories",
    "doi": "https://doi.org/10.1145/3673233",
    "publication_date": "2024-06-18",
    "publication_year": 2024,
    "authors": "Lucas Möller; Sebastian Padó",
    "corresponding_authors": "",
    "abstract": "An important aspect of responsible recommendation systems is the transparency of the prediction mechanisms. This is a general challenge for deep-learning-based systems such as the currently predominant neural news recommender architectures which are optimized to predict clicks by matching candidate news items against users’ reading histories. Such systems achieve state-of-the-art click-prediction performance, but the rationale for their decisions is difficult to assess. At the same time, the economic and societal impact of these systems makes such insights very much desirable. In this paper, we ask the question to what extent the recommendations of current news recommender systems are actually based on content-related evidence from reading histories. We approach this question from an explainability perspective. Building on the concept of integrated gradients, we present a neural news recommender that can accurately attribute individual recommendations to news items and words in input reading histories while maintaining a top scoring click-prediction performance. Using our method as a diagnostic tool, we find that: (a), a substantial number of users’ clicks on news are not explainable from reading histories, and many history-explainable items are actually skipped; (b), while many recommendations are based on content-related evidence in histories, for others the model does not attend to reasonable evidence, and recommendations stem from a spurious bias in user representations. Our code is publicly available 1 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399777907",
    "type": "article"
  },
  {
    "title": "MedNER: Enhanced Named Entity Recognition in Medical Corpus via Optimized Balanced and Deep Active Learning",
    "doi": "https://doi.org/10.1145/3678178",
    "publication_date": "2024-07-17",
    "publication_year": 2024,
    "authors": "Yan Zhuang; Junyan Zhang; Ruogu Lu; Kunlun He; Xiuxing Li",
    "corresponding_authors": "",
    "abstract": "Ever-growing electronic medical corpora provide unprecedented opportunities for researchers to analyze patient conditions and drug effects. Meanwhile, severe challenges emerged in the large-scale electronic medical records process phase. Primarily, emerging words for medical terms, including informal descriptions, are difficult to recognize. Moreover, although deep models can help in entity extraction on medical texts, they require large-scale labels, which are time-intensive to obtain and not always available in the medical domain. However, when encountering a situation where massive unseen concepts appear or labeled data is insufficient, the performance of existing algorithms will suffer an intolerable decline. In this article, we propose a balanced and deep active learning framework for Medical Named Entity Recognition (MedNER) to alleviate the above problems. Specifically, to describe our selection strategy precisely, we first define the uncertainty of a medical sentence as a labeling loss predicted by a loss-prediction module and define diversity as the least text distance between pairs of sentences in a sample batch computed based on word-morpheme embeddings. Furthermore, aiming to make a trade-off between uncertainty and diversity, we formulate a Distinct-K optimization problem to maximize the slightest uncertainty and diversity of chosen sentences. Finally, we propose a threshold-based approximation selection algorithm, Distinct-K Filter , which selects the most beneficial training samples by balancing diversity and uncertainty. Extensive experimental results on real datasets demonstrate that MedNER significantly outperforms existing approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400729358",
    "type": "article"
  },
  {
    "title": "Online Spatial-Temporal EV Charging Scheduling with Incentive Promotion",
    "doi": "https://doi.org/10.1145/3678180",
    "publication_date": "2024-07-17",
    "publication_year": 2024,
    "authors": "Lo Pang-Yun Ting; H. Paul Wang; Jhe-Yun Jhang; Kun-Ta Chuang",
    "corresponding_authors": "",
    "abstract": "The growing adoption of electric vehicles (EVs) has resulted in an increased demand for public EV charging infrastructure. Currently, the collaboration between these stations has become vital for efficient charging scheduling and cost reduction. However, most existing scheduling methods primarily focus on recommending charging stations without considering users’ charging preferences. Adopting these strategies may require considerable modifications to how people charge their EVs, which could lead to a reluctance to follow the scheduling plan from charging services in real-world situations. To address these challenges, we propose the POSKID framework in this article. It focuses on spatial-temporal charging scheduling, aiming to recommend a feasible charging arrangement, including a charging station and a charging time slot, to each EV user while minimizing overall operating costs and ensuring users’ charging satisfaction. The framework adopts an online charging mechanism that provides recommendations without prior knowledge of future electricity information or charging requests. To enhance users’ willingness to accept the recommendations, POSKID incorporates an incentive strategy and a novel embedding method combined with Bayesian personalized analysis. These techniques reveal users’ implicit charging preferences, enhancing the success probability of the charging scheduling task. Furthermore, POSKID integrates an online candidate arrangement selection and an explore-exploit strategy to improve the charging arrangement recommendations based on users’ feedback. Experimental results using real-world datasets validate the effectiveness of POSKID in optimizing charging management, surpassing other strategies. The results demonstrate that POSKID benefits each charging station while ensuring user charging satisfaction.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400729540",
    "type": "article"
  },
  {
    "title": "WC-SBERT: Zero-Shot Topic Classification Using SBERT and Light Self-Training on Wikipedia Categories",
    "doi": "https://doi.org/10.1145/3678183",
    "publication_date": "2024-07-18",
    "publication_year": 2024,
    "authors": "Te-Yu Chi; Jyh‐Shing Roger Jang",
    "corresponding_authors": "",
    "abstract": "In natural language processing (NLP), zero-shot topic classification requires machines to understand the contextual meanings of texts in a downstream task without using the corresponding labeled texts for training, which is highly desirable for various applications. In this article, we propose a novel approach to construct a zero-shot task-specific model called WC-SBERT with satisfactory performance. The proposed approach is highly efficient since it uses light self-training requiring target labels (target class names of downstream tasks) only, which is distinct from other research that uses both the target labels and the unlabeled texts for training. In particular, during the pre-training stage, WC-SBERT uses contrastive learning with multiple negative ranking losses to construct the pre-trained model based on the similarity between Wiki categories. For the self-training stage, online contrastive loss is utilized to reduce the distance between a target label and Wiki categories of similar Wiki pages to the label. Experimental results indicate that compared to existing self-training models, WC-SBERT achieves rapid inference on approximately 6.45 million Wiki text entries by utilizing pre-stored Wikipedia text embeddings, significantly reducing inference time per sample by a factor of 2,746 to 16,746. During the fine-tuning step, the time required for each sample is reduced by a factor of 23–67. Overall, the total training time shows a maximum reduction of 27.5 times across different datasets. Most importantly, our model has achieved state-of-the-art (SOTA) accuracy on two of the three commonly used datasets for evaluating zero-shot classification, namely the AG News (0.84) and Yahoo! Answers (0.64) datasets. The code for WC-SBERT is publicly available on GitHub, 1 and the dataset can also be accessed on Hugging Face. 2",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400777868",
    "type": "article"
  },
  {
    "title": "Toward Ubiquitous Interaction-Attentive and Extreme-Aware Crowd Activity Level Prediction",
    "doi": "https://doi.org/10.1145/3682063",
    "publication_date": "2024-07-29",
    "publication_year": 2024,
    "authors": "Huiqun Huang; Xi Yang; Suining He; Mahan Tabatabaie",
    "corresponding_authors": "",
    "abstract": "Accurate prediction of citywide crowd activity levels (CALs), i.e. , the numbers of participants of citywide crowd activities under different venue categories at certain time and locations, is essential for the city management, the personal service applications, and the entrepreneurs in commercial strategic planning. Existing studies have not thoroughly taken into account the complex spatial and temporal interactions among different categories of CALs and their extreme occurrences, leading to lowered adaptivity and accuracy of their models. To address above concerns, we have proposed IE-CALP , a novel spatio-temporal I nteractive attention-based and E xtreme-aware model for C rowd A ctivity L evel P rediction. The tasks of IE-CALP consist of (a) forecasting the spatial distributions of various CALs at different city regions (spatial CALs), and (b) predicting the number of participants per category of the CALs (categorical CALs). To realize above, we have designed a novel spatial CAL-POI interaction-attentive learning component in IE-CALP to model the spatial interactions across different CAL categories, as well as those among the spatial urban regions and CALs. In addition, IE-CALP incorporate the multi-level trends ( e.g. , daily and weekly levels of temporal granularity) of CALs through a multi-level temporal feature learning component. Furthermore, to enhance the model adaptivity to extreme CALs ( e.g. , during extreme urban events or weather conditions), we further take into account the extreme value theory and model the impacts of historical CALs upon the occurrences of extreme CALs. Extensive experiments upon a total of 738,715 CAL records and 246,660 POIs in New York City (NYC), Los Angeles (LA), and Tokyo have further validated the accuracy, adaptivity, and effectiveness of IE-CALP ’s interaction-attentive and extreme-aware CAL predictions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401079163",
    "type": "article"
  },
  {
    "title": "Adversarial Missingness Attacks on Causal Structure Learning",
    "doi": "https://doi.org/10.1145/3682065",
    "publication_date": "2024-08-27",
    "publication_year": 2024,
    "authors": "Deniz Koyuncu; Alex Gittens; Bülent Yener; Moti Yung",
    "corresponding_authors": "",
    "abstract": "Causality-informed machine learning has been proposed as an avenue for achieving many of the goals of modern machine learning, from ensuring generalization under domain shifts to attaining fairness, robustness, and interpretability. A key component of causal machine learning is the inference of causal structures from observational data; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate structural causal models (SCMs). However, when the data can be audited for correctness (e.g., it is cryptographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner (under strong signed sample input validation, this behavior seems to be the only strategy available to the adversary). Under this model, theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given. Experimental validation of these approaches on real and synthetic datasets, across a range of SCMs from the family of additive noise models (linear Gaussian, linear non-Gaussian, and non-linear Gaussian), demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structure learning algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401933889",
    "type": "article"
  },
  {
    "title": "Multiple-Instance Learning from Pairwise Comparison Bags",
    "doi": "https://doi.org/10.1145/3696460",
    "publication_date": "2024-09-29",
    "publication_year": 2024,
    "authors": "Shengjie Zhou; Senlin Shu; Haobo Wang; Hongxin Wei; Tao Xiang; Beibei Li",
    "corresponding_authors": "",
    "abstract": "Multiple-instance learning (MIL) is a significant weakly supervised learning problem, where the training data consists of bags containing multiple instances and bag-level labels. Most previous MIL research required fully labeled bags. However, collecting such data is challenging due to the labeling costs or privacy concerns. Fortunately, we can easily collect pairwise comparison information, indicating one bag is more likely to be positive than the other. Therefore, we investigate a novel MIL problem about learning a bag-level binary classifier only from pairwise comparison bags. To solve this problem, we display the data generation process and provide a baseline method to train an instance-level classifier based on unlabeled-unlabeled learning. To achieve better performance, we propose a convex formulation to train a bag-level classifier and give a generalization error bound. Comprehensive experiments show that both the baseline method and the convex formulation achieve satisfactory performance, while the convex formulation performs better. 1",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403005059",
    "type": "article"
  },
  {
    "title": "OptiRet-Net: An Optimized Low-Light Image Enhancement Technique for CV-based Applications in Resource-Constrained Environments",
    "doi": "https://doi.org/10.1145/3700136",
    "publication_date": "2024-10-12",
    "publication_year": 2024,
    "authors": "Hanan Hussain; P. S. Tamizharasan; Praveen Kumar Yadav",
    "corresponding_authors": "",
    "abstract": "The illumination of images can significantly impact computer-vision applications such as image classification, multiple object detection, and tracking, leading to a significant decline in detection and tracking accuracy. Recent advancements in deep learning techniques have been applied to low-light image enhancement (LLIE) to combat this issue. Retinex theory-based methods following a decomposition-adjustment pipeline for LLIE have performed well in various aspects. Despite their success, current research on Retinex-based deep learning still needs to improve in terms of optimization techniques and complicated convolution connections, which can be computationally intensive for end-device deployment. We propose an Optimized Retinex-based CNN (OptiRet-Net) deep-learning framework to address these challenges for the low-light image enhancement problem. Our results demonstrate that the proposed method outperforms existing state-of-the-art models in terms of full reference metrics with a PSNR of 21.87, SSIM of 0.80, LPIPS of 0.16, and zero reference metrics with a NIQE of 3.4 and PIQE of 56.6. Additionally, we validate our approach using a comprehensive evaluation comprising five datasets and nine prior methods. Furthermore, we assess the efficacy of our proposed model combining low-light multiple object tracking applications using YOLOX and ByteTrack in versatile video coding (VVC/H.266) across various quantization parameters. Our findings reveal that LLIE-enhanced frames surpass their tracking results with a MOTA of 80.6% and a remarkable precision rate of 96%. Our model also achieves minimal file sizes by effectively compressing the enhanced low-light images while maintaining their quality, making it suitable for resource-constrained environments where storage or bandwidth limitations are a concern.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403353381",
    "type": "article"
  },
  {
    "title": "Special Issue on Responsible Recommender Systems Part 2",
    "doi": "https://doi.org/10.1145/3689367",
    "publication_date": "2024-10-14",
    "publication_year": 2024,
    "authors": "Lina Yao; Julian McAuley; Xianzhi Wang; Dietmar Jannach",
    "corresponding_authors": "",
    "abstract": "Most recommender systems attempt to use collaborative filtering, content-based filtering or hybrid approach to recommend items to new users. Collaborative filtering recommends items to new users based on their similar neighbours, and content-based ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403380451",
    "type": "article"
  },
  {
    "title": "Proposal Semantic Relationship Graph Network for Temporal Action Detection",
    "doi": "https://doi.org/10.1145/3702233",
    "publication_date": "2024-10-28",
    "publication_year": 2024,
    "authors": "Shaowen Su; Yan Zhang; Minggang Gan",
    "corresponding_authors": "",
    "abstract": "Temporal action detection, a critical task in video activity understanding, is typically divided into two stages: proposal generation and classification. However, most existing methods overlook the importance of information transfer among proposals during classification, often treating each proposal in isolation, which hampers accurate label prediction. In this paper, we propose a novel method for inferring semantic relationships both within and between action proposals, guiding the fusion of action proposal features accordingly. Building on this approach, we introduce the Proposal Semantic Relationship Graph Network (PSRGN), an end-to-end model that leverages intra-proposal semantic relationship graphs to extract cross-scale temporal context and an inter-proposal semantic relationship graph to incorporate complementary neighboring information, significantly improving proposal feature quality and overall detection performance. This is the first method to apply graph structure learning in temporal action detection, adaptively constructing the inter-proposal semantic graph. Extensive experiments on two datasets demonstrate the effectiveness of our approach, achieving state-of-the-art results. Code and results are available at http://github.com/Riiick2011/PSRGN .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403829888",
    "type": "article"
  },
  {
    "title": "Extracting Political Interest Model from Interaction Data Based on Novel Word-level Bias Assignment",
    "doi": "https://doi.org/10.1145/3702649",
    "publication_date": "2024-10-31",
    "publication_year": 2024,
    "authors": "Yihong Zhang; Takahiro Hara",
    "corresponding_authors": "",
    "abstract": "In democratic countries, political interest is deeply involved in people's daily lives. Research in political consumerism shows that product purchase decision is also influenced by the political orientation of the consumer. In traditional recommendation system design, user interest in an item is provided by a unified model. Recently, interest disentanglement methods have been introduced. It is shown that by disentangling interest factors such as conformity and private interest, recommendation performance can be significantly improved. However, few studies attempt to disentangle political interest in purchase behavior, which is bipolar. In this paper, we propose a method to extract political interest model from e-commerce interaction data, which is supported by a novel word-level political bias assignment. For the bias assignment part, we improved a political bias distilling method. For the political interest model extraction part, we extend a one-side bias method to make it support bipolar bias. We compare our method with state-of-the-art baseline methods in several evaluation settings, and the experimental results show that our method can achieve superior performance. Further investigation shows that our method is consistent with theories of political consumerism.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403963809",
    "type": "article"
  },
  {
    "title": "BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for Graph Continual Learning",
    "doi": "https://doi.org/10.1145/3702648",
    "publication_date": "2024-10-31",
    "publication_year": 2024,
    "authors": "Jihoon Ko; Shinhwan Kang; Taehyung Kwon; Heechan Moon; Kijung Shin",
    "corresponding_authors": "",
    "abstract": "Continual Learning (CL) is the process of learning ceaselessly a sequence of tasks. Most existing CL methods deal with independent data (e.g., images and text) for which many benchmark frameworks and results under standard experimental settings are available. Compared to them, however, CL methods for graph data (graph CL) are relatively underexplored because of (a) the lack of standard experimental settings, especially regarding how to deal with the dependency between instances, (b) the lack of benchmark datasets and scenarios, and (c) high complexity in implementation and evaluation due to the dependency. In this paper, regarding (a) we define four standard incremental settings (task-, class-, domain-, and time-incremental) for node-, link-, and graph-level problems, extending the previously explored scope. Regarding (b), we provide 35 benchmark scenarios based on 24 real-world graphs. Regarding (c), we develop BeGin, an easy and fool-proof framework for graph CL. BeGin is easily extended since it is modularized with reusable modules for data processing, algorithm design, and evaluation. Especially, the evaluation module is completely separated from user code to eliminate potential mistakes. Regarding benchmark results, we cover 3X more combinations of incremental settings and levels of problems than the latest benchmark. All assets for the benchmark framework are publicly available at https://github.com/ShinhwanKang/BeGin .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403990225",
    "type": "article"
  },
  {
    "title": "Biomedical Information Retrieval with Positive-Unlabeled Learning and Knowledge Graphs",
    "doi": "https://doi.org/10.1145/3702647",
    "publication_date": "2024-11-04",
    "publication_year": 2024,
    "authors": "Yuqi Wang; Qiuyi Chen; Haiyang Zhang; Wei Wang; Qiufeng Wang; Yushan Pan; Liangru Xie; Kaizhu Huang; Anh Nguyen",
    "corresponding_authors": "",
    "abstract": "The rapid growth of biomedical publications has presented significant challenges in the field of information retrieval. Most existing work focuses on document retrieval given explicit queries. However, in real applications such as curated biomedical database maintenance, explicit queries are missing. In this paper, we propose a two-step model for biomedical information retrieval in the case that only a small set of example documents is available without explicit queries. Initially, we extract keywords from the observed documents using large pre-trained language models and biomedical knowledge graphs. These keywords are then enriched with domain-specific entities. Information retrieval techniques can subsequently use the collected entities to rank the documents. Following this, we introduce an iterative Positive-Unlabeled learning method to classify all unlabeled documents. Experiments conducted on the PubMed dataset demonstrate that the proposed technique outperforms the state-of-the-art positive-unlabeled learning methods. The results underscore the effectiveness of integrating large language models and biomedical knowledge graphs in improving zero-shot information retrieval performance in the biomedical domain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404021255",
    "type": "article"
  },
  {
    "title": "Edge Manipulations for the Maximum Vertex-Weighted Bipartite \\(b\\) -matching",
    "doi": "https://doi.org/10.1145/3702650",
    "publication_date": "2024-11-06",
    "publication_year": 2024,
    "authors": "Gennaro Auricchio; Jun Liu; Qun Ma; Jie Zhang",
    "corresponding_authors": "",
    "abstract": "In this paper, we explore the Mechanism Design aspects of the Maximum Vertex-weighted \\(b\\) -Matching (MVbM) problem on bipartite graphs \\((A\\cup T,E)\\) . The set \\(A\\) comprises agents, while \\(T\\) represents tasks. The set \\(E\\) , which connects \\(A\\) and \\(T\\) , is the private information of either agents or tasks. In this framework, we investigate three mechanisms – \\(\\mathbb{M}_{BFS}\\) , \\(\\mathbb{M}_{DFS}\\) , and \\(\\mathbb{M}_{G}\\) . We examine scenarios in which either agents or tasks are strategic and report their adjacent edges to one of the three mechanisms. In both cases, we assume that the strategic entities are bounded by their statements: they can hide edges, but they cannot report edges that do not exist. First, we consider the case in which agents can manipulate. In this framework, \\(\\mathbb{M}_{BFS}\\) and \\(\\mathbb{M}_{DFS}\\) are optimal but not truthful. By characterizing the Nash Equilibria induced by \\(\\mathbb{M}_{BFS}\\) and \\(\\mathbb{M}_{DFS}\\) , we reveal that both mechanisms have a Price of Anarchy ( \\(PoA\\) ) and Price of Stability ( \\(PoS\\) ) of \\(2\\) . These efficiency guarantees are tight; no deterministic mechanism can achieve a lower \\(PoA\\) or \\(PoS\\) . In contrast, the third mechanism, \\(\\mathbb{M}_{G}\\) , is not optimal, but truthful and its approximation ratio is \\(2\\) . We demonstrate that this ratio is optimal; no deterministic and truthful mechanism can outperform it. We then shift our focus to scenarios where tasks can exhibit strategic behaviour. In this case, \\(\\mathbb{M}_{BFS}\\) , \\(\\mathbb{M}_{DFS}\\) , and \\(\\mathbb{M}_{G}\\) all maintain truthfulness, making \\(\\mathbb{M}_{BFS}\\) and \\(\\mathbb{M}_{DFS}\\) truthful and optimal mechanisms. In conclusion, we investigate the manipulability of \\(\\mathbb{M}_{BFS}\\) and \\(\\mathbb{M}_{DFS}\\) through experiments on randomly generated graphs. We observe that (i) \\(\\mathbb{M}_{BFS}\\) is less prone to be manipulated by the first agent than \\(\\mathbb{M}_{DFS}\\) , and (ii) \\(\\mathbb{M}_{BFS}\\) is more manipulable on instances in which the total capacity of the agents is equal to the number of tasks. 1",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404107545",
    "type": "article"
  },
  {
    "title": "Tucker Decomposition Enhanced Dynamic Graph Convolutional Networks for Crowd Flows Prediction",
    "doi": "https://doi.org/10.1145/3706116",
    "publication_date": "2024-12-02",
    "publication_year": 2024,
    "authors": "Genan Dai; Weiyang Kong; Yubao Liu; Bowen Zhang; Xiaojiang Peng; Xiaomao Fan; Hu Huang",
    "corresponding_authors": "",
    "abstract": "Crowd flows prediction is an important problem for traffic management and public safety. Graph Convolutional Network (GCN), known for its ability to effectively capture and utilize topological information, has demonstrated significant advancements in addressing this problem. However, GCN-based models were often based on predefined crowd-flow graphs via historical movement behaviors of human beings and traffic vehicles, which ignored the abnormal changes in crowd flows. In this study, we propose a multi-scale fusion GCN-based framework with Tucker decomposition named mTDNet to enhance dynamic GCN for Crowd flows prediction. Following the paradigm of extant methods, we also employ the predefined crowd-flow graphs as a part of mTDNet to effectively capture the historical movement behaviors of crowd flows. To capture the abnormal changes, we propose a Tucker decomposition-based network with the product of the adjacency matrix of historical movement pattern graphs and an adaptive learning tensor ( \\(ALT\\) ) by reconstructing the crowd flows. Particularly, we utilize the Tucker decomposition scheme to decompose \\(ALT\\) , which enhances the dynamic learning of graph structures, allowing for effective capturing of the dynamic changes in crowd flow, including abnormal changes. Furthermore, a multi-scale three-dimensional GCN is utilized to mine and fuse the multiscale spatio-temporal information from crowd flows, to further boost the mTDNet prediction performance. Experiments conducted on two real-world datasets showed that the proposed mTDNet surpasses other crowd flow prediction methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404921304",
    "type": "article"
  },
  {
    "title": "Detecting Misinformation on Social Media Using Community Insights and Contrastive Learning",
    "doi": "https://doi.org/10.1145/3709009",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Oguzhan Ozcelik; Çağrı Toraman; Fazlı Can",
    "corresponding_authors": "",
    "abstract": "Social media users are more likely to be exposed to similar views and tend to avoid contrasting views, especially when they are part of a community of social media users. In this study, we investigate the presence of user communities and leverage them as a tool to detect misinformation on social media, specifically on Twitter. We propose a misinformation detection framework, namely Similarity-based Misinformation Detection (SiMiD) that employs microblogs and utilizes user-follower interactions within a social network. Our approach extracts important textual features of social media posts using a transformer-based language model. We use contrastive learning and pseudo-labeling to fine-tune the language model. Then, we measure the similarity for each social media post, based on its relevance to each user in the communities. Finally, we train a machine learning model to identify the truthfulness of social media posts using these similarity scores. We evaluate our approach on three social media datasets, compare our method with twelve state-of-the-art approaches, and answer five research questions. The experimental results, supported by statistical tests, show that contrastive learning and user communities can enhance the detection of misinformation on social media. Our model can identify misinformation content by achieving a consistently high weighted F1 score of over 90% across all datasets, even employing only a small number of users in communities. We make our implementations publicly available and provide all details that are necessary for the reproducibility of experiments. 1",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405566696",
    "type": "article"
  },
  {
    "title": "An Underwater Imaging Generative Adversarial Network by Simulating the Mechanism of Light Propagation in Water",
    "doi": "https://doi.org/10.1145/3709003",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Yujuan Sun; Xing Huang; Yanfang Cui; Junyu Dong; Xiaofeng Zhang; Tao Yao",
    "corresponding_authors": "",
    "abstract": "Since capturing underwater images without degradation is challenging, there are few real image datasets with paired ground truth for underwater image enhancement. In this paper, we propose a generative adversarial network (UIGAN) for underwater imaging; the network can convert images and their corresponding depth maps captured in air into images in water. The underwater imaging mechanism relies on many intrinsic parameters in water, which are difficult to estimate without field calibration. As the strong modeling capability of deep neural networks, this paper uses the deep learning model to extract parameters from the real underwater environment. Then the proposed UIGAN simulates the light propagation process (direct attenuation, backscattering and forward scattering) in water by using three modules with different constraints. We can generate a large training dataset with paired images in air and real water environment. The generated UIGAN dataset serves as input to a forward-attention transfer underwater enhancement model (FATUECNN), and it can output the restored images with appearance like those captured in air. The proposed pipeline is verified both qualitatively and quantitatively by extensive experiments and comparison evaluation with the existing state-of-the-art methods. The source code and the pretrained model are made publicly available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405615847",
    "type": "article"
  },
  {
    "title": "Robust Learning under Hybrid Noise",
    "doi": "https://doi.org/10.1145/3709149",
    "publication_date": "2024-12-23",
    "publication_year": 2024,
    "authors": "Wei Yang; Shuo Chen; Shanshan Ye; Bo Han; Chen Gong",
    "corresponding_authors": "",
    "abstract": "Feature noise and label noise are ubiquitous in practical scenarios, which pose great challenges for training a robust machine learning model. Most previous approaches usually deal with only a single problem of either feature noise or label noise. However, in real-world applications, hybrid noise, which contains both feature noise and label noise, is very common due to the unreliable data collection and annotation processes. Although some results have been achieved by a few representation learning based attempts, this issue is still far from being addressed with promising performance and guaranteed theoretical analyses. To address the challenge, we propose a novel unified learning framework called “ F eature and L abel R ecovery” (FLR) to combat the hybrid noise from the perspective of data recovery, where we concurrently reconstruct both the feature matrix and the label matrix of input data. Specifically, the clean feature matrix is discovered by the low-rank approximation, and the ground-truth label matrix is embedded based on the recovered features with a nuclear norm regularization. Meanwhile, the feature noise and label noise are characterized by their respective adaptive matrix norms to satisfy the corresponding maximum likelihood. As this framework leads to a non-convex optimization problem, we develop the non-convex Alternating Direction Method of Multipliers (ADMM) with the convergence guarantee to solve our learning objective. We also provide the theoretical analysis to show that the generalization error of FLR can be upper-bounded in the presence of hybrid noise. Experimental results on several typical benchmark datasets clearly demonstrate the superiority of our proposed method over the state-of-the-art robust learning approaches for various noises.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405720887",
    "type": "article"
  },
  {
    "title": "A Novel Intelligent Video Surveillance System Using Low-Traffic Scene-Preserving Video Anonymization",
    "doi": "https://doi.org/10.1145/3709001",
    "publication_date": "2024-12-24",
    "publication_year": 2024,
    "authors": "Jungwoo Huh; Jiwoo Kang; Jongwook Woo; Sanghoon Lee",
    "corresponding_authors": "",
    "abstract": "With the development of computer vision technology, intelligent video surveillance systems have been developed for automatic monitoring. However, the problem of personal information protection has also emerged. Existing systems attempted to solve this problem by anonymizing a video by, for example, sending only low-dimensional abstract information such as a person’s 2D pose or blurring a person’s face in the video before sending it to the central cloud server. However, these approaches failed to balance scene-preservation and traffic efficiency, because abstract information is too limited for preserving the entire scene, and video modification generates massive traffic. This paper proposes a novel intelligent video surveillance system to overcome such limitations that preserves the scene information and generates minimal traffic through video anonymization. The proposed system reconstructs 3D human models and estimates segmentation masks to preserve a scene captured by a surveillance camera in its entirety. Parametric models represent 3D human models with several sets of parameters, and dictionary coding compresses the segmentation mask with a high compression ratio. The system follows the edge-cloud architecture, where the edge node extracts and transmits the scene information and the central cloud server generates the final anonymized video. We demonstrate the effectiveness of the proposed system by conducting experiments on processing time, scene preservation, and traffic efficiency. Our proposed system runs in real-time (&gt;25fps) in a typical hardware setting and has a data compression ratio of more than 5,000 compared with raw data transfer while maintaining over 85% scene-preservation correlation with the original video.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405734368",
    "type": "article"
  },
  {
    "title": "Mobility Inference on Long-Tailed Sparse Trajectory",
    "doi": "https://doi.org/10.1145/3563457",
    "publication_date": "2022-09-12",
    "publication_year": 2022,
    "authors": "Lei Shi; Yuankai Luo; Shuai Ma; Hanghang Tong; Zhetao Li; Xiatian Zhang; Zhiguang Shan",
    "corresponding_authors": "",
    "abstract": "Analyzing the urban trajectory in cities has become an important topic in data mining. How can we model the human mobility consisting of stay and travel states from the raw trajectory data? How can we infer these mobility states from a single user’s trajectory information? How can we further generalize the mobility inference to the real-world trajectory data that span multiple users and are sparsely sampled over time? In this article, based on formal and rigid definitions of the stay/travel mobility, we propose a single trajectory inference algorithm that utilizes a generic long-tailed sparsity pattern in the large-scale trajectory data. The algorithm guarantees a 100% precision in the stay/travel inference with a provable lower bound in the recall metric. Furthermore, we design a transformer-like deep learning architecture on the problem of mobility inference from multiple sparse trajectories. Several adaptations from the standard transformer network structure are introduced, including the singleton design to avoid the negative effect of sparse labels in the decoder side, the customized space-time embedding on features of location records, and the mask apparatus at the output side for loss function correction. Evaluations on three trajectory datasets of 40 million urban users validate the performance guarantees of the proposed inference algorithm and demonstrate the superiority of our deep learning model, in comparison to sequence learning methods in the literature. On extremely sparse trajectories, the deep learning model improves from the single trajectory inference algorithm with more than two times of overall and F1 accuracy. The model also generalizes to large-scale trajectory data from different sources with good scalability.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3000794341",
    "type": "article"
  },
  {
    "title": "Impact of Driving Behavior on Commuter’s Comfort During Cab Rides: Towards a New Perspective of Driver Rating",
    "doi": "https://doi.org/10.1145/3523063",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Rohit Verma; Sugandh Pargal; Debasree Das; Tanusree Parbat; Sai Shankar Kambalapalli; Bivas Mitra; Sandip Chakraborty",
    "corresponding_authors": "",
    "abstract": "Commuter comfort in cab rides affects driver rating as well as the reputation of ride-hailing firms like Uber/Lyft. Existing research has revealed that commuter comfort not only varies at a personalized level but also is perceived differently on different trips for the same commuter. Furthermore, there are several factors, including driving behavior and driving environment, affecting the perception of comfort. Automatically extracting the perceived comfort level of a commuter due to the impact of the driving behavior is crucial for a timely feedback to the drivers, which can help them to meet the commuter's satisfaction. In light of this, we surveyed around 200 commuters who usually take such cab rides and obtained a set of features that impact comfort during cab rides. Following this, we develop a system Ridergo which collects smartphone sensor data from a commuter, extracts the spatial time series feature from the data, and then computes the level of commuter comfort on a five-point scale with respect to the driving. Ridergo uses a Hierarchical Temporal Memory model-based approach to observe anomalies in the feature distribution and then trains a Multi-task learning-based neural network model to obtain the comfort level of the commuter at a personalized level. The model also intelligently queries the commuter to add new data points to the available dataset and, in turn, improve itself over periodic training. Evaluation of Ridergo on 30 participants shows that the system could provide efficient comfort score with high accuracy when the driving impacts the perceived comfort.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3195281777",
    "type": "article"
  },
  {
    "title": "医用画像セグメンテーションのための深層ネットワークに基づくスーパーピクセル領域マージング【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2020-01-01",
    "publication_year": 2020,
    "authors": "Liu Hui; Haiou Wang; Wu Yan; Lei Xing",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3216621253",
    "type": "article"
  },
  {
    "title": "CAFE and SOUP: Toward Adaptive VDI Workload Prediction",
    "doi": "https://doi.org/10.1145/3529536",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Yao Zhang; Wenping Fan; Qichen Hao; Xinya Wu; Min-Ling Zhang",
    "corresponding_authors": "",
    "abstract": "For Virtual Desktop Infrastructure (VDI) system, effective resource management is rather important where turning off spare virtual machines would help save running cost while maintaining sufficient virtual machines is essential to secure satisfactory user experience. Current VDI resource management strategy works in a passive manner by either reactively driving available capacity based on user demands or following manually configured schedules, which may lead to unnecessary running costs or unsatisfactory user experience. In this article, we propose a first attempt toward proactive VDI resource management, where two adaptive learning approaches for VDI workload prediction are proposed by learning from multi-grained historical features. For non-persistent desktop pool, based on the aggregation session count of pool-sharing users, the CAFE approach induces a pool-level workload predictive model by utilizing coarse-to-fine historical features extracted from aggregation workload data. For persistent desktop pool, based on the session connection status of individual users within the same pool, the SOUP approach induces user-level workload predictive model by incorporating encoded multi-grained features extracted from the logon behavior of individual users into an aggregation pool-level model. Extensive experiments on datasets of real VDI customers and electricity load evidently verify the effectiveness of the proposed adaptive approaches for VDI workload prediction as well as other workload prediction tasks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4224287865",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Intelligent Trajectory Analytics: Part II",
    "doi": "https://doi.org/10.1145/3510021",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Kai Zheng; Yong Li; Cyrus Shahabi; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4224293622",
    "type": "article"
  },
  {
    "title": "Redundant Label Learning via Subspace Representation and Global Disambiguation",
    "doi": "https://doi.org/10.1145/3558547",
    "publication_date": "2022-09-15",
    "publication_year": 2022,
    "authors": "Gengyu Lyu; Songhe Feng; Wei Liu; Shuoyan Liu; Congyan Lang",
    "corresponding_authors": "",
    "abstract": "Redundant Label Learning (RLL) aims at inducing a robust model from training data, where each example is associated with a set of candidate labels, among which some of them are incorrect. Most existing approaches deal with such problem by disambiguating the candidate labels first and then inducing the predictive model from the disambiguated data. However, these approaches only focus on disambiguation for each instance’ candidate label set, while the global label context tends to be ignored. Meanwhile, these approaches usually induce the objective model by directly utilizing the original feature information, which may lead to the model overfitting due to high-dimensional redundant features. To tackle the above issues, we propose a novel feature S ubspac E R epresentation and label G lobal Disambiguat IO n ( SERGIO ) approach, which improves the generalization ability of the learning system from the perspective of both feature space and label space. Specifically, we project the original high-dimensional feature space into a low-dimensional subspace, where the projection matrix is regularized with an orthogonality constraint to make the subspace more compact. Meanwhile, we introduce a label confidence matrix and constrain it with ℓ 1 -norm and trace-norm regularization simultaneously, which are utilized to explore global label correlations and further well in accordance with the nature of single-label classification and multi-label classification problem, respectively. Extensive experiments on both single-label and multi-label RLL datasets demonstrate that our proposed method achieves competitive performance against state-of-the-art approaches.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4295943118",
    "type": "article"
  },
  {
    "title": "CDSM: <u>C</u> ascaded <u>D</u> eep <u>S</u> emantic <u>M</u> atching on Textual Graphs Leveraging Ad-hoc Neighbor Selection",
    "doi": "https://doi.org/10.1145/3573204",
    "publication_date": "2022-12-02",
    "publication_year": 2022,
    "authors": "Jing Yao; Zheng Liu; Junhan Yang; Zhicheng Dou; Xing Xie; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Deep semantic matching aims at discriminating the relationship between documents based on deep neural networks. In recent years, it becomes increasingly popular to organize documents with a graph structure, then leverage both the intrinsic document features and the extrinsic neighbor features to derive discrimination. Most of the existing works mainly care about how to utilize the presented neighbors, whereas limited effort is made to filter appropriate neighbors. We argue that the neighbor features could be highly noisy and partially useful. Thus, a lack of effective neighbor selection will not only incur a great deal of unnecessary computation cost but also restrict the matching accuracy severely. In this work, we propose a novel framework, C ascaded D eep S emantic M atching ( CDSM ), for accurate and efficient semantic matching on textual graphs. CDSM is highlighted for its two-stage workflow. In the first stage, a lightweight CNN-based ad-hod neighbor selector is deployed to filter useful neighbors for the matching task with a small computation cost. We design both one-step and multi-step selection methods. In the second stage, a high-capacity graph-based matching network is employed to compute fine-grained relevance scores based on the well-selected neighbors. It is worth noting that CDSM is a generic framework which accommodates most of the mainstream graph-based semantic matching networks. The major challenge is how the selector can learn to discriminate the neighbors’ usefulness which has no explicit labels. To cope with this problem, we design a weak-supervision strategy for optimization, where we train the graph-based matching network at first and then the ad-hoc neighbor selector is learned on top of the annotations from the matching network. We conduct extensive experiments with three large-scale datasets, showing that CDSM notably improves the semantic matching accuracy and efficiency thanks to the selection of high-quality neighbors. The source code is released at https://github.com/jingjyyao/CDSM.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4311119672",
    "type": "article"
  },
  {
    "title": "Self-supervised Bipartite Graph Representation Learning: A Dirichlet Max-margin Matrix Factorization Approach",
    "doi": "https://doi.org/10.1145/3645098",
    "publication_date": "2024-03-08",
    "publication_year": 2024,
    "authors": "Shenghai Zhong; Shu Guo; Jing Liu; Hongren Huang; Lihong Wang; Jianxin Li; Chen Li; Yiming Hei",
    "corresponding_authors": "",
    "abstract": "Bipartite graph representation learning aims to obtain node embeddings by compressing sparse vectorized representations of interactions between two types of nodes, e.g., users and items. Incorporating structural attributes among homogeneous nodes, such as user communities, improves the identification of similar interaction preferences, namely, user/item embeddings, for downstream tasks. However, existing methods often fail to proactively discover and fully utilize these latent structural attributes. Moreover, the manual collection and labeling of structural attributes is always costly. In this article, we propose a novel approach called Dirichlet Max-margin Matrix Factorization (DM3F), which adopts a self-supervised strategy to discover latent structural attributes and model discriminative node representations. Specifically, in self-supervised learning, our approach generates pseudo group labels (i.e., structural attributes) as a supervised signal using the Dirichlet process without relying on manual collection and labeling, and employs them in a max-margin classification. Additionally, we introduce a Variational Markov Chain Monte Carlo algorithm (Variational MCMC) to effectively update the parameters. The experimental results on six real datasets demonstrate that, in the majority of cases, the proposed method outperforms existing approaches based on matrix factorization and neural networks. Furthermore, the modularity analysis confirms the effectiveness of our model in capturing structural attributes to produce high-quality user embeddings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392595611",
    "type": "article"
  },
  {
    "title": "An Explore–Exploit Workload-Bounded Strategy for Rare Event Detection in Massive Energy Sensor Time Series",
    "doi": "https://doi.org/10.1145/3657641",
    "publication_date": "2024-04-17",
    "publication_year": 2024,
    "authors": "Lo Pang-Yun Ting; Rong Chao; Chai-Shi Chang; Kun-Ta Chuang",
    "corresponding_authors": "",
    "abstract": "With the rise of Internet-of-Things devices, the analysis of sensor-generated energy time series data has become increasingly important. This is especially crucial for detecting rare events like unusual electricity usage or water leakages in residential and commercial buildings, which is essential for optimizing energy efficiency and reducing costs. However, existing detection methods on large-scale data may fail to correctly detect rare events when they do not behave significantly differently from standard events or when their attributes are non-stationary. Additionally, the capacity of computational resources to analyze all time series data generated by an increasing number of sensors becomes a challenge. This situation creates an emergent demand for a workload-bounded strategy. To ensure both effectiveness and efficiency in detecting rare events in massive energy time series, we propose a heuristic-based framework called HALE . This framework utilizes an explore–exploit selection process that is specifically designed to recognize potential features of rare events in energy time series. HALE involves constructing an attribute-aware graph to preserve the attribute information of rare events. A heuristic-based random walk is then derived based on partial labels received at each time period to discover the non-stationarity of rare events. Potential rare event data are selected from the attribute-aware graph, and existing detection models are applied for final confirmation. Our study, which was conducted on three actual energy datasets, demonstrates that the HALE framework is both effective and efficient in its detection capabilities. This underscores its practicality in delivering cost-effective energy monitoring services.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4394877200",
    "type": "article"
  },
  {
    "title": "Teacher-Student Framework for Polyphonic Semi-supervised Sound Event Detection: Survey and Empirical Analysis",
    "doi": "https://doi.org/10.1145/3660641",
    "publication_date": "2024-04-23",
    "publication_year": 2024,
    "authors": "Zhor Diffallah; Hadjer Ykhlef; Hafida Bouarfa",
    "corresponding_authors": "",
    "abstract": "Polyphonic sound event detection refers to the task of automatically identifying sound events occurring simultaneously in an auditory scene. Due to the inherent complexity and variability of real-world auditory scenes, building robust detectors for polyphonic sound event detection poses a significant challenge. The task becomes furthermore challenging without sufficient annotated data to develop sound event detection systems under a supervised learning regime. In this article, we explore the recent developments in polyphonic sound event detection, with a particular emphasis on the application of Teacher-Student techniques within the semi-supervised learning paradigm. Unlike previous works, we have consolidated and organized the fragmented literature on Teacher-Student techniques for polyphonic sound event detection. By examining the latest research, categorizing Teacher-Student approaches, and conducting an empirical study to assess the performance of each approach, this survey offers valuable insights and practical guidance for researchers and practitioners in the field. Our findings highlight the potential benefits of utilizing multiple learners, ensuring consistent predictions, and making thoughtful choices regarding perturbation strategies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4395032904",
    "type": "article"
  },
  {
    "title": "Fair and Efficient Ridesharing: A Dynamic Programming-based Relocation Approach",
    "doi": "https://doi.org/10.1145/3675403",
    "publication_date": "2024-06-29",
    "publication_year": 2024,
    "authors": "Aqsa Ashraf Makhdomi; Iqra Altaf Gillani",
    "corresponding_authors": "",
    "abstract": "Recommending routes by their probability of having a rider has long been the goal of conventional route recommendation systems. While this maximizes the platform-specific criteria of efficiency, it results in sub-optimal outcomes with the disparity among the income of drivers who work for similar time frames. Pioneer studies on fairness in ridesharing platforms have focused on algorithms that match drivers and riders. However, these studies do not consider the time schedules of different riders sharing a ride in the ridesharing mode. To overcome this shortcoming, we present the first route recommendation system for ridesharing networks that explicitly considers fairness as an evaluation criterion. In particular, we design a routing mechanism that reduces the inequality among drivers and provides them with routes that have a similar probability of finding riders over a period of time. However, while optimizing fairness the efficiency of the platform should not be affected as both of these goals are important for the long-term sustainability of the system. In order to jointly optimize fairness and efficiency we consider repositioning drivers with low income to the areas that have a higher probability of finding riders in future. While applying driver repositioning, we design a future-aware policy and allocate the areas to the drivers considering the destination of requests in the corresponding area. Extensive simulations on real-world datasets of Washington DC and New York demonstrate superior performance by our proposed system in comparison to the existing baselines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400146931",
    "type": "article"
  },
  {
    "title": "Retrieving Continuous-Time Event Sequences Using Neural Temporal Point Processes with Learnable Hashing",
    "doi": "https://doi.org/10.1145/3691349",
    "publication_date": "2024-09-03",
    "publication_year": 2024,
    "authors": "Vinayak Gupta; Srikanta Bedathur; Abir De",
    "corresponding_authors": "",
    "abstract": "Temporal sequences have become pervasive in various real-world applications such as finance, spatial mobility, health records, and so on. Consequently, the volume of data generated in the form of continuous-time event sequence(s) or CTES(s) has increased exponentially in the past few years. Thus, a significant fraction of the ongoing research on CTES datasets involves designing models to address downstream tasks such as next-event prediction, long-term forecasting, sequence classification, and so on. The recent developments in predictive modeling using marked temporal point processes (MTPP) have enabled an accurate characterization of several real-world applications involving the CTESs. However, due to the complex nature of these CTES datasets, the task of large-scale retrieval of temporal sequences has been overlooked by the past literature. In detail, by CTES retrieval we mean that for an input query sequence, a retrieval system must return a ranked list of relevant sequences from a large corpus. To tackle this, we propose NeuroSeqRet , a first-of-its-kind framework designed specifically for end-to-end CTES retrieval. Specifically, NeuroSeqRet introduces multiple enhancements over standard retrieval frameworks and first applies a trainable unwarping function on the query sequence which makes it comparable with corpus sequences, especially when a relevant query-corpus pair has individually different attributes. Next, it feeds the unwarped query sequence and the corpus sequence into MTPP-guided neural relevance models. We develop four variants of the relevance model for different kinds of applications based on the tradeoff between accuracy and efficiency. We also propose an optimization framework to learn binary sequence embeddings from the relevance scores, suitable for the locality-sensitive hashing leading to a significant speedup in returning top- K results for a given query sequence. Our experiments with several datasets show the significant accuracy boost of NeuroSeqRet beyond several baselines, as well as the efficacy of our hashing mechanism.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402170413",
    "type": "article"
  },
  {
    "title": "D <scp>e</scp> ME <scp>t</scp> RIS: Counting (near)-Cliques by Crawling",
    "doi": "https://doi.org/10.1145/3699517",
    "publication_date": "2024-10-07",
    "publication_year": 2024,
    "authors": "Suman K. Bera; Jayesh Choudhari; Shahrzad Haddadan; Sara Ahmadian",
    "corresponding_authors": "",
    "abstract": "We study the problem of approximately counting cliques and near cliques in a graph, where the access to the graph is only available through crawling its vertices. This model has been introduced recently to capture real-life scenarios in which the entire graph is too massive to be stored as a whole or be scanned entirely. Sampling vertices independently is non-trivial in this model, thus algorithms which rely on sampling often use a random walk. The goal is to provide an accurate estimate by seeing only a small portion of the graph. This model is known as the random walk model or the neighborhood query model. We introduce D e ME t RIS: Dense Motif Estimation through Random Incident Sampling. This method provides a scalable algorithm for clique and near clique counting in the random walk model. We prove the correctness of our algorithm through rigorous mathematical analysis and extensive experiments. Both our theoretical results and our experiments show that D e ME t RIS obtains a high precision estimation by only crawling a sub-linear portion on vertices. Therefore, we demonstrate a significant improvement over previous known results.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403184765",
    "type": "article"
  },
  {
    "title": "Question-Attentive Review-Level Explanation for Neural Rating Regression",
    "doi": "https://doi.org/10.1145/3699516",
    "publication_date": "2024-10-08",
    "publication_year": 2024,
    "authors": "Trung-Hoang Le; Hady W. Lauw",
    "corresponding_authors": "",
    "abstract": "Recommendation explanations help to improve their acceptance by end users. Explanations come in many different forms. One that is of interest here is presenting an existing review of the recommended item as the explanation. The challenge is in selecting a suitable review, which is customarily addressed by assessing the relative importance or “attention” of each review to the recommendation objective. Our focus is improving review-level explanation by leveraging additional information in the form of questions and answers (QA). The proposed framework employs QA in an attention mechanism that aligns reviews to various QAs of an item and assesses their contribution jointly to the recommendation objective. The benefits are two-fold. For one, QA aids in selecting more useful reviews. For another, QA itself could accompany a well-aligned review in an expanded form of explanation. Experiments on datasets of ten product categories showcase the efficacies of our method as compared to comparable baselines in identifying useful reviews and QAs, while maintaining parity in recommendation performance.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403221707",
    "type": "article"
  },
  {
    "title": "Counterfactual Explainer for Deep Reinforcement Learning Models Using Policy Distillation",
    "doi": "https://doi.org/10.1145/3709146",
    "publication_date": "2024-12-24",
    "publication_year": 2024,
    "authors": "Amir Samadi; Konstantinos Koufos; Kurt Debattista; Mehrdad Dianati",
    "corresponding_authors": "",
    "abstract": "Deep Reinforcement Learning (DRL) has demonstrated promising capability in solving complex control problems. However, DRL applications in safety-critical systems are hindered by the inherent lack of robust validation techniques to assure their performance in such applications. One of the key requirements of the verification process is the development of effective techniques to explain the system functionality, providing why the system produces specific results in given circumstances. Recently, interpretation methods based on the Counterfactual (CF) explanation approach have been proposed to address the problem of explanation in DRLs. This paper proposes a novel CF explainer to interpret the decisions made by a black-box DRL. To evaluate the efficacy of the proposed explanation framework, we carried out several experiments in the domains of automated driving systems (ADSs) and the Atari Pong game. Our analysis demonstrates that the proposed framework generates plausible and meaningful explanations for various decisions made by deep underlying DRLs. Additionally, we discuss the practical implications of our approach for various automotive stakeholders, illustrating its potential real-world impact. Source codes are available at: https://github.com/Amir-Samadi/Counterfactual-Explanation .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405734344",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Online Advertising",
    "doi": "https://doi.org/10.1145/2668123",
    "publication_date": "2015-01-23",
    "publication_year": 2015,
    "authors": "Dou Shen; Deepak Agarwal",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1966448198",
    "type": "article"
  },
  {
    "title": "Visual Understanding with RGB-D Sensors",
    "doi": "https://doi.org/10.1145/2732265",
    "publication_date": "2015-03-31",
    "publication_year": 2015,
    "authors": "Richang Hong; Shuicheng Yan; Zhengyou Zhang",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Visual Understanding with RGB-D Sensors: An Introduction to the Special Issue Editors: Richang Hong Hefei University of Technology Hefei, Anhui, China Hefei University of Technology Hefei, Anhui, ChinaView Profile , Shuicheng Yan National University of Singapore, Singapore National University of Singapore, SingaporeView Profile , Zhengyou Zhang Microsoft Research Microsoft ResearchView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 6Issue 2May 2015 Article No.: 11pp 1–3https://doi.org/10.1145/2732265Published:31 March 2015Publication History 0citation238DownloadsMetricsTotal Citations0Total Downloads238Last 12 Months27Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2041417020",
    "type": "article"
  },
  {
    "title": "Choosing a Candidate Using Efficient Allocation of Biased Information",
    "doi": "https://doi.org/10.1145/2558327",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Shulamit Reches; Meir Kalech",
    "corresponding_authors": "",
    "abstract": "This article deals with a decision-making problem concerning an agent who wants to choose a partner from multiple candidates for long-term collaboration. To choose the best partner, the agent can rely on prior information he knows about the candidates. However, to improve his decision, he can request additional information from information sources. Nonetheless, acquiring information from external information sources about candidates may be biased due to different personalities of the agent searching for a partner and the information source. In addition, information may be costly. Considering the bias and the cost of the information sources, the optimization problem addressed in this article is threefold: (1) determining the necessary amount of additional information, (2) selecting information sources from which to request the information, and (3) choosing the candidates on whom to request the additional information. We propose a heuristic to solve this optimization problem. The results of experiments on simulated and real-world domains demonstrate the efficiency of our algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2082071697",
    "type": "article"
  },
  {
    "title": "Snap &amp; Play",
    "doi": "https://doi.org/10.1145/2668109",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Si Liu; Qiang Chen; Shuicheng Yan; Changsheng Xu; Hanqing Lu",
    "corresponding_authors": "",
    "abstract": "In this article, by taking a popular game, the Find-the-Difference (FiDi) game, as a concrete example, we explore how state-of-the-art image processing techniques can assist in developing a personalized, automatic, and dynamic game. Unlike the traditional FiDi game, where image pairs (source image and target image) with five different patches are manually produced by professional game developers, the proposed Personalized FiDi (P-FiDi) electronic game can be played in a fully automatic Snap &amp; Play mode. Snap means that players first take photos with their digital cameras. The newly captured photos are used as source images and fed into the P-FiDi system to autogenerate the counterpart target images for users to play . Four steps are adopted to autogenerate target images: enhancing the visual quality of source images, extracting some changeable patches from the source image, selecting the most suitable combination of changeable patches and difference styles for the image, and generating the differences on the target image with state-of-the-art image processing techniques. In addition, the P-FiDi game can be easily redesigned for the im-game advertising. Extensive experiments show that the P-FiDi electronic game is satisfying in terms of player experience, seamless advertisement, and technical feasibility.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2161242423",
    "type": "article"
  },
  {
    "title": "Introduction to the ACM TIST Special Issue on Intelligent Healthcare Informatics",
    "doi": "https://doi.org/10.1145/2791398",
    "publication_date": "2015-07-04",
    "publication_year": 2015,
    "authors": "Carlo Combi; Jiming Liu",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Introduction to the ACM TIST Special Issue on Intelligent Healthcare Informatics Editors: Carlo Combi View Profile , Jiming Liu View Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 6Issue 4August 2015 Article No.: 51pp 1–3https://doi.org/10.1145/2791398Published:04 July 2015Publication History 0citation216DownloadsMetricsTotal Citations0Total Downloads216Last 12 Months30Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2271216505",
    "type": "article"
  },
  {
    "title": "Bounds on Direct and Indirect Effects of Treatment on a Continuous Endpoint",
    "doi": "https://doi.org/10.1145/2668134",
    "publication_date": "2015-12-17",
    "publication_year": 2015,
    "authors": "Peng Luo; Zhi Geng",
    "corresponding_authors": "",
    "abstract": "Direct effect of a treatment variable on an endpoint variable and indirect effect through a mediate variable are important concepts for understanding a causal mechanism. However, the randomized assignment of treatment is not sufficient for identifying the direct and indirect effects, and extra assumptions and conditions are required, such as the sequential ignorability assumption without unobserved confounders or the sequential potential ignorability assumption. But these assumptions may not be credible in many applications. In this article, we consider the bounds on controlled direct effect, natural direct effect, and natural indirect effect without these extra assumptions. Cai et al. [2008] presented the bounds for the case of a binary endpoint, and we extend their results to the general case for an arbitrary endpoint.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2294328038",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2973184",
    "publication_date": "2016-10-03",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Large networks are becoming a widely used abstraction for studying complex systems in a broad set of disciplines, ranging from social-network analysis to molecular biology and neuroscience. Despite an increasing need to analyze and manipulate large ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230355044",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2699158",
    "publication_date": "2015-01-23",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Recommender systems are quickly becoming ubiquitous in applications such as e-commerce, social media channels, and content providers, among others, acting as an enabling mechanism designed to overcome the information overload problem by improving ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232248802",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2830012",
    "publication_date": "2015-10-16",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Learning to rank, which learns the ranking function from training data, has become an emerging research area in information retrieval and machine learning. Most existing work on learning to rank assumes that the training data is clean, which is not ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237032960",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2801030",
    "publication_date": "2015-08-13",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Cities are composed of complex systems with physical, cyber, and social components. Current works on extracting and understanding city events mainly rely on technology-enabled infrastructure to observe and record events. In this work, we propose an ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240133322",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2906145",
    "publication_date": "2016-07-14",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present an incremental Bayesian model that resolves key issues of crowd size and data quality for consensus labeling. We evaluate our method using data collected from a real-world citizen science program, BeeWatch, which invites members of the public ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242828854",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2850424",
    "publication_date": "2016-01-22",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Compared to constraint-based causal discovery, causal discovery based on functional causal models is able to identify the whole causal model under appropriate assumptions [Shimizu et al. 2006; Hoyer et al. 2009; Zhang and Hyvärinen 2009b]. Functional ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250931099",
    "type": "paratext"
  },
  {
    "title": "PP-PG: Combining Parameter Perturbation with Policy Gradient Methods for Effective and Efficient Explorations in Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3452008",
    "publication_date": "2021-06-03",
    "publication_year": 2021,
    "authors": "Shilei Li; Meng Li; Jiongming Su; Shaofei Chen; Zhimin Yuan; Qing Ye",
    "corresponding_authors": "",
    "abstract": "Efficient and stable exploration remains a key challenge for deep reinforcement learning (DRL) operating in high-dimensional action and state spaces. Recently, a more promising approach by combining the exploration in the action space with the exploration in the parameters space has been proposed to get the best of both methods. In this article, we propose a new iterative and close-loop framework by combining the evolutionary algorithm (EA), which does explorations in a gradient-free manner directly in the parameters space with an actor-critic, and the deep deterministic policy gradient (DDPG) reinforcement learning algorithm, which does explorations in a gradient-based manner in the action space to make these two methods cooperate in a more balanced and efficient way. In our framework, the policies represented by the EA population (the parametric perturbation part) can evolve in a guided manner by utilizing the gradient information provided by the DDPG and the policy gradient part (DDPG) is used only as a fine-tuning tool for the best individual in the EA population to improve the sample efficiency. In particular, we propose a criterion to determine the training steps required for the DDPG to ensure that useful gradient information can be generated from the EA generated samples and the DDPG and EA part can work together in a more balanced way during each generation. Furthermore, within the DDPG part, our algorithm can flexibly switch between fine-tuning the same previous RL-Actor and fine-tuning a new one generated by the EA according to different situations to further improve the efficiency. Experiments on a range of challenging continuous control benchmarks demonstrate that our algorithm outperforms related works and offers a satisfactory trade-off between stability and sample efficiency.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3172611114",
    "type": "article"
  },
  {
    "title": "A Comprehensive Approach to On-board Autonomy Verification and Validation",
    "doi": "https://doi.org/10.1145/3472715",
    "publication_date": "2021-08-20",
    "publication_year": 2021,
    "authors": "Marco Bozzano; Alessandro Cimatti; Marco Roveri",
    "corresponding_authors": "",
    "abstract": "Deep space missions are characterized by severely constrained communication links. To meet the needs of future missions and increase their scientific return, future space systems will require an increased level of autonomy on-board. In this work, we propose a comprehensive approach to on-board autonomy. We rely on model-based reasoning, and we consider many important (on-line and off-line) reasoning capabilities such as plan generation, validation, execution and monitoring, runtime diagnosis, and fault detection, identification, and recovery. The controlled platform is represented symbolically, and the reasoning capabilities are seen as symbolic manipulation of such formal model. We have developed a prototype of our framework, and we have integrated it within an on-board Autonomous Reasoning Engine. Finally, we have evaluated our approach on three case-studies inspired by real-world projects and characterized it in terms of reliability, availability, and performance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3194089987",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Intelligent Trajectory Analytics: Part I",
    "doi": "https://doi.org/10.1145/3495230",
    "publication_date": "2021-12-23",
    "publication_year": 2021,
    "authors": "Kai Zheng; Yong Li; Cyrus Shahabi; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4200146902",
    "type": "article"
  },
  {
    "title": "Introduction to special section on paraphrasing",
    "doi": "https://doi.org/10.1145/2483669.2483670",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Haifeng Wang; Bill Dolan; Idan Szpektor; Shiqi Zhao",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1988668202",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue on intelligent multimedia systems and technology",
    "doi": "https://doi.org/10.1145/1899412.1899413",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "Xian‐Sheng Hua; Qi Tian; Alberto Del Bimbo; Ramesh Jain",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1999442641",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on social computing, behavioral-cultural modeling, and prediction",
    "doi": "https://doi.org/10.1145/2483669.2483684",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Shanchieh Jay Yang; Dana Nau; John Salerno",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2003726773",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue on social web mining",
    "doi": "https://doi.org/10.1145/2542182.2542187",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Francesco Bonchi; Wray Buntine; Ricard Gavaldà; Shengbo Guo",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2022266472",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on large-scale machine learning",
    "doi": "https://doi.org/10.1145/1961189.1961197",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Chun‐Nan Hsu",
    "corresponding_authors": "Chun‐Nan Hsu",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2023498706",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on intelligent tutoring and coaching systems",
    "doi": "https://doi.org/10.1145/2438653.2438663",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Qing Li; Xiangfeng Luo; Wenyin Liu; Cristina Conati",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2038997980",
    "type": "article"
  },
  {
    "title": "Introduction to special section on trust in multiagent systems",
    "doi": "https://doi.org/10.1145/2438653.2438658",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Rino Falcone; Munindar P. Singh",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2050136417",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on machine learning for business applications",
    "doi": "https://doi.org/10.1145/1961189.1961190",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Charles X. Ling",
    "corresponding_authors": "Charles X. Ling",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2094609653",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1899412",
    "publication_date": "2011-02-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Active learning is a machine learning technique that selects the most informative samples for labeling and uses them as training data. It has been widely explored in multimedia research community for its capability of reducing human annotation effort. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235466616",
    "type": "paratext"
  },
  {
    "title": "Introduction",
    "doi": "https://doi.org/10.1145/2036264.2036270",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236637789",
    "type": "article"
  },
  {
    "title": "EachWiki",
    "doi": "https://doi.org/10.1145/2337542.2337556",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Haofen Wang; Linyun Fu; Wei Jin; Yong Yu",
    "corresponding_authors": "",
    "abstract": "Wikipedia, one of the best-known wikis and the world’s largest free online encyclopedia, has embraced the power of collaborative editing to harness collective intelligence. However, using such a wiki to create high-quality articles is not as easy as people imagine, given for instance the difficulty of reusing knowledge already available in Wikipedia. As a result, the heavy burden of upbuilding and maintaining the ever-growing online encyclopedia still rests on a small group of people. In this article, we aim at facilitating wiki authoring by providing annotation recommendations, thus lightening the burden of both contributors and administrators. We leverage the collective wisdom of the users by exploiting Semantic Web technologies with Wikipedia data and adopt a unified algorithm to support link, category, and semantic relation recommendation. A prototype system named EachWiki is proposed and evaluated. The experimental results show that it has achieved considerable improvements in terms of effectiveness, efficiency and usability. The proposed approach can also be applied to other wiki-based collaborative editing systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1978484546",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Distance Metric Learning in Intelligent Systems",
    "doi": "https://doi.org/10.1145/2168752.2168766",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Steven C. H. Hoi; Rong Jin; Jinhui Tang; Zhi‐Hua Zhou",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1987778062",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Artificial Intelligence in Space",
    "doi": "https://doi.org/10.1145/2168752.2168762",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Steve Chien; Amedeo Cesta",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1995563425",
    "type": "article"
  },
  {
    "title": "Preface to special issue on applications of automated planning",
    "doi": "https://doi.org/10.1145/1869397.1869398",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Yixin Chen",
    "corresponding_authors": "Yixin Chen",
    "abstract": "research-article Share on Preface to special issue on applications of automated planning Author: Yixin Chen Washington University in St. Louis Washington University in St. LouisView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 1Issue 2Article No.: 9pp 1–3https://doi.org/10.1145/1869397.1869398Published:03 December 2010Publication History 0citation255DownloadsMetricsTotal Citations0Total Downloads255Last 12 Months4Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2089112716",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Computational Models of Collective Intelligence in the Social Web",
    "doi": "https://doi.org/10.1145/2337542.2337543",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Evgeniy Gabrilovich; Zhong Su; Jie Tang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2140607470",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Intelligent Multimedia Systems and Technology Part II",
    "doi": "https://doi.org/10.1145/2168752.2168753",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Xian‐Sheng Hua; Qi Tian; Alberto Del Bimbo; Ramesh Jain",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2162823282",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1869397",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Julie Porteous; Marc Cavazza; Fred Charles",
    "corresponding_authors": "",
    "abstract": "We have seen ten years of the application of AI planning to the problem of narrative generation in Interactive Storytelling (IS). In that time planning has emerged as the dominant technology and has featured in a number of prototype systems. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244618747",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2168752",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The proliferation of MP3 players and the exploding amount of digital music content call for novel ways of music organization and retrieval to meet the ever-increasing demand for easy and effective information access. As almost every music piece is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256697605",
    "type": "paratext"
  },
  {
    "title": "As-You-Type Social Aware Search",
    "doi": "https://doi.org/10.1145/3035969",
    "publication_date": "2017-06-30",
    "publication_year": 2017,
    "authors": "Paul Lagrée; Bogdan Cautis; Hossein Vahabi",
    "corresponding_authors": "",
    "abstract": "Modern search applications feature real-time as-you-type query search. In its elementary form, the problem consists in retrieving a set of k search results, that is, performing a search with a given prefix, and showing the top-ranked results. In this article, we focus on as-you-type keyword search over social media, that is, data published by users who are interconnected through a social network. We adopt a “network-aware” interpretation for information relevance, by which information produced by users who are closer to the user issuing a request is considered more relevant. This query model raises new challenges for effectiveness and efficiency in online search, even when the intent of the user is fully specified, as a complete query given as input in one keystroke. This is mainly because it requires a joint exploration of the social space and traditional IR indexes, such as inverted lists. We describe a memory-efficient and incremental prefix-based retrieval algorithm, which also exhibits an anytime behavior, allowing output of the most likely answer within any chosen runtime limit. We evaluate our approach through extensive experiments for several applications and search scenarios. We consider searching for posts in microblogging (Twitter and Tumblr), for businesses (Yelp), as well as for movies (Amazon) based on reviews. We also conduct a series of experiments comparing our algorithm with baselines using state-of-the-art techniques and measuring the improvements brought by several key optimizations. They show that our solution is effective in answering real-time as-you-type searches over social media.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2729996043",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on <i>Social Media Processing</i> ( <i>TIST</i> - <i>SMP</i> )",
    "doi": "https://doi.org/10.1145/3110318",
    "publication_date": "2017-07-24",
    "publication_year": 2017,
    "authors": "Ronald S. Burt; Jie Tang; Michalis Vazirgiannis; Shuang Yang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2736337086",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3040485",
    "publication_date": "2017-04-22",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Social media websites have become important information sharing platforms. The rapid development of social media platforms has led to increasingly large-scale social media data, which has shown remarkable societal and marketing values. There are needs ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241916421",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3134224",
    "publication_date": "2017-10-17",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244607387",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3127339",
    "publication_date": "2017-09-15",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "P2P lending is an emerging Internet-based application where individuals can directly borrow money from each other. The past decade has witnessed the rapid development and prevalence of online P2P lending platforms, examples of which include Prosper, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247729287",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3120923",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With recent advances in radio-frequency identification (RFID), wireless sensor networks, and Web services, physical things are becoming an integral part of the emerging ubiquitous Web. Finding correlations among ubiquitous things is a crucial ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250820588",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3004291",
    "publication_date": "2017-01-18",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Tensors and tensor decompositions are very powerful and versatile tools that can model a wide variety of heterogeneous, multiaspect data. As a result, tensor decompositions, which extract useful latent information out of multiaspect data tensors, have ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252699422",
    "type": "paratext"
  },
  {
    "title": "Towards Query-Efficient Black-Box Attacks: A Universal Dual Transferability-Based Framework",
    "doi": "https://doi.org/10.1145/3583777",
    "publication_date": "2023-02-13",
    "publication_year": 2023,
    "authors": "Tao Xiang; Hangcheng Liu; Shangwei Guo; Yan Gan; Wenjian He; Xiaofeng Liao",
    "corresponding_authors": "",
    "abstract": "Adversarial attacks have threatened the application of deep neural networks in security-sensitive scenarios. Most existing black-box attacks fool the target model by interacting with it many times and producing global perturbations. However, all pixels are not equally crucial to the target model; thus, indiscriminately treating all pixels will increase query overhead inevitably. In addition, existing black-box attacks take clean samples as start points, which also limits query efficiency. In this article, we propose a novel black-box attack framework, constructed on a strategy of dual transferability (DT), to perturb the discriminative areas of clean examples within limited queries. The first kind of transferability is the transferability of model interpretations. Based on this property, we identify the discriminative areas of clean samples for generating local perturbations. The second is the transferability of adversarial examples, which helps us to produce local pre-perturbations for further improving query efficiency. We achieve the two kinds of transferability through an independent auxiliary model and do not incur extra query overhead. After identifying discriminative areas and generating pre-perturbations, we use the pre-perturbed samples as better start points and further perturb them locally in a black-box manner to search the corresponding adversarial examples. The DT strategy is general; thus, the proposed framework can be applied to different types of black-box attacks. We conduct extensive experiments to show that, under various system settings, our framework can significantly improve the query efficiency of existing black-box attacks and attack success rates.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4320490968",
    "type": "article"
  },
  {
    "title": "Disease Simulation in Airport Scenario Based on Individual Mobility Model",
    "doi": "https://doi.org/10.1145/3593589",
    "publication_date": "2023-05-20",
    "publication_year": 2023,
    "authors": "Zhenyu Han; Siran Ma; Changzheng Gao; Erzhuo Shao; Yulai Xie; Yang Zhang; Lu Geng; Yong Li",
    "corresponding_authors": "",
    "abstract": "As the rapid-spreading disease COVID-19 occupies the world, most governments adopt strict control policies to alleviate the impact of the virus. These policies successfully reduced the prevalence and delayed the epidemic peak, while they are also associated with high economic and social costs. To bridge the microscopic epidemic transmission patterns and control policies, simulation systems play an important role. In this work, we propose an agent-based disease simulator for indoor public spaces, which contribute to most of the transmission in cities. As an example, we study Guangzhou Baiyun International Airport, which is one of the most bustling aviation hubs in China. Specifically, we design a high-efficiency mobility generation module to reconstruct the individual trajectories considering both lingering behavior and crowd mobility, which greatly enhances the credibility of the simulated mobility and ensures real-time performance. Based on the individual trajectories, we propose a multi-path disease transmission module optimized for indoor public spaces, which includes three main transmission paths as close contact transmission, aerosol transmission, and object surface transmission. We design a novel convolution-based algorithm to mimic the diffusion process, which can leverage the high concurrent capability of the graphics processing unit to accelerate the simulation process. Leveraging our simulation paradigm, the effectiveness of common policy interventions can be quantitatively evaluated. For mobility interventions, we find that lingering control is the most effective mobility intervention with 32.35% fewer infections, while increasing social distance and increasing walking speed have a similar effect with 15.15% and 18.02% fewer infections. It demonstrates the importance of introducing crowd mobility into disease transmission simulation. For transmission processes, we find the aerosol transmission involves in 99.99% of transmission, which highlights the importance of ventilation in indoor public spaces. Our simulation also demonstrates that without strict entrance detection to identify the input infections, only performing frequent disinfection cannot achieve desirable epidemic outcomes. Based on our simulation paradigm, we can shed light on better policy designs that achieve a good balance between disease spreading control and social costs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4377139642",
    "type": "article"
  },
  {
    "title": "Meaning-Sensitive Text Data Augmentation with Intelligent Masking",
    "doi": "https://doi.org/10.1145/3623403",
    "publication_date": "2023-09-13",
    "publication_year": 2023,
    "authors": "Buddhika Kasthuriarachchy; Madhu Chetty; Adrian Shatte; Darren Walls",
    "corresponding_authors": "",
    "abstract": "With the recent popularity of applying large-scale deep neural network-based models for natural language processing (NLP), attention to develop methods for text data augmentation is at its peak, since the limited size of training data tends to significantly affect the accuracy of these models. To this end, we propose a novel text data augmentation technique called Intelligent Masking with Optimal Substitutions Text Data Augmentation (IMOSA). IMOSA, developed for labelled sentences, can identify the most favourable sentences and locate the appropriate word combinations in a particular sentence to replace and generate synthetic sentences with a meaning closer to the original sentence, while also significantly increasing the diversity of the dataset. We demonstrate that the proposed technique notably improves the performance of classifiers based on attention-based transformer models through the extensive experiments for five different text classification tasks which are performed under the low data regime in a context-aware NLP setting. The analysis clearly shows that IMOSA effectively generates more sentences using favourable original examples and completely ignores undesirable examples. Furthermore, the experiments carried out confirm IMOSA’s ability to add diversity to the augmented dataset using multiple distinct masking patterns against the same original sentence, which remarkably adds variety to the training dataset. IMOSA consistently outperforms the two key masked language model-based text data augmentation techniques, and demonstrates a robust performance against the critical challenging NLP tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386710487",
    "type": "article"
  },
  {
    "title": "Performing Cancer Diagnosis via an Isoform Expression Ranking-based LSTM Model",
    "doi": "https://doi.org/10.1145/3625237",
    "publication_date": "2023-09-23",
    "publication_year": 2023,
    "authors": "Óscar Reyes; Eduardo Pérez",
    "corresponding_authors": "",
    "abstract": "The known set of genetic factors involved in the development of several types of cancer has considerably been expanded, thus easing to devise and implement better therapeutic strategies. The automatic diagnosis of cancer, however, remains as a complex task because of the high heterogeneity of tumors and the biological variability between samples. In this work, a long short-term memory network-based model is proposed for diagnosing cancer from transcript-base data. An efficient method that transforms data into gene/isoform expression-based rankings was formulated, allowing us to directly embed important information in the relative order of the elements of a ranking that can subsequently ease the classification of samples. The proposed predictive model leverages the power of deep recurrent neural networks, being able to learn existing patterns on the individual rankings of isoforms describing each sample of the population. To evaluate the suitability of the proposal, an extensive experimental study was conducted on 17 transcript-based datasets, and the results showed the effectiveness of this novel approach and also indicated the gene/isoforms expression-based rankings contained valuable information that can lead to a more effective cancer diagnosis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386982023",
    "type": "article"
  },
  {
    "title": "One-step Multi-view Clustering with Consensus Graph and Data Representation Convolution",
    "doi": "https://doi.org/10.1145/3630634",
    "publication_date": "2023-10-27",
    "publication_year": 2023,
    "authors": "F. Dornaika",
    "corresponding_authors": "F. Dornaika",
    "abstract": "Multi-view clustering aims to partition unlabeled patterns into disjoint clusters using consistent and complementary information derived from features of patterns in multiple views. Downstream methods perform this clustering sequentially: estimation of individual or consistent similarity matrices, spectral embedding, and clustering. In this article, we present an approach that can address some of the shortcomings of previous multiview clustering methods. We propose a single objective function whose optimization can jointly provide the consistent graph matrix for all views, the unified spectral data representation, the cluster assignments, and the view weights. We propose a new constraint term that sets the cluster index matrix to the convolution of the consistent spectral projection matrix over the consistent graph. Our proposed scheme has two interesting properties that the recent works do not have simultaneously. First, the cluster assignments can be estimated directly without the need for an additional clustering phase, which depends heavily on initialization. Second, the soft cluster assignments are directly linked to the kernel representation of the features of the views. Moreover, our method automatically computes the weights of each view, requiring fewer hyperparameters. We have conducted a series of experiments on real datasets. These demonstrate the effectiveness of the proposed approach, which compares favorably to many competing multi-view clustering methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4387968613",
    "type": "article"
  },
  {
    "title": "Explicit State Representation Guided Video-based Pedestrian Attribute Recognition",
    "doi": "https://doi.org/10.1145/3626240",
    "publication_date": "2023-10-26",
    "publication_year": 2023,
    "authors": "Wei-Qing Lu; Hai‐Miao Hu; Jinzuo Yu; Shifeng Zhang; Hanzi Wang",
    "corresponding_authors": "",
    "abstract": "The pedestrian attribute recognition aims to generate a structured description of pedestrians, which serves an important role in surveillance. Current works usually assume that the images and the specific pedestrian states, including pedestrian occlusion and pedestrian orientation, are given. However, we argue that the current works ignore the guidance of the pedestrian state and cannot achieve the appropriate performance since the appearance feature will become unreliable due to the variance of the pedestrian state, which is common in practice. Therefore, this paper proposes the Explicit State Representation (ExSR) Guided Pedestrian Attribute Recognition to improve the accuracy through state learning and attribute fusion among frames. Firstly, the pedestrian state is explicitly represented by concatenating the pedestrian orientation and occlusion, which can be accurately determined via analyzing the pose. Secondly, the state-aware pedestrian attribute fusion method is proposed and divided into two cases, namely the inter-state case and the intra-state case. In the intra-state case, the appearance feature will remain stable and the attribute relations are propagated to refine. The method of exploiting attribute relations within a single frame is the Graph Neural Network. In the inter-state case, the state changes, the attribute relationship propagation is prevented, and the advantages of attribute recognition in each frame are complemented to make a reliable judgment on the invisible region. The experimental results demonstrate that the ExSR outperforms the state-of-the-art methods on two public databases, benefiting from the explicit introduction of the state into the attribute recognition.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388195847",
    "type": "article"
  },
  {
    "title": "Second-order Confidence Network for Early Classification of Time Series",
    "doi": "https://doi.org/10.1145/3631531",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Junwei Lv; Yuqi Chu; Jun Hu; Peipei Li; Xuegang Hu",
    "corresponding_authors": "",
    "abstract": "Time series data are ubiquitous in a variety of disciplines. Early classification of time series, which aims to predict the class label of a time series as early and accurately as possible, is a significant but challenging task in many time-sensitive applications. Existing approaches mainly utilize heuristic stopping rules to capture stopping signals from the prediction results of time series classifiers. However, heuristic stopping rules can only capture obvious stopping signals, which makes these approaches give either correct but late predictions or early but incorrect predictions. To tackle the problem, we propose a novel second-order confidence network for early classification of time series, which can automatically learn to capture implicit stopping signals in early time series in a unified framework. The proposed model leverages deep neural models to capture temporal patterns and outputs second-order confidence to reflect the implicit stopping signals. Specifically, our model exploits the data not only from a time step but also from the probability sequence to capture stopping signals. By combining stopping signals from the classifier output and the second-order confidence, we design a more robust trigger to decide whether or not to request more observations from future time steps. Experimental results show that our approach can achieve superior results in early classification compared to state-of-the-art approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388210417",
    "type": "article"
  },
  {
    "title": "Mixture of Joint Nonhomogeneous Markov Chains to Cluster and Model Water Consumption Behavior Sequences",
    "doi": "https://doi.org/10.1145/3347452",
    "publication_date": "2019-10-24",
    "publication_year": 2019,
    "authors": "Milad Leyli-Abadi; Allou Samé; Latifa Oukhellou; Nicolas Cheifetz; Pierre Mandel; Cédric Féliers; O. Chesneau",
    "corresponding_authors": "",
    "abstract": "The emergence of smart meters has fostered the collection of massive data that support a better understanding of consumer behaviors and better management of water resources and networks. The main focus of this article is to analyze consumption behavior over time; thus, we first identify the main weekly consumption patterns. This approach allows each meter to be represented by a categorical series, where each category corresponds to a weekly consumption behavior. By considering the resulting consumption behavior sequences, we propose a new methodology based on a mixture of nonhomogeneous Markov models to cluster these categorical time series. Using this method, the meters are described by the Markovian dynamics of their cluster. The latent variable that controls cluster membership is estimated alongside the parameters of the Markov model using a novel classification expectation maximization algorithm. A specific entropy measure is formulated to evaluate the quality of the estimated partition by considering the joint Markovian dynamics. The proposed clustering model can also be used to predict future consumption behaviors within each cluster. Numerical experiments using real water consumption data provided by a water utility in France and gathered over 19 months are conducted to evaluate the performance of the proposed approach in terms of both clustering and prediction. The results demonstrate the effectiveness of the proposed method.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2971623043",
    "type": "article"
  },
  {
    "title": "超局所空間クラウド消費におけるタスク割当のための実時間フレームワーク【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Tran Luan; Hien To; Liyue Fan; Shahabi Cyrus",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3173554806",
    "type": "article"
  },
  {
    "title": "マイクロブログにおける二重意味拡張とディープハッシングに基づく短いテキスト解析【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "CUI WAN-QIU; Junping Du; Wang Dawei; Xunpu Yuan; Feifei Kou; Liyan Zhou; Zhou Nan",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3181628581",
    "type": "article"
  },
  {
    "title": "介入に基づく偽造分析を用いたシミュレーションモデルにおける因果関係の検出【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "C. H. Benjamin; Miles Simon",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3183119560",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3375625",
    "publication_date": "2019-12-14",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Forecasting price trend of bulk commodities is important in international trade, not only for markets participants to schedule production and marketing plans but also for government administrators to adjust policies. Previous studies cannot support ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234492966",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3183892",
    "publication_date": "2018-02-21",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Co-saliency detection is a newly emerging and rapidly growing research area in the computer vision community. As a novel branch of visual saliency, co-saliency detection refers to the discovery of common and salient foregrounds from two or more relevant ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236667154",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3306498",
    "publication_date": "2019-02-28",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236699601",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3154791",
    "publication_date": "2018-01-18",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Answering medical questions related to complex medical cases, as required in modern Clinical Decision Support (CDS) systems, imposes (1) access to vast medical knowledge and (2) sophisticated inference techniques. In this article, we examine the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240683410",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3368406",
    "publication_date": "2019-12-14",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The development of smart vehicles brings drivers and passengers a comfortable and safe environment. Various emerging applications are promising to enrich users’ traveling experiences and daily life. However, how to execute computing-intensive ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246746439",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3360733",
    "publication_date": "2019-11-14",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Many causal discovery algorithms infer graphical structure from observational data. The PC algorithm in particular estimates a completed partially directed acyclic graph (CPDAG), or an acyclic graph containing directed edges identifiable with ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247453142",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3167125",
    "publication_date": "2018-02-13",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Real-time human mobility modeling is essential to various urban applications. To model such human mobility, numerous data-driven techniques have been proposed. However, existing techniques are mostly driven by data from a single view, for example, a ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250156908",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3210369",
    "publication_date": "2018-07-18",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Eliminating the negative effect of non-stationary environmental noise is a long-standing research topic for automatic speech recognition but still remains an important challenge. Data-driven supervised approaches, especially the ones based on deep ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252481863",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3289398",
    "publication_date": "2018-11-15",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With the rapid development of location-based social networks (LBSNs), spatial item recommendation has become an important way of helping users discover interesting locations to increase their engagement with location-based services. The availability of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253025653",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3325195",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The proliferation of fake news on social media has opened up new directions of research for timely identification and containment of fake news and mitigation of its widespread impact on public opinion. While much of the earlier research was focused on ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256093330",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3344873",
    "publication_date": "2019-08-29",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article comprehensively surveys the development of trajectory data classification. Considering the critical role of trajectory data classification in modern intelligent systems for surveillance security, abnormal behavior detection, crowd behavior ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256364207",
    "type": "paratext"
  },
  {
    "title": "Adaptive HTF-MPR",
    "doi": "https://doi.org/10.1145/3396949",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Ahmad Albaqsami; Maryam S. Hosseini; Masoomeh Jasemi; Nader Bagherzadeh",
    "corresponding_authors": "",
    "abstract": "Deep neural networks are widely used in many artificial intelligence applications. They have demonstrated state-of-the-art accuracy on many artificial intelligence tasks. For this high accuracy to occur, deep neural networks require the right parameter values. This is achieved by a process known as training . The training of large amounts of data via many iterations comes at a high cost in regard to computation time and energy. Optimal resource allocation would therefore reduce the training time. TensorFlow, a computational graph library developed by Google, alleviates the development of neural network models and provides the means to train these networks. In this article, we propose Adaptive HTF-MPR to carry out the resource allocation, or mapping, on TensorFlow. Adaptive HTF-MPR searches for the best mapping in a hybrid approach. We applied the proposed methodology on two well-known image classifiers: VGG-16 and AlexNet. We also performed a full analysis of the solution space of MNIST Softmax. Our results demonstrate that Adaptive HTF-MPR outperforms the default homogeneous TensorFlow mapping. In addition to the speed up, Adaptive HTF-MPR can react to changes in the state of the system and adjust to an improved mapping.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3041424607",
    "type": "article"
  },
  {
    "title": "CSL+",
    "doi": "https://doi.org/10.1145/3426193",
    "publication_date": "2020-11-25",
    "publication_year": 2020,
    "authors": "Adil Alim; Jin-Hee Cho; Feng Chen",
    "corresponding_authors": "",
    "abstract": "Using unreliable information sources generating conflicting evidence may lead to a large uncertainty, which significantly hurts the decision making process. Recently, many approaches have been taken to integrate conflicting data from multiple sources and/or fusing conflicting opinions from different entities. To explicitly deal with uncertainty, a belief model called Subjective Logic (SL), as a variant of Dumpster-Shafer Theory, has been proposed to represent subjective opinions and to merge multiple opinions by offering a rich volume of fusing operators, which have been used to solve many opinion inference problems in trust networks. However, the operators of SL are known to be lack of scalability in inferring unknown opinions from large network data as a result of the sequential procedures of merging multiple opinions. In addition, SL does not consider deriving opinions in the presence of conflicting evidence. In this work, we propose a hybrid inference method that combines SL and Probabilistic Soft Logic (PSL), namely, Collective Subjective Plus, CSL + , which is resistible to highly conflicting evidence or a lack of evidence. PSL can reason a belief in a collective manner to deal with large-scale network data, allowing high scalability based on relationships between opinions. However, PSL does not consider an uncertainty dimension in a subjective opinion. To take benefits from both SL and PSL, we proposed a hybrid approach called CSL + for achieving high scalability and high prediction accuracy for unknown opinions with uncertainty derived from a lack of evidence and/or conflicting evidence. Through the extensive experiments on four semi-synthetic and two real-world datasets, we showed that the CSL + outperforms the state-of-the-art belief model (i.e., SL), probabilistic inference models (i.e., PSL, CSL), and deep learning model (i.e., GCN-VAE-opinion) in terms of prediction accuracy, computational complexity, and real running time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3110072407",
    "type": "article"
  },
  {
    "title": "A Theoretical Revisit to Linear Convergence for Saddle Point Problems",
    "doi": "https://doi.org/10.1145/3420035",
    "publication_date": "2020-12-10",
    "publication_year": 2020,
    "authors": "Wendi Wu; Yawei Zhao; En Zhu; Xinwang Liu; Xingxing Zhang; Lailong Luo; Shixiong Wang; Jianping Yin",
    "corresponding_authors": "",
    "abstract": "Recently, convex-concave bilinear Saddle Point Problems (SPP) is widely used in lasso problems, Support Vector Machines, game theory, and so on. Previous researches have proposed many methods to solve SPP, and present their convergence rate theoretically. To achieve linear convergence, analysis in those previouse studies requires strong convexity of φ( z ). But, we find the linear convergence can also be achieved even for a general convex but not strongly convex φ( z ). In the article, by exploiting the strong duality of SPP, we propose a new method to solve SPP, and achieve the linear convergence. We present a new general sufficient condition to achieve linear convergence, but do not require the strong convexity of φ( z ). Furthermore, a more efficient method is also proposed, and its convergence rate is analyzed in theoretical. Our analysis shows that the well conditioned φ( z ) is necessary to improve the efficiency of our method. Finally, we conduct extensive empirical studies to evaluate the convergence performance of our methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3110980999",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Deep Learning for Spatio-Temporal Data: Part 2",
    "doi": "https://doi.org/10.1145/3510023",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Senzhang Wang; Junbo Zhang; Yanjie Fu; Yong Li",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on Deep Learning for Spatio-Temporal Data: Part 2 Editors: Senzhang Wang Central South University, China Central South University, ChinaView Profile , Junbo Zhang JD Intelligent Cities Research, JD iCity, JD Tech, China JD Intelligent Cities Research, JD iCity, JD Tech, ChinaView Profile , Yanjie Fu University of Central Florida, U.S.A. University of Central Florida, U.S.A.View Profile , Yong Li Tsinghua University, China Tsinghua University, ChinaView Profile Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 13Issue 2April 2022 Article No.: 17pp 1–4https://doi.org/10.1145/3510023Online:26 March 2022Publication History 0citation147DownloadsMetricsTotal Citations0Total Downloads147Last 12 Months147Last 6 weeks10 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4220652637",
    "type": "article"
  },
  {
    "title": "Jointly Optimizing Expressional and Residual Models for 3D Facial Expression Removal",
    "doi": "https://doi.org/10.1145/3533312",
    "publication_date": "2022-04-29",
    "publication_year": 2022,
    "authors": "Qian Zheng; Yueming Wang; Zhenfang Hu; Xiaobo Zhang; Zhaohui Wu; Gang Pan",
    "corresponding_authors": "",
    "abstract": "This article proposes a facial expression removal method to recover a 3D neutral face from a single 3D expressional or non-neutral face. We treat a 3D non-neutral face as the sum of its neutral one and the residual. This can be satisfied if the correspondence between 3D vertices of expressional faces and those of neutral faces is established. We propose a non-rigid deformation method to establish the correspondence between 3D faces. Then, according to algebra inequality, the minimization of a neutral face model can be replaced by the minimization of its upper bound, i.e., the errors of an expressional face model and a residual model. Thus, we co-optimize the representation errors of the latter two models and build the relationship between the representation coefficients of the two models. Given an expressional face as the input, its corresponding neutral face can be inferred by the associative representation parameters in these two models. In the testing stage, we use an iterative joint fitting scheme to obtain a more accurate recovery. Extensive experiments are conducted to evaluate our method. The results show that our method obtains considerably better performance than existing methods in terms of average root mean square errors and recognition rates, and also better visual effects.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4225159571",
    "type": "article"
  },
  {
    "title": "Preface to Federated Learning: Algorithms, Systems, and Applications: Part 2",
    "doi": "https://doi.org/10.1145/3536420",
    "publication_date": "2022-08-24",
    "publication_year": 2022,
    "authors": "Qiang Yang; Yongxin Tong; Yang Liu; Yangqiu Song; Hao Peng; Boi Faltings",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4292882012",
    "type": "article"
  },
  {
    "title": "Interior Individual Trajectory Simulation with Population Distribution Constraint",
    "doi": "https://doi.org/10.1145/3529108",
    "publication_date": "2022-08-16",
    "publication_year": 2022,
    "authors": "Erzhuo Shao; Zhenyu Han; Yulai Xie; Yang Zhang; Lu Geng; Yong Li",
    "corresponding_authors": "",
    "abstract": "Individual trajectory generation plays an important role in simulation tasks, reconstructing fine-grained mobility behaviors that can be used to evaluate epidemic risks, congestion risks, or commercial profit. Previous research works adopt the Newton’s mechanic-based particle model as their core algorithm, such as the Social Force model. However, real-world human mobility behaviors hardly follow the particle models, especially in the interior scenes where interactions between pedestrians and environments matter. In this article, we propose a Social Force-based trajectory simulator for interior scenarios that improve both trajectory quality and generation speed for interior scenarios. First, we introduce prior scene knowledge to guide the generation process, where pedestrians are armed with exploration behaviors that follow the group-level distribution. It provides more flexibility to simulate complicated human behaviors rather than straight-line movements, generating high-quality individual trajectories. Experiments show that the correlation between the aggregated population distribution of generated trajectories and ground-truth distribution is improved by 11.84% by our method. Second, we optimize the algorithm procedure by introducing a caching mechanism for tenderized intermediate values, along with graph-processing-unit-based implementation. Compared with the baseline Social Force model, we reduced the time consumption by 95%. More importantly, based on our simulation paradigm, we quantitatively evaluate several common mobility interventions in our simulation scenario, which can shed light on better policy designs in public spaces.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4293063381",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on the Federated Learning: Algorithms, Systems, and Applications: Part 1",
    "doi": "https://doi.org/10.1145/3514223",
    "publication_date": "2022-08-25",
    "publication_year": 2022,
    "authors": "Qiang Yang; Yongxin Tong; Yang Liu; Yangqiu Song; Hao Peng; Boi Faltings",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Issue on the Federated Learning: Algorithms, Systems, and Applications: Part 1 Editors: Qiang Yang WeBank, Hong Kong University of Science and Technology, China WeBank, Hong Kong University of Science and Technology, ChinaSearch about this author , Yongxin Tong Beihang University, China Beihang University, ChinaSearch about this author , Yang Liu WeBank, China WeBank, ChinaSearch about this author , Yangqiu Song Hong Kong University of Science and Technology, China Hong Kong University of Science and Technology, ChinaSearch about this author , Hao Peng Beihang University, China Beihang University, ChinaSearch about this author , Boi Faltings Ecole Polytechnique Federale de Lausanne, Switzerland Ecole Polytechnique Federale de Lausanne, SwitzerlandSearch about this author Authors Info & Claims ACM Transactions on Intelligent Systems and TechnologyVolume 13Issue 4August 2022 Article No.: 52pp 1–3https://doi.org/10.1145/3514223Published:25 August 2022Publication History 0citation238DownloadsMetricsTotal Citations0Total Downloads238Last 12 Months238Last 6 weeks63 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4293091155",
    "type": "article"
  },
  {
    "title": "Parallel Connected LSTM for Matrix Sequence Prediction with Elusive Correlations",
    "doi": "https://doi.org/10.1145/3469437",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Qi Zhao; Chuqiao Chen; Guangcan Liu; Qingshan Liu; Shengyong Chen",
    "corresponding_authors": "",
    "abstract": "This article is about a challenging problem called matrix sequence prediction, which is motivated from the application of taxi order prediction. Remarkably, the problem differs greatly from previous sequence prediction tasks in the sense that the time-wise correlations are quite elusive; namely, distant entries could be strongly correlated and nearby entries are unnecessarily related. Such distinct specifics make prevalent convolution-recurrence-based methods inadequate to apply. To remedy this trouble, we propose a novel architecture called Parallel Connected LSTM (PcLSTM), which integrates two new mechanisms, Multi-channel Linearized Connection (McLC) and Adaptive Parallel Unit (APU), into the framework of LSTM. Benefiting from the strengths of McLC and APU, our PcLSTM is able to handle well both the elusive correlations within each timestamp and the temporal dependencies across different timestamps, achieving state-of-the-art performance in a set of experiments demonstrated on synthetic and real-world datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3195530201",
    "type": "article"
  },
  {
    "title": "MVGAN: Multi-View Graph Attention Network for Social Event Detection.",
    "doi": null,
    "publication_date": "2021-01-01",
    "publication_year": 2021,
    "authors": "Wanqiu Cui; Junping Du; Dawei Wang; Feifei Kou; Zhe Xue",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3197941751",
    "type": "article"
  }
]
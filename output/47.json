[
  {
    "title": "MaMaDroid",
    "doi": "https://doi.org/10.1145/3313391",
    "publication_date": "2019-04-09",
    "publication_year": 2019,
    "authors": "Lucky Onwuzurike; Enrico Mariconti; Panagiotis Andriotis; Emiliano De Cristofaro; Gordon J. Ross; Gianluca Stringhini",
    "corresponding_authors": "",
    "abstract": "As Android has become increasingly popular, so has malware targeting it, thus motivating the research community to propose different detection techniques. However, the constant evolution of the Android ecosystem, and of malware itself, makes it hard to design robust tools that can operate for long periods of time without the need for modifications or costly re-training. Aiming to address this issue, we set to detect malware from a behavioral point of view, modeled as the sequence of abstracted API calls. We introduce M A M A D ROID , a static-analysis-based system that abstracts app’s API calls to their class, package, or family, and builds a model from their sequences obtained from the call graph of an app as Markov chains. This ensures that the model is more resilient to API changes and the features set is of manageable size. We evaluate M A M A D ROID using a dataset of 8.5K benign and 35.5K malicious apps collected over a period of 6 years, showing that it effectively detects malware (with up to 0.99 F-measure) and keeps its detection capabilities for long periods of time (up to 0.87 F-measure 2 years after training). We also show that M A M A D ROID remarkably overperforms D ROID APIM INER , a state-of-the-art detection system that relies on the frequency of ( raw ) API calls. Aiming to assess whether M A M A D ROID ’s effectiveness mainly stems from the API abstraction or from the sequencing modeling, we also evaluate a variant of it that uses frequency (instead of sequences), of abstracted API calls. We find that it is not as accurate, failing to capture maliciousness when trained on malware samples that include API calls that are equally or more frequently used by benign apps.",
    "cited_by_count": 256,
    "openalex_id": "https://openalex.org/W2963204406",
    "type": "article"
  },
  {
    "title": "Scalable Private Set Intersection Based on OT Extension",
    "doi": "https://doi.org/10.1145/3154794",
    "publication_date": "2018-01-02",
    "publication_year": 2018,
    "authors": "Benny Pinkas; Thomas Schneider; Michael Zohner",
    "corresponding_authors": "",
    "abstract": "Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing any information about items that are not in the intersection. It is one of the best studied applications of secure computation and many PSI protocols have been proposed. However, the variety of existing PSI protocols makes it difficult to identify the solution that performs best in a respective scenario, especially since they were not compared in the same setting. In addition, existing PSI protocols are several orders of magnitude slower than an insecure naïve hashing solution, which is used in practice. In this article, we review the progress made on PSI protocols and give an overview of existing protocols in various security models. We then focus on PSI protocols that are secure against semi-honest adversaries and take advantage of the most recent efficiency improvements in Oblivious Transfer (OT) extension, propose significant optimizations to previous PSI protocols, and suggest a new PSI protocol whose runtime is superior to that of existing protocols. We compare the performance of the protocols, both theoretically and experimentally, by implementing all protocols on the same platform, give recommendations on which protocol to use in a particular setting, and evaluate the progress on PSI protocols by comparing them to the currently employed insecure naïve hashing protocol. We demonstrate the feasibility of our new PSI protocol by processing two sets with a billion elements each.",
    "cited_by_count": 247,
    "openalex_id": "https://openalex.org/W2782492233",
    "type": "article"
  },
  {
    "title": "Attribute Inference Attacks in Online Social Networks",
    "doi": "https://doi.org/10.1145/3154793",
    "publication_date": "2018-01-02",
    "publication_year": 2018,
    "authors": "Neil Zhenqiang Gong; Bin Liu",
    "corresponding_authors": "",
    "abstract": "We propose new privacy attacks to infer attributes (e.g., locations, occupations, and interests) of online social network users. Our attacks leverage seemingly innocent user information that is publicly available in online social networks to infer missing attributes of targeted users. Given the increasing availability of (seemingly innocent) user information online, our results have serious implications for Internet privacy—private attributes can be inferred from users’ publicly available data unless we take steps to protect users from such inference attacks. To infer attributes of a targeted user, existing inference attacks leverage either the user’s publicly available social friends or the user’s behavioral records (e.g., the web pages that the user has liked on Facebook, the apps that the user has reviewed on Google Play), but not both. As we will show, such inference attacks achieve limited success rates. However, the problem becomes qualitatively different if we consider both social friends and behavioral records. To address this challenge, we develop a novel model to integrate social friends and behavioral records, and design new attacks based on our model. We theoretically and experimentally demonstrate the effectiveness of our attacks. For instance, we observe that, in a real-world large-scale dataset with 1.1 million users, our attack can correctly infer the cities a user lived in for 57% of the users; via confidence estimation , we are able to increase the attack success rate to over 90% if the attacker selectively attacks half of the users. Moreover, we show that our attack can correctly infer attributes for significantly more users than previous attacks.",
    "cited_by_count": 115,
    "openalex_id": "https://openalex.org/W2781896769",
    "type": "article"
  },
  {
    "title": "Amandroid",
    "doi": "https://doi.org/10.1145/3183575",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Fengguo Wei; Sankardas Roy; Xinming Ou; Robby",
    "corresponding_authors": "",
    "abstract": "We present a new approach to static analysis for security vetting of Android apps and a general framework called Amandroid. Amandroid determines points-to information for all objects in an Android app component in a flow and context-sensitive (user-configurable) way and performs data flow and data dependence analysis for the component. Amandroid also tracks inter-component communication activities. It can stitch the component-level information into the app-level information to perform intra-app or inter-app analysis. In this article, (a) we show that the aforementioned type of comprehensive app analysis is completely feasible in terms of computing resources with modern hardware, (b) we demonstrate that one can easily leverage the results from this general analysis to build various types of specialized security analyses—in many cases the amount of additional coding needed is around 100 lines of code, and (c) the result of those specialized analyses leveraging Amandroid is at least on par and often exceeds prior works designed for the specific problems, which we demonstrate by comparing Amandroid’s results with those of prior works whenever we can obtain the executable of those tools. Since Amandroid’s analysis directly handles inter-component control and data flows, it can be used to address security problems that result from interactions among multiple components from either the same or different apps. Amandroid’s analysis is sound in that it can provide assurance of the absence of the specified security problems in an app with well-specified and reasonable assumptions on Android runtime system and its library.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2803054784",
    "type": "article"
  },
  {
    "title": "Adversarial EXEmples",
    "doi": "https://doi.org/10.1145/3473039",
    "publication_date": "2021-09-02",
    "publication_year": 2021,
    "authors": "Luca Demetrio; Scott E. Coull; Battista Biggio; Giovanni Lagorio; Alessandro Armando; Fabio Roli",
    "corresponding_authors": "",
    "abstract": "Recent work has shown that adversarial Windows malware samples—referred to as adversarial EXE mples in this article—can bypass machine learning-based detection relying on static code analysis by perturbing relatively few input bytes. To preserve malicious functionality, previous attacks either add bytes to existing non-functional areas of the file, potentially limiting their effectiveness, or require running computationally demanding validation steps to discard malware variants that do not correctly execute in sandbox environments. In this work, we overcome these limitations by developing a unifying framework that does not only encompass and generalize previous attacks against machine-learning models, but also includes three novel attacks based on practical, functionality-preserving manipulations to the Windows Portable Executable file format. These attacks, named Full DOS , Extend , and Shift , inject the adversarial payload by respectively manipulating the DOS header, extending it, and shifting the content of the first section. Our experimental results show that these attacks outperform existing ones in both white-box and black-box scenarios, achieving a better tradeoff in terms of evasion rate and size of the injected payload, while also enabling evasion of models that have been shown to be robust to previous attacks. To facilitate reproducibility of our findings, we open source our framework and all the corresponding attack implementations as part of the secml-malware Python library. We conclude this work by discussing the limitations of current machine learning-based malware detectors, along with potential mitigation strategies based on embedding domain knowledge coming from subject-matter experts directly into the learning process.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W4288072399",
    "type": "article"
  },
  {
    "title": "A General Framework for Adversarial Examples with Objectives",
    "doi": "https://doi.org/10.1145/3317611",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Mahmood Sharif; Sruti Bhagavatula; Lujo Bauer; Michael K. Reiter",
    "corresponding_authors": "",
    "abstract": "Images perturbed subtly to be misclassified by neural networks, called adversarial examples, have emerged as a technically deep challenge and an important concern for several application domains. Most research on adversarial examples takes as its only constraint that the perturbed images are similar to the originals. However, real-world application of these ideas often requires the examples to satisfy additional objectives, which are typically enforced through custom modifications of the perturbation process. In this paper, we propose adversarial generative nets (AGNs), a general methodology to train a generator neural network to emit adversarial examples satisfying desired objectives. We demonstrate the ability of AGNs to accommodate a wide range of objectives, including imprecise ones difficult to model, in two application domains. In particular, we demonstrate physical adversarial examples---eyeglass frames designed to fool face recognition---with better robustness, inconspicuousness, and scalability than previous approaches, as well as a new attack to fool a handwritten-digit classifier.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2932026309",
    "type": "article"
  },
  {
    "title": "MOTION – A Framework for Mixed-Protocol Multi-Party Computation",
    "doi": "https://doi.org/10.1145/3490390",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Lennart Braun; Daniel Demmler; Thomas Schneider; Oleksandr Tkachenko",
    "corresponding_authors": "",
    "abstract": "We present MOTION, an efficient and generic open-source framework for mixed-protocol secure multi-party computation (MPC). MOTION is built in a user-friendly, modular, and extensible way, intended to be used as a tool in MPC research and to increase adoption of MPC protocols in practice. Our framework incorporates several important engineering decisions such as full communication serialization, which enables MPC over arbitrary messaging interfaces and removes the need of owning network sockets. MOTION also incorporates several performance optimizations that improve the communication complexity and latency, e.g., better online round complexity of precomputed correlated Oblivious Transfer (OT).We instantiate our framework with protocols for N parties and security against up to passive corruptions: the MPC protocols of Goldreich-Micali-Wigderson (GMW) in its arithmetic and Boolean version and OT-based BMR (Ben-Efraim et al., CCS'16), as well as novel and highly efficient conversions between them, including a non-interactive conversion from BMR to arithmetic GMW.MOTION is highly efficient, which we demonstrate in our experiments. Compared to secure evaluation of AES-128 with parties in a high-latency network with OT-based BMR, we achieve a 16 better throughput of 16 AES evaluations per second using BMR. With this, we show that BMR is much more competitive than previously assumed. For parties and full-threshold protocols in a LAN, MOTION is-faster than the previous best passively secure implementation from the MP-SPDZ framework, and-faster than the actively secure SCALE-MAMBA framework. Finally, we show that our framework is highly efficient for privacy-preserving neural network inference.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W3090471584",
    "type": "article"
  },
  {
    "title": "<scp>CySecBERT</scp> : A Domain-Adapted Language Model for the Cybersecurity Domain",
    "doi": "https://doi.org/10.1145/3652594",
    "publication_date": "2024-03-15",
    "publication_year": 2024,
    "authors": "Markus Bayer; Philipp Kuehn; Ramin Shanehsaz; Christian Reuter",
    "corresponding_authors": "",
    "abstract": "The field of cysec is evolving fast. Security professionals are in need of intelligence on past, current and —ideally — upcoming threats, because attacks are becoming more advanced and are increasingly targeting larger and more complex systems. Since the processing and analysis of such large amounts of information cannot be addressed manually, cysec experts rely on machine learning techniques. In the textual domain, pre-trained language models such as Bidirectional Encoder Representations from Transformers (BERT) have proven to be helpful as they provide a good baseline for further fine-tuning. However, due to the domain-knowledge and the many technical terms in cysec, general language models might miss the gist of textual information. For this reason, we create a high-quality dataset 1 and present a language model 2 specifically tailored to the cysec domain that can serve as a basic building block for cybersecurity systems. The model is compared on 15 tasks: Domain-dependent extrinsic tasks for measuring the performance on specific problems, intrinsic tasks for measuring the performance of the internal representations of the model, as well as general tasks from the SuperGLUE benchmark. The results of the intrinsic tasks show that our model improves the internal representation space of domain words compared with the other models. The extrinsic, domain-dependent tasks, consisting of sequence tagging and classification, show that the model performs best in cybersecurity scenarios. In addition, we pay special attention to the choice of hyperparameters against catastrophic forgetting, as pre-trained models tend to forget the original knowledge during further training.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4392849751",
    "type": "article"
  },
  {
    "title": "Multi-Stage Enhanced Zero Trust Intrusion Detection System for Unknown Attack Detection in Internet of Things and Traditional Networks",
    "doi": "https://doi.org/10.1145/3725216",
    "publication_date": "2025-03-19",
    "publication_year": 2025,
    "authors": "Malek Al‐Zewairi; Sufyan Almajali; Moussa Ayyash; Mohamed Rahouti; Fernando Martinez Lopez; Nordine Quadar",
    "corresponding_authors": "",
    "abstract": "Detecting unknown cyberattacks remains an open research problem and a significant challenge for the research community and the security industry. This paper tackles the detection of unknown cybersecurity attacks in the Internet of Things (IoT) and traditional networks by categorizing them into two types: entirely new classes of unknown attacks (type-A) and unknown attacks within already known classes (type-B). To address this, we propose a novel multi-stage, multi-layer zero trust architecture for an intrusion detection system (IDS), uniquely designed to handle these attack types. The architecture employs a hybrid methodology that combines two supervised and one unsupervised learning stages in a funnel-like design, significantly advancing current detection capabilities. A key innovation is the layered filtering mechanism, leveraging type-A and type-B attack concepts to systematically classify traffic as malicious unless proven otherwise. Using four benchmark datasets, the proposed system demonstrates significant improvements in accuracy, recall, and error classification rates for unknown attacks, achieving an average accuracy and recall ranging between 88% and 95%. This work offers a robust, scalable framework for enhancing cybersecurity in diverse network environments.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4408622805",
    "type": "article"
  },
  {
    "title": "Sancus 2.0",
    "doi": "https://doi.org/10.1145/3079763",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Job Noorman; Jo Van Bulck; Jan Tobias Mühlberg; Frank Piessens; Pieter Maene; Bart Preneel; Ingrid Verbauwhede; Johannes Götzfried; Tilo Müller; Felix Freiling",
    "corresponding_authors": "",
    "abstract": "The Sancus security architecture for networked embedded devices was proposed in 2013 at the USENIX Security conference. It supports remote (even third-party) software installation on devices while maintaining strong security guarantees. More specifically, Sancus can remotely attest to a software provider that a specific software module is running uncompromised and can provide a secure communication channel between software modules and software providers. Software modules can securely maintain local state and can securely interact with other software modules that they choose to trust. Over the past three years, significant experience has been gained with applications of Sancus, and several extensions of the architecture have been investigated—both by the original designers as well as by independent researchers. Informed by these additional research results, this journal version of the Sancus paper describes an improved design and implementation, supporting additional security guarantees (such as confidential deployment) and a more efficient cryptographic core. We describe the design of Sancus 2.0 (without relying on any prior knowledge of Sancus) and develop and evaluate a prototype FPGA implementation. The prototype extends an MSP430 processor with hardware support for the memory access control and cryptographic functionality required to run Sancus. We report on our experience using Sancus in a variety of application scenarios and discuss some important avenues of ongoing and future work.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2739746516",
    "type": "article"
  },
  {
    "title": "Privacy Games Along Location Traces",
    "doi": "https://doi.org/10.1145/3009908",
    "publication_date": "2016-12-16",
    "publication_year": 2016,
    "authors": "Reza Shokri; George Theodorakopoulos; Carmela Troncoso",
    "corresponding_authors": "",
    "abstract": "The mainstream approach to protecting the privacy of mobile users in location-based services (LBSs) is to alter (e.g., perturb, hide, and so on) the users’ actual locations in order to reduce exposed sensitive information. In order to be effective, a location-privacy preserving mechanism must consider both the privacy and utility requirements of each user, as well as the user’s overall exposed locations (which contribute to the adversary’s background knowledge). In this article, we propose a methodology that enables the design of optimal user-centric location obfuscation mechanisms respecting each individual user’s service quality requirements, while maximizing the expected error that the optimal adversary incurs in reconstructing the user’s actual trace. A key advantage of a user-centric mechanism is that it does not depend on third-party proxies or anonymizers; thus, it can be directly integrated in the mobile devices that users employ to access LBSs. Our methodology is based on the mutual optimization of user/adversary objectives (maximizing location privacy versus minimizing localization error) formalized as a Stackelberg Bayesian game. This formalization makes our solution robust against any location inference attack, that is, the adversary cannot decrease the user’s privacy by designing a better inference algorithm as long as the obfuscation mechanism is designed according to our privacy games. We develop two linear programs that solve the location privacy game and output the optimal obfuscation strategy and its corresponding optimal inference attack. These linear programs are used to design location privacy--preserving mechanisms that consider the correlation between past, current, and future locations of the user, thus can be tuned to protect different privacy objectives along the user’s location trace. We illustrate the efficacy of the optimal location privacy--preserving mechanisms obtained with our approach against real location traces, showing their performance in protecting users’ different location privacy objectives.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2566989010",
    "type": "article"
  },
  {
    "title": "Fast Proxy Re-Encryption for Publish/Subscribe Systems",
    "doi": "https://doi.org/10.1145/3128607",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Yuriy Polyakov; Kurt Rohloff; Gyana Sahu; Vinod Vaikuntanathan",
    "corresponding_authors": "",
    "abstract": "We develop two IND-CPA-secure multihop unidirectional Proxy Re-Encryption (PRE) schemes by applying the Ring-LWE (RLWE) key switching approach from the homomorphic encryption literature. Unidirectional PRE is ideal for secure publish-subscribe operations where a publisher encrypts information using a public key without knowing upfront who the subscriber will be and what private key will be used for decryption. The proposed PRE schemes provide a multihop capability, meaning that when PRE-encrypted information is published onto a PRE-enabled server, the server can either delegate access to specific clients or enable other servers the right to delegate access. Our first scheme (which we call NTRU-ABD-PRE) is based on a variant of the NTRU-RLWE homomorphic encryption scheme. Our second and main PRE scheme (which we call BV-PRE) is built on top of the Brakerski-Vaikuntanathan (BV) homomorphic encryption scheme and relies solely on the RLWE assumption. We present an open-source C++ implementation of both schemes and discuss several algorithmic and software optimizations. We examine parameter selection tradeoffs in the context of security, runtime/latency, throughput, ciphertext expansion, memory usage, and multihop capabilities. Our experimental analysis demonstrates that BV-PRE outperforms NTRU-ABD-PRE in both single-hop and multihop settings. The BV-PRE scheme has a lower time and space complexity than existing IND-CPA-secure lattice-based PRE schemes and requires small concrete parameters, making the scheme computationally efficient for use on low-resource embedded systems while still providing 100 bits of security. We present practical recommendations for applying the PRE schemes to several use cases of ad hoc information sharing for publish-subscribe operations.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2756242929",
    "type": "article"
  },
  {
    "title": "Tractor Beam",
    "doi": "https://doi.org/10.1145/3309735",
    "publication_date": "2019-04-09",
    "publication_year": 2019,
    "authors": "Juhwan Noh; Yu‐Jin Kwon; Yunmok Son; Hocheol Shin; Do-Hyun Kim; Jaeyeong Choi; Yongdae Kim",
    "corresponding_authors": "",
    "abstract": "The consumer drone market is booming. Consumer drones are predominantly used for aerial photography; however, their use has been expanding because of their autopilot technology. Unfortunately, terrorists have also begun to use consumer drones for kamikaze bombing and reconnaissance. To protect against such threats, several companies have started “anti-drone” services that primarily focus on disrupting or incapacitating drone operations. However, the approaches employed are inadequate, because they make any drone that has intruded stop and remain over the protected area. We specify this issue by introducing the concept of safe-hijacking , which enables a hijacker to expel the intruding drone from the protected area remotely. As a safe-hijacking strategy, we investigated whether consumer drones in the autopilot mode can be hijacked via adaptive GPS spoofing. Specifically, as consumer drones activate GPS fail-safe and change their flight mode whenever a GPS error occurs, we performed black- and white-box analyses of GPS fail-safe flight mode and the following behavior after GPS signal recovery of existing consumer drones. Based on our analyses results, we developed a taxonomy of consumer drones according to these fail-safe mechanisms and designed safe-hijacking strategies for each drone type. Subsequently, we applied these strategies to four popular drones: DJI Phantom 3 Standard, DJI Phantom 4, Parrot Bebop 2, and 3DR Solo. The results of field experiments and software simulations verified the efficacy of our safe-hijacking strategies against these drones and demonstrated that the strategies can force them to move in any direction with high accuracy.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2938880258",
    "type": "article"
  },
  {
    "title": "Efficient Privacy-Preserving Matrix Factorization for Recommendation via Fully Homomorphic Encryption",
    "doi": "https://doi.org/10.1145/3212509",
    "publication_date": "2018-06-27",
    "publication_year": 2018,
    "authors": "Jinsu Kim; Dongyoung Koo; Yuna Kim; Hyunsoo Yoon; Junbum Shin; Sungwook Kim",
    "corresponding_authors": "",
    "abstract": "There are recommendation systems everywhere in our daily life. The collection of personal data of users by a recommender in the system may cause serious privacy issues. In this article, we propose the first privacy-preserving matrix factorization for recommendation using fully homomorphic encryption. Our protocol performs matrix factorization over encrypted users’ rating data and returns encrypted outputs so that the recommendation system learns nothing on rating values and resulting user/item profiles. Furthermore, the protocol provides a privacy-preserving method to optimize the tuning parameters that can be a business benefit for the recommendation service providers. To overcome the performance degradation caused by the use of fully homomorphic encryption, we introduce a novel data structure to perform computations over encrypted vectors, which are essential for matrix factorization, through secure two-party computation in part. Our experiments demonstrate the efficiency of our protocol.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2811423811",
    "type": "article"
  },
  {
    "title": "Proactively Identifying Emerging Hacker Threats from the Dark Web",
    "doi": "https://doi.org/10.1145/3409289",
    "publication_date": "2020-08-25",
    "publication_year": 2020,
    "authors": "Sagar Samtani; Hongyi Zhu; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "Cybersecurity experts have appraised the total global cost of malicious hacking activities to be $450 billion annually. Cyber Threat Intelligence (CTI) has emerged as a viable approach to combat this societal issue. However, existing processes are criticized as inherently reactive to known threats. To combat these concerns, CTI experts have suggested proactively examining emerging threats in the vast, international online hacker community. In this study, we aim to develop proactive CTI capabilities by exploring online hacker forums to identify emerging threats in terms of popularity and tool functionality. To achieve these goals, we create a novel Diachronic Graph Embedding Framework (D-GEF). D-GEF operates on a Graph-of-Words (GoW) representation of hacker forum text to generate word embeddings in an unsupervised manner. Semantic displacement measures adopted from diachronic linguistics literature identify how terminology evolves. A series of benchmark experiments illustrate D-GEF's ability to generate higher quality than state-of-the-art word embedding models (e.g., word2vec) in tasks pertaining to semantic analogy, clustering, and threat classification. D-GEF's practical utility is illustrated with in-depth case studies on web application and denial of service threats targeting PHP and Windows technologies, respectively. We also discuss the implications of the proposed framework for strategic, operational, and tactical CTI scenarios. All datasets and code are publicly released to facilitate scientific reproducibility and extensions of this work.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W3086302916",
    "type": "article"
  },
  {
    "title": "The Android Platform Security Model",
    "doi": "https://doi.org/10.1145/3448609",
    "publication_date": "2021-04-28",
    "publication_year": 2021,
    "authors": "René Mayrhofer; Jeffrey Vander Stoep; Chad Brubaker; Nick Kralevich",
    "corresponding_authors": "",
    "abstract": "Android is the most widely deployed end-user focused operating system. With its growing set of use cases encompassing communication, navigation, media consumption, entertainment, finance, health, and access to sensors, actuators, cameras, or microphones, its underlying security model needs to address a host of practical threats in a wide variety of scenarios while being useful to non-security experts. The model needs to strike a difficult balance between security, privacy, and usability for end users, assurances for app developers, and system performance under tight hardware constraints. While many of the underlying design principles have implicitly informed the overall system architecture, access control mechanisms, and mitigation techniques, the Android security model has previously not been formally published. This article aims to both document the abstract model and discuss its implications. Based on a definition of the threat model and Android ecosystem context in which it operates, we analyze how the different security measures in past and current Android implementations work together to mitigate these threats. There are some special cases in applying the security model, and we discuss such deliberate deviations from the abstract model.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W3158714349",
    "type": "article"
  },
  {
    "title": "On Generating Network Traffic Datasets with Synthetic Attacks for Intrusion Detection",
    "doi": "https://doi.org/10.1145/3424155",
    "publication_date": "2021-01-02",
    "publication_year": 2021,
    "authors": "Carlos García Cordero; Emmanouil Vasilomanolakis; Aidmar Wainakh; Max Mühlhäuser; Simin Nadjm‐Tehrani",
    "corresponding_authors": "",
    "abstract": "Most research in the field of network intrusion detection heavily relies on datasets. Datasets in this field, however, are scarce and difficult to reproduce. To compare, evaluate, and test related work, researchers usually need the same datasets or at least datasets with similar characteristics as the ones used in related work. In this work, we present concepts and the Intrusion Detection Dataset Toolkit (ID2T) to alleviate the problem of reproducing datasets with desired characteristics to enable an accurate replication of scientific results. Intrusion Detection Dataset Toolkit (ID2T) facilitates the creation of labeled datasets by injecting synthetic attacks into background traffic. The injected synthetic attacks created by ID2T blend with the background traffic by mimicking the background traffic's properties. This article has three core contributions. First, we present a comprehensive survey on intrusion detection datasets. In the survey, we propose a classification to group the negative qualities found in the datasets. Second, the architecture of ID2T is revised, improved, and expanded in comparison to previous work. The architectural changes enable ID2T to inject recent and advanced attacks, such as the EternalBlue exploit or a peer-to-peer botnet. ID2T's functionality provides a set of tests, known as TIDED, that helps identify potential defects in the background traffic into which attacks are injected. Third, we illustrate how ID2T is used in different use-case scenarios to replicate scientific results with the help of reproducible datasets. ID2T is open source software and is made available to the community to expand its arsenal of attacks and capabilities.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W3119524937",
    "type": "article"
  },
  {
    "title": "Design, Development, and Evaluation of a Cybersecurity, Privacy, and Digital Literacy Game for Tweens",
    "doi": "https://doi.org/10.1145/3469821",
    "publication_date": "2021-09-30",
    "publication_year": 2021,
    "authors": "Sana Maqsood; Sonia Chiasson",
    "corresponding_authors": "",
    "abstract": "Tweens are avid users of digital media, which exposes them to various online threats. Teachers are primarily expected to teach children safe online behaviours, despite not necessarily having the required training or classroom tools to support this education. Using the theory of procedural rhetoric and established game design principles, we designed a classroom-based cybersecurity, privacy, and digital literacy game for tweens that has since been deployed to over 300 Canadian elementary schools. The game, A Day in the Life of the JOs , teaches children about 25 cybersecurity, privacy, and digital literacy topics and allows them to practice what they have learned in a simulated environment. We employed a user-centered design process to create the game, iteratively testing its design and effectiveness with children and teachers through five user studies (with a total of 63 child participants and 21 teachers). Our summative evaluation with children showed that the game improved their cybersecurity, privacy, and digital literacy knowledge and behavioural intent and was positively received by them. Our summative evaluation with teachers also showed positive results. Teachers liked that the game represented the authentic experiences of children on digital media and that it aligned with their curriculum requirements; they were interested in using it in their classrooms. In this article, we discuss our process and experience of designing a production quality game for children and provide evidence of its effectiveness with both children and teachers.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W3203438733",
    "type": "article"
  },
  {
    "title": "Assessing Cyber Risk in Cyber-Physical Systems Using the ATT&amp;CK Framework",
    "doi": "https://doi.org/10.1145/3571733",
    "publication_date": "2022-11-21",
    "publication_year": 2022,
    "authors": "Ahmed Amro; Vasileios Gkioulos; Sokratis Katsikas",
    "corresponding_authors": "",
    "abstract": "Autonomous transport is receiving increasing attention, with research and development activities already providing prototype implementations. In this article we focus on Autonomous Passenger Ships (APS) , which are being considered as a solution for passenger transport across urban waterways. The ambition of the authors has been to examine the safety and security implications of such a Cyber Physical System (CPS) , particularly focusing on threats that endanger the passengers and the operational environment of the APS. Accordingly, the article presents a new risk assessment approach based on a Failure Modes Effects and Criticality Analysis (FMECA) that is enriched with selected semantics and components of the MITRE ATT&amp;CK framework, in order to utilize the encoded common knowledge and facilitate the expression of attacks. Then, the proposed approach is demonstrated through conducting a risk assessment for a communication architecture tailored to the requirements of APSs that were proposed in earlier work. Moreover, we propose a group of graph theory-based metrics for estimating the impact of the identified risks. The use of this method has resulted in the identification of risks and their corresponding countermeasures, in addition to identifying risks with limited existing mitigation mechanisms. The benefits of the proposed approach are the comprehensive, atomic, and descriptive nature of the identified threats, which reduce the need for expert judgment, and the granular impact estimation metrics that reduce the impact of bias. All these features are provided in a semi-automated approach to reduce the required effort and collectively are argued to enrich the design-level risk assessment processes with an updatable industry threat model standard, namely ATT&amp;CK.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W4309756669",
    "type": "article"
  },
  {
    "title": "Privacy Policies across the Ages: Content of Privacy Policies 1996–2021",
    "doi": "https://doi.org/10.1145/3590152",
    "publication_date": "2023-04-01",
    "publication_year": 2023,
    "authors": "Isabel Wagner",
    "corresponding_authors": "Isabel Wagner",
    "abstract": "It is well known that most users do not read privacy policies but almost always tick the box to agree with them. While the length and readability of privacy policies have been well studied and many approaches for policy analysis based on natural language processing have been proposed, existing studies are limited in their depth and scope, often focusing on a small number of data practices at single point in time. In this article, we fill this gap by analyzing the 25-year history of privacy policies using machine learning and natural language processing and presenting a comprehensive analysis of policy contents. Specifically, we collect a large-scale longitudinal corpus of privacy policies from 1996 to 2021 and analyze their content in terms of the data practices they describe, the rights they grant to users, and the rights they reserve for their organizations. We pay particular attention to changes in response to recent privacy regulations such as the GDPR and CCPA. We observe some positive changes, such as reductions in data collection post-GDPR, but also a range of concerning data practices, such as widespread implicit data collection for which users have no meaningful choices or access rights. Our work is an important step toward making privacy policies machine readable on the user side, which would help users match their privacy preferences against the policies offered by web services.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4362452929",
    "type": "article"
  },
  {
    "title": "<scp>Euler</scp> : Detecting Network Lateral Movement via Scalable Temporal Link Prediction",
    "doi": "https://doi.org/10.1145/3588771",
    "publication_date": "2023-03-24",
    "publication_year": 2023,
    "authors": "Isaiah J. King; H. Howie Huang",
    "corresponding_authors": "",
    "abstract": "Lateral movement is a key stage of system compromise used by advanced persistent threats. Detecting it is no simple task. When network host logs are abstracted into discrete temporal graphs, the problem can be reframed as anomalous edge detection in an evolving network. Research in modern deep graph learning techniques has produced many creative and complicated models for this task. However, as is the case in many machine learning fields, the generality of models is of paramount importance for accuracy and scalability during training and inference. In this article, we propose a formalized approach to this problem with a framework we call Euler . It consists of a model-agnostic graph neural network stacked upon a model-agnostic sequence encoding layer such as a recurrent neural network. Models built according to the Euler framework can easily distribute their graph convolutional layers across multiple machines for large performance improvements. Additionally, we demonstrate that Euler -based models are as good, or better, than every state-of-the-art approach to anomalous link detection and prediction that we tested. As anomaly-based intrusion detection systems, our models efficiently identified anomalous connections between entities with high precision and outperformed all other unsupervised techniques for anomalous lateral movement detection. Additionally, we show that as a piece of a larger anomaly detection pipeline, Euler models perform well enough for use in real-world systems. With more advanced, yet still lightweight, alerting mechanisms ingesting the embeddings produced by Euler models, precision is boosted from 0.243, to 0.986 on real-world network traffic.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W4360851419",
    "type": "article"
  },
  {
    "title": "A Close Look at a Daily Dataset of Malware Samples",
    "doi": "https://doi.org/10.1145/3291061",
    "publication_date": "2019-01-22",
    "publication_year": 2019,
    "authors": "Xabier Ugarte-Pedrero; Mariano Graziano; Davide Balzarotti",
    "corresponding_authors": "",
    "abstract": "The number of unique malware samples is growing out of control. Over the years, security companies have designed and deployed complex infrastructures to collect and analyze this overwhelming number of samples. As a result, a security company can collect more than 1M unique files per day only from its different feeds. These are automatically stored and processed to extract actionable information derived from static and dynamic analysis. However, only a tiny amount of this data is interesting for security researchers and attracts the interest of a human expert. To the best of our knowledge, nobody has systematically dissected these datasets to precisely understand what they really contain. The security community generally discards the problem because of the alleged prevalence of uninteresting samples. In this article, we guide the reader through a step-by-step analysis of the hundreds of thousands Windows executables collected in one day from these feeds. Our goal is to show how a company can employ existing state-of-the-art techniques to automatically process these samples and then perform manual experiments to understand and document what is the real content of this gigantic dataset. We present the filtering steps, and we discuss in detail how samples can be grouped together according to their behavior to support manual verification. Finally, we use the results of this measurement experiment to provide a rough estimate of both the human and computer resources that are required to get to the bottom of the catch of the day .",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2912095101",
    "type": "article"
  },
  {
    "title": "VULCON",
    "doi": "https://doi.org/10.1145/3196884",
    "publication_date": "2018-06-12",
    "publication_year": 2018,
    "authors": "Katheryn A. Farris; Ankit Shah; George Cybenko; Rajesh Ganesan; Sushil Jajodia",
    "corresponding_authors": "",
    "abstract": "Vulnerability remediation is a critical task in operational software and network security management. In this article, an effective vulnerability management strategy, called VULCON (VULnerability CONtrol), is developed and evaluated. The strategy is based on two fundamental performance metrics: (1) time-to-vulnerability remediation (TVR) and (2) total vulnerability exposure (TVE). VULCON takes as input real vulnerability scan reports, metadata about the discovered vulnerabilities, asset criticality, and personnel resources. VULCON uses a mixed-integer multiobjective optimization algorithm to prioritize vulnerabilities for patching, such that the above performance metrics are optimized subject to the given resource constraints. VULCON has been tested on multiple months of real scan data from a cyber-security operations center (CSOC). Results indicate an overall TVE reduction of 8.97% when VULCON optimizes a realistic security analyst workforce’s effort. Additionally, VULCON demonstrates that it can determine monthly resources required to maintain a target TVE score. As such, VULCON provides valuable operational guidance for improving vulnerability response processes in CSOCs.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2808052182",
    "type": "article"
  },
  {
    "title": "A Video-based Attack for Android Pattern Lock",
    "doi": "https://doi.org/10.1145/3230740",
    "publication_date": "2018-07-24",
    "publication_year": 2018,
    "authors": "Guixin Ye; Zhanyong Tang; Dingyi Fang; Xiaojiang Chen; Willy Wolff; Adam J. Aviv; Zheng Wang",
    "corresponding_authors": "",
    "abstract": "Pattern lock is widely used for identification and authentication on Android devices. This article presents a novel video-based side channel attack that can reconstruct Android locking patterns from video footage filmed using a smartphone. As a departure from previous attacks on pattern lock, this new attack does not require the camera to capture any content displayed on the screen. Instead, it employs a computer vision algorithm to track the fingertip movement trajectory to infer the pattern. Using the geometry information extracted from the tracked fingertip motions, the method can accurately infer a small number of (often one) candidate patterns to be tested by an attacker. We conduct extensive experiments to evaluate our approach using 120 unique patterns collected from 215 independent users. Experimental results show that the proposed attack can reconstruct over 95% of the patterns in five attempts. We discovered that, in contrast to most people’s belief, complex patterns do not offer stronger protection under our attacking scenarios. This is demonstrated by the fact that we are able to break all but one complex patterns (with a 97.5% success rate) as opposed to 60% of the simple patterns in the first attempt. We demonstrate that this video-side channel is a serious concern for not only graphical locking patterns but also PIN-based passwords, as algorithms and analysis developed from the attack can be easily adapted to target PIN-based passwords. As a countermeasure, we propose to change the way the Android locking pattern is constructed and used. We show that our proposal can successfully defeat this video-based attack. We hope the results of this article can encourage the community to revisit the design and practical use of Android pattern lock.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2883350670",
    "type": "article"
  },
  {
    "title": "Mo(bile) Money, Mo(bile) Problems",
    "doi": "https://doi.org/10.1145/3092368",
    "publication_date": "2017-08-11",
    "publication_year": 2017,
    "authors": "Bradley Reaves; Jasmine Bowers; Nolen Scaife; Adam Bates; Arnav Bhartiya; Patrick Traynor; Kevin Butler",
    "corresponding_authors": "",
    "abstract": "Mobile money, also known as branchless banking, leverages ubiquitous cellular networks to bring much-needed financial services to the unbanked in the developing world. These services are often deployed as smartphone apps, and although marketed as secure, these applications are often not regulated as strictly as traditional banks, leaving doubt about the truth of such claims. In this article, we evaluate these claims and perform the first in-depth measurement analysis of branchless banking applications. We first perform an automated analysis of all 46 known Android mobile money apps across the 246 known mobile money providers from 2015. We then perform a comprehensive manual teardown of the registration, login, and transaction procedures of a diverse 15% of these apps. We uncover pervasive vulnerabilities spanning botched certification validation, do-it-yourself cryptography, and other forms of information leakage that allow an attacker to impersonate legitimate users, modify transactions, and steal financial records. These findings show that the majority of these apps fail to provide the protections needed by financial services. In an expanded re-evaluation one year later, we find that these systems have only marginally improved their security. Additionally, we document our experiences working in this sector for future researchers and provide recommendations to improve the security of this critical ecosystem. Finally, through inspection of providers’ terms of service, we also discover that liability for these problems unfairly rests on the shoulders of the customer, threatening to erode trust in branchless banking and hinder efforts for global financial inclusion.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2742827529",
    "type": "article"
  },
  {
    "title": "Efficient Attack Graph Analysis through Approximate Inference",
    "doi": "https://doi.org/10.1145/3105760",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Luis Muñoz-González; Daniele Sgandurra; Andrea Paudice; Emil Lupu",
    "corresponding_authors": "",
    "abstract": "Attack graphs provide compact representations of the attack paths an attacker can follow to compromise network resources from the analysis of network vulnerabilities and topology. These representations are a powerful tool for security risk assessment. Bayesian inference on attack graphs enables the estimation of the risk of compromise to the system’s components given their vulnerabilities and interconnections and accounts for multi-step attacks spreading through the system. While static analysis considers the risk posture at rest, dynamic analysis also accounts for evidence of compromise, for example, from Security Information and Event Management software or forensic investigation. However, in this context, exact Bayesian inference techniques do not scale well. In this article, we show how Loopy Belief Propagation—an approximate inference technique—can be applied to attack graphs and that it scales linearly in the number of nodes for both static and dynamic analysis, making such analyses viable for larger networks. We experiment with different topologies and network clustering on synthetic Bayesian attack graphs with thousands of nodes to show that the algorithm’s accuracy is acceptable and that it converges to a stable solution. We compare sequential and parallel versions of Loopy Belief Propagation with exact inference techniques for both static and dynamic analysis, showing the advantages and gains of approximate inference techniques when scaling to larger attack graphs.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2963622436",
    "type": "article"
  },
  {
    "title": "A Formal Approach to Physics-based Attacks in Cyber-physical Systems",
    "doi": "https://doi.org/10.1145/3373270",
    "publication_date": "2020-02-05",
    "publication_year": 2020,
    "authors": "Ruggero Lanotte; Massimo Merro; Andrei Munteanu; Luca Viganò",
    "corresponding_authors": "",
    "abstract": "We apply formal methods to lay and streamline theoretical foundations to reason about Cyber-Physical Systems (CPSs) and physics-based attacks, i.e., attacks targeting physical devices. We focus on a formal treatment of both integrity and denial of service attacks to sensors and actuators of CPSs, and on the timing aspects of these attacks. Our contributions are fourfold. (1) We define a hybrid process calculus to model both CPSs and physics-based attacks. (2) We formalise a threat model that specifies MITM attacks that can manipulate sensor readings or control commands to drive a CPS into an undesired state; we group these attacks into classes and provide the means to assess attack tolerance/vulnerability with respect to a given class of attacks, based on a proper notion of most powerful physics-based attack. (3) We formalise how to estimate the impact of a successful attack on a CPS and investigate possible quantifications of the success chances of an attack. (4) We illustrate our definitions and results by formalising a non-trivial running example in U PPAAL SMC, the statistical extension of the U PPAAL model checker; we use U PPAAL SMC as an automatic tool for carrying out a static security analysis of our running example in isolation and when exposed to three different physics-based attacks with different impacts.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2995364870",
    "type": "article"
  },
  {
    "title": "Key Negotiation Downgrade Attacks on Bluetooth and Bluetooth Low Energy",
    "doi": "https://doi.org/10.1145/3394497",
    "publication_date": "2020-07-04",
    "publication_year": 2020,
    "authors": "Daniele Antonioli; Nils Ole Tippenhauer; Kasper Rasmussen",
    "corresponding_authors": "",
    "abstract": "Bluetooth (BR/EDR) and Bluetooth Low Energy (BLE) are pervasive wireless technologies specified in the Bluetooth standard. The standard includes key negotiation protocols used to generate long-term keys (during pairing) and session keys (during secure connection establishment). In this work, we demonstrate that the key negotiation protocols of Bluetooth and BLE are vulnerable to standard-compliant entropy downgrade attacks. In particular, we show how an attacker can downgrade the entropy of any Bluetooth session key to 1 byte, and of any BLE long-term key and session key to 7 bytes. Such low entropy values enable the attacker to brute-force Bluetooth long-term keys and BLE long-term and session keys, and to break all the security guarantees promised by Bluetooth and BLE. As a result of our attacks, an attacker can decrypt all the ciphertext and inject valid ciphertext in any Bluetooth and BLE network. Our key negotiation downgrade attacks are conducted remotely, do not require access to the victims’ devices, and are stealthy to the victims. As the attacks are standard-compliant, they are effective regardless of the usage of the strongest Bluetooth and BLE security modes (including Secure Connections), the Bluetooth version, and the implementation details of the devices used by the victims. We successfully attack 38 Bluetooth devices (32 unique Bluetooth chips) and 19 BLE devices from different vendors, using all the major versions of the Bluetooth standard. Finally, we present effective legacy compliant and non-legacy compliant countermeasures to mitigate our key negotiation downgrade attacks.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W3038161846",
    "type": "article"
  },
  {
    "title": "A Systematic Analysis of the Capital One Data Breach: Critical Lessons Learned",
    "doi": "https://doi.org/10.1145/3546068",
    "publication_date": "2022-07-07",
    "publication_year": 2022,
    "authors": "Shaharyar Khan; Ilya Kabanov; Yunke Hua; Stuart Madnick",
    "corresponding_authors": "",
    "abstract": "The 2019 Capital One data breach was one of the largest data breaches impacting the privacy and security of personal information of over a 100 million individuals. In most reports about a cyberattack, you will often hear that it succeeded because a single employee clicked on a link in a phishing email or forgot to patch some software, making it seem like an isolated, one-off, trivial problem involving maybe one person, committing a mistake or being negligent. But that is usually not the complete story. By ignoring the related managerial and organizational failures, you are leaving in place the conditions for the next breach. Using our Cybersafety analysis methodology, we identified control failures spanning control levels, going from rather technical issues up to top management, the Board of Directors, and Government regulators. In this analysis, we reconstruct the Capital One hierarchical cyber safety control structure, identify what parts failed and why, and provide recommendations for improvements. This work demonstrates how to discover the true causes of security failures in complex information systems and derive systematic cybersecurity improvements that likely apply to many other organizations. It also provides an approach that individuals can use to evaluate and better secure their organizations.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4284895455",
    "type": "article"
  },
  {
    "title": "FENCE: Feasible Evasion Attacks on Neural Networks in Constrained Environments",
    "doi": "https://doi.org/10.1145/3544746",
    "publication_date": "2022-06-21",
    "publication_year": 2022,
    "authors": "Alesia Chernikova; Alina Oprea",
    "corresponding_authors": "",
    "abstract": "As advances in Deep Neural Networks (DNNs) demonstrate unprecedented levels of performance in many critical applications, their vulnerability to attacks is still an open question. We consider evasion attacks at testing time against Deep Learning in constrained environments, in which dependencies between features need to be satisfied. These situations may arise naturally in tabular data or may be the result of feature engineering in specific application domains, such as threat detection in cyber security. We propose a general iterative gradient-based framework called FENCE for crafting evasion attacks that take into consideration the specifics of constrained domains and application requirements. We apply it against Feed-Forward Neural Networks trained for two cyber security applications: network traffic botnet classification and malicious domain classification, to generate feasible adversarial examples. We extensively evaluate the success rate and performance of our attacks, compare their improvement over several baselines, and analyze factors that impact the attack success rate, including the optimization objective and the data imbalance. We show that with minimal effort (e.g., generating 12 additional network connections), an attacker can change the model’s prediction from the Malicious class to Benign and evade the classifier. We show that models trained on datasets with higher imbalance are more vulnerable to our FENCE attacks. Finally, we demonstrate the potential of performing adversarial training in constrained domains to increase the model resilience against these evasion attacks.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3102844060",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Decision Trees Training and Prediction",
    "doi": "https://doi.org/10.1145/3517197",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Adi Akavia; Max Leibovich; Yehezkel S. Resheff; Roey Ron; Moni Shahar; Margarita Vald",
    "corresponding_authors": "",
    "abstract": "In the era of cloud computing and machine learning, data has become a highly valuable resource. Recent history has shown that the benefits brought forth by this data driven culture come at a cost of potential data leakage. Such breaches have a devastating impact on individuals and industry, and lead the community to seek privacy preserving solutions. A promising approach is to utilize Fully Homomorphic Encryption ( \\( \\mathsf {FHE } \\) ) to enable machine learning over encrypted data, thus providing resiliency against information leakage. However, computing over encrypted data incurs a high computational overhead, thus requiring the redesign of algorithms, in an “ \\( \\mathsf {FHE } \\) -friendly” manner, to maintain their practicality. In this work we focus on the ever-popular tree based methods, and propose a new privacy-preserving solution to training and prediction for trees over data encrypted with homomorphic encryption. Our solution employs a low-degree approximation for the step-function together with a lightweight interactive protocol, to replace components of the vanilla algorithm that are costly over encrypted data. Our protocols for decision trees achieve practical usability demonstrated on standard UCI datasets encrypted with fully homomorphic encryption. In addition, the communication complexity of our protocols is independent of the tree size and dataset size in prediction and training, respectively, which significantly improves on prior works. 1",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3184223012",
    "type": "article"
  },
  {
    "title": "Pump Up Password Security! Evaluating and Enhancing Risk-Based Authentication on a Real-World Large-Scale Online Service",
    "doi": "https://doi.org/10.1145/3546069",
    "publication_date": "2022-06-30",
    "publication_year": 2022,
    "authors": "Stephan Wiefling; Paul René Jørgensen; Sigurd Thunem; Luigi Lo Iacono",
    "corresponding_authors": "",
    "abstract": "Risk-based authentication (RBA) aims to protect users against attacks involving stolen passwords. RBA monitors features during login, and requests re-authentication when feature values widely differ from previously observed ones. It is recommended by various national security organizations, and users perceive it more usable and equally secure than equivalent two-factor authentication. Despite that, RBA is still only used by very few online services. Reasons for this include a lack of validated open resources on RBA properties, implementation, and configuration. This effectively hinders the RBA research, development, and adoption progress. To close this gap, we provide the first long-term RBA analysis on a real-world large-scale online service. We collected feature data of 3.3 million users and 31.3 million login attempts over more than one year. Based on the data, we provide (i) studies on RBA's real-world characteristics, and its configurations and enhancements to balance usability, security, and privacy, (ii) a machine learning based RBA parameter optimization method to support administrators finding an optimal configuration for their own use case scenario, (iii) an evaluation of the round-trip time feature's potential to replace the IP address for enhanced user privacy, and (iv) a synthesized RBA data set to reproduce this research and to foster future RBA research. Our results provide insights on selecting an optimized RBA configuration so that users profit from RBA after just a few logins. The open data set enables researchers to study, test, and improve RBA for widespread deployment in the wild.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4283724392",
    "type": "article"
  },
  {
    "title": "SoK: Human-centered Phishing Susceptibility",
    "doi": "https://doi.org/10.1145/3575797",
    "publication_date": "2022-12-09",
    "publication_year": 2022,
    "authors": "Sijie Zhuo; Robert Biddle; Yun Sing Koh; Danielle Lottridge; Giovanni Russello",
    "corresponding_authors": "",
    "abstract": "Phishing is recognized as a serious threat to organizations and individuals. While there have been significant technical advances in blocking phishing attacks, end-users remain the last line of defence after phishing emails reach their email inboxes. Most of the existing literature on this subject has focused on the technical aspects related to phishing. The factors that cause humans to be susceptible to phishing attacks are still not well-understood. To fill this gap, we reviewed the available literature and systematically categorized the phishing susceptibility variables studied. We classify variables based on their temporal scope, which led us to propose a three-stage Phishing Susceptibility Model (PSM) for explaining how humans are vulnerable to phishing attacks. This model reveals several research gaps that need to be addressed to understand and improve protection against phishing susceptibility. Our review also systematizes existing studies by their sample size and generalizability and further suggests a practical impact assessment of the value of studying variables: Some more easily lead to improvements than others. We believe that this article can provide guidelines for future phishing susceptibility research to improve experiment design and the quality of findings.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4311134468",
    "type": "article"
  },
  {
    "title": "TLS-MHSA: An Efficient Detection Model for Encrypted Malicious Traffic based on Multi-Head Self-Attention Mechanism",
    "doi": "https://doi.org/10.1145/3613960",
    "publication_date": "2023-08-07",
    "publication_year": 2023,
    "authors": "Jinfu Chen; Luo Song; Saihua Cai; Haodi Xie; Shang Yin; Bilal Ahmad",
    "corresponding_authors": "",
    "abstract": "In recent years, the use of TLS (Transport Layer Security) protocol to protect communication information has become increasingly popular as users are more aware of network security. However, hackers have also exploited the salient features of the TLS protocol to carry out covert malicious attacks, which threaten the security of network space. Currently, the commonly used traffic detection methods are not always reliable when applied to the problem of encrypted malicious traffic detection due to their limitations. The most significant problem is that these methods do not focus on the key features of encrypted traffic. To address this problem, this study proposes an efficient detection model for encrypted malicious traffic based on transport layer security protocol and a multi-head self-attention mechanism called TLS-MHSA. Firstly, we extract the features of TLS traffic during pre-processing and perform traffic statistics to filter redundant features. Then, we use a multi-head self-attention mechanism to focus on learning key features as well as generate the most important combined features to construct the detection model, thereby detecting the encrypted malicious traffic. Finally, we use a public dataset to verify the effectiveness and efficiency of the TLS-MHSA model, and the experimental results show that the proposed TLS-MHSA model has high precision, recall, F1-measure, AUC-ROC as well as higher stability than seven state-of-the-art detection models.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4385636980",
    "type": "article"
  },
  {
    "title": "Uncovering CWE-CVE-CPE Relations with Threat Knowledge Graphs",
    "doi": "https://doi.org/10.1145/3641819",
    "publication_date": "2024-01-19",
    "publication_year": 2024,
    "authors": "Zhenpeng Shi; Nikolay Matyunin; Kálmán Graffi; David Starobinski",
    "corresponding_authors": "",
    "abstract": "Security assessment relies on public information about products, vulnerabilities, and weaknesses. So far, databases in these categories have rarely been analyzed in combination. Yet, doing so could help predict unreported vulnerabilities and identify common threat patterns. In this article, we propose a methodology for producing and optimizing a knowledge graph that aggregates knowledge from common threat databases (CVE, CWE, and CPE). We apply the threat knowledge graph to predict associations between threat databases, specifically between products, vulnerabilities, and weaknesses. We evaluate the prediction performance both in closed world with associations from the knowledge graph and in open world with associations revealed afterward. Using rank-based metrics (i.e., Mean Rank, Mean Reciprocal Rank, and Hits@N scores), we demonstrate the ability of the threat knowledge graph to uncover many associations that are currently unknown but will be revealed in the future, which remains useful over different time periods. We propose approaches to optimize the knowledge graph and show that they indeed help in further uncovering associations. We have made the artifacts of our work publicly available.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4391026296",
    "type": "article"
  },
  {
    "title": "Deep PackGen: A Deep Reinforcement Learning Framework for Adversarial Network Packet Generation",
    "doi": "https://doi.org/10.1145/3712307",
    "publication_date": "2025-01-14",
    "publication_year": 2025,
    "authors": "Soumyadeep Hore; Jalal Ghadermazi; Diwas Paudel; Ankit Shah; Tapas K. Das; Nathaniel D. Bastian",
    "corresponding_authors": "",
    "abstract": "Recent advancements in artificial intelligence (AI) and machine learning (ML) algorithms, coupled with the availability of faster computing infrastructure, have enhanced the security posture of cybersecurity operations centers (defenders) through the development of ML-aided network intrusion detection systems (NIDS). Concurrently, the abilities of adversaries to evade security have also increased with the support of AI/ML models. Therefore, defenders need to proactively prepare for evasion attacks that exploit the detection mechanisms of NIDS. Recent studies have found that the perturbation of flow-based and packet-based features can deceive ML models, but these approaches have limitations. Perturbations made to the flow-based features are difficult to reverse-engineer, while samples generated with perturbations to the packet-based features are not playable. Our methodological framework, Deep PackGen, employs deep reinforcement learning to generate adversarial packets and aims to overcome the limitations of approaches in the literature. By taking raw malicious network packets as inputs and systematically making perturbations on them, Deep PackGen camouflages them as benign packets while still maintaining their functionality. In our experiments, using publicly available data, Deep PackGen achieved an average adversarial success rate of 66.4% against various ML models and across different attack types. Our investigation also revealed that more than 45% of the successful adversarial samples were out-of-distribution packets that evaded the decision boundaries of the classifiers. The knowledge gained from our study on the adversary’s ability to make specific evasive perturbations to different types of malicious packets can help defenders enhance the robustness of their NIDS against evolving adversarial attacks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4406371502",
    "type": "article"
  },
  {
    "title": "Differentially Private K-Means Clustering and a Hybrid Approach to Private Optimization",
    "doi": "https://doi.org/10.1145/3133201",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Dong Su; Jianneng Cao; Ninghui Li; Elisa Bertino; Min Lyu; Hongxia Jin",
    "corresponding_authors": "",
    "abstract": "k -means clustering is a widely used clustering analysis technique in machine learning. In this article, we study the problem of differentially private k -means clustering. Several state-of-the-art methods follow the single-workload approach, which adapts an existing machine-learning algorithm by making each step private. However, most of them do not have satisfactory empirical performance. In this work, we develop techniques to analyze the empirical error behaviors of one of the state-of-the-art single-workload approaches, DPLloyd, which is a differentially private version of the Lloyd algorithm for k &gt;-means clustering. Based on the analysis, we propose an improvement of DPLloyd. We also propose a new algorithm for k -means clustering from the perspective of the noninteractive approach, which publishes a synopsis of the input dataset and then runs k -means on synthetic data generated from the synopsis. We denote this approach by EUGkM. After analyzing the empirical error behaviors of EUGkM, we further propose a hybrid approach that combines our DPLloyd improvement and EUGkM. Results from extensive and systematic experiments support our analysis and demonstrate the effectiveness of the DPLloyd improvement, EUGkM, and the hybrid approach.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2765846180",
    "type": "article"
  },
  {
    "title": "<i>FOSSIL</i>",
    "doi": "https://doi.org/10.1145/3175492",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Saed Alrabaee; Paria Shirani; Lingyu Wang; Mourad Debbabi",
    "corresponding_authors": "",
    "abstract": "Identifying free open-source software (FOSS) packages on binaries when the source code is unavailable is important for many security applications, such as malware detection, software infringement, and digital forensics. This capability enhances both the accuracy and the efficiency of reverse engineering tasks by avoiding false correlations between irrelevant code bases. Although the FOSS package identification problem belongs to the field of software engineering, conventional approaches rely strongly on practical methods in data mining and database searching. However, various challenges in the use of these methods prevent existing function identification approaches from being effective in the absence of source code. To make matters worse, the introduction of obfuscation techniques, the use of different compilers and compilation settings, and software refactoring techniques has made the automated detection of FOSS packages increasingly difficult. With very few exceptions, the existing systems are not resilient to such techniques, and the exceptions are not sufficiently efficient. To address this issue, we propose FOSSIL , a novel resilient and efficient system that incorporates three components. The first component extracts the syntactical features of functions by considering opcode frequencies and applying a hidden Markov model statistical test. The second component applies a neighborhood hash graph kernel to random walks derived from control-flow graphs, with the goal of extracting the semantics of the functions. The third component applies z-score to the normalized instructions to extract the behavior of instructions in a function. The components are integrated using a Bayesian network model, which synthesizes the results to determine the FOSS function. The novel approach of combining these components using the Bayesian network has produced stronger resilience to code obfuscation. We evaluate our system on three datasets, including real-world projects whose use of FOSS packages is known, malware binaries for which there are security and reverse engineering reports purporting to describe their use of FOSS, and a large repository of malware binaries. We demonstrate that our system is able to identify FOSS packages in real-world projects with a mean precision of 0.95 and with a mean recall of 0.85. Furthermore, FOSSIL is able to discover FOSS packages in malware binaries that match those listed in security and reverse engineering reports. Our results show that modern malware binaries contain 0.10--0.45 of FOSS packages.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2790751137",
    "type": "article"
  },
  {
    "title": "The Password Life Cycle",
    "doi": "https://doi.org/10.1145/3183341",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Elizabeth Stobert; Robert Biddle",
    "corresponding_authors": "",
    "abstract": "Managing passwords is a difficult task for users, who must create, remember, and keep track of large numbers of passwords. In this work, we investigated users’ coping strategies for password management. Through a series of interviews, we identified a “life cycle” of password use and find that users’ central task in coping with their passwords is rationing their effort to best protect their important accounts. We followed up this work by interviewing experts about their password management practices and found that experts rely on the same kinds of coping strategies as non-experts, but that their increased situation awareness of security allows them to better ration their effort into protecting their accounts. Finally, we conducted a survey study to explore how the life cycle model generalizes to the larger population and find that the life cycle and rationing patterns can be seen in the broader population, but that survey respondents were less likely to characterize security management as a challenging task.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2801242599",
    "type": "article"
  },
  {
    "title": "Will They Use It or Not? Investigating Software Developers’ Intention to Follow Privacy Engineering Methodologies",
    "doi": "https://doi.org/10.1145/3364224",
    "publication_date": "2019-11-03",
    "publication_year": 2019,
    "authors": "Awanthika Senarath; Marthie Grobler; Nalin Asanka Gamagedara Arachchilage",
    "corresponding_authors": "",
    "abstract": "With the increasing concerns over privacy in software systems, there is a growing enthusiasm to develop methods to support the development of privacy aware software systems. Inadequate privacy in software system designs could result in users losing their sensitive data, such as health information and financial information, which may cause financial and reputation loss. Privacy Engineering Methodologies (PEMs) are introduced into the software development processes with the goal of guiding software developers to embed privacy into the systems they design. However, for PEMs to be successful it is imperative that software developers have a positive intention to use PEMs. Otherwise, developers may attempt to bypass the privacy methodologies or use them partially and hence develop software systems that may not protect user privacy appropriately. To investigate the factors that affect software developers’ behavioural intention to follow PEMs, in this article, we conducted a study with 149 software developers. Findings of the study show that the usefulness of the PEM to the developers’ existing work to be the strongest determinant that affects software developers’ intention to follow PEMs. Moreover, the compatibility of the PEM with their way of work and how the PEM demonstrates its results when used were also found to be significant. These findings provide important insights in understanding the behaviour of software developers and how they perceive PEMs. The findings could be used to assist organisations and researchers to deploy PEMs and design PEMs that are positively accepted by software developers.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2986667521",
    "type": "article"
  },
  {
    "title": "The Dilemma of User Engagement in Privacy Notices",
    "doi": "https://doi.org/10.1145/3372296",
    "publication_date": "2020-02-08",
    "publication_year": 2020,
    "authors": "Farzaneh Karegar; John Sören Pettersson; Simone Fischer‐Hübner",
    "corresponding_authors": "",
    "abstract": "Privacy notices and consent forms are the means of conveying privacy policy information to users. In Europe, a valid consent needs to be confirmed by a clear affirmative action. Despite previous research, it is not yet clear whether user engagement with consent forms via different types of interactions for confirming consent may play a significant role in effectively drawing user attention to the content, even after repeated exposure. We investigate, in a laboratory study, how different types of interactions that engage users with consent forms differ in terms of their effectiveness, efficiency, and user satisfaction. In addition, we examine if and how habituation affects user attention and satisfaction, and the time they spend on giving their consent. We conducted a controlled experiment with 80 participants in four different groups where people either were engaged actively with the policy content via Drag and Drop (DAD), Swipe, or Checkboxes, or were not actively engaged with the content (as the control condition) in a first-exposure phase and in a habituation phase. We measured user attention to consent forms along multiple dimensions, including direct, objective measurements and indirect, self-reported measures. Our results show that the different types of interactions may affect user attention to certain parts of policy information. In particular, the DAD action results in significantly more user attention to the data items compared to other groups. However, with repeated exposure to consent forms, the difference disappears. We conclude that user engagement with policy content needs to be designed with care, so that attention to substantial policy information is increased and not negatively affected.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W3013836207",
    "type": "article"
  },
  {
    "title": "An Extensive Formal Analysis of Multi-factor Authentication Protocols",
    "doi": "https://doi.org/10.1145/3440712",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Charlie Jacomme; Steve Kremer",
    "corresponding_authors": "",
    "abstract": "Passwords are still the most widespread means for authenticating users, even though they have been shown to create huge security problems. This motivated the use of additional authentication mechanisms in so-called multi-factor authentication protocols. In this article, we define a detailed threat model for this kind of protocol: While in classical protocol analysis attackers control the communication network, we take into account that many communications are performed over TLS channels, that computers may be infected by different kinds of malware, that attackers could perform phishing, and that humans may omit some actions. We formalize this model in the applied pi calculus and perform an extensive analysis and comparison of several widely used protocols—variants of Google 2-step and FIDO’s U2F (Yubico’s Security Key token). The analysis is completely automated, generating systematically all combinations of threat scenarios for each of the protocols and using the P ROVERIF tool for automated protocol analysis. To validate our model and attacks, we demonstrate their feasibility in practice, even though our experiments are run in a laboratory environment. Our analysis highlights weaknesses and strengths of the different protocols. It allows us to suggest several small modifications of the existing protocols that are easy to implement, as well as an extension of Google 2-step that improves security in several threat scenarios.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3125712971",
    "type": "article"
  },
  {
    "title": "Maat",
    "doi": "https://doi.org/10.1145/3465361",
    "publication_date": "2021-07-19",
    "publication_year": 2021,
    "authors": "Aleieldin Salem; Sebastian Bănescu; Alexander Pretschner",
    "corresponding_authors": "",
    "abstract": "The malware analysis and detection research community relies on the online platform VirusTotal to label Android apps based on the scan results of around 60 antiviral scanners. Unfortunately, there are no standards on how to best interpret the scan results acquired from VirusTotal, which leads to the utilization of different threshold-based labeling strategies (e.g., if 10 or more scanners deem an app malicious, it is considered malicious). While some of the utilized thresholds may be able to accurately approximate the ground truths of apps, the fact that VirusTotal changes the set and versions of the scanners it uses makes such thresholds unsustainable over time. We implemented a method, Maat , that tackles these issues of standardization and sustainability by automatically generating a Machine Learning ( ML )-based labeling scheme, which outperforms threshold-based labeling strategies. Using the VirusTotal scan reports of 53K Android apps that span 1 year, we evaluated the applicability of Maat ’s Machine Learning ( ML )-based labeling strategies by comparing their performance against threshold-based strategies. We found that such ML -based strategies (a) can accurately and consistently label apps based on their VirusTotal scan reports, and (b) contribute to training ML -based detection methods that are more effective at classifying out-of-sample apps than their threshold-based counterparts.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3185024416",
    "type": "article"
  },
  {
    "title": "A Deep Dive Inside DREBIN: An Explorative Analysis beyond Android Malware Detection Scores",
    "doi": "https://doi.org/10.1145/3503463",
    "publication_date": "2022-05-04",
    "publication_year": 2022,
    "authors": "Nadia Daoudi; Kevin Allix; Tegawendé F. Bissyandé; Jacques Klein",
    "corresponding_authors": "",
    "abstract": "Machine learning advances have been extensively explored for implementing large-scale malware detection. When reported in the literature, performance evaluation of machine learning based detectors generally focuses on highlighting the ratio of samples that are correctly or incorrectly classified, overlooking essential questions on why/how the learned models can be demonstrated as reliable. In the Android ecosystem, several recent studies have highlighted how evaluation setups can carry biases related to datasets or evaluation methodologies. Nevertheless, there is little work attempting to dissect the produced model to provide some understanding of its intrinsic characteristics. In this work, we fill this gap by performing a comprehensive analysis of a state-of-the-art Android malware detector, namely DREBIN, which constitutes today a key reference in the literature. Our study mainly targets an in-depth understanding of the classifier characteristics in terms of (1) which features actually matter among the hundreds of thousands that DREBIN extracts, (2) whether the high scores of the classifier are dependent on the dataset age, and (3) whether DREBIN’s explanations are consistent within malware families, among others. Overall, our tentative analysis provides insights into the discriminatory power of the feature set used by DREBIN to detect malware. We expect our findings to bring about a systematisation of knowledge for the community.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W4281293216",
    "type": "article"
  },
  {
    "title": "Hidden in Plain Sight: Exploring Privacy Risks of Mobile Augmented Reality Applications",
    "doi": "https://doi.org/10.1145/3524020",
    "publication_date": "2022-03-18",
    "publication_year": 2022,
    "authors": "Sarah M. Lehman; Abrar S. Alrumayh; Kunal Kolhe; Haibin Ling; Chiu C. Tan",
    "corresponding_authors": "",
    "abstract": "Mobile augmented reality systems are becoming increasingly common and powerful, with applications in such domains as healthcare, manufacturing, education, and more. This rise in popularity is thanks in part to the functionalities offered by commercially available vision libraries such as ARCore, Vuforia, and Google’s ML Kit; however, these libraries also give rise to the possibility of a hidden operations threat , that is, the ability of a malicious or incompetent application developer to conduct additional vision operations behind the scenes of an otherwise honest AR application without alerting the end-user. In this article, we present the privacy risks associated with the hidden operations threat and propose a framework for application development and runtime permissions targeted specifically at preventing the execution of hidden operations. We follow this with a set of experimental results, exploring the feasibility and utility of our system in differentiating between user-expectation-compliant and non-compliant AR applications during runtime testing, for which preliminary results demonstrate accuracy of up to 71%. We conclude with a discussion of open problems in the areas of software testing and privacy standards in mobile AR systems.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4221089815",
    "type": "article"
  },
  {
    "title": "Beyond Gradients: Exploiting Adversarial Priors in Model Inversion Attacks",
    "doi": "https://doi.org/10.1145/3592800",
    "publication_date": "2023-04-24",
    "publication_year": 2023,
    "authors": "Dmitrii Usynin; Daniel Rueckert; Georgios Kaissis",
    "corresponding_authors": "",
    "abstract": "Collaborative machine learning settings such as federated learning can be susceptible to adversarial interference and attacks. One class of such attacks is termed model inversion attacks , characterised by the adversary reverse-engineering the model into disclosing the training data. Previous implementations of this attack typically only rely on the shared data representations, ignoring the adversarial priors, or require that specific layers are present in the target model, reducing the potential attack surface. In this work, we propose a novel context-agnostic model inversion framework that builds on the foundations of gradient-based inversion attacks, but additionally exploits the features and the style of the data controlled by an in-the-network adversary. Our technique outperforms existing gradient-based approaches both qualitatively and quantitatively across all training settings, showing particular effectiveness against the collaborative medical imaging tasks. Finally, we demonstrate that our method achieves significant success on two downstream tasks: sensitive feature inference and facial recognition spoofing.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4366825776",
    "type": "article"
  },
  {
    "title": "VulANalyzeR: Explainable Binary Vulnerability Detection with Multi-task Learning and Attentional Graph Convolution",
    "doi": "https://doi.org/10.1145/3585386",
    "publication_date": "2023-03-03",
    "publication_year": 2023,
    "authors": "Litao Li; Steven H. H. Ding; Yuan Tian; Benjamin C. M. Fung; Philippe Charland; Weihan Ou; Leo Song; Congwei Chen",
    "corresponding_authors": "",
    "abstract": "Software vulnerabilities have been posing tremendous reliability threats to the general public as well as critical infrastructures, and there have been many studies aiming to detect and mitigate software defects at the binary level. Most of the standard practices leverage both static and dynamic analysis, which have several drawbacks like heavy manual workload and high complexity. Existing deep learning-based solutions not only suffer to capture the complex relationships among different variables from raw binary code but also lack the explainability required for humans to verify, evaluate, and patch the detected bugs. We propose VulANalyzeR, a deep learning-based model, for automated binary vulnerability detection, Common Weakness Enumeration-type classification, and root cause analysis to enhance safety and security. VulANalyzeR features sequential and topological learning through recurrent units and graph convolution to simulate how a program is executed. The attention mechanism is integrated throughout the model, which shows how different instructions and the corresponding states contribute to the final classification. It also classifies the specific vulnerability type through multi-task learning as this not only provides further explanation but also allows faster patching for zero-day vulnerabilities. We show that VulANalyzeR achieves better performance for vulnerability detection over the state-of-the-art baselines. Additionally, a Common Vulnerability Exposure dataset is used to evaluate real complex vulnerabilities. We conduct case studies to show that VulANalyzeR is able to accurately identify the instructions and basic blocks that cause the vulnerability even without given any prior knowledge related to the locations during the training phase.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4323042475",
    "type": "article"
  },
  {
    "title": "Detection of Rogue Certificates from Trusted Certificate Authorities Using Deep Neural Networks",
    "doi": "https://doi.org/10.1145/2975591",
    "publication_date": "2016-09-17",
    "publication_year": 2016,
    "authors": "Dong Zheng; Kevin Kane; L. Jean Camp",
    "corresponding_authors": "",
    "abstract": "Rogue certificates are valid certificates issued by a legitimate certificate authority (CA) that are nonetheless untrustworthy; yet trusted by web browsers and users. With the current public key infrastructure, there exists a window of vulnerability between the time a rogue certificate is issued and when it is detected. Rogue certificates from recent compromises have been trusted for as long as weeks before detection and revocation. Previous proposals to close this window of vulnerability require changes in the infrastructure, Internet protocols, or end user experience. We present a method for detecting rogue certificates from trusted CAs developed from a large and timely collection of certificates. This method automates classification by building machine-learning models with Deep Neural Networks (DNN). Despite the scarcity of rogue instances in the dataset, DNN produced a classification method that is proven both in simulation and in the July 2014 compromise of the India CCA. We report the details of the classification method and illustrate that it is repeatable, such as with datasets obtained from crawling. We describe the classification performance under our current research deployment.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2522455971",
    "type": "article"
  },
  {
    "title": "Security Evaluation of a Banking Fraud Analysis System",
    "doi": "https://doi.org/10.1145/3178370",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Michele Carminati; Mario Polino; Andrea Continella; Andrea Lanzi; Federico Maggi; Stefano Zanero",
    "corresponding_authors": "",
    "abstract": "The significant growth of banking fraud, fueled by the underground economy of malware, has raised the need for effective detection systems. Therefore, in the last few years, banks have upgraded their security to protect transactions from fraud. State-of-the-art solutions detect fraud as deviations from customers’ spending habits. To the best of our knowledge, almost all existing approaches do not provide an in-depth model’s granularity and security analysis against elusive attacks. In this article, we examine Banksealer, a decision support system for banking fraud analysis that evaluates the influence on detection performance of the granularity at which spending habits are modeled and its security against evasive attacks. First, we compare user-centric modeling, which builds a model for each user, with system-centric modeling, which builds a model for the entire system, from the point of view of detection performance. Then, we assess the robustness of Banksealer against malicious attackers that are aware of the structure of the models in use. To this end, we design and implement a proof-of-concept attack tool that performs mimicry attacks, emulating a sophisticated attacker that cloaks frauds to avoid detection. We experimentally confirm the feasibility of such attacks, their cost, and the effort required by an attacker in order to perform them. In addition, we discuss possible countermeasures. We provide a comprehensive evaluation on a large real-world dataset obtained from one of the largest Italian banks.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2801308643",
    "type": "article"
  },
  {
    "title": "Quantifying Interdependent Risks in Genomic Privacy",
    "doi": "https://doi.org/10.1145/3035538",
    "publication_date": "2017-02-06",
    "publication_year": 2017,
    "authors": "Mathias Humbert; Erman Ayday; Jean‐Pierre Hubaux; Amalio Telenti",
    "corresponding_authors": "",
    "abstract": "The rapid progress in human-genome sequencing is leading to a high availability of genomic data. These data is notoriously very sensitive and stable in time, and highly correlated among relatives. In this article, we study the implications of these familial correlations on kin genomic privacy. We formalize the problem and detail efficient reconstruction attacks based on graphical models and belief propagation. With our approach, an attacker can infer the genomes of the relatives of an individual whose genome or phenotype are observed by notably relying on Mendel’s Laws, statistical relationships between the genomic variants, and between the genome and the phenotype. We evaluate the effect of these dependencies on privacy with respect to the amount of observed variants and the relatives sharing them. We also study how the algorithmic performance evolves when we take these various relationships into account. Furthermore, to quantify the level of genomic privacy as a result of the proposed inference attack, we discuss possible definitions of genomic privacy metrics, and compare their values and evolution. Genomic data reveals Mendelian disorders and the likelihood of developing severe diseases, such as Alzheimer’s. We also introduce the quantification of health privacy , specifically, the measure of how well the predisposition to a disease is concealed from an attacker. We evaluate our approach on actual genomic data from a pedigree and show the threat extent by combining data gathered from a genome-sharing website as well as an online social network.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2586154897",
    "type": "article"
  },
  {
    "title": "Introducing the Temporal Dimension to Memory Forensics",
    "doi": "https://doi.org/10.1145/3310355",
    "publication_date": "2019-03-18",
    "publication_year": 2019,
    "authors": "Fabio Pagani; Oleksii Fedorov; Davide Balzarotti",
    "corresponding_authors": "",
    "abstract": "Kickstarted by the Digital Forensic Research Workshop (DFRWS) conference in 2005, modern memory analysis is now one of most active areas of computer forensics and it mostly focuses on techniques to locate key operating system data structures and extract high-level information. These techniques work on the assumption that the information inside a memory dump is consistent and the copy of the physical memory was obtained in an atomic operation. Unfortunately, this is seldom the case in real investigations, where software acquisition tools record information while the rest of the system is running. Thus, since the content of the memory is changing very rapidly, the resulting memory dump may contain inconsistent data. While this problem is known, its consequences are unclear and often overlooked. Unfortunately, errors can be very subtle and can affect the results of an analysis in ways that are difficult to detect. In this article, we argue that memory forensics should also consider the time in which each piece of data was acquired. This new temporal dimension provides a preliminary way to assess the reliability of a given result and opens the door to new research directions that can minimize the effect of the acquisition time or detect inconsistencies. To support our hypothesis, we conducted several experiments to show that inconsistencies are very frequent and can negatively impact an analysis. We then discuss modifications we made to popular memory forensic tools to make the temporal dimension explicit during the analysis and to minimize its effect by resorting to a locality-based acquisition.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2923208273",
    "type": "article"
  },
  {
    "title": "On the Security of Smartphone Unlock PINs",
    "doi": "https://doi.org/10.1145/3473040",
    "publication_date": "2021-09-30",
    "publication_year": 2021,
    "authors": "Philipp Markert; Daniel V. Bailey; Maximilian Golla; Markus Dürmuth; Adam J. Aviv",
    "corresponding_authors": "",
    "abstract": "In this article, we provide the first comprehensive study of user-chosen four- and six-digit PINs ( n =1705) collected on smartphones with participants being explicitly primed for device unlocking. We find that against a throttled attacker (with 10, 30, or 100 guesses, matching the smartphone unlock setting), using six-digit PINs instead of four-digit PINs provides little to no increase in security and surprisingly may even decrease security. We also study the effects of blocklists, where a set of “easy to guess” PINs is disallowed during selection. Two such blocklists are in use today by iOS, for four digits (274 PINs) as well as six digits (2,910 PINs). We extracted both blocklists and compared them with six other blocklists, three for each PIN length. In each case, we had a small (four-digit: 27 PINs; six-digit: 29 PINs), a large (four-digit: 2,740 PINs; six-digit: 291,000 PINs), and a placebo blocklist that always excluded the first-choice PIN. For four-digit PINs, we find that the relatively small blocklist in use today by iOS offers little to no benefit against a throttled guessing attack. Security gains are only observed when the blocklist is much larger. In the six-digit case, we were able to reach a similar security level with a smaller blocklist. As the user frustration increases with the blocklists size, developers should employ a blocklist that is as small as possible while ensuring the desired security. Based on our analysis, we recommend that for four-digit PINs a blocklist should contain the 1,000 most popular PINs to provide the best balance between usability and security and for six-digit PINs the 2,000 most popular PINs should be blocked.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3204765815",
    "type": "article"
  },
  {
    "title": "Dealing with Security Alert Flooding: Using Machine Learning for Domain-independent Alert Aggregation",
    "doi": "https://doi.org/10.1145/3510581",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Max Landauer; Florian Skopik; Markus Wurzenberger; Andreas Rauber",
    "corresponding_authors": "",
    "abstract": "Intrusion Detection Systems (IDS) secure all kinds of IT infrastructures through automatic detection of malicious activities. Unfortunately, they are known to produce large numbers of alerts that often become overwhelming for manual analysis. Therefore, aggregation methods have been developed for filtering, grouping, and correlating alerts. However, existing techniques either rely on manually defined attack scenarios or require specific alert formats, such as IDMEF that include IP addresses. This makes the application of existing aggregation methods infeasible for alerts from host-based or anomaly-based IDSs that frequently lack such network-related data. In this paper, we therefore present a domain-independent alert aggregation technique. We introduce similarity measures and merging strategies for arbitrary semi-structured alerts and alert groups. Based on these metrics and techniques we propose an incremental procedure for the generation of abstract alert patterns that enable continuous classification of incoming alerts. Evaluations show that our approach is capable of reducing the number of alert groups for human review by around \\( 80\\% \\) and assigning attack classifiers to the groups with true positive rates of \\( 80\\% \\) and false positive rates lower than \\( 5\\% \\) .",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4220983750",
    "type": "article"
  },
  {
    "title": "Generating Quality Threat Intelligence Leveraging OSINT and a Cyber Threat Unified Taxonomy",
    "doi": "https://doi.org/10.1145/3530977",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Cláudio Martins; Ibéria Medeiros",
    "corresponding_authors": "",
    "abstract": "Today’s threats use multiple means of propagation, such as social engineering, email, and application vulnerabilities, and often operate in different phases, such as single device compromise, lateral network movement, and data exfiltration. These complex threats rely on advanced persistent threats supported by well-advanced tactics for appearing unknown to traditional security defenses. As organizations realize that attacks are increasing in size and complexity, cyber threat intelligence (TI) is growing in popularity and use. This trend followed the evolution of advanced persistent threats, as they require a different level of response that is more specific to the organization. TI can be obtained via many formats, with open-source intelligence one of the most common, and using threat intelligence platforms (TIPs) that aid organizations to consume, produce, and share TI. TIPs have multiple advantages that enable organizations to quickly bootstrap the core processes of collecting, analyzing, and sharing threat-related information. However, current TIPs have some limitations that prevent their mass adoption. This article proposes AECCP, a platform that addresses some of the TIPs limitations. AECCP improves quality TI by classifying it accordingly a single unified taxonomy , removing the information with low value, enriching it with valuable information from open-source intelligence sources, and aggregating it for complementing information associated with the same threat. AECCP was validated and evaluated with three datasets of events and compared with two other platforms, showing that it can generate quality TI automatically and help security analysts analyze security incidents in less time.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4280596655",
    "type": "article"
  },
  {
    "title": "Security Best Practices: A Critical Analysis Using IoT as a Case Study",
    "doi": "https://doi.org/10.1145/3563392",
    "publication_date": "2022-09-15",
    "publication_year": 2022,
    "authors": "David Barrera; Christopher Bellman; Paul C. van Oorschot",
    "corresponding_authors": "",
    "abstract": "Academic research has highlighted the failure of many Internet of Things (IoT) product manufacturers to follow accepted practices, while IoT security best practices have recently attracted considerable attention worldwide from industry and governments. Given current examples of security advice, confusion is evident from guidelines that conflate desired outcomes with security practices to achieve those outcomes. We explore a surprising lack of clarity, and void in the literature, on what (generically) best practice means, independent of identifying specific individual practices or highlighting failure to follow best practices. We consider categories of security advice, and analyze how they apply over the lifecycle of IoT devices. For concreteness in discussion, we use iterative inductive coding to code and systematically analyze a set of 1,013 IoT security best practices, recommendations, and guidelines collated from industrial, government, and academic sources. Among our findings, of all analyzed items, 68% fail to meet our definition of an (actionable) practice, and 73% of all actionable advice relates to the software development lifecycle phase, highlighting the critical position of manufacturers and developers. We hope that our work provides a basis for the community to better understand best practices, identify and reach consensus on specific practices, and find ways to motivate relevant stakeholders to follow them.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4296132168",
    "type": "article"
  },
  {
    "title": "Combining Cyber Security Intelligence to Refine Automotive Cyber Threats",
    "doi": "https://doi.org/10.1145/3644075",
    "publication_date": "2024-02-05",
    "publication_year": 2024,
    "authors": "Florian Sommer; Mona Gierl; Reiner Kriesten; Frank Kargl; Eric Sax",
    "corresponding_authors": "",
    "abstract": "Modern vehicles increasingly rely on electronics, software, and communication technologies (cyber space) to perform their driving task. Over-The-Air (OTA) connectivity further extends the cyber space by creating remote access entry points. Accordingly, the vehicle is exposed to security attacks that are able to impact road safety. A profound understanding of security attacks, vulnerabilities, and mitigations is necessary to protect vehicles against cyber threats. While automotive threat descriptions, such as in UN R155, are still abstract, this creates a risk that potential vulnerabilities are overlooked and the vehicle is not secured against them. So far, there is no common understanding of the relationship of automotive attacks, the concrete vulnerabilities they exploit, and security mechanisms that would protect the system against these attacks. In this article, we aim at closing this gap by creating a mapping between UN R155, Microsoft STRIDE classification, Common Attack Pattern Enumeration and Classification (CAPEC), and Common Weakness Enumeration (CWE). In this way, already existing detailed knowledge of attacks, vulnerabilities, and mitigations is combined and linked to the automotive domain. In practice, this refines the list of UN R155 threats and therefore supports vehicle manufacturers, suppliers, and approval authorities to meet and assess the requirements for vehicle development in terms of cybersecurity. Overall, 204 mappings between UN threats, STRIDE, CAPEC attack patterns, and CWE weaknesses were created. We validated these mappings by applying our Automotive Attack Database (AAD) that consists of 361 real-world attacks on vehicles. Furthermore, 25 additional attack patterns were defined based on automotive-related attacks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4391540423",
    "type": "article"
  },
  {
    "title": "A Decentralized Private Data Marketplace using Blockchain and Secure Multi-Party Computation",
    "doi": "https://doi.org/10.1145/3652162",
    "publication_date": "2024-03-16",
    "publication_year": 2024,
    "authors": "Julen Bernabé-Rodríguez; Albert Garreta; Óscar Lage",
    "corresponding_authors": "",
    "abstract": "Big data has proven to be a very useful tool for companies and users, but companies with larger datasets have ended being more competitive than the others thanks to machine learning or artificial intelligence. Secure multi-party computation (SMPC) allows the smaller companies to jointly train arbitrary models on their private data while assuring privacy, and thus gives data owners the ability to perform what are currently known as federated learning algorithms. Besides, with a blockchain it is possible to coordinate and audit those computations in a decentralized way. In this document, we consider a private data marketplace as a space where researchers and data owners meet to agree the use of private data for statistics or more complex model trainings. This document presents a candidate architecure for a private data marketplace by combining SMPC and a public, general-purpose blockchain. Such a marketplace is proposed as a smart contract deployed in the blockchain, while the privacy preserving computation is held by SMPC.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4392885488",
    "type": "article"
  },
  {
    "title": "Backdoor Attacks in Peer-to-Peer Federated Learning",
    "doi": "https://doi.org/10.1145/3691633",
    "publication_date": "2024-10-22",
    "publication_year": 2024,
    "authors": "Georgios Syros; Gökberk Yar; Simona Boboila; Cristina Nita-Rotaru; Alina Oprea",
    "corresponding_authors": "",
    "abstract": "Most machine learning applications rely on centralized learning processes, opening up the risk of exposure of their training datasets. While federated learning (FL) mitigates to some extent these privacy risks, it relies on a trusted aggregation server for training a shared global model. Recently, new distributed learning architectures based on Peer-to-Peer Federated Learning (P2PFL) offer advantages in terms of both privacy and reliability. Still, their resilience to poisoning attacks during training has not been investigated. In this paper, we propose new backdoor attacks for P2PFL that leverage structural graph properties to select the malicious nodes, and achieve high attack success, while remaining stealthy. We evaluate our attacks under various realistic conditions, including multiple graph topologies, limited adversarial visibility of the network, and clients with non-IID data. Finally, we show the limitations of existing defenses adapted from FL and design a new defense that successfully mitigates the backdoor attacks, without an impact on model accuracy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4403619386",
    "type": "article"
  },
  {
    "title": "Level Up with ML Vulnerability Identification: Leveraging Domain Constraints in Feature Space for Robust Android Malware Detection",
    "doi": "https://doi.org/10.1145/3711899",
    "publication_date": "2025-01-13",
    "publication_year": 2025,
    "authors": "Hamid Bostani; Zhengyu Zhao; Zhuoran Liu; Veelasha Moonsamy",
    "corresponding_authors": "",
    "abstract": "Machine Learning (ML) promises to enhance the efficacy of Android Malware Detection (AMD); however, ML models are vulnerable to realistic evasion attacks—crafting realizable Adversarial Examples (AEs) that satisfy Android malware domain constraints. To eliminate ML vulnerabilities, defenders aim to identify susceptible regions in the feature space where ML models are prone to deception. The primary approach to identifying vulnerable regions involves investigating realizable AEs, but generating these feasible apps poses a challenge. For instance, previous work has relied on generating either feature-space norm-bounded AEs or problem-space realizable AEs in adversarial hardening. The former is efficient but lacks full coverage of vulnerable regions while the latter can uncover these regions by satisfying domain constraints but is known to be time-consuming. To address these limitations, we propose an approach to facilitate the identification of vulnerable regions. Specifically, we introduce a new interpretation of Android domain constraints in the feature space, followed by a novel technique that learns them. Our empirical evaluations across various evasion attacks indicate effective detection of AEs using learned domain constraints, with an average of 89.6%. Furthermore, extensive experiments on different Android malware detectors demonstrate that utilizing our learned domain constraints in Adversarial Training (AT) outperforms other AT-based defenses that rely on norm-bounded AEs or state-of-the-art non-uniform perturbations. Finally, we show that retraining a malware detector with a wide variety of feature-space realizable AEs results in a 77.9% robustness improvement against realizable AEs generated by unknown problem-space transformations, with up to 70 × faster training than using problem-space realizable AEs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406302397",
    "type": "article"
  },
  {
    "title": "ZT-SDN: An ML-Powered Zero-Trust Architecture for Software-Defined Networks",
    "doi": "https://doi.org/10.1145/3712262",
    "publication_date": "2025-01-15",
    "publication_year": 2025,
    "authors": "Charalampos Katsis; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "Zero Trust (ZT) is a security paradigm aiming to curtail an attacker’s lateral movements within a network by implementing least-privilege and per-request access control policies. However, its widespread adoption is hindered by the difficulty of generating proper rules due to the lack of detailed knowledge of communication requirements and the characteristic behaviors of communicating entities under benign conditions. Consequently, manual rule generation becomes cumbersome and error-prone. To address these problems, we propose ZT-SDN , an automated framework for learning and enforcing network access control in Software-Defined Networks. ZT-SDN collects data from the underlying network and models the network “transactions’’ performed by communicating entities as graphs. The nodes represent entities, while the directed edges represent transactions identified by different protocol stacks observed. It uses novel unsupervised learning approaches to extract transaction patterns directly from the network data, such as the allowed protocol stacks and port numbers and data transmission behavior. Finally, ZT-SDN uses an innovative approach to generate correct access control rules and infer strong associations between them, allowing proactive rule deployment in forwarding devices. We show the framework’s efficacy in detecting abnormal network accesses and abuses of permitted flows in changing network conditions with real network datasets. Additionally, we showcase ZT-SDN’s scalability and the network’s performance when applied in an SDN environment.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406418707",
    "type": "article"
  },
  {
    "title": "Intriguing Properties of Adversarial ML Attacks in the Problem Space [Extended Version]",
    "doi": "https://doi.org/10.1145/3742895",
    "publication_date": "2025-06-21",
    "publication_year": 2025,
    "authors": "Jacopo Cortellazzi; Erwin Quiring; Daniel J. Arp; Feargus Pendlebury; Fabio Pierazzi; Lorenzo Cavallaro",
    "corresponding_authors": "",
    "abstract": "Recent research efforts on adversarial machine learning (ML) have investigated problem-space attacks, focusing on the generation of real evasive objects in domains where, unlike images, there is no clear inverse mapping to the feature space (e.g., software). However, the design, comparison, and real-world implications of problem-space attacks remain underexplored. This article makes three major contributions. Firstly, we propose a general formalization for adversarial ML evasion attacks in the problem-space, which includes the definition of a comprehensive set of constraints on available transformations, preserved semantics, absent artifacts, and plausibility. We shed light on the relationship between feature space and problem space, and we introduce the concept of side-effect features as the by-product of the inverse feature-mapping problem. This enables us to define and prove necessary and sufficient conditions for the existence of problem-space attacks. Secondly, building on our general formalization, we propose a novel problem-space attack on Android malware that overcomes past limitations in terms of semantics and artifacts. We have tested our approach on a dataset with 150K Android apps from 2016 and 2018 which show the practical feasibility of evading a state-of-the-art malware classifier along with its hardened version. Thirdly, we explore the effectiveness of adversarial training as a possible approach to enforce robustness against adversarial samples, evaluating its effectiveness on the considered machine learning models under different scenarios. Our results demonstrate that “adversarial-malware as a service’’ is a realistic threat, as we automatically generate thousands of realistic and inconspicuous adversarial applications at scale, where on average it takes only a few minutes to generate an adversarial instance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411505063",
    "type": "article"
  },
  {
    "title": "Efficient and Accurate Behavior-Based Tracking of Malware-Control Domains in Large ISP Networks",
    "doi": "https://doi.org/10.1145/2960409",
    "publication_date": "2016-08-17",
    "publication_year": 2016,
    "authors": "Babak Rahbarinia; Roberto Perdisci; Manos Antonakakis",
    "corresponding_authors": "",
    "abstract": "In this article, we propose Segugio , a novel defense system that allows for efficiently tracking the occurrence of new malware-control domain names in very large ISP networks. Segugio passively monitors the DNS traffic to build a machine-domain bipartite graph representing who is querying what . After labeling nodes in this query behavior graph that are known to be either benign or malware-related, we propose a novel approach to accurately detect previously unknown malware-control domains. We implemented a proof-of-concept version of Segugio and deployed it in large ISP networks that serve millions of users. Our experimental results show that Segugio can track the occurrence of new malware-control domains with up to 94% true positives (TPs) at less than 0.1% false positives (FPs). In addition, we provide the following results: (1) we show that Segugio can also detect control domains related to new, previously unseen malware families, with 85% TPs at 0.1% FPs; (2) Segugio’s detection models learned on traffic from a given ISP network can be deployed into a different ISP network and still achieve very high detection accuracy; (3) new malware-control domains can be detected days or even weeks before they appear in a large commercial domain-name blacklist; (4) Segugio can be used to detect previously unknown malware-infected machines in ISP networks; and (5) we show that Segugio clearly outperforms domain-reputation systems based on Belief Propagation.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2509891819",
    "type": "article"
  },
  {
    "title": "Looks Like Eve",
    "doi": "https://doi.org/10.1145/2904018",
    "publication_date": "2016-06-16",
    "publication_year": 2016,
    "authors": "Simon Eberz; Kasper Rasmussen; Vincent Lenders; Ivan Martinović",
    "corresponding_authors": "",
    "abstract": "We introduce a novel biometric based on distinctive eye movement patterns. The biometric consists of 20 features that allow us to reliably distinguish users based on differences in these patterns. We leverage this distinguishing power along with the ability to gauge the users’ task familiarity, that is, level of knowledge, to address insider threats. In a controlled experiment, we test how both time and task familiarity influence eye movements and feature stability, and how different subsets of features affect the classifier performance. These feature subsets can be used to tailor the eye movement biometric to different authentication methods and threat models. Our results show that eye movement biometrics support reliable and stable continuous authentication of users. We investigate different approaches in which an attacker could attempt to use inside knowledge to mimic the legitimate user. Our results show that while this advance knowledge is measurable, it does not increase the likelihood of successful impersonation. In order to determine the time stability of our features, we repeat the experiment twice within 2 weeks. The results indicate that we can reliably authenticate users over the entire period. We show that lower sampling rates provided by low-cost hardware pose a challenge, but that reliable authentication is possible even at the rate of 50Hz commonly available with consumer-level devices. In a second set of experiments, we evaluate how our authentication system performs across a variety of real-world tasks, including reading, writing, and web browsing. We discuss the advantages and limitations of our approach in detail and give practical insights on the use of this biometric in a real-world environment.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2423693064",
    "type": "article"
  },
  {
    "title": "SoK: A Modularized Approach to Study the Security of Automatic Speech Recognition Systems",
    "doi": "https://doi.org/10.1145/3510582",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Yuxuan Chen; Jiangshan Zhang; Xuejing Yuan; Shengzhi Zhang; Kai Chen; Xiaofeng Wang; Shanqing Guo",
    "corresponding_authors": "",
    "abstract": "With the wide use of Automatic Speech Recognition (ASR) in applications such as human machine interaction, simultaneous interpretation, audio transcription, and so on, its security protection becomes increasingly important. Although recent studies have brought to light the weaknesses of popular ASR systems that enable out-of-band signal attack, adversarial attack, and so on, and further proposed various remedies (signal smoothing, adversarial training, etc.), a systematic understanding of ASR security (both attacks and defenses) is still missing, especially on how realistic such threats are and how general existing protection could be. In this article, we present our systematization of knowledge for ASR security and provide a comprehensive taxonomy for existing work based on a modularized workflow. More importantly, we align the research in this domain with that on security in Image Recognition System (IRS), which has been extensively studied, using the domain knowledge in the latter to help understand where we stand in the former. Generally, both IRS and ASR are perceptual systems. Their similarities allow us to systematically study existing literature in ASR security based on the spectrum of attacks and defense solutions proposed for IRS, and pinpoint the directions of more advanced attacks and the directions potentially leading to more effective protection in ASR. In contrast, their differences, especially the complexity of ASR compared with IRS, help us learn unique challenges and opportunities in ASR security. Particularly, our experimental study shows that transfer attacks across ASR models are feasible, even in the absence of knowledge about models (even their types) and training data.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3137766544",
    "type": "article"
  },
  {
    "title": "Evaluating the Strength of Genomic Privacy Metrics",
    "doi": "https://doi.org/10.1145/3020003",
    "publication_date": "2017-01-09",
    "publication_year": 2017,
    "authors": "Isabel Wagner",
    "corresponding_authors": "Isabel Wagner",
    "abstract": "The genome is a unique identifier for human individuals. The genome also contains highly sensitive information, creating a high potential for misuse of genomic data (for example, genetic discrimination). In this paper, I investigated how genomic privacy can be measured in scenarios where an adversary aims to infer a person's genomic markers by constructing probability distributions on the values of genetic variations. I measured the strength of privacy metrics by requiring that metrics are monotonic with increasing adversary strength and uncovered serious problems with several existing metrics currently used to measure genomic privacy. I provide suggestions on metric selection, interpretation, and visualization, and illustrate the work flow using a case study on Alzheimer's disease.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3123606170",
    "type": "article"
  },
  {
    "title": "Data Usage Control for Distributed Systems",
    "doi": "https://doi.org/10.1145/3183342",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Florian Kelbert; Alexander Pretschner",
    "corresponding_authors": "",
    "abstract": "Data usage control enables data owners to enforce policies over how their data may be used after they have been released and accessed. We address distributed aspects of this problem, which arise if the protected data reside within multiple systems. We contribute by formalizing, implementing, and evaluating a fully decentralized system that (i) generically and transparently tracks protected data across systems, (ii) propagates data usage policies along, and (iii) efficiently and preventively enforces policies in a decentralized manner. The evaluation shows that (i) dataflow tracking and policy propagation achieve a throughput of 21--54% of native execution and (ii) decentralized policy enforcement outperforms a centralized approach in many situations.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2751779988",
    "type": "article"
  },
  {
    "title": "Pareto Optimal Security Resource Allocation for Internet of Things",
    "doi": "https://doi.org/10.1145/3139293",
    "publication_date": "2017-10-24",
    "publication_year": 2017,
    "authors": "Antonino Rullo; Daniele Midi; Edoardo Serra; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "In many Internet of Thing (IoT) application domains security is a critical requirement, because malicious parties can undermine the effectiveness of IoT-based systems by compromising single components and/or communication channels. Thus, a security infrastructure is needed to ensure the proper functioning of such systems even under attack. However, it is also critical that security be at a reasonable resource and energy cost. In this article, we focus on the problem of efficiently and effectively securing IoT networks by carefully allocating security resources in the network area. In particular, given a set of security resources R and a set of attacks to be faced A , our method chooses the subset of R that best addresses the attacks in A , and the set of locations where to place them, that ensure the security coverage of all IoT devices at minimum cost and energy consumption. We model our problem according to game theory and provide a Pareto-optimal solution in which the cost of the security infrastructure, its energy consumption, and the probability of a successful attack are minimized. Our experimental evaluation shows that our technique improves the system robustness in terms of packet delivery rate for different network topologies. Furthermore, we also provide a method for handling the computation of the resource allocation plan for large-scale networks scenarios, where the optimization problem may require an unreasonable amount of time to be solved. We show how our proposed method drastically reduces the computing time, while providing a reasonable approximation of the optimal solution.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2766954398",
    "type": "article"
  },
  {
    "title": "Handling Anti-Virtual Machine Techniques in Malicious Software",
    "doi": "https://doi.org/10.1145/3139292",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Hao Shi; Jelena Mirković; Abdulla Alwabel",
    "corresponding_authors": "",
    "abstract": "Malware analysis relies heavily on the use of virtual machines (VMs) for functionality and safety. There are subtle differences in operation between virtual and physical machines. Contemporary malware checks for these differences and changes its behavior when it detects a VM presence. These anti-VM techniques hinder malware analysis. Existing research approaches to uncover differences between VMs and physical machines use randomized testing, and thus cannot guarantee completeness. In this article, we propose a detect-and-hide approach, which systematically addresses anti-VM techniques in malware. First, we propose cardinal pill testing —a modification of red pill testing that aims to enumerate the differences between a given VM and a physical machine through carefully designed tests. Cardinal pill testing finds five times more pills by running 15 times fewer tests than red pill testing. We examine the causes of pills and find that, while the majority of them stem from the failure of VMs to follow CPU specifications, a small number stem from under-specification of certain instructions by the Intel manual. This leads to divergent implementations in different CPU and VM architectures. Cardinal pill testing successfully enumerates the differences that stem from the first cause. Finally, we propose VM Cloak —a WinDbg plug-in which hides the presence of VMs from malware. VM Cloak monitors each execute malware command, detects potential pills, and at runtime modifies the command’s outcomes to match those that a physical machine would generate. We implemented VM Cloak and verified that it successfully hides VM presence from malware.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2773100910",
    "type": "article"
  },
  {
    "title": "Technological and Human Factors of Malware Attacks",
    "doi": "https://doi.org/10.1145/3210311",
    "publication_date": "2018-07-12",
    "publication_year": 2018,
    "authors": "Fanny Lalonde Lévesque; Sonia Chiasson; Anil Somayaji; José M. Fernandez",
    "corresponding_authors": "",
    "abstract": "The success (or failure) of malware attacks depends upon both technological and human factors. The most security-conscious users are susceptible to unknown vulnerabilities, and even the best security mechanisms can be circumvented as a result of user actions. Although there has been significant research on the technical aspects of malware attacks and defence, there has been much less research on how users interact with both malware and current malware defences. This article describes a field study designed to examine the interactions between users, antivirus (AV) software, and malware as they occur on deployed systems. In a fashion similar to medical studies that evaluate the efficacy of a particular treatment, our experiment aimed to assess the performance of AV software and the human risk factors of malware attacks. The 4-month study involved 50 home users who agreed to use laptops that were instrumented to monitor for possible malware attacks and gather data on user behaviour. This study provided some very interesting, non-intuitive insights into the efficacy of AV software and human risk factors. AV performance was found to be lower under real-life conditions compared to tests conducted in controlled conditions. Moreover, computer expertise, volume of network usage, and peer-to-peer activity were found to be significant correlates of malware attacks. We assert that this work shows the viability and the merits of evaluating security products, techniques, and strategies to protect systems through long-term field studies with greater ecological validity than can be achieved through other means.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2883457276",
    "type": "article"
  },
  {
    "title": "Measuring, Characterizing, and Detecting Facebook Like Farms",
    "doi": "https://doi.org/10.1145/3121134",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Muhammad Ikram; Lucky Onwuzurike; Shehroze Farooqi; Emiliano De Cristofaro; Arik Friedman; Guillaume Jourjon; Mohamed Ali Kâafar; Muhammad Shafiq",
    "corresponding_authors": "",
    "abstract": "Online social networks offer convenient ways to reach out to large audiences. In particular, Facebook pages are increasingly used by businesses, brands, and organizations to connect with multitudes of users worldwide. As the number of likes of a page has become a de-facto measure of its popularity and profitability, an underground market of services artificially inflating page likes (“like farms ”) has emerged alongside Facebook’s official targeted advertising platform. Nonetheless, besides a few media reports, there is little work that systematically analyzes Facebook pages’ promotion methods. Aiming to fill this gap, we present a honeypot-based comparative measurement study of page likes garnered via Facebook advertising and from popular like farms. First, we analyze likes based on demographic, temporal, and social characteristics and find that some farms seem to be operated by bots and do not really try to hide the nature of their operations, while others follow a stealthier approach, mimicking regular users’ behavior. Next, we look at fraud detection algorithms currently deployed by Facebook and show that they do not work well to detect stealthy farms that spread likes over longer timespans and like popular pages to mimic regular users. To overcome their limitations, we investigate the feasibility of timeline-based detection of like farm accounts, focusing on characterizing content generated by Facebook accounts on their timelines as an indicator of genuine versus fake social activity. We analyze a wide range of features extracted from timeline posts, which we group into two main categories: lexical and non-lexical. We find that like farm accounts tend to re-share content more often, use fewer words and poorer vocabulary, and more often generate duplicate comments and likes compared to normal users. Using relevant lexical and non-lexical features, we build a classifier to detect like farms accounts that achieves a precision higher than 99% and a 93% recall.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2727710601",
    "type": "article"
  },
  {
    "title": "Abstract Non-Interference",
    "doi": "https://doi.org/10.1145/3175660",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Roberto Giacobazzi; Isabella Mastroeni",
    "corresponding_authors": "",
    "abstract": "Non-interference happens when some elements of a dynamic system do not interfere, i.e., do not affect, other elements in the same system. Originally introduced in language-based security, non-interference means that the manipulation of private information has no effect on public observations of data. In this article, we introduce abstract non-interference as a weakening of non-interference by abstract interpretation. Abstract non-interference is parametric on which private information we want to protect and which are the observational capabilities of the external observer, i.e., what the attacker can observe of a computation and of the data manipulated during the computation. This allows us to model a variety of situations in information-flow security, where the security of a system can be mastered by controlling the degree of precision of the strongest harmless attacker and the properties that are potentially leaked in case of successful attack.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2785627758",
    "type": "article"
  },
  {
    "title": "Resilient Privacy Protection for Location-Based Services through Decentralization",
    "doi": "https://doi.org/10.1145/3319401",
    "publication_date": "2019-09-25",
    "publication_year": 2019,
    "authors": "Hongyu Jin; Panos Papadimitratos",
    "corresponding_authors": "",
    "abstract": "Location-Based Services (LBSs) provide valuable services, with convenient features for mobile users. However, the location and other information disclosed through each query to the LBS erodes user privacy. This is a concern especially because LBS providers can be honest-but-curious , collecting queries and tracking users’ whereabouts and infer sensitive user data. This motivated both centralized and decentralized location privacy protection schemes for LBSs: anonymizing and obfuscating LBS queries to not disclose exact information, while still getting useful responses. Decentralized schemes overcome disadvantages of centralized schemes, eliminating anonymizers, and enhancing users’ control over sensitive information. However, an insecure decentralized system could create serious risks beyond private information leakage. More so, attacking an improperly designed decentralized LBS privacy protection scheme could be an effective and low-cost step to breach user privacy. We address exactly this problem, by proposing security enhancements for mobile data sharing systems. We protect user privacy while preserving accountability of user activities, leveraging pseudonymous authentication with mainstream cryptography. We show our scheme can be deployed with off-the-shelf devices based on an experimental evaluation of an implementation in a static automotive testbed.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3124600629",
    "type": "article"
  },
  {
    "title": "A <scp>Solicitous</scp> Approach to Smart Contract Verification",
    "doi": "https://doi.org/10.1145/3564699",
    "publication_date": "2022-09-28",
    "publication_year": 2022,
    "authors": "Rodrigo Otoni; Matteo Marescotti; Leonardo Alt; Patrick Eugster; Antti E. J. Hyvärinen; Natasha Sharygina",
    "corresponding_authors": "",
    "abstract": "Smart contracts are tempting targets of attacks, as they often hold and manipulate significant financial assets, are immutable after deployment, and have publicly available source code, with assets estimated in the order of millions of dollars being lost in the past due to vulnerabilities. Formal verification is thus a necessity, but smart contracts challenge the existing highly efficient techniques routinely applied in the symbolic verification of software, due to specificities not present in general programming languages. A common feature of existing works in this area is the attempt to reuse off-the-shelf verification tools designed for general programming languages. This reuse can lead to inefficiency and potentially unsound results, as domain translation is required. In this article, we describe a carefully crafted approach that directly models the central aspects of smart contracts natively, going from the contract to its logical representation without intermediary steps. We use the expressive and highly automatable logic of constrained Horn clauses for modeling and instantiate our approach to the Solidity language. A tool implementing our approach, called Solicitous , was developed and integrated into the SMTChecker module of the Solidity compiler solc. We evaluated our approach on an extensive benchmark set containing 22,446 real-world smart contracts deployed on the Ethereum blockchain over a 27-month period. The results show that our approach is able to establish safety of significantly more contracts than comparable, publicly available verification tools, with an order of magnitude increase in the percentage of formally verified contracts.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4297493117",
    "type": "article"
  },
  {
    "title": "RansomShield: A Visualization Approach to Defending Mobile Systems Against Ransomware",
    "doi": "https://doi.org/10.1145/3579822",
    "publication_date": "2023-01-17",
    "publication_year": 2023,
    "authors": "Nada Lachtar; Duha Ibdah; Hamza Khan; Anys Bacha",
    "corresponding_authors": "",
    "abstract": "The unprecedented growth in mobile systems has transformed the way we approach everyday computing. Unfortunately, the emergence of a sophisticated type of malware known as ransomware poses a great threat to consumers of this technology. Traditional research on mobile malware detection has focused on approaches that rely on analyzing bytecode for uncovering malicious apps. However, cybercriminals can bypass such methods by embedding malware directly in native machine code, making traditional methods inadequate. Another challenge that detection solutions face is scalability. The sheer number of malware variants released every year makes it difficult for solutions to efficiently scale their coverage. To address these concerns, this work presents RansomShield, an energy-efficient solution that leverages CNNs to detect ransomware. We evaluate CNN architectures that have been known to perform well on computer vision tasks and examine their suitability for ransomware detection. We show that systematically converting native instructions from Android apps into images using space-filling curve visualization techniques enable CNNs to reliably detect ransomware with high accuracy. We characterize the robustness of this approach across ARM and x86 architectures and demonstrate the effectiveness of this solution across heterogeneous platforms including smartphones and chromebooks. We evaluate the suitability of different models for mobile systems by comparing their energy demands using different platforms. In addition, we present a CNN introspection framework that determines the important features that are needed for ransomware detection. Finally, we evaluate the robustness of this solution against adversarial machine learning (AML) attacks using state-of-the-art Android malware dataset.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4316813679",
    "type": "article"
  },
  {
    "title": "Performance and Usability Evaluation of Brainwave Authentication Techniques with Consumer Devices",
    "doi": "https://doi.org/10.1145/3579356",
    "publication_date": "2023-01-18",
    "publication_year": 2023,
    "authors": "Patricia Arias-Cabarcos; Matin Fallahi; Thilo Habrich; Karen Schulze; Christian Becker; Thorsten Strufe",
    "corresponding_authors": "",
    "abstract": "Brainwaves have demonstrated to be unique enough across individuals to be useful as biometrics. They also provide promising advantages over traditional means of authentication, such as resistance to external observability, revocability, and intrinsic liveness detection. However, most of the research so far has been conducted with expensive, bulky, medical-grade helmets, which offer limited applicability for everyday usage. With the aim to bring brainwave authentication and its benefits closer to real world deployment, we investigate brain biometrics with consumer devices. We conduct a comprehensive measurement experiment and user study that compare five authentication tasks on a user sample up to 10 times larger than those from previous studies, introducing three novel techniques based on cognitive semantic processing. Furthermore, we apply our analysis on high-quality open brainwave data obtained with a medical-grade headset, to assess the differences. We investigate both the performance, security, and usability of the different options and use this evidence to elicit design and research recommendations. Our results show that it is possible to achieve Equal Error Rates as low as 7.2% (a reduction between 68–72% with respect to existing approaches) based on brain responses to images with current inexpensive technology. We show that the common practice of testing authentication systems only with known attacker data is unrealistic and may lead to overly optimistic evaluations. With regard to adoption, users call for simpler devices, faster authentication, and better privacy.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4317209693",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Decentralized Federated Learning over Time-varying Communication Graph",
    "doi": "https://doi.org/10.1145/3591354",
    "publication_date": "2023-04-06",
    "publication_year": 2023,
    "authors": "Yang Lu; Zhengxin Yu; Neeraj Suri",
    "corresponding_authors": "",
    "abstract": "Establishing how a set of learners can provide privacy-preserving federated learning in a fully decentralized (peer-to-peer, no coordinator) manner is an open problem. We propose the first privacy-preserving consensus-based algorithm for the distributed learners to achieve decentralized global model aggregation in an environment of high mobility, where participating learners and the communication graph between them may vary during the learning process. In particular, whenever the communication graph changes, the Metropolis-Hastings method [ 69 ] is applied to update the weighted adjacency matrix based on the current communication topology. In addition, the Shamir’s secret sharing (SSS) scheme [ 61 ] is integrated to facilitate privacy in reaching consensus of the global model. The article establishes the correctness and privacy properties of the proposed algorithm. The computational efficiency is evaluated by a simulation built on a federated learning framework with a real-world dataset.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4362667358",
    "type": "article"
  },
  {
    "title": "An Experimental Assessment of Inconsistencies in Memory Forensics",
    "doi": "https://doi.org/10.1145/3628600",
    "publication_date": "2023-10-20",
    "publication_year": 2023,
    "authors": "Jenny Ottmann; Frank Breitinger; Felix Freiling",
    "corresponding_authors": "",
    "abstract": "Memory forensics is concerned with the acquisition and analysis of copies of volatile memory (memory dumps). Based on an empirical assessment of observable inconsistencies in 360 memory dumps of a running Linux system, we confirm a state of overwhelming inconsistency in memory forensics: almost a third of these dumps had an empty process list and was therefore obviously incomplete. Out of those dumps that were analyzable, almost every second dump showed some form of inconsistency that potentially impacts the interpretation of the dump in a forensic investigation. These results are based on a new way to estimate the level of causal consistency of a memory dump. The factors influencing these inconsistencies are less clear but in general correlate with the level of concurrency (system load and number of threads).",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4387804485",
    "type": "article"
  },
  {
    "title": "Long-Span Program Behavior Modeling and Attack Detection",
    "doi": "https://doi.org/10.1145/3105761",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Xiaokui Shu; Danfeng Yao; Naren Ramakrishnan; Trent Jaeger",
    "corresponding_authors": "",
    "abstract": "Intertwined developments between program attacks and defenses witness the evolution of program anomaly detection methods. Emerging categories of program attacks, e.g., non-control data attacks and data-oriented programming, are able to comply with normal trace patterns at local views. This article points out the deficiency of existing program anomaly detection models against new attacks and presents long-span behavior anomaly detection (LAD), a model based on mildly context-sensitive grammar verification. The key feature of LAD is its reasoning of correlations among arbitrary events that occurred in long program traces. It extends existing correlation analysis between events at a stack snapshot, e.g., paired call and ret, to correlation analysis among events that historically occurred during the execution. The proposed method leverages specialized machine learning techniques to probe normal program behavior boundaries in vast high-dimensional detection space. Its two-stage modeling/detection design analyzes event correlation at both binary and quantitative levels. Our prototype successfully detects all reproduced real-world attacks against sshd, libpcre, and sendmail. The detection procedure incurs 0.1 ms to 1.3 ms overhead to profile and analyze a single behavior instance that consists of tens of thousands of function call or system call events.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2755572540",
    "type": "article"
  },
  {
    "title": "<i>NoiSense Print</i>",
    "doi": "https://doi.org/10.1145/3410447",
    "publication_date": "2020-09-28",
    "publication_year": 2020,
    "authors": "Chuadhry Mujeeb Ahmed; Aditya P. Mathur; Martín Ochoa",
    "corresponding_authors": "",
    "abstract": "Fingerprinting of various physical and logical devices has been proposed for uniquely identifying users or devices of mainstream IT systems such as PCs, laptops, and smart phones. However, the application of such techniques in Industrial Control Systems (ICS) is less explored for reasons such as a lack of direct access to such systems and the cost of faithfully reproducing realistic threat scenarios. This work addresses the feasibility of using fingerprinting techniques in the context of realistic ICS related to water treatment and distribution systems. A model-free sensor fingerprinting scheme ( NoiSense ) and a model-based sensor fingerprinting scheme ( NoisePrint ) are proposed. Using extensive experimentation with sensors, it is shown that noise patterns due to microscopic imperfections in hardware manufacturing can uniquely identify sensors with accuracy as high as 97%. The proposed technique can be used to detect physical attacks, such as the replacement of legitimate sensors by faulty or manipulated sensors. For NoisePrint , a combined fingerprint for sensor and process noise is created. The difference (called residual), between expected and observed values, i.e., noise, is used to derive a model of the system. It was found that in steady state the residual vector is a function of process and sensor noise. Data from experiments reveals that a multitude of sensors can be uniquely identified with a minimum accuracy of 90% based on NoisePrint . Also proposed is a novel challenge-response protocol that exposes more powerful cyber-attacks, including replay attacks.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3090223178",
    "type": "article"
  },
  {
    "title": "Adaptive Cyber Defense Against Multi-Stage Attacks Using Learning-Based POMDP",
    "doi": "https://doi.org/10.1145/3418897",
    "publication_date": "2020-11-08",
    "publication_year": 2020,
    "authors": "Zhisheng Hu; Minghui Zhu; Peng Liu",
    "corresponding_authors": "",
    "abstract": "Growing multi-stage attacks in computer networks impose significant security risks and necessitate the development of effective defense schemes that are able to autonomously respond to intrusions during vulnerability windows. However, the defender faces several real-world challenges, e.g., unknown likelihoods and unknown impacts of successful exploits. In this article, we leverage reinforcement learning to develop an innovative adaptive cyber defense to maximize the cost-effectiveness subject to the aforementioned challenges. In particular, we use Bayesian attack graphs to model the interactions between the attacker and networks. Then we formulate the defense problem of interest as a partially observable Markov decision process problem where the defender maintains belief states to estimate system states, leverages Thompson sampling to estimate transition probabilities, and utilizes reinforcement learning to choose optimal defense actions using measured utility values. The algorithm performance is verified via numerical simulations based on real-world attacks.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3099080616",
    "type": "article"
  },
  {
    "title": "A Usability Study of Four Secure Email Tools Using Paired Participants",
    "doi": "https://doi.org/10.1145/3313761",
    "publication_date": "2019-04-09",
    "publication_year": 2019,
    "authors": "Scott Ruoti; Jeff Andersen; Luke Dickinson; Scott Heidbrink; Tyler Monson; Mark O'Neill; Ken Reese; Brad Spendlove; Elham Vaziripour; Justin Wu; Daniel Zappala; Kent Seamons",
    "corresponding_authors": "",
    "abstract": "Secure email is increasingly being touted as usable by novice users, with a push for adoption based on recent concerns about government surveillance. To determine whether secure email is ready for grassroots adoption, we employ a laboratory user study that recruits pairs of novice users to install and use several of the latest systems to exchange secure messages. We present both quantitative and qualitative results from 28 pairs of novices as they use Private WebMail (Pwm), Tutanota, and Virtru and 10 pairs of novices as they use Mailvelope. Participants report being more at ease with this type of study and better able to cope with mistakes since both participants are “on the same page.” We find that users prefer integrated solutions over depot-based solutions and that tutorials are important in helping first-time users. Finally, our results demonstrate that Pretty Good Privacy using manual key management is still unusable for novice users, with 9 of 10 participant pairs failing to complete the study.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2937339343",
    "type": "article"
  },
  {
    "title": "Using Generative Adversarial Networks to Break and Protect Text Captchas",
    "doi": "https://doi.org/10.1145/3378446",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Guixin Ye; Zhanyong Tang; Dingyi Fang; Zhanxing Zhu; Yansong Feng; Pengfei Xu; Xiaojiang Chen; Jungong Han; Zheng Wang",
    "corresponding_authors": "",
    "abstract": "Text-based CAPTCHAs remains a popular scheme for distinguishing between a legitimate human user and an automated program. This article presents a novel genetic text captcha solver based on the generative adversarial network. As a departure from prior text captcha solvers that require a labor-intensive and time-consuming process to construct, our scheme needs significantly fewer real captchas but yields better performance in solving captchas. Our approach works by first learning a synthesizer to automatically generate synthetic captchas to construct a base solver. It then improves and fine-tunes the base solver using a small number of labeled real captchas. As a result, our attack requires only a small set of manually labeled captchas, which reduces the cost of launching an attack on a captcha scheme. We evaluate our scheme by applying it to 33 captcha schemes, of which 11 are currently used by 32 of the top-50 popular websites. Experimental results demonstrate that our scheme significantly outperforms four prior captcha solvers and can solve captcha schemes where others fail. As a countermeasure, we propose to add imperceptible perturbations onto a captcha image. We demonstrate that our countermeasure can greatly reduce the success rate of the attack.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3021533631",
    "type": "article"
  },
  {
    "title": "Mimicry Attacks on Smartphone Keystroke Authentication",
    "doi": "https://doi.org/10.1145/3372420",
    "publication_date": "2020-02-05",
    "publication_year": 2020,
    "authors": "Hassan Khan; Urs Hengartner; Daniel Vogel",
    "corresponding_authors": "",
    "abstract": "Keystroke behaviour-based authentication employs the unique typing behaviour of users to authenticate them. Recent such proposals for virtual keyboards on smartphones employ diverse temporal, contact, and spatial features to achieve over 95% accuracy. Consequently, they have been suggested as a second line of defense with text-based password authentication. We show that a state-of-the-art keystroke behaviour-based authentication scheme is highly vulnerable against mimicry attacks. While previous research used training interfaces to attack physical keyboards, we show that this approach has limited effectiveness against virtual keyboards. This is mainly due to the large number of diverse features that the attacker needs to mimic for virtual keyboards. We address this challenge by developing an augmented reality-based app that resides on the attacker’s smartphone and leverages computer vision and keystroke data to provide real-time guidance during password entry on the victim’s phone. In addition, we propose an audiovisual attack in which the attacker overlays transparent film printed with spatial pointers on the victim’s device and uses audio cues to match the temporal behaviour of the victim. Both attacks require neither tampering or installing software on the victim’s device nor specialized hardware. We conduct experiments with 30 users to mount over 400 mimicry attacks. We show that our methods enable an attacker to mimic keystroke behaviour on virtual keyboards with little effort. We also demonstrate the extensibility of our augmented reality-based technique by successfully mounting mimicry attacks on a swiping behaviour-based continuous authentication system.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3013184273",
    "type": "article"
  },
  {
    "title": "A Large-Scale Analysis of the Semantic Password Model and Linguistic Patterns in Passwords",
    "doi": "https://doi.org/10.1145/3448608",
    "publication_date": "2021-04-20",
    "publication_year": 2021,
    "authors": "Rafael Veras; Christopher Collins; Julie Thorpe",
    "corresponding_authors": "",
    "abstract": "In this article, we present a thorough evaluation of semantic password grammars. We report multifactorial experiments that test the impact of sample size, probability smoothing, and linguistic information on password cracking. The semantic grammars are compared with state-of-the-art probabilistic context-free grammar ( PCFG ) and neural network models, and tested in cross-validation and A vs. B scenarios. We present results that reveal the contributions of part-of-speech (syntactic) and semantic patterns, and suggest that the former are more consequential to the security of passwords. Our results show that in many cases PCFGs are still competitive models compared to their latest neural network counterparts. In addition, we show that there is little performance gain in training PCFGs with more than 1 million passwords. We present qualitative analyses of four password leaks (Mate1, 000webhost, Comcast, and RockYou) based on trained semantic grammars, and derive graphical models that capture high-level dependencies between token classes. Finally, we confirm the similarity inferences from our qualitative analysis by examining the effectiveness of grammars trained and tested on all pairs of leaks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3155266060",
    "type": "article"
  },
  {
    "title": "Binsec/Rel: Symbolic Binary Analyzer for Security with Applications to Constant-Time and Secret-Erasure",
    "doi": "https://doi.org/10.1145/3563037",
    "publication_date": "2022-09-12",
    "publication_year": 2022,
    "authors": "Lesly-Ann Daniel; Sébastien Bardin; Tamara Rezk",
    "corresponding_authors": "",
    "abstract": "This article tackles the problem of designing efficient binary-level verification for a subset of information flow properties encompassing constant-time and secret-erasure . These properties are crucial for cryptographic implementations but are generally not preserved by compilers. Our proposal builds on relational symbolic execution enhanced with new optimizations dedicated to information flow and binary-level analysis, yielding a dramatic improvement over prior work based on symbolic execution. We implement a prototype, Binsec/Rel , for bug-finding and bounded-verification of constant-time and secret-erasure and perform extensive experiments on a set of 338 cryptographic implementations, demonstrating the benefits of our approach. Using Binsec/Rel , we also automate two prior manual studies on preservation of constant-time and secret-erasure by compilers for a total of 4,148 and 1,156 binaries, respectively. Interestingly, our analysis highlights incorrect usages of volatile data pointer for secret-erasure and shows that scrubbing mechanisms based on volatile function pointers can introduce additional register spilling that might break secret-erasure. We also discovered that gcc -O0 and backend passes of clang introduce violations of constant-time in implementations that were previously deemed secure by a state-of-the-art constant-time verification tool operating at LLVM level, showing the importance of reasoning at binary level.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4295290086",
    "type": "article"
  },
  {
    "title": "Risk Prediction of IoT Devices Based on Vulnerability Analysis",
    "doi": "https://doi.org/10.1145/3510360",
    "publication_date": "2022-05-04",
    "publication_year": 2022,
    "authors": "Pascal Oser; Rens W. van der Heijden; S. Lüders; Frank Kargl",
    "corresponding_authors": "",
    "abstract": "Internet of Things (IoT) devices are becoming more widespread not only in areas such as smart homes and smart cities but also in research and office environments. The sheer number, heterogeneity, and limited patch availability provide significant challenges for the security of both office networks and the Internet in general. The systematic estimation of device risks, which is essential for mitigation decisions, is currently a skill-intensive task that requires expertise in network vulnerability scanning, as well as manual effort in firmware binary analysis. This article introduces SAFER, 1 the Security Assessment Framework for Embedded-device Risks, which enables a semi-automated risk assessment of IoT devices in any network. SAFER combines information from network device identification and automated firmware analysis to estimate the current risk associated with the device. Based on past vulnerability data and vendor patch intervals for device models, SAFER extrapolates those observations into the future using different automatically parameterized prediction models. Based on that, SAFER also estimates an indicator for future security risks. This enables users to be aware of devices exposing high risks in the future. One major strength of SAFER over other approaches is its scalability, achieved through significant automation. To demonstrate this strength, we apply SAFER in the network of a large multinational organization, to systematically assess the security level of hundreds of IoT devices on large-scale networks. Results indicate that SAFER successfully identified 531 out of 572 devices leading to a device identification rate of 92.83 %, analyzed 825 firmware images, and predicted the current and future security risk for 240 devices.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4281288583",
    "type": "article"
  },
  {
    "title": "DELM: Deep Ensemble Learning Model for Anomaly Detection in Malicious Network Traffic-based Adaptive Feature Aggregation and Network Optimization",
    "doi": "https://doi.org/10.1145/3690637",
    "publication_date": "2024-08-29",
    "publication_year": 2024,
    "authors": "Mukhtar Ahmed; Jinfu Chen; Ernest Akpaku; Rexford Nii Ayitey Sosu; Ajmal Latif",
    "corresponding_authors": "",
    "abstract": "With the rapid advancements in internet technology, the complexity and sophistication of network traffic attacks are increasing, making it challenging for traditional anomaly detection systems to analyze and detect malicious network attacks. The increasing advancedness of cyber threats calls for innovative approaches to identify malicious patterns within network traffic precisely. The primary issue lies in the fact that these approaches do not focus on the essential adaptive features of network traffic. We proposed an effective anomaly detection system for malicious network traffic attacks called the Deep Ensemble Learning Model (DELM). We leverage the structure of the Feedforward Deep Neural Network (FDNN), and Deep Belief Network (DBN), incorporating multiple hidden layers with non-linear activation functions. Integrating Adaptive Feature Aggregation (AFA) with the FDNN algorithm dynamically adjusts the feature aggregation process based on incoming traffic characteristics to improve adaptability. The Conditional Generative Network was employed to enhance DELM for generating data for minority classes. To improve the model’s accuracy, we applied batch normalization and data augmentation techniques for preprocessing, utilized n-gram, one-hot encoding, and feature aggregation methods for effective feature extraction. This study significantly contributes to network security by enhancing systems for detecting malicious network traffic. With its interpretability and adaptability, our proposed model shows promise in addressing the evolving cyber threat and fortifying critical network infrastructure. The experimental results demonstrate that our model performs with higher stability than the existing state-of-the-art detection approaches, as reflected by its higher accuracy, precision, recall, F1-score, and AUC-ROC.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4402005644",
    "type": "article"
  },
  {
    "title": "Analysis of Reflexive Eye Movements for Fast Replay-Resistant Biometric Authentication",
    "doi": "https://doi.org/10.1145/3281745",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Ivo Sluganovic; Marc Roeschlin; Kasper Rasmussen; Ivan Martinović",
    "corresponding_authors": "",
    "abstract": "Eye tracking devices have recently become increasingly popular as an interface between people and cons-umer-grade electronic devices. Due to the fact that human eyes are fast, responsive, and carry information unique to an individual, analyzing person’s gaze is particularly attractive for rapid biometric authentication. Unfortunately, previous proposals for gaze-based authentication systems either suffer from high error rates or requires long authentication times. We build on the fact that some eye movements can be reflexively and predictably triggered and develop an interactive visual stimulus for elicitation of reflexive eye movements that support the extraction of reliable biometric features in a matter of seconds, without requiring any memorization or cognitive effort on the part of the user. As an important benefit, our stimulus can be made unique for every authentication attempt and thus incorporated in a challenge-response biometric authentication system. This allows us to prevent replay attacks, which are possibly the most applicable attack vectors against biometric authentication. Using a gaze tracking device, we build a prototype of our system and perform a series of systematic user experiments with 30 participants from the general public. We thoroughly analyze various system parameters and evaluate the performance and security guarantees under several different attack scenarios. The results show that our system matches or surpasses existing gaze-based authentication methods in achieved equal error rates (6.3%) while achieving significantly lower authentication times (5s).",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2901576596",
    "type": "article"
  },
  {
    "title": "DADS",
    "doi": "https://doi.org/10.1145/3325822",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Samuel Wedaj; Kolin Paul; Vinay J. Ribeiro",
    "corresponding_authors": "",
    "abstract": "We present a novel scheme called Decentralized Attestation for Device Swarms (DADS), which is, to the best of our knowledge, the first to accomplish decentralized attestation in device swarms. Device swarms are smart, mobile, and interconnected devices that operate in large numbers and are likely to be part of emerging applications in Cyber-Physical Systems (CPS) and Industrial Internet of Things (IIoTs). Swarm devices process and exchange safety, privacy, and mission-critical information. Thus, it is important to have a good code verification technique that scales to device swarms and establishes trust among collaborating devices. DADS has several advantages over current state-of-the-art swarm attestation techniques: It is decentralized, has no single point of failure, and can handle changing topologies after nodes are compromised. DADS assures system resilience to node compromise/failure while guaranteeing only devices that execute genuine code remain part of the group. We conduct performance measurements of communication, computation, memory, and energy using the TrustLite embedded systems architecture in OMNeT++ simulation environment. We show that the proposed approach can significantly reduce communication cost and is very efficient in terms of computation, memory, and energy requirements. We also analyze security and show that DADS is very effective and robust against various attacks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2963715337",
    "type": "article"
  },
  {
    "title": "CrowdPrivacy",
    "doi": "https://doi.org/10.1145/3375752",
    "publication_date": "2020-02-05",
    "publication_year": 2020,
    "authors": "Fang‐Jing Wu; Tie Luo",
    "corresponding_authors": "",
    "abstract": "Location-based services (LBSs) typically crowdsource geo-tagged data from mobile users. Collecting more data will generally improve the utility for LBS providers; however, it also leads to more privacy exposure of users’ mobility patterns. Although the tension between data utility and user privacy has been recognized, there lacks a solution that determines how much data to collect—in both spatial and temporal domains—is the “best” for both mobile users and the service provider. This article proposes a strategy toward making an optimal tradeoff such that a user submits data only if her mobility privacy will not be compromised and the data utility of the LBS provider will be sufficiently improved. To this end, we first define and formulate a concept called privacy exposure , which incorporates both the spatial distribution and the temporal transition of a user’s activity points . Second, we define and quantify data utility in terms of spatial repetitions and temporal closeness among data based on an economic principle. Then, we propose a PRivacy-preserving and UTility-Enhancing Crowdsourcing (PRUTEC) algorithm to determine, on behalf of each mobile user, whether a newly sensed piece of data should be submitted to the LBS provider. Our simulation demonstrates that PRUTEC improves the data utility of the service provider with a much less amount of data to collect and reduces privacy exposure for mobile users while collecting useful data continuously.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3013230133",
    "type": "article"
  },
  {
    "title": "Following Passive DNS Traces to Detect Stealthy Malicious Domains Via Graph Inference",
    "doi": "https://doi.org/10.1145/3401897",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Mohamed Nabeel; Issa Khalil; Bei Guan; Ting Yu",
    "corresponding_authors": "",
    "abstract": "Malicious domains, including phishing websites, spam servers, and command and control servers, are the reason for many of the cyber attacks nowadays. Thus, detecting them in a timely manner is important to not only identify cyber attacks but also take preventive measures. There has been a plethora of techniques proposed to detect malicious domains by analyzing Domain Name System (DNS) traffic data. Traditionally, DNS acts as an Internet miscreant’s best friend, but we observe that the subtle traces in DNS logs left by such miscreants can be used against them to detect malicious domains. Our approach is to build a set of domain graphs by connecting “related” domains together and injecting known malicious and benign domains into these graphs so that we can make inferences about the other domains in the domain graphs. A key challenge in building these graphs is how to accurately identify related domains so that incorrect associations are minimized and the number of domains connected from the dataset is maximized. Based on our observations, we first train two classifiers and then devise a set of association rules that assist in linking domains together. We perform an in-depth empirical analysis of the graphs built using these association rules on passive DNS data and show that our techniques can detect many more malicious domains than the state-of-the-art.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3038175633",
    "type": "article"
  },
  {
    "title": "On the Workflow Satisfiability Problem with Class-Independent Constraints for Hierarchical Organizations",
    "doi": "https://doi.org/10.1145/2988239",
    "publication_date": "2016-10-22",
    "publication_year": 2016,
    "authors": "Jason Crampton; Andrei Gagarin; Gregory Gutin; Mark Jones; Magnus Wahlström",
    "corresponding_authors": "",
    "abstract": "A workflow specification defines a set of steps, a set of users, and an access control policy. The policy determines which steps a user is authorized to perform and imposes constraints on which sets of users can perform which sets of steps. The workflow satisfiability problem (WSP) is the problem of determining whether there exists an assignment of users to workflow steps that satisfies the policy. Given the computational hardness of WSP and its importance in the context of workflow management systems, it is important to develop algorithms that are as efficient as possible to solve WSP. In this article, we study the fixed-parameter tractability of WSP in the presence of class-independent constraints, which enable us to (1) model security requirements based on the groups to which users belong and (2) generalize the notion of a user-independent constraint. Class-independent constraints are defined in terms of equivalence relations over the set of users. We consider sets of nested equivalence relations because this enables us to model security requirements in hierarchical organizations. We prove that WSP is fixed-parameter tractable (FPT) for class-independent constraints defined over nested equivalence relations and develop an FPT algorithm to solve WSP instances incorporating such constraints. We perform experiments to evaluate the performance of our algorithm and compare it with that of SAT4J, an off-the-shelf pseudo-Boolean SAT solver. The results of these experiments demonstrate that our algorithm significantly outperforms SAT4J for many instances of WSP.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2535631240",
    "type": "article"
  },
  {
    "title": "Quantum Leap and Crash",
    "doi": "https://doi.org/10.1145/3398726",
    "publication_date": "2020-06-12",
    "publication_year": 2020,
    "authors": "Darren Hurley-Smith; Julio Hernández-Castro",
    "corresponding_authors": "",
    "abstract": "Random numbers are essential for cryptography and scientific simulation. Generating truly random numbers for cryptography can be a slow and expensive process. Quantum physics offers a variety of promising solutions to this challenge, proposing sources of entropy that may be genuinely unpredictable, based on the inherent randomness of certain physical phenomena. These properties have been employed to design Quantum Random Number Generators (QRNGs), some of which are commercially available. In this work, we present the first published analysis of the Quantis family of QRNGs (excluding AIS-31 models), designed and manufactured by ID Quantique (IDQ). Our study also includes Comscire’s PQ32MU QRNG, and two online services: the Australian National University’s (ANU) QRNG, and the Humboldt Physik generator. Each QRNG is analysed using five batteries of statistical tests: Dieharder, National Institute of Standards and Technology (NIST) SP800-22, Ent, Tuftests and TestU01, as part of our thorough examination of their output. Our analysis highlights issues with current certification schemes, which largely rely on NIST SP800-22 and Diehard tests of randomness. We find that more recent tests of randomness identify issues in the output of QRNG, highlighting the need for mandatory post-processing even for low-security usage of random numbers sourced from QRNGs.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3034348343",
    "type": "article"
  },
  {
    "title": "Analyzing Dynamic Code",
    "doi": "https://doi.org/10.1145/3426470",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Vincenzo Arceri; Isabella Mastroeni",
    "corresponding_authors": "",
    "abstract": "Dynamic languages, such as JavaScript, employ string-to-code primitives to turn dynamically generated text into executable code at run-time. These features make standard static analysis extremely hard if not impossible, because its essential data structures, i.e., the control-flow graph and the system of recursive equations associated with the program to analyze, are themselves dynamically mutating objects. Nevertheless, assembling code at run-time by manipulating strings, such as by eval in JavaScript, has been always strongly discouraged, since it is often recognized that “ eval is evil ,” leading static analyzers to not consider such statements or ignoring their effects. Unfortunately, the lack of formal approaches to analyze string-to-code statements pose a perfect habitat for malicious code, that is surely evil and do not respect good practice rules, allowing them to hide malicious intents as strings to be converted to code and making static analyses blind to the real malicious aim of the code. Hence, the need to handle string-to-code statements approximating what they can execute, and therefore allowing the analysis to continue (even in the presence of dynamically generated program statements) with an acceptable degree of precision, should be clear. To reach this goal, we propose a static analysis allowing us to collect string values and to soundly over-approximate and analyze the code potentially executed by a string-to-code statement.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3124933548",
    "type": "article"
  },
  {
    "title": "Flexible Mechanisms for Remote Attestation",
    "doi": "https://doi.org/10.1145/3470535",
    "publication_date": "2021-09-30",
    "publication_year": 2021,
    "authors": "Sarah C. Helble; Ian D. Kretz; Peter Loscocco; John D. Ramsdell; Paul D. Rowe; Perry Alexander",
    "corresponding_authors": "",
    "abstract": "Remote attestation consists of generating evidence of a system’s integrity via measurements and reporting the evidence to a remote party for appraisal in a form that can be trusted. The parties that exchange information must agree on formats and protocols. We assert there is a large variety of patterns of interactions among appraisers and attesters of interest. Therefore, it is important to standardize on flexible mechanisms for remote attestation. We make our case by describing scenarios that require the exchange of evidence among multiple parties using a variety of message passing patterns. We show cases in which changes in the order of evidence collection result in important differences to what can be inferred by an appraiser. We argue that adding the ability to negotiate the appropriate kind of attestation allows for remote attestations that better adapt to a dynamically changing environment. Finally, we suggest a language-based solution to taming the complexity of specifying and negotiating attestation procedures.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3203215087",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Dynamic Symmetric Searchable Encryption with Controllable Leakage",
    "doi": "https://doi.org/10.1145/3446920",
    "publication_date": "2021-04-20",
    "publication_year": 2021,
    "authors": "Shujie Cui; Xiangfu Song; Muhammad Rizwan Asghar; Steven D. Galbraith⋆; Giovanni Russello",
    "corresponding_authors": "",
    "abstract": "Searchable Encryption (SE) is a technique that allows Cloud Service Providers to search over encrypted datasets without learning the content of queries and records. In recent years, many SE schemes have been proposed to protect outsourced data. However, most of them leak sensitive information, from which attackers could still infer the content of queries and records by mounting leakage-based inference attacks, such as the count attack and file-injection attack . In this work, first we define the leakage in searchable encrypted databases and analyse how the leakage is leveraged in existing leakage-based attacks. Second, we propose a &lt;underline&gt;P&lt;/underline&gt;rivacy-preserving &lt;underline&gt;M&lt;/underline&gt;ulti-&lt;underline&gt;c&lt;/underline&gt;loud based dynamic symmetric SE scheme for relational &lt;underline&gt;D&lt;/underline&gt;ata&lt;underline&gt;b&lt;/underline&gt;ase ( P-McDb ). P-McDb has minimal leakage, which not only ensures confidentiality of queries and records but also protects the search, intersection, and size patterns. Moreover, P-McDb ensures both forward and backward privacy of the database. Thus, P-McDb could resist existing leakage-based attacks, e.g., active file/record-injection attacks. We give security definition and analysis to show how P-McDb hides the aforementioned patterns. Finally, we implemented a prototype of P-McDb and tested it using the TPC-H benchmark dataset. Our evaluation results show that users can get the required records in 2.16 s when searching over 4.1 million records.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3152607780",
    "type": "article"
  },
  {
    "title": "EI-MTD: Moving Target Defense for Edge Intelligence against Adversarial Attacks",
    "doi": "https://doi.org/10.1145/3517806",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Yaguan Qian; Y.S. Guo; Qiqi Shao; Jiamin Wang; Bin Wang; Zhaoquan Gu; Xiang Ling; Chunming Wu",
    "corresponding_authors": "",
    "abstract": "Edge intelligence has played an important role in constructing smart cities, but the vulnerability of edge nodes to adversarial attacks becomes an urgent problem. A so-called adversarial example can fool a deep learning model on an edge node for misclassification. Due to the transferability property of adversarial examples, an adversary can easily fool a black-box model by a local substitute model. Edge nodes in general have limited resources, which cannot afford a complicated defense mechanism like that on a cloud data center. To address the challenge, we propose a dynamic defense mechanism, namely EI-MTD. The mechanism first obtains robust member models of small size through differential knowledge distillation from a complicated teacher model on a cloud data center. Then, a dynamic scheduling policy, which builds on a Bayesian Stackelberg game, is applied to the choice of a target model for service. This dynamic defense mechanism can prohibit the adversary from selecting an optimal substitute model for black-box attacks. We also conduct extensive experiments to evaluate the proposed mechanism, and results show that EI-MTD could protect edge intelligence effectively against adversarial attacks in black-box settings.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3087792431",
    "type": "article"
  },
  {
    "title": "DeepMark: A Scalable and Robust Framework for DeepFake Video Detection",
    "doi": "https://doi.org/10.1145/3629976",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Tang Li; Qingqing Ye; Haibo Hu; Qiao Xue; Yaxin Xiao; Jin Li",
    "corresponding_authors": "",
    "abstract": "With the rapid growth of DeepFake video techniques, it becomes increasingly challenging to identify them visually, posing a huge threat to our society. Unfortunately, existing detection schemes are limited to exploiting the artifacts left by DeepFake manipulations, so they struggle to keep pace with the ever-improving DeepFake models. In this work, we propose DeepMark, a scalable and robust framework for detecting DeepFakes. It imprints essential visual features of a video into DeepMark Meta (DMM) and uses it to detect DeepFake manipulations by comparing the extracted visual features with the ground truth in DMM. Therefore, DeepMark is future-proof, because a DeepFake video must aim to alter some visual feature, no matter how “natural” it looks. Furthermore, DMM also contains a signature for verifying the integrity of the above features. And an essential link to the features as well as their signature is attached with error correction codes and embedded in the video watermark. To improve the efficiency of DMM creation, we also present a threshold-based feature selection scheme and a deduced face detection scheme. Experimental results demonstrate the effectiveness and efficiency of DeepMark on DeepFake video detection under various datasets and parameter settings.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4388230638",
    "type": "article"
  },
  {
    "title": "GyrosFinger",
    "doi": "https://doi.org/10.1145/3177751",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Yunmok Son; Juhwan Noh; Jaeyeong Choi; Yongdae Kim",
    "corresponding_authors": "",
    "abstract": "Drones are widely used for various purposes such as delivery, aerial photography, and surveillance. Considering the increasing drone-related services, tracking the locations of drones can cause security threats such as escaping from drone surveillance, disturbing drone-related services, and capturing drones. For wirelessly monitoring the status of drones, telemetry is used, and this status information contains various data such as latitude and longitude, calibrated sensor outputs, and sensor offsets. Because most of the telemetry implementation supports neither authentication nor encryption, an attacker can obtain the status information of the drones by using an appropriate wireless communication device such as software-defined radio. While the attacker knows the locations of the drones from the status information, this information is not sufficient for tracking drones because the status information does not include any identity information that can bind the identity of the drone with its location. &lt;?tight?&gt;In this article, we propose a fingerprinting method for drones in motion for the binding of the identity of the drone with its location. Our fingerprinting method is based on the sensor outputs included in the status information, i.e., the offsets of micro-electro mechanical systems (MEMS) gyroscope, an essential sensor for maintaining the attitude of drones. We found that the offsets of MEMS gyroscopes are different from each other because of manufacturing mismatches, and the offsets of five drones obtained through their telemetry are distinguishable and constant during their flights. To evaluate the performance of our fingerprinting method on a larger scale, we collected the offsets from 70 stand-alone MEMS gyroscopes to generate fingerprints. Our experimental results show that, when using the offsets of three and two axes calculated from 128 samples of the raw outputs per axis as fingerprints, the F-scores of the proposed method reach 98.78% and 94.47%, respectively. The offsets collected after a month are also fingerprinted with F-scores of 96.58% and 78.45% under the same condition, respectively. The proposed fingerprinting method is effective, robust, and persistent. Additionally, unless the MEMS gyroscope is not replaced, our fingerprinting method can be used for drone tracking even when the target drones are flying.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2786193123",
    "type": "article"
  },
  {
    "title": "ISOTOP",
    "doi": "https://doi.org/10.1145/3267339",
    "publication_date": "2018-10-23",
    "publication_year": 2018,
    "authors": "Taous Madi; Yosr Jarraya; Amir Alimohammadifar; Suryadipta Majumdar; Yushun Wang; Makan Pourzandi; Lingyu Wang; Mourad Debbabi",
    "corresponding_authors": "",
    "abstract": "Multi-tenancy in the cloud is a double-edged sword. While it enables cost-effective resource sharing, it increases security risks for the hosted applications. Indeed, multiplexing virtual resources belonging to different tenants on the same physical substrate may lead to critical security concerns such as cross-tenants data leakage and denial of service. Particularly, virtual networks isolation failures are among the foremost security concerns in the cloud. To remedy these, automated tools are needed to verify security mechanisms compliance with relevant security policies and standards. However, auditing virtual networks isolation is challenging due to the dynamic and layered nature of the cloud. Particularly, inconsistencies in network isolation mechanisms across cloud-stack layers, namely, the infrastructure management and the implementation layers, may lead to virtual networks isolation breaches that are undetectable at a single layer. In this article, we propose an offline automated framework for auditing consistent isolation between virtual networks in OpenStack-managed cloud spanning over overlay and layer 2 by considering both cloud layers’ views. To capture the semantics of the audited data and its relation to consistent isolation requirement, we devise a multi-layered model for data related to each cloud-stack layer’s view. Furthermore, we integrate our auditing system into OpenStack, and present our experimental results on assessing several properties related to virtual network isolation and consistency. Our results show that our approach can be successfully used to detect virtual network isolation breaches for large OpenStack-based data centers in reasonable time.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2896299572",
    "type": "article"
  },
  {
    "title": "KIST",
    "doi": "https://doi.org/10.1145/3278121",
    "publication_date": "2018-12-10",
    "publication_year": 2018,
    "authors": "Rob Jansen; Matthew Traudt; John Geddes; Chris Wacek; Micah Sherr; Paul Syverson",
    "corresponding_authors": "",
    "abstract": "Tor’s growing popularity and user diversity has resulted in network performance problems that are not well understood, though performance is understood to be a significant factor in Tor’s security. A large body of work has attempted to solve performance problems without a complete understanding of where congestion occurs in Tor. In this article, we first study congestion in Tor at individual relays as well as along the entire end-to-end Tor path and find that congestion occurs almost exclusively in egress kernel socket buffers. We then analyze Tor’s socket interactions and discover two major contributors to Tor’s congestion: Tor writes sockets sequentially, and Tor writes as much as possible to each socket. To improve Tor’s performance, we design, implement, and test KIST: a new socket management algorithm that uses real-time kernel information to dynamically compute the amount to write to each socket while considering all circuits of all writable sockets when scheduling cells. We find that, in the medians, KIST reduces circuit congestion by more than 30%, reduces network latency by 18%, and increases network throughput by nearly 10%. We also find that client and relay performance with KIST improves as more relays deploy it and as network load and packet loss rates increase. We analyze the security of KIST and find an acceptable performance and security tradeoff, as it does not significantly affect the outcome of well-known latency, throughput, and traffic correlation attacks. KIST has been merged and configured as the default socket scheduling algorithm in Tor version 0.3.2.1-alpha (released September 18, 2017) and became stable in Tor version 0.3.2.9 (released January 9, 2018). While our focus is Tor, our techniques and observations should help analyze and improve overlay and application performance, both for security applications and in general.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2905490327",
    "type": "article"
  },
  {
    "title": "Hybrid Private Record Linkage",
    "doi": "https://doi.org/10.1145/3318462",
    "publication_date": "2019-04-26",
    "publication_year": 2019,
    "authors": "Fang-Yu Rao; Jianneng Cao; Elisa Bertino; Murat Kantarcıoğlu",
    "corresponding_authors": "",
    "abstract": "Private record linkage protocols allow multiple parties to exchange matching records, which refer to the same entities or have similar values, while keeping the non-matching ones secret. Conventional protocols are based on computationally expensive cryptographic primitives and therefore do not scale. To address these scalability issues, hybrid protocols have been proposed that combine differential privacy techniques with secure multiparty computation techniques. However, a drawback of such protocols is that they disclose to the parties both the matching records and the differentially private synopses of the datasets involved in the linkage. Consequently, differential privacy is no longer always satisfied. To address this issue, we propose a novel framework that separates the private synopses from the matching records. The two parties do not access the synopses directly, but still use them to efficiently link records. We theoretically prove the security of our framework under the state-of-the-art privacy notion of differential privacy for record linkage (DPRL). In addition, we develop a simple but effective strategy for releasing private synopses. Extensive experimental results show that our framework is superior to the existing methods in terms of efficiency.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2943322967",
    "type": "article"
  },
  {
    "title": "How to Train Your Browser",
    "doi": "https://doi.org/10.1145/2939374",
    "publication_date": "2016-07-19",
    "publication_year": 2016,
    "authors": "Dimitris Mitropoulos; Konstantinos Stroggylos; Diomidis Spinellis; Angelos D. Keromytis",
    "corresponding_authors": "",
    "abstract": "Cross-Site Scripting (XSS) is one of the most common web application vulnerabilities. It is therefore sometimes referred to as the “buffer overflow of the web.” Drawing a parallel from the current state of practice in preventing unauthorized native code execution (the typical goal in a code injection), we propose a script whitelisting approach to tame JavaScript-driven XSS attacks. Our scheme involves a transparent script interception layer placed in the browser’s JavaScript engine. This layer is designed to detect every script that reaches the browser, from every possible route, and compare it to a list of valid scripts for the site or page being accessed; scripts not on the list are prevented from executing. To avoid the false positives caused by minor syntactic changes (e.g., due to dynamic code generation), our layer uses the concept of contextual fingerprints when comparing scripts. Contextual fingerprints are identifiers that represent specific elements of a script and its execution context. Fingerprints can be easily enriched with new elements, if needed, to enhance the proposed method’s robustness. The list can be populated by the website’s administrators or a trusted third party. To verify our approach, we have developed a prototype and tested it successfully against an extensive array of attacks that were performed on more than 50 real-world vulnerable web applications. We measured the browsing performance overhead of the proposed solution on eight websites that make heavy use of JavaScript. Our mechanism imposed an average overhead of 11.1% on the execution time of the JavaScript engine. When measured as part of a full browsing session, and for all tested websites, the overhead introduced by our layer was less than 0.05%. When script elements are altered or new scripts are added on the server side, a new fingerprint generation phase is required. To examine the temporal aspect of contextual fingerprints, we performed a short-term and a long-term experiment based on the same websites. The former, showed that in a short period of time (10 days), for seven of eight websites, the majority of valid fingerprints stay the same (more than 92% on average). The latter, though, indicated that, in the long run, the number of fingerprints that do not change is reduced. Both experiments can be seen as one of the first attempts to study the feasibility of a whitelisting approach for the web.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2475762190",
    "type": "article"
  },
  {
    "title": "Build It, Break It, Fix It",
    "doi": "https://doi.org/10.1145/3383773",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "James Parker; Michael Hicks; Andrew Ruef; Michelle L. Mazurek; Dave Levin; Daniel Votipka; Piotr Mardziel; Kelsey R. Fulton",
    "corresponding_authors": "",
    "abstract": "Typical security contests focus on breaking or mitigating the impact of buggy systems. We present the Build-it, Break-it, Fix-it (BIBIFI) contest, which aims to assess the ability to securely build software, not just break it. In BIBIFI, teams build specified software with the goal of maximizing correctness, performance, and security. The latter is tested when teams attempt to break other teams’ submissions. Winners are chosen from among the best builders and the best breakers. BIBIFI was designed to be open-ended—teams can use any language, tool, process, and so on, that they like. As such, contest outcomes shed light on factors that correlate with successfully building secure software and breaking insecure software. We ran three contests involving a total of 156 teams and three different programming problems. Quantitative analysis from these contests found that the most efficient build-it submissions used C/C++, but submissions coded in a statically type safe language were 11× less likely to have a security flaw than C/C++ submissions. Break-it teams that were also successful build-it teams were significantly better at finding security bugs.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3038040579",
    "type": "article"
  },
  {
    "title": "Exploitation Techniques for Data-oriented Attacks with Existing and Potential Defense Approaches",
    "doi": "https://doi.org/10.1145/3462699",
    "publication_date": "2021-09-02",
    "publication_year": 2021,
    "authors": "Long Cheng; Salman Ahmed; Hans Liljestrand; Thomas Nyman; Haipeng Cai; Trent Jaeger; N. Asokan; Danfeng Yao",
    "corresponding_authors": "",
    "abstract": "Data-oriented attacks manipulate non-control data to alter a program’s benign behavior without violating its control-flow integrity. It has been shown that such attacks can cause significant damage even in the presence of control-flow defense mechanisms. However, these threats have not been adequately addressed. In this survey article, we first map data-oriented exploits, including Data-Oriented Programming (DOP) and Block-Oriented Programming (BOP) attacks, to their assumptions/requirements and attack capabilities. Then, we compare known defenses against these attacks, in terms of approach, detection capabilities, overhead, and compatibility. It is generally believed that control flows may not be useful for data-oriented security. However, data-oriented attacks (especially DOP attacks) may generate side effects on control-flow behaviors in multiple dimensions (i.e., incompatible branch behaviors and frequency anomalies). We also characterize control-flow anomalies caused by data-oriented attacks. In the end, we discuss challenges for building deployable data-oriented defenses and open research questions.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3198309584",
    "type": "article"
  },
  {
    "title": "Defending Against Membership Inference Attacks on Beacon Services",
    "doi": "https://doi.org/10.1145/3603627",
    "publication_date": "2023-06-07",
    "publication_year": 2023,
    "authors": "Rajagopal Venkatesaramani; Zhiyu Wan; Bradley Malin; Yevgeniy Vorobeychik",
    "corresponding_authors": "",
    "abstract": "Large genomic datasets are created through numerous activities, including recreational genealogical investigations, biomedical research, and clinical care. At the same time, genomic data has become valuable for reuse beyond their initial point of collection, but privacy concerns often hinder access. Beacon services have emerged to broaden accessibility to such data. These services enable users to query for the presence of a particular minor allele in a dataset, and information helps care providers determine if genomic variation is spurious or has some known clinical indication. However, various studies have shown that this process can leak information regarding if individuals are members of the underlying dataset. There are various approaches to mitigate this vulnerability, but they are limited in that they (1) typically rely on heuristics to add noise to the Beacon responses; (2) offer probabilistic privacy guarantees only, neglecting data utility; and (3) assume a batch setting where all queries arrive at once. In this article, we present a novel algorithmic framework to ensure privacy in a Beacon service setting with a minimal number of query response flips. We represent this problem as one of combinatorial optimization in both the batch setting and the online setting (where queries arrive sequentially). We introduce principled algorithms with both privacy and, in some cases, worst-case utility guarantees. Moreover, through extensive experiments, we show that the proposed approaches significantly outperform the state of the art in terms of privacy and utility, using a dataset consisting of 800 individuals and 1.3 million single nucleotide variants.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4379796806",
    "type": "article"
  },
  {
    "title": "DEEPFAKER: A Unified Evaluation Platform for Facial Deepfake and Detection Models",
    "doi": "https://doi.org/10.1145/3634914",
    "publication_date": "2023-11-29",
    "publication_year": 2023,
    "authors": "Li Wang; Xiangtao Meng; Dan Li; Xuhong Zhang; Shouling Ji; Shanqing Guo",
    "corresponding_authors": "",
    "abstract": "Deepfake data contains realistically manipulated faces—its abuses pose a huge threat to the security and privacy-critical applications. Intensive research from academia and industry has produced many deepfake/detection models, leading to a constant race of attack and defense. However, due to the lack of a unified evaluation platform, many critical questions on this subject remain largely unexplored. How is the anti-detection ability of the existing deepfake models? How generalizable are existing detection models against different deepfake samples? How effective are the detection APIs provided by the cloud-based vendors? How evasive and transferable are adversarial deepfakes in the lab and real-world environment? How do various factors impact the performance of deepfake and detection models? To bridge the gap, we design and implement DEEPFAKER 1 a unified and comprehensive deepfake detection evaluation platform. Specifically, DEEPFAKER has integrated 10 state-of-the-art deepfake methods and 9 representative detection methods, while providing a user-friendly interface and modular design that allows for easy integration of new methods. Leveraging DEEPFAKER , we conduct a large-scale empirical study of facial deepfake/detection models and draw a set of key findings: (i) the detection methods have poor generalization on samples generated by different deepfake methods; (ii) there is no significant correlation between anti-detection ability and visual quality of deepfake samples; (iii) the current detection APIs have poor detection performance and adversarial deepfakes can achieve about 70% attack success rate on all cloud-based vendors, calling for an urgent need to deploy effective and robust detection APIs; (iv) the detection methods in the lab are more robust against transfer attacks than the detection APIs in the real-world environment; and (v) deepfake videos may not always be more difficult to detect after video compression. We envision that DEEPFAKER will benefit future research on facial deepfake and detection.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4389140876",
    "type": "article"
  },
  {
    "title": "AdverSPAM: Adversarial SPam Account Manipulation in Online Social Networks",
    "doi": "https://doi.org/10.1145/3643563",
    "publication_date": "2024-01-26",
    "publication_year": 2024,
    "authors": "Federico Concone; Salvatore Gaglio; Andrea Giammanco; Giuseppe Lo Re; Marco Morana",
    "corresponding_authors": "",
    "abstract": "In recent years, the widespread adoption of Machine Learning (ML) at the core of complex IT systems has driven researchers to investigate the security and reliability of ML techniques. A very specific kind of threats concerns the adversary mechanisms through which an attacker could induce a classification algorithm to provide the desired output. Such strategies, known as Adversarial Machine Learning (AML), have a twofold purpose: to calculate a perturbation to be applied to the classifier’s input such that the outcome is subverted, while maintaining the underlying intent of the original data. Although any manipulation that accomplishes these goals is theoretically acceptable, in real scenarios perturbations must correspond to a set of permissible manipulations of the input, which is rarely considered in the literature. In this article, we present AdverSPAM , an AML technique designed to fool the spam account detection system of an Online Social Network (OSN). The proposed black-box evasion attack is formulated as an optimization problem that computes the adversarial sample while maintaining two important properties of the feature space, namely statistical correlation and semantic dependency . Although being demonstrated in an OSN security scenario, such an approach might be applied in other context where the aim is to perturb data described by mutually related features. Experiments conducted on a public dataset show the effectiveness of AdverSPAM compared to five state-of-the-art competitors, even in the presence of adversarial defense mechanisms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4391262667",
    "type": "article"
  },
  {
    "title": "Texture to the Rescue",
    "doi": "https://doi.org/10.1145/3092816",
    "publication_date": "2017-08-11",
    "publication_year": 2017,
    "authors": "Ehsan Toreini; Siamak F. Shahandashti; Feng Hao",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a novel paper fingerprinting technique based on analyzing the translucent patterns revealed when a light source shines through the paper. These patterns represent the inherent texture of paper, formed by the random interleaving of wooden particles during the manufacturing process. We show that these patterns can be easily captured by a commodity camera and condensed into a compact 2,048-bit fingerprint code. Prominent works in this area (Nature 2005, IEEE S8P 2009, CCS 2011) have all focused on fingerprinting paper based on the paper “surface.” We are motivated by the observation that capturing the surface alone misses important distinctive features such as the noneven thickness, random distribution of impurities, and different materials in the paper with varying opacities. Through experiments, we demonstrate that the embedded paper texture provides a more reliable source for fingerprinting than features on the surface. Based on the collected datasets, we achieve 0% false rejection and 0% false acceptance rates. We further report that our extracted fingerprints contain 807 degrees of freedom (DoF), which is much higher than the 249 DoF with iris codes (that have the same size of 2,048 bits). The high amount of DoF for texture-based fingerprints makes our method extremely scalable for recognition among very large databases; it also allows secure usage of the extracted fingerprint in privacy-preserving authentication schemes based on error correction techniques.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2613717821",
    "type": "article"
  },
  {
    "title": "Authentication Challenges in a Global Environment",
    "doi": "https://doi.org/10.1145/3007208",
    "publication_date": "2017-01-09",
    "publication_year": 2017,
    "authors": "Stephanos Matsumoto; Raphael M. Reischuk; Paweł Szałachowski; Tiffany Hyun‐Jin Kim; Adrian Perrig",
    "corresponding_authors": "",
    "abstract": "In this article, we address the problem of scaling authentication for naming, routing, and end-entity (EE) certification to a global environment in which authentication policies and users’ sets of trust roots vary widely. The current mechanisms for authenticating names (DNSSEC), routes (BGPSEC), and EE certificates (TLS) do not support a coexistence of authentication policies, affect the entire Internet when compromised, cannot update trust root information efficiently, and do not provide users with the ability to make flexible trust decisions. We propose the Scalable Authentication Infrastructure for Next-generation Trust (SAINT), which partitions the Internet into groups with common, local trust roots and isolates the effects of a compromised trust root. SAINT requires groups with direct routing connections to cross-sign each other for authentication purposes, allowing diverse authentication policies while keeping all entities’ authentication information globally discoverable. SAINT makes trust root management a central part of the network architecture, enabling trust root updates within seconds and allowing users to make flexible trust decisions. SAINT operates without a significant performance penalty and can be deployed alongside existing infrastructures.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2569104544",
    "type": "article"
  },
  {
    "title": "Evaluating the Privacy Guarantees of Location Proximity Services",
    "doi": "https://doi.org/10.1145/3007209",
    "publication_date": "2017-02-03",
    "publication_year": 2017,
    "authors": "George Argyros; Theofilos Petsios; Suphannee Sivakorn; Angelos D. Keromytis; Jason Polakis",
    "corresponding_authors": "",
    "abstract": "Location-based services have become an integral part of everyday life. To address the privacy issues that emerge from the use and sharing of location information, social networks and smartphone applications have adopted location proximity schemes as a means of balancing user privacy with utility. Unfortunately, despite the extensive academic literature on this topic, the schemes that large service providers have adopted are not always designed or implemented correctly, rendering users vulnerable to location-disclosure attacks. Such attacks have recently received major publicity as, in some cases, they even exposed citizens of oppressive regimes to life-threatening risks. In this article, we systematically assess the defenses that popular location-based services and mobile applications deploy to guard against adversaries seeking to identify a user’s location. We provide the theoretical foundations for formalizing the privacy guarantees of currently adopted proximity models, design practical attacks for each case, and prove tight bounds on the number of queries required for carrying out successful attacks in practice. To evaluate the completeness of our approach, we conduct extensive experiments against popular services including Facebook, Foursquare, and Grindr. Our results demonstrate that, even though the aforementioned services implement various privacy-preserving techniques to protect their users, they are still vulnerable to attacks. In particular, we are able to pinpoint Facebook users within 5m of their exact location. For Foursquare and Grindr, users are pinpointed within 15m of their location in 90% of the cases, even with the strictest privacy settings enabled. Our attacks are highly efficient and complete within a few seconds. The severity of our findings was acknowledged by Facebook and Foursquare, both of which have followed our recommendations and adopted our design of a safe proximity scheme in their production systems. As the number of mobile applications offering location functionality will continue to increase, service providers and software developers must be able to assess the privacy guarantees that their services offer. To that end, we discuss viable defenses that can be currently adopted by all major services, and provide an open-source testing framework to be used by researchers and service providers who wish to evaluate the privacy-preserving properties of applications offering proximity functionality.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2586344326",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Publishing of Hierarchical Data",
    "doi": "https://doi.org/10.1145/2976738",
    "publication_date": "2016-09-15",
    "publication_year": 2016,
    "authors": "Ismet Ozalp; Mehmet Emre Gürsoy; Mehmet Ercan Nergiz; Yücel Saygın",
    "corresponding_authors": "",
    "abstract": "Many applications today rely on storage and management of semi-structured information, for example, XML databases and document-oriented databases. These data often have to be shared with untrusted third parties, which makes individuals’ privacy a fundamental problem. In this article, we propose anonymization techniques for privacy-preserving publishing of hierarchical data. We show that the problem of anonymizing hierarchical data poses unique challenges that cannot be readily solved by existing mechanisms. We extend two standards for privacy protection in tabular data ( k -anonymity and ℓ-diversity) and apply them to hierarchical data. We present utility-aware algorithms that enforce these definitions of privacy using generalizations and suppressions of data values. To evaluate our algorithms and their heuristics, we experiment on synthetic and real datasets obtained from two universities. Our experiments show that we significantly outperform related methods that provide comparable privacy guarantees.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2511914794",
    "type": "article"
  },
  {
    "title": "Discriminative Power of Typing Features on Desktops, Tablets, and Phones for User Identification",
    "doi": "https://doi.org/10.1145/3377404",
    "publication_date": "2020-02-05",
    "publication_year": 2020,
    "authors": "Amith K. Belman; Vir V. Phoha",
    "corresponding_authors": "",
    "abstract": "Research in Keystroke-Dynamics (KD) has customarily focused on temporal features without considering context to generate user templates that are used in authentication. Additionally, work on KD in hand-held devices such as smart-phones and tablets have shown that these features alone do not perform satisfactorily for authentication. In this work, we analyze the discriminatory power of the most-used conventional features found in the literature, propose a set of context-sensitive or word-specific features, and analyze the discriminatory power of proposed features using their classification results. To perform these tasks, we use the keystroke data consisting of over 650K keystrokes, collected from 20 unique users during different activities on desktops, tablets, and phones, over a span of two months. On an average, each user made 12.5K, 9K, and 10K keystrokes on desktop, tablet, and phone, respectively. We find that the conventional features are not highly discriminatory on desktops and are only marginally better on hand-held devices for user identification. By using information of the context, a subset (derived after analysis) of our proposed word-specific features offers superior discrimination among users on all devices. We find that a majority of the classifiers, built using these features, perform user identification well with accuracies in the range of 90% to 97%, average precision and recall values of 0.914 and 0.901, respectively, on balanced test samples in 10-fold cross validation. We also find that proposed features work best on hand-held devices. This work calls for a shift from using conventional KD features to a set of context-sensitive or word-specific KD features that take advantage of known information such as context.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3013808539",
    "type": "article"
  },
  {
    "title": "One Size Does Not Fit All",
    "doi": "https://doi.org/10.1145/3429741",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Marcus Botacin; Hojjat Aghakhani; Stefano Ortolani; Christopher Kruegel; Giovanni Vigna; Daniela S Oliveira; Paulo Lício de Geus; André Grégio",
    "corresponding_authors": "",
    "abstract": "Malware analysis is an essential task to understand infection campaigns, the behavior of malicious codes, and possible ways to mitigate threats. Malware analysis also allows better assessment of attackers’ capabilities, techniques, and processes. Although a substantial amount of previous work provided a comprehensive analysis of the international malware ecosystem, research on regionalized, country-, and population-specific malware campaigns have been scarce. Moving towards addressing this gap, we conducted a longitudinal (2012-2020) and comprehensive (encompassing an entire population of online banking users) study of MS Windows desktop malware that actually infected Brazilian banks’ users. We found that the Brazilian financial desktop malware has been evolving quickly: it started to make use of a variety of file formats instead of typical PE binaries, relied on native system resources, and abused obfuscation techniques to bypass detection mechanisms. Our study on the threats targeting a significant population on the ecosystem of the largest and most populous country in Latin America can provide invaluable insights that may be applied to other countries’ user populations, especially those in the developing world that might face cultural peculiarities similar to Brazil’s. With this evaluation, we expect to motivate the security community/industry to seriously consider a deeper level of customization during the development of next-generation anti-malware solutions, as well as to raise awareness towards regionalized and targeted Internet threats.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3125868980",
    "type": "article"
  },
  {
    "title": "Attack Context Embedded Data Driven Trust Diagnostics in Smart Metering Infrastructure",
    "doi": "https://doi.org/10.1145/3426739",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Shameek Bhattacharjee; Venkata Praveen Kumar Madhavarapu; Simone Silvestri; Sajal K. Das",
    "corresponding_authors": "",
    "abstract": "Spurious power consumption data reported from compromised meters controlled by organized adversaries in the Advanced Metering Infrastructure (AMI) may have drastic consequences on a smart grid’s operations. While existing research on data falsification in smart grids mostly defends against isolated electricity theft, we introduce a taxonomy of various data falsification attack types, when smart meters are compromised by organized or strategic rivals. To counter these attacks, we first propose a coarse-grained and a fine-grained anomaly-based security event detection technique that uses indicators such as deviation and directional change in the time series of the proposed anomaly detection metrics to indicate: (i) occurrence, (ii) type of attack, and (iii) attack strategy used, collectively known as attack context . Leveraging the attack context information, we propose three attack response metrics to the inferred attack context: (a) an unbiased mean indicating a robust location parameter; (b) a median absolute deviation indicating a robust scale parameter; and (c) an attack probability time ratio metric indicating the active time horizon of attacks. Subsequently, we propose a trust scoring model based on Kullback-Leibler (KL) divergence, that embeds the appropriate unbiased mean, the median absolute deviation, and the attack probability ratio metric at runtime to produce trust scores for each smart meter. These trust scores help classify compromised smart meters from the non-compromised ones. The embedding of the attack context, into the trust scoring model, facilitates accurate and rapid classification of compromised meters, even under large fractions of compromised meters, generalize across various attack strategies and margins of false data. Using real datasets collected from two different AMIs, experimental results show that our proposed framework has a high true positive detection rate, while the average false alarm and missed detection rates are much lesser than 10% for most attack combinations for two different real AMI micro-grid datasets. Finally, we also establish fundamental theoretical limits of the proposed method, which will help assess the applicability of our method to other domains.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3122578843",
    "type": "article"
  },
  {
    "title": "Paralinguistic Privacy Protection at the Edge",
    "doi": "https://doi.org/10.1145/3570161",
    "publication_date": "2022-11-03",
    "publication_year": 2022,
    "authors": "Ranya Aloufi; Hamed Haddadi; David Boyle",
    "corresponding_authors": "",
    "abstract": "Voice user interfaces and digital assistants are rapidly entering our lives and becoming singular touch points spanning our devices. These always-on services capture and transmit our audio data to powerful cloud services for further processing and subsequent actions. Our voices and raw audio signals collected through these devices contain a host of sensitive paralinguistic information that is transmitted to service providers regardless of deliberate or false triggers. As our emotional patterns and sensitive attributes like our identity, gender, and well-being are easily inferred using deep acoustic models, we encounter a new generation of privacy risks by using these services. One approach to mitigate the risk of paralinguistic-based privacy breaches is to exploit a combination of cloud-based processing with privacy-preserving, on-device paralinguistic information learning and filtering before transmitting voice data. In this article we introduce EDGY , a configurable, lightweight, disentangled representation learning framework that transforms and filters high-dimensional voice data to identify and contain sensitive attributes at the edge prior to offloading to the cloud. We evaluate EDGY’s on-device performance and explore optimization techniques, including model quantization and knowledge distillation, to enable private, accurate, and efficient representation learning on resource-constrained devices. Our results show that EDGY runs in tens of milliseconds with 0.2% relative improvement in “zero-shot” ABX score or minimal performance penalties of approximately 5.95% word error rate (WER) in learning linguistic representations from raw voice signals, using a CPU and a single-core ARM processor without specialized hardware.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3097320994",
    "type": "article"
  },
  {
    "title": "Industrial Control Systems Security via Runtime Enforcement",
    "doi": "https://doi.org/10.1145/3546579",
    "publication_date": "2022-07-04",
    "publication_year": 2022,
    "authors": "Ruggero Lanotte; Massimo Merro; Andrei Munteanu",
    "corresponding_authors": "",
    "abstract": "With the advent of Industry 4.0 , industrial facilities and critical infrastructures are transforming into an ecosystem of heterogeneous physical and cyber components, such as programmable logic controllers , increasingly interconnected and therefore exposed to cyber-physical attacks , i.e., security breaches in cyberspace that may adversely affect the physical processes underlying industrial control systems . In this article, we propose a formal approach based on runtime enforcement to ensure specification compliance in networks of controllers, possibly compromised by colluding malware that may locally tamper with actuator commands, sensor readings, and inter-controller communications. Our approach relies on an ad-hoc sub-class of Ligatti et al.’s edit automata to enforce controllers represented in Hennessy and Regan’s Timed Process Language . We define a synthesis algorithm that, given an alphabet 𝒫 of observable actions and a timed correctness property e , returns a monitor that enforces the property e during the execution of any (potentially corrupted) controller with alphabet 𝒫, and complying with the property e . Our monitors do mitigation by correcting and suppressing incorrect actions of corrupted controllers and by generating actions in full autonomy when the controller under scrutiny is not able to do so in a correct manner. Besides classical requirements, such as transparency and soundness , the proposed enforcement enjoys deadlock- and diverge-freedom of monitored controllers, together with scalability when dealing with networks of controllers. Finally, we test the proposed enforcement mechanism on a non-trivial case study, taken from the context of industrial water treatment systems, in which the controllers are injected with different malware with different malicious goals.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4283796786",
    "type": "article"
  },
  {
    "title": "A Vulnerability Assessment Framework for Privacy-preserving Record Linkage",
    "doi": "https://doi.org/10.1145/3589641",
    "publication_date": "2023-04-03",
    "publication_year": 2023,
    "authors": "Anushka Vidanage; Peter Christen; Thilina Ranbaduge; Rainer Schnell",
    "corresponding_authors": "",
    "abstract": "The linkage of records to identify common entities across multiple data sources has gained increasing interest over the last few decades. In the absence of unique entity identifiers, quasi-identifying attributes such as personal names and addresses are generally used to link records. Due to privacy concerns that arise when such sensitive information is used, privacy-preserving record linkage (PPRL) methods have been proposed to link records without revealing any sensitive or confidential information about these records. Popular PPRL methods such as Bloom filter encoding, however, are known to be susceptible to various privacy attacks. Therefore, a systematic analysis of the privacy risks associated with sensitive databases as well as PPRL methods used in linkage projects is of great importance. In this article we present a novel framework to assess the vulnerabilities of sensitive databases and existing PPRL encoding methods. We discuss five types of vulnerabilities: frequency, length, co-occurrence, similarity, and similarity neighborhood, of both plaintext and encoded values that an adversary can exploit in order to reidentify sensitive plaintext values from encoded data. In an experimental evaluation we assess the vulnerabilities of two databases using five existing PPRL encoding methods. This evaluation shows that our proposed framework can be used in real-world linkage applications to assess the vulnerabilities associated with sensitive databases to be linked, as well as with PPRL encoding methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4362583440",
    "type": "article"
  },
  {
    "title": "Semi-Supervised Classification of Malware Families Under Extreme Class Imbalance via Hierarchical Non-Negative Matrix Factorization with Automatic Model Selection",
    "doi": "https://doi.org/10.1145/3624567",
    "publication_date": "2023-09-18",
    "publication_year": 2023,
    "authors": "Maksim E. Eren; Manish Bhattarai; Robert J. Joyce; Edward Raff; Charles Nicholas; Boian S. Alexandrov",
    "corresponding_authors": "",
    "abstract": "Identification of the family to which a malware specimen belongs is essential in understanding the behavior of the malware and developing mitigation strategies. Solutions proposed by prior work, however, are often not practicable due to the lack of realistic evaluation factors. These factors include learning under class imbalance, the ability to identify new malware, and the cost of production-quality labeled data. In practice, deployed models face prominent, rare, and new malware families. At the same time, obtaining a large quantity of up-to-date labeled malware for training a model can be expensive. In this article, we address these problems and propose a novel hierarchical semi-supervised algorithm, which we call the HNMFk Classifier , that can be used in the early stages of the malware family labeling process. Our method is based on non-negative matrix factorization with automatic model selection, that is, with an estimation of the number of clusters. With HNMFk Classifier , we exploit the hierarchical structure of the malware data together with a semi-supervised setup, which enables us to classify malware families under conditions of extreme class imbalance. Our solution can perform abstaining predictions, or rejection option, which yields promising results in the identification of novel malware families and helps with maintaining the performance of the model when a low quantity of labeled data is used. We perform bulk classification of nearly 2,900 both rare and prominent malware families, through static analysis, using nearly 388,000 samples from the EMBER-2018 corpus. In our experiments, we surpass both supervised and semi-supervised baseline models with an F1 score of 0.80.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386831175",
    "type": "article"
  },
  {
    "title": "Is Bitcoin Future as Secure as We Think? Analysis of Bitcoin Vulnerability to Bribery Attacks Launched through Large Transactions",
    "doi": "https://doi.org/10.1145/3641546",
    "publication_date": "2024-01-18",
    "publication_year": 2024,
    "authors": "Ghader Ebrahimpour; Mohammad Sayad Haghighi",
    "corresponding_authors": "",
    "abstract": "Bitcoin uses blockchain technology to maintain transactions order and provides probabilistic guarantees to prevent double-spending, assuming that an attacker’s computational power does not exceed 50% of the network power. In this article, we design a novel bribery attack and show that this guarantee can be hugely undermined. Miners are assumed to be rational in this setup, and they are given incentives that are dynamically calculated. In this attack, the adversary misuses the Bitcoin protocol to bribe miners and maximize their gained advantage. We will reformulate the bribery attack to propose a general mathematical foundation upon which we build multiple strategies. We show that, unlike Whale Attack, these strategies are practical, especially in the future when halvings lower the mining rewards. In the so-called “guaranteed variable-rate bribing with commitment” strategy, through optimization by Differential Evolution (DE), we show how double-spending is possible in the Bitcoin ecosystem for any transaction whose value is above 218.9BTC, and this comes with 100% success rate. A slight reduction in the success probability, e.g., by 10%, brings the threshold down to 165BTC. If the rationality assumption holds, then this shows how vulnerable blockchain-based systems like Bitcoin are. We suggest a soft fork on Bitcoin to fix this issue at the end.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4390984748",
    "type": "article"
  },
  {
    "title": "Security Analysis of the Consumer Remote SIM Provisioning Protocol",
    "doi": "https://doi.org/10.1145/3663761",
    "publication_date": "2024-05-06",
    "publication_year": 2024,
    "authors": "Abu Shohel Ahmed; Aleksi Peltonen; Mohit Sethi; Tuomas Aura",
    "corresponding_authors": "",
    "abstract": "Remote SIM provisioning (RSP) for consumer devices is the protocol specified by the GSM Association for downloading SIM profiles into a secure element in a mobile device. The process is commonly known as eSIM, and it is expected to replace removable SIM cards. The security of the protocol is critical because the profile includes the credentials with which the mobile device will authenticate to the mobile network. In this article, we present a formal security analysis of the consumer RSP protocol. We model the multi-party protocol in applied pi calculus, define formal security goals, and verify them in ProVerif. The analysis shows that the consumer RSP protocol protects against a network adversary when all the intended participants are honest. However, we also model the protocol in realistic partial compromise scenarios where the adversary controls a legitimate participant or communication channel. The security failures in the partial compromise scenarios reveal weaknesses in the protocol design. The most important observation is that the security of RSP depends unnecessarily on it being encapsulated in a TLS tunnel. Also, the lack of pre-established identifiers means that a compromised download server anywhere in the world or a compromised secure element can be used for attacks against RSP between honest participants. Additionally, the lack of reliable methods for verifying user intent can lead to serious security failures. Based on the findings, we recommend practical improvements to RSP implementations, future versions of the specification, and mobile operator processes to increase the robustness of eSIM security.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4396671102",
    "type": "article"
  },
  {
    "title": "ZTA-IoT: A Novel Architecture for Zero-Trust in IoT Systems and an Ensuing Usage Control Model",
    "doi": "https://doi.org/10.1145/3671147",
    "publication_date": "2024-08-16",
    "publication_year": 2024,
    "authors": "Safwa Ameer; Lopamudra Praharaj; Ravi Sandhu; Smriti Bhatt; Maanak Gupta",
    "corresponding_authors": "",
    "abstract": "Recently, several researchers motivated the need to integrate Zero Trust (ZT) principles when designing and implementing authentication and authorization systems for IoT. An integrated Zero Trust IoT system comprises the network infrastructure (physical and virtual) and operational policies in place for IoT as a product of a ZT architecture plan. This article proposes a novel Zero Trust architecture for IoT systems called ZTA-IoT. Additionally, based on different types of interactions between various layers and components in this architecture, we present ZTA-IoT-ACF, an access control framework that recognizes different interactions that need to be controlled in IoT systems. Within this framework, the article then refines its focus to object-level interactions, i.e., interactions where the target resource is a device (equivalently a thing) or an information file generated or stored by a device. Building on the recently proposed Zero Trust score-based authorization framework (ZT-SAF), we develop the object-level Zero Trust score-based authorization framework for IoT systems, denoted as ZTA-IoT-OL-SAF, to govern access requests in this context. With this machinery in place, we finally develop a novel usage control model for users-to-objects and devices-to-objects interactions, denoted as UCON \\(_{IoT}\\) . We give formal definitions, illustrative use cases, and a proof-of-concept implementation of UCON \\(_{IoT}\\) . This article is a first step toward establishing a rigorous formally defined score-based access control framework for Zero Trust IoT systems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4399744879",
    "type": "article"
  },
  {
    "title": "Deepfake Detection Model Combining Texture Differences and Frequency Domain Information",
    "doi": "https://doi.org/10.1145/3706636",
    "publication_date": "2024-12-03",
    "publication_year": 2024,
    "authors": "S. S. Fang; Zhiyong Zhang; Bin Song",
    "corresponding_authors": "",
    "abstract": "In recent years, public security incidents caused by deepfake technology have occurred frequently around the world, which makes an efficient and accurate deepfake detection model crucial. The existing advanced methods use the manipulation features in the image to realize the binary classification of real and fake images by training complex neural network models. However, these models rely on a single manipulation feature, and the detection accuracy of these methods will be greatly reduced when the forgery technology or image quality of the training dataset and the validation dataset are different. Inspired by the existing work, we propose a two-stream collaborative learning framework that combines spatial texture differences and frequency information. The average difference convolution (ADC) is designed to extract the spatial texture difference information of the image, and the gray image frequency-aware decomposition (GFAD) is used to extract the artifact information of the image in the frequency domain. At the same time, the ViT idea is combined with cross-attention mechanism for feature fusion to comprehensively mine forged features in forged images. Experimental results show that the proposed model has good detection effects on three benchmark datasets. In terms of cross-dataset evaluation, the AUC on Celeb-DF dataset reaches 82.86%, which is better than the existing advanced methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4404970528",
    "type": "article"
  },
  {
    "title": "Don’t Trust the Cloud, Verify",
    "doi": "https://doi.org/10.1145/3079762",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Marcus Brandenburger; Christian Cachin; Nikola Knežević",
    "corresponding_authors": "",
    "abstract": "Cloud services have turned remote computation into a commodity and enable convenient online collaboration. However, they require that clients fully trust the service provider in terms of confidentiality, integrity, and availability. Toward reducing this dependency, this article introduces VICOS , a protocol for verification of integrity and consistency for cloud object storage that enables a group of mutually trusting clients to detect data integrity and consistency violations for a cloud object storage service. It aims at services where multiple clients cooperate on data stored remotely on a potentially misbehaving service. VICOS enforces the consistency notion of fork-linearizability, supports wait-free client semantics for most operations, and reduces the computation and communication overhead compared to previous protocols. VICOS is based on a generic authenticated data structure. Moreover, its operations cover the hierarchical name space of a cloud object store, supporting a real-world interface and not only a simplistic abstraction. A prototype of VICOS that works with the key-value store interface of commodity cloud storage services has been implemented, and an evaluation demonstrates its advantage compared to existing systems.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2740847423",
    "type": "article"
  },
  {
    "title": "Enhancing Branch Monitoring for Security Purposes",
    "doi": "https://doi.org/10.1145/3152162",
    "publication_date": "2018-01-02",
    "publication_year": 2018,
    "authors": "Marcus Botacin; Paulo Lício de Geus; André Grégio",
    "corresponding_authors": "",
    "abstract": "Malware and code-reuse attacks are the most significant threats to current systems operation. Solutions developed to countermeasure them have their weaknesses exploited by attackers through sandbox evasion and antidebug crafting. To address such weaknesses, we propose a framework that relies on the modern processors’ branch monitor feature to allow us to analyze malware while reducing evasion effects. The use of hardware assistance aids in increasing stealthiness, a key feature for debuggers, as modern software (malicious or benign) may be antianalysis armored. We achieve stealthier code execution control by using the branch monitor hardware’s inherent interrupt capabilities, keeping the code under execution intact. Previous works on branch monitoring have already addressed the ROP attack problem but require code injection and/or are limited in their capture window size. Therefore, we also propose a ROP detector without these limitations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2782227862",
    "type": "article"
  },
  {
    "title": "ANCHOR",
    "doi": "https://doi.org/10.1145/3301305",
    "publication_date": "2019-02-26",
    "publication_year": 2019,
    "authors": "Diego Kreutz; Jiangshan Yu; Fernando M. V. Ramos; Paulo Esteves-Veríssimo",
    "corresponding_authors": "",
    "abstract": "Software-defined networking (SDN) decouples the control and data planes of traditional networks, logically centralizing the functional properties of the network in the SDN controller. While this centralization brought advantages such as a faster pace of innovation, it also disrupted some of the natural defenses of traditional architectures against different threats. The literature on SDN has mostly been concerned with the functional side, despite some specific works concerning non-functional properties such as security or dependability. Though addressing the latter in an ad-hoc, piecemeal way may work, it will most likely lead to efficiency and effectiveness problems. We claim that the enforcement of non-functional properties as a pillar of SDN robustness calls for a systemic approach. We further advocate, for its materialization, the reiteration of the successful formula behind SDN: ‘logical centralization’. As a general concept, we propose anchor , a subsystem architecture that promotes the logical centralization of non-functional properties. To show the effectiveness of the concept, we focus on security in this article: we identify the current security gaps in SDNs and we populate the architecture middleware with the appropriate security mechanisms in a global and consistent manner. Essential security mechanisms provided by anchor include reliable entropy and resilient pseudo-random generators, and protocols for secure registration and association of SDN devices. We claim and justify in the article that centralizing such mechanisms is key for their effectiveness by allowing us to define and enforce global policies for those properties; reduce the complexity of controllers and forwarding devices; ensure higher levels of robustness for critical services; foster interoperability of the non-functional property enforcement mechanisms; and promote the security and resilience of the architecture itself. We discuss design and implementation aspects, and we prove and evaluate our algorithms and mechanisms, including the formalisation of the main protocols and the verification of their core security properties using the T amarin prover.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2963097227",
    "type": "article"
  },
  {
    "title": "Server Location Verification (SLV) and Server Location Pinning",
    "doi": "https://doi.org/10.1145/3139294",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "AbdelRahman Abdou; Paul C. van Oorschot",
    "corresponding_authors": "",
    "abstract": "We introduce the first known mechanism providing realtime server location verification. Its uses include enhancing server authentication by enabling browsers to automatically interpret server location information. We describe the design of this new measurement-based technique, Server Location Verification (SLV), and evaluate it using PlanetLab. We explain how SLV is compatible with the increasing trends of geographically distributed content dissemination over the Internet, without causing any new interoperability conflicts. Additionally, we introduce the notion of (verifiable) server location pinning (conceptually similar to certificate pinning) to support SLV, and evaluate their combined impact using a server-authentication evaluation framework. The results affirm the addition of new security benefits to the existing TLS-based authentication mechanisms. We implement SLV through a location verification service, the simplest version of which requires no server-side changes. We also implement a simple browser extension that interacts seamlessly with the verification infrastructure to obtain realtime server location-verification results.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2963557245",
    "type": "article"
  },
  {
    "title": "Friendly Fire",
    "doi": "https://doi.org/10.1145/3444963",
    "publication_date": "2021-04-01",
    "publication_year": 2021,
    "authors": "Musard Balliu; Massimo Merro; Michele Pasqua; Mikhail Shcherbakov",
    "corresponding_authors": "",
    "abstract": "IoT platforms enable users to connect various smart devices and online services via reactive apps running on the cloud. These apps, often developed by third-parties, perform simple computations on data triggered by external information sources and actuate the results of computations on external information sinks. Recent research shows that unintended or malicious interactions between the different (even benign) apps of a user can cause severe security and safety risks. These works leverage program analysis techniques to build tools for unveiling unexpected interference across apps for specific use cases. Despite these initial efforts, we are still lacking a semantic framework for understanding interactions between IoT apps. The question of what security policy cross-app interference embodies remains largely unexplored. This article proposes a semantic framework capturing the essence of cross-app interactions in IoT platforms. The framework generalizes and connects syntactic enforcement mechanisms to bisimulation-based notions of security, thus providing a baseline for formulating soundness criteria of these enforcement mechanisms. Specifically, we present a calculus that models the behavioral semantics of a system of apps executing concurrently, and use it to define desirable semantic policies targeting the security and safety of IoT apps. To demonstrate the usefulness of our framework, we define and implement static analyses for enforcing cross-app security and safety, and prove them sound with respect to our semantic conditions. We also leverage real-world apps to validate the practical benefits of our tools based on the proposed enforcement mechanisms.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3141835785",
    "type": "article"
  },
  {
    "title": "Two-factor Password-authenticated Key Exchange with End-to-end Security",
    "doi": "https://doi.org/10.1145/3446807",
    "publication_date": "2021-04-28",
    "publication_year": 2021,
    "authors": "Stanisław Jarecki; Mohammed Jubur; Hugo Krawczyk; Nitesh Saxena; Maliheh Shirvanian",
    "corresponding_authors": "",
    "abstract": "We present a secure two-factor authentication (TFA) scheme based on the user’s possession of a password and a crypto-capable device. Security is “end-to-end” in the sense that the attacker can attack all parts of the system, including all communication links and any subset of parties (servers, devices, client terminals), can learn users’ passwords, and perform active and passive attacks, online and offline. In all cases the scheme provides the highest attainable security bounds given the set of compromised components. Our solution builds a TFA scheme using any Device-enhanced Password-authenticated Key Exchange (PAKE), defined by Jarecki et al., and any Short Authenticated String (SAS) Message Authentication, defined by Vaudenay. We show an efficient instantiation of this modular construction, which utilizes any password-based client-server authentication method, with or without reliance on public-key infrastructure. The security of the proposed scheme is proven in a formal model that we formulate as an extension of the traditional PAKE model. We also report on a prototype implementation of our schemes, including TLS-based and PKI-free variants, as well as several instantiations of the SAS mechanism, all demonstrating the practicality of our approach. Finally, we present a usability study evaluating the viability of our protocol contrasted with the traditional PIN-based TFA approach in terms of efficiency, potential for errors, user experience, and security perception of the underlying manual process. 1",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3158726383",
    "type": "article"
  },
  {
    "title": "Optimal Packet Camouflage Against Traffic Analysis",
    "doi": "https://doi.org/10.1145/3442697",
    "publication_date": "2021-08-19",
    "publication_year": 2021,
    "authors": "Louma Chaddad; Ali Chehab; Imad H. Elhajj; Ayman Kayssi",
    "corresponding_authors": "",
    "abstract": "Research has proved that supposedly secure encrypted network traffic is actually threatened by privacy and security violations from many aspects. This is mainly due to flow features leaking evidence about user activity and data content. Currently, adversaries can use statistical traffic analysis to create classifiers for network applications and infer users’ sensitive data. In this article, we propose a system that optimally prevents traffic feature leaks. In our first algorithm, we model the packet length probability distribution of the source app to be protected and that of the target app that the source app will resemble. We define a model that mutates the packet lengths of a source app to those lengths from the target app having similar bin probability. This would confuse a classifier by identifying a mutated source app as the target app. In our second obfuscation algorithm, we present an optimized scheme resulting in a trade-off between privacy and complexity overhead. For this reason, we propose a mathematical model for network obfuscation. We formulate analytically the problem of selecting the target app and the length from the target app to mutate to. Then, we propose an algorithm to solve it dynamically. Extensive evaluation of the proposed models, on real app traffic traces, shows significant obfuscation efficiency with relatively acceptable overhead. We were able to reduce a classification accuracy from 91.1% to 0.22% using the first algorithm, with 11.86% padding overhead. The same classification accuracy was reduced to 1.76% with only 0.73% overhead using the second algorithm.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3195233401",
    "type": "article"
  },
  {
    "title": "Differentially Private Real-Time Release of Sequential Data",
    "doi": "https://doi.org/10.1145/3544837",
    "publication_date": "2022-06-23",
    "publication_year": 2022,
    "authors": "Xueru Zhang; Mohammad Mahdi Khalili; Mingyan Liu",
    "corresponding_authors": "",
    "abstract": "Many data analytics applications rely on temporal data, generated (and possibly acquired) sequentially for online analysis. How to release this type of data in a privacy-preserving manner is of great interest and more challenging than releasing one-time, static data. Because of the (potentially strong) temporal correlation within the data sequence, the overall privacy loss can accumulate significantly over time; an attacker with statistical knowledge of the correlation can be particularly hard to defend against. An idea that has been explored in the literature to mitigate this problem is to factor this correlation into the perturbation/noise mechanism. Existing work, however, either focuses on the offline setting (where perturbation is designed and introduced after the entire sequence has become available), or requires a priori information on the correlation in generating perturbation. In this study we propose an approach where the correlation is learned as the sequence is generated, and is used for estimating future data in the sequence. This estimate then drives the generation of the noisy released data. This method allows us to design better perturbation and is suitable for real-time operations. Using the notion of differential privacy, we show this approach achieves high accuracy with lower privacy loss compared to existing methods.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4283331487",
    "type": "article"
  },
  {
    "title": "“Sign in with ... <i>Privacy</i> ”: Timely Disclosure of Privacy Differences among Web SSO Login Options",
    "doi": "https://doi.org/10.1145/3711898",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Srivathsan G. Morkonda; Sonia Chiasson; Paul C. van Oorschot",
    "corresponding_authors": "",
    "abstract": "The number of login options on web sites has increased since the introduction of web single sign-on (SSO) protocols. Web SSO services allow users to grant web sites or relying parties (RPs) access to their personal profile information from identity provider (IdP) accounts. Many RP sites fail to provide sufficient privacy-related information to allow users to make informed login decisions. Moreover, privacy differences in permission requests across login options are largely hidden from users and are time-consuming to manually extract and compare. In this paper, we present an empirical analysis of popular RP implementations supporting three major IdP login options (Facebook, Google, and Apple) and categorize RPs in the top 500 sites into four client-side code patterns. Informed by these RP patterns, we design and implement SSOPrivateEye (SPEye), a browser extension prototype that extracts and displays to users permission request information from SSO login options in RPs covering the three IdPs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406220365",
    "type": "article"
  },
  {
    "title": "The Dark Side of Native Code on Android",
    "doi": "https://doi.org/10.1145/3712308",
    "publication_date": "2025-01-17",
    "publication_year": 2025,
    "authors": "Antonio Ruggia; Andrea Possemato; Savino Dambra; Alessio Merlo; Simone Aonzo; Davide Balzarotti",
    "corresponding_authors": "",
    "abstract": "From a little research experiment to an essential component of military arsenals, malicious software has constantly been growing and evolving for more than three decades. On the other hand, from a negligible market share, the Android operating system is nowadays the most widely used mobile operating system, becoming a desirable target for large-scale malware distribution. While scientific literature has followed this trend, one aspect has been understudied: the role of native code in malicious Android apps. Android apps are written in high-level languages, but thanks to the Java Native Interface (JNI), Android also supports calling native (C/C++) library functions. While allowing native code in Android apps has a strong positive impact from a performance perspective, it dramatically complicates its analysis because bytecode and native code need different abstractions and analysis algorithms, and they thus pose different challenges and limitations. Consequently, these difficulties are often (ab)used to hide malicious payloads. In this work, we propose a novel methodology to reverse engineering Android apps focusing on suspicious patterns related to native components, i.e., surreptitious code that requires further inspection. We implemented a static analysis tool based on such methodology, which can bridge the “Java” and the native worlds and perform an in-depth analysis of tag code blocks responsible for suspicious behavior. These tags benefit the human facing the reverse engineering task: they clearly indicate which part of the code to focus on to find malicious code. Then, we performed a longitudinal analysis of Android malware over the past ten years and compared the recent malicious samples with actual top apps on the Google Play Store. Our work depicts typical behaviors of modern malware, its evolution, and how it abuses the native layer to complicate the analysis, especially with dynamic code loading and novel anti-analysis techniques. Finally, we show a use case for our suspicious tags: we trained and tested a machine learning algorithm for a binary classification task. Even if suspicious does not imply malicious, our classifier obtained a remarkable F1-score of 0.97, showing that our methodology can be helpful to both humans and machines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406536165",
    "type": "article"
  },
  {
    "title": "Quantifying and Exploiting Adversarial Vulnerability: Gradient-Based Input Pre-Filtering for Enhanced Performance in Black-Box Attacks",
    "doi": "https://doi.org/10.1145/3716384",
    "publication_date": "2025-02-05",
    "publication_year": 2025,
    "authors": "Naveen Karunanayake; Bhanuka Silva; Yasod Ginige; Suranga Seneviratne; Sanjay Chawla",
    "corresponding_authors": "",
    "abstract": "We investigate the vulnerability of inputs in an adversarial setting and demonstrate that certain samples are more susceptible to adversarial perturbations compared to others. Specifically, we employ a simple yet effective approach to quantify the adversarial vulnerability of inputs, which relies on the clipped gradients of the loss with respect to the input. Our observations indicate that inputs with a low percentage of zero gradient components tend to be more vulnerable to attacks. These findings are supported by a theoretical explanation on a linear model and empirical evidence on deep neural networks. Across all datasets we tested, we find that inputs with the lowest zero gradient percentage, on average, exhibit 34.5% more susceptibility to adversarial attacks than randomly selected inputs. Additionally, we demonstrate that the zero gradient percentage, as a metric, transfers across different model architectures. Finally, we propose a novel black-box attack pipeline that enhances the efficiency of conventional query-based black-box attacks and show that input pre-filtering based on ZGP can boost the attack success rates, particularly under low perturbation levels. On average, across all datasets we test, our approach outperforms the conventional shadow model-based and query-based black-box attack pipelines by 44.9% and 30.4%, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407187497",
    "type": "article"
  },
  {
    "title": "Revisiting GPS Spoofing in Phasor Measurement: Real-World Exploitation and Practical Detection in Power Grids",
    "doi": "https://doi.org/10.1145/3720543",
    "publication_date": "2025-02-28",
    "publication_year": 2025,
    "authors": "Chunghyo Kim; Juhwan Noh; Esmaeil Ghahremani; Yongdae Kim",
    "corresponding_authors": "",
    "abstract": "Phasor Measurement Units (PMUs) are critical devices in modern power grids, providing precise voltage and current phasor measurements (synchrophasors) for real-time monitoring, fault detection, and stability assessment. While previous research suggested that arbitrary time manipulation through GPS spoofing could disrupt grid operations, our study reveals that successful attacks require specific conditions, contrary to earlier assumptions. Through careful analysis of the synchrophasor data specification (IEEE Standard C37.118.x), we demonstrate that arbitrary time manipulation does not directly lead to phase manipulation. Instead, arbitrary manipulations can cause GPS holdover (loss of lock), alert operators with erroneous timing, and ultimately invalidate the received synchrophasors. An experiment with a commercial PMU confirms our specification analysis. We identify the time spoofing conditions to avoid GPS holdover and discover that nanosecond-scale signal alignment (approximately 375 ns error) and gradual time manipulation (around 50 ns/s error) are required. Experiments on a commercial Wide Area Monitoring System (WAMS) testbed demonstrate that GPS spoofing meeting the identified criteria results in a 500-microsecond time error (10.8-degree phase error) after 12 hours without triggering alarms. Given that a 60-degree phase variation is considered a fault, triggering protection mechanisms, this GPS spoofing technique could potentially induce false faults within 70 hours. To counter this threat, we propose a practical method to distinguish GPS spoofing-induced false faults from actual faults caused by events like lightning strikes or ground shorts. Analysis of 10 real-world incidents from the past six months demonstrates that genuine faults consistently exhibit instantaneous phase variations within three electrical cycles, providing a basis for differentiation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408067309",
    "type": "article"
  },
  {
    "title": "Attack Detection Using Item Vector Shift in Matrix Factorisation Recommenders",
    "doi": "https://doi.org/10.1145/3721285",
    "publication_date": "2025-02-28",
    "publication_year": 2025,
    "authors": "Sulthana Shams; Douglas J. Leith",
    "corresponding_authors": "",
    "abstract": "This paper proposes a novel method for detecting shilling attacks in Matrix Factorization (MF)-based Recommender Systems (RS), in which attackers use false user-item feedback to promote a specific item. Unlike existing methods that use either use supervised learning to distinguish between attack and genuine profiles or analyse target item rating distributions to detect false ratings, our method uses an unsupervised technique to detect false ratings by examining shifts in item preference vectors that exploit rating deviations and user characteristics, making it a promising new direction. The experimental results demonstrate the effectiveness of our approach in various attack scenarios, including those involving obfuscation techniques.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408067479",
    "type": "article"
  },
  {
    "title": "Time Series Analysis Neural Networks for Detecting False Data Injection Attacks of Different Rates on Power Grid State Estimation",
    "doi": "https://doi.org/10.1145/3723164",
    "publication_date": "2025-03-16",
    "publication_year": 2025,
    "authors": "Danushka Senarathna; Spyros Tragoudas; Jason Wibbenmeyer; Nasser Khdeer",
    "corresponding_authors": "",
    "abstract": "False Data Injection Attacks (FDIAs) that target the state estimation pose an immense threat to the security of power grids. Deep Neural Network (DNN) based methods have shown promising results in detecting such FDIAs. Among existing state-of-the-art DNN models, time series analysis DNNs have demonstrated superior FDIA detection capability. This paper discusses the challenges associated with applying time series analysis DNNs for detecting FDIAs and emphasizes the impact of the attack rate on the detection rate of attacks. We demonstrate that existing time series analysis DNNs are highly vulnerable to FDIAs executed at low attack rates. This paper presents various alternative implementations for time series classifiers and time series predictors to improve the FDIA detection rate. A novel method is proposed to train time series classification neural networks to detect FDIAs of any attack rate with high efficiency. Subsequently, an enhanced FDIA detection framework that includes a time series classifier and multiple predictors is presented. Furthermore, an analytical criterion is derived to estimate the FDIA detection rate of time series analysis DNNs under any attack rate. Experimental results obtained on IEEE bus systems using state-of-the-art DNN architectures support the effectiveness of the proposed training method and the proposed framework. The proposed training method significantly improved the detection rate of FDIAs at low attack rates. Up to a 48% improvement in the FDIA detection rate was observed in the proposed framework when compared to the state-of-the-art.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408488648",
    "type": "article"
  },
  {
    "title": "A Secret Sharing-Inspired Robust Distributed Backdoor Attack to Federated Learning",
    "doi": "https://doi.org/10.1145/3725814",
    "publication_date": "2025-03-22",
    "publication_year": 2025,
    "authors": "Yuxin Yang; Qiang Li; Yuede Ji; Binghui Wang",
    "corresponding_authors": "",
    "abstract": "Federated Learning (FL) is vulnerable to backdoor attacks—especially distributed backdoor attacks (DBA) that are more persistent and stealthy than centralized backdoor attacks. However, we observe that the attack effectiveness of DBA can be largely reduced when encountering rebels, i.e., the agents promising to perform the attack, but do not do so. To robustify DBAs, we present SSRDBA , a secret sharing-inspired robust DBA to FL. To be specific, given a same global trigger as DBA, SSRDBA carefully divides it into different shares based on secret sharing and exploits these shares to poison local data on malicious devices, respectively. SSRDBA enjoys several merits, e.g., only partial malicious agents guarantee the reconstruction of the global trigger. Extensive experimental results show that SSRDBA is more robust to rebels than DBA and can evade the state-of-the-art FL defenses mainly for centralized backdoor attacks. To mitigate SSRDBA , we further design a novel defense mechanism, termed NFDR, which shows great potential against SSRDBA on certain independent identically distributed datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408723982",
    "type": "article"
  },
  {
    "title": "Site Inspector: Improving Browser Communication of Website Security Information",
    "doi": "https://doi.org/10.1145/3726867",
    "publication_date": "2025-04-01",
    "publication_year": 2025,
    "authors": "Eric Spero; Robert Biddle",
    "corresponding_authors": "",
    "abstract": "Phishing sites exploit users’ limited understanding of website identity to mimic legitimate sites. While X.509 certificates can provide crucial cues regarding a website’s identity, current browsers fail to effectively communicate this information to users, even as phishing becomes an increasingly serious issue. To address this, we developed Site Inspector (SI), a UI tool that conveys website identity and connection encryption information, along with brief explanations of the relevant underlying security concepts. SI is implemented as a Mozilla Firefox browser extension, but the basic design could be integrated into any web browser. SI organizes content in a three-tiered abstraction hierarchy, drawing on Ecological Interface Design. The top level presents an indicator of the website owner, if known, and also whether the connection is encrypted. The second and third levels offer progressively detailed explanations of the verification process. SI adheres to design principles aimed at educating users about security through the UI while overcoming associated challenges. Its text is concise and direct, respecting limitations in users’ attentional resources and motivation to engage with security matters. As a proof of concept for SI’s principled design, we conducted a user study with 30 participants to evaluate its effectiveness in helping users differentiate real from fraudulent websites. Results suggested that SI improved users’ ability to identify fraudulent sites. Future work will involve further testing with a larger user base, integrated SI directly into browsers, and ultimately a more widespread and improved validation process for certificates, with stronger verification and transparency",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409061996",
    "type": "article"
  },
  {
    "title": "Security Implications of the Morello Platform: An Empirical Threat Model-Based Analysis",
    "doi": "https://doi.org/10.1145/3728360",
    "publication_date": "2025-04-07",
    "publication_year": 2025,
    "authors": "Sami Ullah; Awais Rashid",
    "corresponding_authors": "",
    "abstract": "This paper explores the software security potential of ARM’s Morello experimental hardware platform, an embodiment of the Capability Hardware Enhanced RISC Instructions (CHERI) model. We navigate the intricacies of Morello adoption, uncovering both the promise and the challenges it presents for bolstering software security assurance. Employing the Juliet Test Suite, we conduct a rigorous security assessment of Morello’s operational modes — Purecap and Hybrid — shedding light on the ramifications for the software development lifecycle and assurance processes. Our findings affirm the robust spatial safety Morello confers, especially in its Purecap mode, while also underscoring the persisting temporal vulnerabilities in the CheriBSD version used in our experiments. We discuss the novel challenges associated with Morello adoption, including the management of CHERI violation exceptions, the imperative of software-hardware co-validation, and the specialized training requisites for development and assurance teams. We draw attention to potential risks, like crashes from CHERI violations potentially metamorphosing into Denial of Service (DoS) attacks. Transitioning to the Morello model could necessitate substantial alterations in software design principles, development methodologies, and security assurance protocols.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409212859",
    "type": "article"
  },
  {
    "title": "Behavior Nets: Context-Aware Behavior Modeling for Code Injection-Based Windows Malware",
    "doi": "https://doi.org/10.1145/3729228",
    "publication_date": "2025-04-10",
    "publication_year": 2025,
    "authors": "Jerre Starink; Marieke Huisman; Peter Andreas; Andrea Continella",
    "corresponding_authors": "",
    "abstract": "Despite significant effort put into research and development of defense mechanisms, new malware is continuously developed rapidly, making it still one of the major threats on the Internet. For malware to be successful, it is in the developer’s best interest to evade detection as long as possible. One method in achieving this is using Code Injection, where malicious code is injected into another benign process, making it do something it was not intended to do. Automated detection and characterization of Code Injection is difficult. Many injection techniques depend solely on system calls that in isolation look benign and can easily be confused with other background system activity. There is therefore a need for models that can consider the context in which a single system event resides, such that relevant activity can be distinguished easily. In previous work, we conducted the first systematic study on code injection to gain more insights into the different techniques available to malware developers on the Windows platform. This paper extends this work by introducing and formalizing Behavior Nets: A novel, reusable, context-aware modeling language that expresses malicious software behavior in observable events and their general interdependence. This allows for matching on system calls, even if those system calls are typically used in a benign context. We evaluate Behavior Nets and experimentally confirm that introducing event context into behavioral signatures yields better results in characterizing malicious behavior than state-of-the-art. We conclude with valuable insights on how future malware research based on dynamic analysis should be conducted.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409335556",
    "type": "article"
  },
  {
    "title": "Dimensional Robustness Certification for Deep Neural Networks in Network Intrusion Detection Systems",
    "doi": "https://doi.org/10.1145/3715121",
    "publication_date": "2025-04-16",
    "publication_year": 2025,
    "authors": "Mengdie Huang; Yingjun Lin; Xiaofeng Chen; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "Network intrusion detection systems based on deep learning are gaining significant traction in cyber security due to their high prediction accuracy and strong adaptability to evolving cyber threats. However, a serious drawback is their vulnerability to evasion attacks that rely on adversarial examples. To provide robustness guarantees for deep neural networks against any possible perturbations, certified defenses against perturbations within a l p -bounded region around the input are being increasingly explored. Unfortunately, unlike existing image domain approaches that concentrate on homogeneous input feature spaces, the progress on certified defense for the network traffic domain, which is characterized by heterogeneous features, has been very limited. To address such a gap, we present the design and practicality of a novel framework, Multi-order Adaptive Randomized Smoothing (MARS), for certifying the robustness of network intrusion detectors based on deep neural networks. Experiments on various network intrusion detection systems show that MARS significantly improves the tightness of robustness certification (12.23 \\(\\% \\) increase in l 2 certified radius), detection accuracy on evasion attack (7.17 \\(\\% \\) improvement on l ∞ -PGD, 10.11 \\(\\% \\) improvement on l 1 -EAD), and prediction accuracy on natural corruption (16.65 \\(\\% \\) enhancement on latency, 18.23 \\(\\% \\) enhancement on packet loss) compared to the SOTA method. We have also conducted an extensive analysis of the dimension-wise certified robustness of the network intrusion detector. The results indicate that the dimensional certified radii obtained using MARS reveal the robustness differences across feature dimensions, aligning with the empirical evaluation findings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409483265",
    "type": "article"
  },
  {
    "title": "Performance Enhancement of Intrusion Detection System in Cloud by Using Boruta Algorithm",
    "doi": "https://doi.org/10.1145/3736761",
    "publication_date": "2025-05-22",
    "publication_year": 2025,
    "authors": "Oumaima Lifandali; Zouhair Chiba; Noreddine Abghour; Khalid Moussaid; Mounia Miyara; Abdellah Ouaguid",
    "corresponding_authors": "",
    "abstract": "Presently, cloud computing stands as a dependable choice for enterprises seeking contemporary, adaptable IT solutions capable of managing vast volumes of business data. Its adoption holds the promise of enhancing operational efficiency and productivity. However, cloud computing remains a dynamic and evolving technology landscape, fraught with inherent security challenges. Malevolent actors perpetually scour for novel methodologies to compromise the integrity of data hosted within cloud environments. For instance, data theft, achieved through downloading or encrypting sensitive information, and Distributed Denial of Service (DDoS) assaults targeting cloud infrastructures, pose persistent threats. To address these pressing concerns, the solution outlined in this paper advocates for intrusion detection within cloud environments employing a plethora of classification algorithms. To ensure the precision of outcomes, the proposed approach incorporates the meticulous selection of pertinent attributes from the dataset, leveraging the Boruta algorithm. Our research has demonstrated that combining Boruta with classifiers yields impressive results, achieving a recall of 100% with KNN on the CICIDS 2017 dataset and a precision of 100% with Naive Bayes on the CICDDOS 2019 dataset. These results underscore the significant role of feature selection in enhancing detection performance, affirming its importance for achieving optimal results in intrusion detection systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410601012",
    "type": "article"
  },
  {
    "title": "Comprehensive Kernel Safety in the Spectre Era: Mitigations and Performance Evaluation",
    "doi": "https://doi.org/10.1145/3743678",
    "publication_date": "2025-06-12",
    "publication_year": 2025,
    "authors": "Davide Davoli; Martin Avanzini; Tamara Rezk",
    "corresponding_authors": "",
    "abstract": "The efficacy of address space layout randomization has been formally demonstrated in a shared-memory model by Abadi et al., contingent on specific assumptions about victim programs. However, modern operating systems, implementing layout randomization in the kernel, diverge from these assumptions and operate on a separate memory model with communication through system calls. In this work, we relax Abadi et al.’s language assumptions while demonstrating that layout randomization offers a comparable safety guarantee in a system with memory separation. However, in practice, speculative execution and side-channels are recognized threats to layout randomization. We show that kernel safety cannot be restored for attackers capable of using side-channels and speculative execution, and introduce enforcement mechanisms that can guarantee speculative kernel safety for safe system calls in the Spectre era. We implement three suitable mechanisms and we evaluate their performance overhead on the Linux kernel.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411242114",
    "type": "article"
  },
  {
    "title": "Breaking BLE MAC Address Randomization with Allowlist-Based Side Channels and its Countermeasure",
    "doi": "https://doi.org/10.1145/3744559",
    "publication_date": "2025-06-25",
    "publication_year": 2025,
    "authors": "Yue Zhang; Zhiqiang Lin",
    "corresponding_authors": "",
    "abstract": "Bluetooth Low Energy (BLE) is ubiquitous today. To prevent a BLE device (e.g., a smartphone) from being connected by unknown devices, it uses allowlisting to allow the connectivity from only recognized devices. Unfortunately, we show that this allowlist feature actually introduces a side channel for device tracking, since a device with the allowed list behaves differently even though it has used randomized MAC addresses. Even worse, we also find that the current MAC address randomization scheme specified in Bluetooth protocol is flawed, suffering from a replay attack with which an attacker can replay a sniffed MAC address to probe whether a targeted device will respond or not based on its allowlist. We have validated our allowlist-based side channel attacks with 43 BLE peripheral devices, 11 centrals, and 4 development boards, and found none of them once configured with allowlisting is immune to the proposed attacks. We advocate the use of an interval unpredictable, central and peripheral synchronized random MAC address randomization scheme to defeat passive device tracking (introducing 1% power consumption overhead for centrals and 6.75% for peripherals, and 88.49 μ s performance overhead for centrals and 94.46 μ s for peripherals), and the use of timestamps to derive randomized MAC addresses such that attackers can no longer be able to replay them to defeat active device tracking (introducing 3.04% overhead for peripherals, and 63.58 μ s and 20.54 μ s performance overhead for centrals and peripherals). Our field testing with a long range Bluetooth sniffer shows that 16, 422 of 100, 101 sniffed devices are subject to our BAT attacks. We have disclosed our findings to Bluetooth SIG and many other stakeholders in October 2020. Bluetooth SIG assigned CVE-2020-35473 to track this logical-level protocol flaw. Google assigned our findings as a high severity design flaw and awarded us with a bug bounty.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411652468",
    "type": "article"
  },
  {
    "title": "Assessing and Mitigating the Privacy Implications of Eye Tracking on Handheld Mobile Devices",
    "doi": "https://doi.org/10.1145/3746452",
    "publication_date": "2025-06-28",
    "publication_year": 2025,
    "authors": "Noora Alsakar; Norah Alotaibi; Mohamed Khamis; Simone Stumpf",
    "corresponding_authors": "",
    "abstract": "While gaze data brings benefits like allowing hands-free interaction, it can also reveal sensitive information about people, such as their gender, age, and geographical origin. Privacy leakage and safeguards have been explored for gaze data collected through headsets and stationary eye trackers, but never for gaze data collected through handheld mobile devices, like smartphones. Eye tracking on handheld mobile devices has the potential to be ubiquitous, but gaze data is typically of lower quality, compounded by additional noise and instability due to less controlled environments and screen size constraints. To address this gap, we provide the first evidence of privacy leakage through gaze data collected on handheld mobile devices. In a user study (N=35), we collected our novel SmartEyePhone dataset of gaze data using a smartphone’s front-facing camera. Second, we present the first evaluation and comparison of 3 Differential Privacy (DP) techniques against our dataset and the TüEyeQ dataset, which was collected in prior work using a stationary remote eye tracker. We found that SmartEyePhone dataset leaks on average 65.5% of private data. DP mechanisms reduce privacy leakage in our data by 22.33% using Laplace mechanism, 10.43% using Exponential mechanism, 22.60% using Gaussian mechanism, and 28.34% using AI model perturbation. However, this also reduces the accuracy of the main task prediction, and is impacted by the choice of privacy parameter values. We present insights on the trade-off between privacy preservation and the practical usefulness of gaze data. Our insights advance the understanding of privacy in mobile settings and pave the way for privacy preserving gaze-enabled handheld mobile devices.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411757492",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Training of Support Vector Machines via Secure Multiparty Computation",
    "doi": "https://doi.org/10.1145/3749373",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Daniel Francisco Jaramillo Jaramillo; Hernán Darío Vanegas Madrigal; Daniel Escudero; Fernando A. Morales",
    "corresponding_authors": "",
    "abstract": "The power and ubiquity of machine learning demand security measures for protecting sensitive data. Secure multiparty computation (MPC) techniques enable a group of parties to jointly compute a given function while keeping the information private. In this work, we engineer a prototype for privately training support vector machines (SVMs) using MPC techniques. We conduct an extensive study on how different approaches for training SVMs interact with existing state-of-the-art MPC protocols. We identify the least squares (LS) approach as the best suited for privately training. We then optimize fixed-point precision, ensuring accuracy while keeping low running time and communication. The technical details of the optimization involve bounds on the step size of a gradient method to solve a linear system, which might be of independent interest. We further propose and analyse different alternatives to improve the LS approach on an MPC implementation, and we compare their performance. The best improvement yields up to 2x reduction of the running time and communication complexity, without affecting the accuracy of the trained model. In order to illustrate the feasibility of our solution, we securely train SVMs for two realistic tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412577869",
    "type": "article"
  },
  {
    "title": "Cheesecloth: Zero-Knowledge Proofs of Real-World Vulnerabilities",
    "doi": "https://doi.org/10.1145/3747589",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Santiago Cuéllar Gempeler; Bill Harris; James Parker; Stuart Pernsteiner; Ian Sweet; Eran Tromer",
    "corresponding_authors": "",
    "abstract": "Currently, when a security analyst discovers a vulnerability in critical software system, they must navigate a fraught dilemma: immediately disclosing the vulnerability to the public could harm the system’s users; whereas disclosing the vulnerability only to the software’s vendor lets the vendor disregard or deprioritize the security risk, to the detriment of unwittingly-affected users. A compelling recent line of work aims to resolve this by using Zero Knowledge (ZK) protocols that let analysts prove that they know a vulnerability in a program, without revealing the details of the vulnerability or the inputs that exploit it. In principle, this could be achieved by generic ZK techniques. In practice, ZK vulnerability proofs to date have been restricted in scope and expressibility, due to challenges related to generating proof statements that model real-world software at scale and to directly formulating violated properties. This paper presents Cheesecloth , a novel proof-statement compiler, which proves practical vulnerabilities in ZK by soundly-but-aggressively preprocessing programs on public inputs, selectively revealing information about executed control segments, and formalizing information leakage using a novel storage-labeling scheme. Cheesecloth ’s practicality is demonstrated by generating ZK proofs of well-known vulnerabilities in (previous versions of) critical software, including the Heartbleed information leakage in OpenSSL, a memory vulnerability in the FFmpeg multimedia encoding framework, a cryptographic implementation bug in the Secure Scuttlebutt decentralised social network, and a denial of service vulnerability in OpenSSL.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412577907",
    "type": "article"
  },
  {
    "title": "MGAN: A Multi-view Graph Adaptive Network for Robust Malicious Traffic Detection",
    "doi": "https://doi.org/10.1145/3757741",
    "publication_date": "2025-07-31",
    "publication_year": 2025,
    "authors": "Ernest Akpaku; Jinfu Chen; Mukhtar Ahmed; Francis Kwadzo Agbenyegah; Joshua Ofoeda",
    "corresponding_authors": "",
    "abstract": "Detecting malicious network traffic in large-scale, dynamic environments presents a significant challenge due to the complexity of network relationships and the evolving nature of cyber threats. Existing graph-based and sequence-based models often fail to capture both spatial dependencies and temporal patterns effectively, resulting in suboptimal detection. This study introduces the Multi-view Graph Adaptive Network (MGAN), a novel framework that integrates multi-hop graph neural network (GNN) aggregation with transformer-based sequence modeling to address these challenges. MGAN captures long-range spatial dependencies and temporal dynamics in network traffic, enabling the detection of complex attack patterns. It incorporates Dirichlet sampling for robust neighbor selection in sparse and noisy data environments and mutual information maximization to align multi-view representations for consistency. Additionally, a multi-view attention mechanism aggregates information across different hops, balancing local and global network context. Extensive experiments on four real-world datasets demonstrate MGAN’s superiority over 7 baseline models, achieving an average F1-Score above 97%, surpassing the best baseline by 2.35%. MGAN maintains detection accuracy above 97% and remains robust under data sparsity, achieving F1-Scores over 95% even when 40% of connectivity information is removed. Under noisy conditions, MGAN retains accuracy above 93%, outperforming baselines by over 4.5%. In zero-day attack scenarios, it achieves detection rates exceeding 96% for previously unseen attack categories. MGAN also exhibits exceptional computational efficiency, processing 2,034 samples per second with a detection time of 3.00 milliseconds per sample, outperforming all competing models in both accuracy and speed.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412776987",
    "type": "article"
  },
  {
    "title": "IDPA: Indiscriminate Data Poisoning Attacks Targeting Pre-trained Encoder Based on Contrastive Learning",
    "doi": "https://doi.org/10.1145/3757916",
    "publication_date": "2025-08-01",
    "publication_year": 2025,
    "authors": "A. Hu; Zhiyong Zhang; Gaoyuan Quan; Xinxin Yue",
    "corresponding_authors": "",
    "abstract": "Indiscriminate data poisoning attacks are highly effective against unsupervised learning. However, recent studies show that contrastive learning is also susceptible to data poisoning attacks. As a form of data poisoning attack, the attacker adds poison to the clean pre-training dataset. This article proposes IDPA, an indiscriminate data poisoning attack targeting the encoder in contrastive learning. where the attacker’s goal is to directly poison the pre-trained encoder. The feature vectors of any clean sample and the attacked sample from the attacker will exhibit high similarity, causing the downstream classifier to misclassify the clean sample as the samples designated by the attacker. Therefore, this article formulates IDPA as a dual optimization problem and defines two loss functions: the attack effectiveness loss and the model utility loss. These losses are associated with effectively poisoning the pre-trained encoder and maintaining the accuracy of the downstream classifier, respectively. During training, the attack affects the contrastive learning algorithm and predictions are made on multiple datasets. Experimental results show that the attack success rate of 92%. This article evaluates the effectiveness of IDPA on the CLIP dataset released by OpenAI, with attack success rate of 88%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412841386",
    "type": "article"
  },
  {
    "title": "Generalizable Multi-Model Fusion for Multi-Class DoS Detection Using Cognitive Diversity and Rank-Score Analysis",
    "doi": "https://doi.org/10.1145/3749374",
    "publication_date": "2025-07-18",
    "publication_year": 2025,
    "authors": "Mohamed Rahouti; Dinesh Verma; Evans Owusu; Yufeng Xin; Daniel Hsu; Christina Schweikert",
    "corresponding_authors": "",
    "abstract": "Detecting and mitigating Denial-of-Service (DoS) attacks is crucial for ensuring the availability and security of online services. While various machine learning (ML) models have been utilized for DoS attack detection, there is a need for innovative approaches to improving their performance, especially for the more challenging multi-class detection problem. In this paper, we propose adopting a cutting-edge approach called Combinatorial Fusion Analysis (CFA), which leverages a recently developed framework to combine multiple ML models for improved DoS attack detection. Our methodology involves advanced score combination, rank combination, weighted combination techniques, and the diversity strength of scoring systems. Through rigorous performance evaluations, we showcase the efficacy of the combinatorial fusion approach. Our evaluations encompass key metrics such as detection precision, recall, and F1-score, providing comprehensive insights into the interpretability and effectiveness of our approach. We highlight the challenge faced by individual models in classifying low-profiled attacks, while excelling in other attack types. To overcome this limitation, model fusion techniques were used to create a comprehensive model capable of addressing both low-profiled attacks and other traffic types. Furthermore, our findings highlight the potential of this approach for enhancing DoS attack detection capabilities and contributing to the development of more robust defense mechanisms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413060438",
    "type": "article"
  },
  {
    "title": "Swarm: A Distributed Ledger-based Framework to Enhance Air Traffic Control Security Using ADS-B Protocol",
    "doi": "https://doi.org/10.1145/3759456",
    "publication_date": "2025-08-13",
    "publication_year": 2025,
    "authors": "Gabriele Digregorio; Edoardo Saputelli; Stefano Longari; Michele Carminati; Stefano Zanero",
    "corresponding_authors": "",
    "abstract": "In aviation, safety is paramount, with air traffic control (ATC) playing a crucial role in monitoring aircraft to prevent collisions and manage traffic flows. In response to increasing air traffic, a renewal process has been initiated. This includes deploying the automatic dependent surveillance-broadcast (ADS-B) communications protocol, which aims to enhance surveillance precision and increase the number of aircraft that can be handled simultaneously. This transition is transforming ATC from a radar-based system to a more advanced satellite-based global positioning system (GPS) location tracking system. However, due to its inherently open design, the ADS-B protocol lacks critical security features such as authentication, necessitating the adoption of additional security measures to mitigate potential cyber-attacks. To address these vulnerabilities, this work introduces Swarm, an innovative distributed ledger-based framework, built on top of the ADS-B protocol and aimed at enhancing the security of air traffic control (ATC) while avoiding single points of failure. Swarm can be integrated into existing ATC infrastructure without requiring any modifications to the ADS-B protocol. We evaluate Swarm through rigorous and realistic attack scenarios, using real-world aviation data, demonstrating its capability to enhance the security of the aviation domain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413167397",
    "type": "article"
  },
  {
    "title": "Incentivizing Secure Software Development: The Role of Voluntary Audit and Liability Waiver",
    "doi": "https://doi.org/10.1145/3765287",
    "publication_date": "2025-08-30",
    "publication_year": 2025,
    "authors": "Ziyuan Huang; Gergely Biczók; Mingyan Liu",
    "corresponding_authors": "",
    "abstract": "Misaligned incentives in secure software development have long been a challenge in security economics. Product liability, a powerful legal framework in other industries, has been largely ineffective for software products until recent times. However, the rapid regulatory responses to recent global cyber attacks by both the US and EU, together with the (relative) success of the General Data Protection Regulation in defining both duty and standard of care for software vendors, may enable regulators to use liability to re-align incentives for the benefit of the digital society. The United States National Cybersecurity Strategy suggests shifting responsibility for cyber incidents back to software vendors and proposes the concept of the liability waiver: if a software company voluntarily undergoes and passes an IT security audit, its future product liability is (fully or partially) waived. This paper examines this audit-liability framework from both vendor and auditor perspectives. For vendors, we model the decision process as a sequential problem: a vendor must pass an audit to release a product and can attempt the audit multiple times. We show that the optimal strategy for an opt-in vendor is to never quit and to exert cumulative investments in either a “one-and-done” or “incremental” manner. For auditors, we explore how to design audits that encourage voluntary participation while maximizing vendor effort. We further investigate dynamic audit designs that can amplify vendors’ cumulative investments in security. Our findings provide insights into how liability waivers and audit strategies can re-align incentives, fostering a more secure digital ecosystem.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413843745",
    "type": "article"
  },
  {
    "title": "Highliner: Enhancing Binary Analysis through NLP-Based Instruction-Level Detection of C++ Inline Functions",
    "doi": "https://doi.org/10.1145/3765521",
    "publication_date": "2025-09-02",
    "publication_year": 2025,
    "authors": "Lorenzo Dall'Aglio; Lorenzo Binosi; Michele Carminati; Stefano Zanero; Mario Polino",
    "corresponding_authors": "",
    "abstract": "The complexities introduced by compiler optimization have long stood as a significant obstacle in binary analysis and reverse engineering. Function inlining, in particular, complicates function recognition by replacing function calls with the entire body of the callee, mixing code from multiple functions. State-of-the-art approaches can identify inlined functions at basic block granularity, but cannot determine which instructions belong to each function and precisely deduce inlined boundaries. Without this information, further analyses such as decompilation cannot be performed effectively. This paper presents Highliner, a novel approach that improves state-of-the-art approaches by identifying inline instances at instruction-level granularity. Highliner operates downstream of block-level detectors: given basic blocks reported by state-of-the-art approaches as belonging to a specific inlined function, it labels each instruction as Inlined or Not inlined and recovers the inlined-function boundaries. We treat the problem as a sequence tagging task typical of NLP and implement a learning-based technique involving instruction embedding and recurrent neural networks. We compile a dataset of open-source projects with different optimizations and use the DWARF debug information standard to construct labeled sequences of inline instructions. We use this dataset to train, validate, and test a sequence labeling architecture in which instructions are encoded via the pre-trained assembly language transformer PalmTree and then processed by an RNN-based classifier to produce binary predictions. When evaluated as a binary classifier, Highliner achieves an F1-score of 0.94 overall. In addition, when specifically tested on recognizing function boundaries, Highliner achieves an Accuracy of 0.82 on initial boundaries and 0.83 on final boundaries.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413931710",
    "type": "article"
  },
  {
    "title": "Evaluating Honeyfile Realism and Enticement Metrics",
    "doi": "https://doi.org/10.1145/3763792",
    "publication_date": "2025-09-18",
    "publication_year": 2025,
    "authors": "Roelien C. Timmer; David Liebowitz; ‪Surya Nepal‬; Salil S. Kanhere",
    "corresponding_authors": "",
    "abstract": "Deceptive files, often called honeyfiles, have become an established tool in cyber security. Advances in machine learning (ML) models for content generation now allow the synthesis of deceptive material automatically and at scale. Metrics to quantify honeyfile attributes are thus essential to creating and evaluating effective deceptions. The two critical aspects of honeyfiles for which metrics are useful are enticement and realism . Enticement is the ability to attract the attention of intruders or users with malicious intent. Realism measures the similarity of deceptive artefacts to the objects they mimic. In the honeyfile literature, metrics for these attributes have been proposed: the Common Token Count (CTC) [1], and Topic Semantic Matching (TSM) [2] scores for enticement, and coherence and cohesion [3] for realism. In this study, we compare these metrics to the perceptions of human users exposed to text samples in a simulated data breach scenario on a crowd-sourcing platform. We recruited participants to judge the realism and enticement of honeyfile text generated using several techniques. The main findings are: (i) for the enticement metrics, TSM is aligned with the perceived enticement (p-value&lt;0.001), while for the CTC score, we find inconsistent and inconclusive results, and (ii) for the realism metrics, cohesion and coherence, do not consistently align with perceived realism.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414343920",
    "type": "article"
  },
  {
    "title": "SatIQ: Extensible and Stable Satellite Authentication using Hardware Fingerprinting",
    "doi": "https://doi.org/10.1145/3768619",
    "publication_date": "2025-09-18",
    "publication_year": 2025,
    "authors": "Joshua Smailes; Sebastian Köhler; Simon Birnbach; Martin Strohmeier; Ivan Martinović",
    "corresponding_authors": "",
    "abstract": "As satellite systems become a greater part of critical infrastructure, they have become a significantly more appealing target for attacks. The availability of cheap off-the-shelf radio hardware has made signal spoofing and physical layer attacks more accessible than ever to a wide range of adversaries, from hobbyists to nation-state actors. Legacy systems are particularly vulnerable due to their lack of cryptographic security, and cannot be patched to support novel security measures. In this paper we use radio transmitter fingerprinting to authenticate satellite downlinks, using characteristics of the transmitter hardware expressed as impairments on the physical layer radio signal. Our SatIQ system employs a Siamese neural network and an autoencoder to extract an efficient encoding of message headers that preserves identifying information. We focus on high sample rate fingerprinting, making device fingerprints difficult to forge without similarly high sample rate transmitting hardware. We collected 10 290 000 messages from the Iridium satellite constellation at 25 MS/s, and demonstrate that the SatIQ model trained on this data maintains performance over time without retraining, and can be used on new transmitters with no impact on performance. We analyze the system’s robustness against weather and signal factors, and demonstrate its effectiveness under attack, achieving an Equal Error Rate of 0.072 and ROC AUC of 0.960. We conclude that our techniques are useful for building fingerprinting systems that are effective at authenticating satellite communication, maintain performance over time and across satellite replacement, and provide robustness against spoofing and replay by raising the required budget for attacks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414343936",
    "type": "article"
  },
  {
    "title": "Efficient Privacy-Preserving Conjunctive Searchable Encryption for Cloud-IoT Healthcare Systems",
    "doi": "https://doi.org/10.1145/3769425",
    "publication_date": "2025-09-26",
    "publication_year": 2025,
    "authors": "Jianfeng Ma; Tianqi Peng; Bei Gong; Muhammad Waqas; Hisham Alasmary; Sheng Chen",
    "corresponding_authors": "",
    "abstract": "In cloud-Internet of Things (IoT) healthcare systems, private medical data leakage is a serious concern as the cloud server is not fully trusted. Dynamic searchable symmetric encryption (DSSE), with necessary forward and backward privacy security properties, enables doctors to retrieve ciphertexts while guaranteeing data privacy. However, existing forward and backward private DSSE schemes are not well-suited for cloud-IoT healthcare systems with attribute-value type databases. To this end, we propose an efficient privacy-preserving conjunctive searchable encryption scheme for cloud-IoT healthcare systems, called PC-SE. It is the first conjunctive DSSE scheme designed for attribute-value type databases. Specifically, we design flexible search capabilities for PC-SE to address users’ various search requirements. It can not only achieve precise conjunctive search based on keywords but also realize broad attribute search. Moreover, our scheme achieves fine-grained search for attribute values while maintaining forward and Type-I − backward privacy. This approach reduces the communication burden and minimizes the risk of privacy exposure. To ensure that users with different authorities can only access the corresponding attribute values, we introduce an attribute access control mechanism in PC-SE. Finally, security analysis and experimental results demonstrate that PC-SE is secure and effective.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414556781",
    "type": "article"
  },
  {
    "title": "Payload-Aware Intrusion Detection with CMAE and Large Language Models",
    "doi": "https://doi.org/10.1145/3769682",
    "publication_date": "2025-09-27",
    "publication_year": 2025,
    "authors": "Y. Kim; Chanjae Lee; Young Yoon",
    "corresponding_authors": "",
    "abstract": "Intrusion Detection Systems (IDS) play a vital role in network security, yet signature-based methods are limited by high false positive rates (FPR) and inability to detect novel threats. Recent AI-based approaches offer improved adaptability, but most rely on flow-level or statistical features, constraining their ability to analyze sophisticated payload-based attacks. To address these challenges, we present a dual-path IDS framework: Xavier-CMAE, a lightweight model using Hex2Int tokenization and Xavier initialization, achieves 99.9718% accuracy and a 0.0182% FPR without pre-training; and LLM-CMAE, which leverages pre-trained LLM tokenizers for enhanced detection, achieves 99.9696% accuracy and a 0.0194% FPR at higher computational cost. Experimental results on the CIC-IDS2017 dataset reveal a distinct trade-off between efficiency and Contextually Adept and Scalable (CAS) power, indicating that a modular approach may enable both real-time scalability and in-depth threat analysis. This work advances AI-powered intrusion detection by (1) introducing a modular, payload-centric dual-path architecture that combines lightweight and CAS detection for adaptive, layered security; (2) demonstrating that Xavier-CMAE achieves real-time scalability and state-of-the-art accuracy without embedding pre-training; and (3) exploring the effectiveness and future potential of integrating pre-trained LLM tokenizers for nuanced, selective threat analysis and robust IDS design.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414575228",
    "type": "article"
  },
  {
    "title": "Dynamic Privacy-preserving Identity Generation from Fingerprint Sensor Data for Secure Applications",
    "doi": "https://doi.org/10.1145/3769862",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Priyabrata Dash; Fagul Pandey; Monalisa Sarma; Debasis Samanta",
    "corresponding_authors": "",
    "abstract": "In secure sensor-based applications, generating unique and secure credentials is crucial for ensuring trust and privacy. Traditionally, pseudo-random number generators have been used for this purpose. However, biometric data, especially fingerprint features, has emerged as a robust alternative. This paper proposes a dynamic approach for generating a privacy-preserving unique identity from fingerprint sensor data. The method isolates a region of interest (ROI) from the fingerprint image and extracts two feature sets: minutiae-based data and texture-based information. These features are combined and optimized to produce a hybrid feature vector containing discriminative and relevant attributes. A unique identity (termed a key) is then dynamically generated from this vector, characterized by reliability, revocability, unlinkability, and irreversibility. Extensive evaluations using fingerprint images from sensors of varying quality and resolution have demonstrated the method’s robustness. The generated identities have been statistically validated using NIST and Diehard test suites, confirming strong adherence to randomness requirements. Also, comprehensive security analyses have shown resilience against different adversarial attacks. Notably, the approach avoids storing biometric data or generated identities, enhancing privacy protection. These features make the proposed method ideal for secure sensor-based applications such as authentication, data storage security, and digital signature schemes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414665249",
    "type": "article"
  },
  {
    "title": "Efficient Authorization of Graph-database Queries in an Attribute-supporting ReBAC Model",
    "doi": "https://doi.org/10.1145/3401027",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Syed Zain R. Rizvi; Philip W. L. Fong",
    "corresponding_authors": "",
    "abstract": "Neo4j is a popular graph database that offers two versions: an enterprise edition and a community edition . The enterprise edition offers customizable Role-based Access Control features through custom developed procedures , while the community edition does not offer any access control support. Being a graph database, Neo4j appears to be a natural application for Relationship-Based Access Control (ReBAC), an access control paradigm where authorization decisions are based on relationships between subjects and resources in the system (i.e., an authorization graph). In this article, we present AReBAC, an attribute-supporting ReBAC model for Neo4j that provides finer-grained access control by operating over resources instead of procedures. AReBAC employs Nano-Cypher, a declarative policy language based on Neo4j’s Cypher query language, the result of which allows us to weave database queries with access control policies and evaluate both simultaneously. Evaluating the combined query and policy produces a result that (i) matches the search criteria, and (ii) the requesting subject is authorized to access. AReBAC is accompanied by the algorithms and their implementation required for the realization of the presented ideas, including GP-Eval, a query evaluation algorithm. We also introduce Live-End Backjumping (LBJ), a backtracking scheme that provides a significant performance boost over conflict-directed backjumping for evaluating queries. As demonstrated in our previous work, the original version of GP-Eval already performs significantly faster than the Neo4j’s Cypher evaluation engine. The optimized version of GP-Eval , which employs LBJ, further improves the performance significantly, thereby demonstrating the capabilities of the technique.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3039186344",
    "type": "article"
  },
  {
    "title": "The Seven Deadly Sins of the HTML5 WebAPI",
    "doi": "https://doi.org/10.1145/3403947",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Michalis Diamantaris; Francesco Marcantoni; Sotiris Ioannidis; Jason Polakis",
    "corresponding_authors": "",
    "abstract": "Modern smartphone sensors can be leveraged for providing novel functionality and greatly improving the user experience. However, sensor data can be misused by privacy-invasive or malicious entities. Additionally, a wide range of other attacks that use mobile sensor data have been demonstrated; while those attacks have typically relied on users installing malicious apps, browsers have eliminated that constraint with the deployment of HTML5 WebAPI. In this article, we conduct a comprehensive evaluation of the multifaceted threat that mobile web browsing poses to users by conducting a large-scale study of mobile-specific HTML5 WebAPI calls across more than 183K of the most popular websites. We build a novel testing infrastructure consisting of actual smartphones on top of a dynamic Android app analysis framework, allowing us to conduct an end-to-end exploration. In detail, our system intercepts and tracks data access in real time, from the WebAPI JavaScript calls down to the Android system calls. Our study reveals the extent to which websites are actively leveraging the WebAPI for collecting sensor data, with 2.89% of websites accessing at least one sensor. To provide a comprehensive assessment of the risks of this emerging practice, we create a taxonomy of sensor-based attacks from prior studies and present an in-depth analysis by framing our collected data within that taxonomy. We find that 1.63% of websites can carry out at least one attack and emphasize the need for a standardized policy across all browsers and the ability for users to control what sensor data each website can access.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3039204255",
    "type": "article"
  },
  {
    "title": "On the Security and Usability Implications of Providing Multiple Authentication Choices on Smartphones",
    "doi": "https://doi.org/10.1145/3410155",
    "publication_date": "2020-08-25",
    "publication_year": 2020,
    "authors": "Geumhwan Cho; Jun Ho Huh; Soolin Kim; Junsung Cho; Heesung Park; Yenah Lee; Konstantin Beznosov; Hyoungshick Kim",
    "corresponding_authors": "",
    "abstract": "The latest smartphones have started providing multiple authentication options including PINs, patterns, and passwords (knowledge based), as well as face, fingerprint, iris, and voice identification (biometric-based). In this article, we conducted two user studies to investigate how the convenience and security of unlocking phones are influenced by the provision of multiple authentication options. In a task-based user study with 52 participants, we analyze how participants choose an option to unlock their smartphone in daily life. The user study results demonstrate that providing multiple biometric-based authentication choices does not really influence convenience, because fingerprint had monopolistic dominance in the usage of unlock methods (111 of a total of 115 unlock trials that used a biometric-based authentication factor) due to users’ habitual behavior and fastness in unlocking phones. However, convenience was influenced by the provision of both knowledge-based and biometric-based authentication categories, as biometric-based authentication options were used in combination with knowledge-based authentication options—pattern was another frequently used unlock method. Our findings were confirmed and generalized through a follow-up survey with 327 participants. First, knowledge-based and biometric-based authentication options are used interchangeably. Second, providing multiple authentication options for knowledge-based authentication may influence convenience—both PINs (55.7%) and patterns (39.2%) are quite evenly used. Last, in contrast to knowledge-based authentication, providing multiple authentication choices for biometric-based authentication has less influence on choosing unlock options—fingerprint scanner is the most frequently used option (134 of 187 unlock methods used among biometric-based authentication options).",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3081539385",
    "type": "article"
  },
  {
    "title": "Formal Analysis of Mobile Multi-Factor Authentication with Single Sign-On Login",
    "doi": "https://doi.org/10.1145/3386685",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Giada Sciarretta; Roberto Carbone; Silvio Ranise; Luca Viganò",
    "corresponding_authors": "",
    "abstract": "Over the last few years, there has been an almost exponential increase in the number of mobile applications that deal with sensitive data, such as applications for e-commerce or health. When dealing with sensitive data, classical authentication solutions based on username-password pairs are not enough, and multi-factor authentication solutions that combine two or more authentication factors of different categories are required instead. Even if several solutions are currently used, their security analyses have been performed informally or semiformally at best, and without a reference model and a precise definition of the multi-factor authentication property. This makes a comparison among the different solutions both complex and potentially misleading. In this article, we first present the design of two reference models for native applications based on the requirements of two real-world use-case scenarios. Common features between them are the use of one-time password approaches and the support of a single sign-on experience. Then, we provide a formal specification of our threat model and the security goals, and discuss the automated security analysis that we performed. Our formal analysis validates the security goals of the two reference models we propose and provides an important building block for the formal analysis of different multi-factor authentication solutions.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3033229503",
    "type": "article"
  },
  {
    "title": "The System That Cried Wolf",
    "doi": "https://doi.org/10.1145/3393926",
    "publication_date": "2020-06-12",
    "publication_year": 2020,
    "authors": "Hocheol Shin; Juhwan Noh; Do-Hyun Kim; Yongdae Kim",
    "corresponding_authors": "",
    "abstract": "Fire alarm and signaling systems are a networked system of fire detectors, fire control units, automated fire extinguishers, and fire notification appliances. Malfunction of these safety-critical cyber-physical systems may lead to chaotic evacuations, property damage, and even loss of human life. Therefore, reliability is one of the most crucial factors for fire detectors. Indeed, even a single report of a fire cannot be ignored, considering the importance of early fire detection and suppression. In this article, we show that wide-area smoke detectors, which are globally installed in critical infrastructures such as airports, sports facilities, and auditoriums, have significant vulnerabilities in terms of reliability; one can remotely and stealthily induce false fire alarms and suppress real fire alarms with a minimal attacker capability using simple equipment. The practicality and generalizability of these vulnerabilities has been assessed based on the demonstration of two types of sensor attacks on two commercial off-the-shelf optical beam smoke detectors from different manufacturers. Further, the practical considerations of building stealthy attack equipment has been analyzed, and an extensive survey of almost all optical beam smoke detectors on the market has been conducted. In addition, we show that the current standards of the fire alarm network connecting the detector and a control unit exacerbate the problem, making it impossible or very difficult to mitigate the threats we found. Finally, we discuss hardware- and software-based possible countermeasures for both wide-area smoke detectors and the fire alarm network; the effectiveness of one of the countermeasures is experimentally evaluated.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3044518720",
    "type": "article"
  },
  {
    "title": "Formal Modelling and Automated Trade-off Analysis of Enforcement Architectures for Cryptographic Access Control in the Cloud",
    "doi": "https://doi.org/10.1145/3474056",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Stefano Berlato; Roberto Carbone; Adam J. Lee; Silvio Ranise",
    "corresponding_authors": "",
    "abstract": "To facilitate the adoption of cloud by organizations, Cryptographic Access Control (CAC) is the obvious solution to control data sharing among users while preventing partially trusted Cloud Service Providers (CSP) from accessing sensitive data. Indeed, several CAC schemes have been proposed in the literature. Despite their differences, available solutions are based on a common set of entities—e.g., a data storage service or a proxy mediating the access of users to encrypted data—that operate in different (security) domains—e.g., on-premise or the CSP. However, the majority of these CAC schemes assumes a fixed assignment of entities to domains; this has security and usability implications that are not made explicit and can make inappropriate the use of a CAC scheme in certain scenarios with specific trust assumptions and requirements. For instance, assuming that the proxy runs at the premises of the organization avoids the vendor lock-in effect but may give rise to other security concerns (e.g., malicious insiders attackers). To the best of our knowledge, no previous work considers how to select the best possible architecture (i.e., the assignment of entities to domains) to deploy a CAC scheme for the trust assumptions and requirements of a given scenario. In this article, we propose a methodology to assist administrators in exploring different architectures for the enforcement of CAC schemes in a given scenario. We do this by identifying the possible architectures underlying the CAC schemes available in the literature and formalizing them in simple set theory. This allows us to reduce the problem of selecting the most suitable architectures satisfying a heterogeneous set of trust assumptions and requirements arising from the considered scenario to a decidable Multi-objective Combinatorial Optimization Problem (MOCOP) for which state-of-the-art solvers can be invoked. Finally, we show how we use the capability of solving the MOCOP to build a prototype tool assisting administrators to preliminarily perform a “What-if” analysis to explore the trade-offs among the various architectures and then use available standards and tools (such as TOSCA and Cloudify) for automated deployment in multiple CSPs.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3215837761",
    "type": "article"
  },
  {
    "title": "Vulnerabilities of Unattended Face Verification Systems to Facial Components-based Presentation Attacks: An Empirical Study",
    "doi": "https://doi.org/10.1145/3491199",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Le Qin; Fei Peng; Min Long; Raghavendra Ramachandra; Christoph Busch",
    "corresponding_authors": "",
    "abstract": "As face presentation attacks (PAs) are realistic threats for unattended face verification systems, face presentation attack detection (PAD) has been intensively investigated in past years, and the recent advances in face PAD have significantly reduced the success rate of such attacks. In this article, an empirical study on a novel and effective face impostor PA is made. In the proposed PA, a facial artifact is created by using the most vulnerable facial components, which are optimally selected based on the vulnerability analysis of different facial components to impostor PAs. An attacker can launch a face PA by presenting a facial artifact on his or her own real face. With a collected PA database containing various types of artifacts and presentation attack instruments (PAIs), the experimental results and analysis show that the proposed PA poses a more serious threat to face verification and PAD systems compared with the print, replay, and mask PAs. Moreover, the generalization ability of the proposed PA and the vulnerability analysis with regard to commercial systems are also investigated by evaluating unknown face verification and real-world PAD systems. It provides a new paradigm for the study of face PAs.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3217669900",
    "type": "article"
  },
  {
    "title": "Information Leakage Games: Exploring Information as a Utility Function",
    "doi": "https://doi.org/10.1145/3517330",
    "publication_date": "2022-04-09",
    "publication_year": 2022,
    "authors": "Mário S. Alvim; Konstantinos Chatzikokolakis; Yusuke Kawamoto; Catuscia Palamidessi",
    "corresponding_authors": "",
    "abstract": "A common goal in the areas of secure information flow and privacy is to build effective defenses against unwanted leakage of information. To this end, one must be able to reason about potential attacks and their interplay with possible defenses. In this paper, we propose a game-theoretic framework to formalize strategies of attacker and defender in the context of information leakage, and provide a basis for developing optimal defense methods. A novelty of our games is that their utility is given by information leakage, which in some cases may behave in a non-linear way. This causes a significant deviation from classic game theory, in which utility functions are linear with respect to players' strategies. Hence, a key contribution of this paper is the establishment of the foundations of information leakage games. We consider two kinds of games, depending on the notion of leakage considered. The first kind, the QIF-games, is tailored for the theory of quantitative information flow (QIF). The second one, the DP-games, corresponds to differential privacy (DP).",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3114739256",
    "type": "article"
  },
  {
    "title": "A Novel Cross-Network Embedding for Anchor Link Prediction with Social Adversarial Attacks",
    "doi": "https://doi.org/10.1145/3548685",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Huanran Wang; Wu Yang; Wei Wang; Dapeng Man; Jiguang Lv",
    "corresponding_authors": "",
    "abstract": "Anchor link prediction across social networks plays an important role in multiple social network analysis. Traditional methods rely heavily on user privacy information or high-quality network topology information. These methods are not suitable for multiple social networks analysis in real-life. Deep learning methods based on graph embedding are restricted by the impact of the active privacy protection policy of users on the graph structure. In this paper, we propose a novel method which neutralizes the impact of users’ evasion strategies. First, graph embedding with conditional estimation analysis is used to obtain a robust embedding vector space. Secondly, cross-network features space for supervised learning is constructed via the constraints of cross-network feature collisions. The combination of robustness enhancement and cross-network feature collisions constraints eliminate the impact of evasion strategies. Extensive experiments on large-scale real-life social networks demonstrate that the proposed method significantly outperforms the state-of-the-art methods in terms of precision, adaptability, and robustness for the scenarios with evasion strategies.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4285727651",
    "type": "article"
  },
  {
    "title": "ThermoSecure: Investigating the Effectiveness of AI-Driven Thermal Attacks on Commonly Used Computer Keyboards",
    "doi": "https://doi.org/10.1145/3563693",
    "publication_date": "2022-09-15",
    "publication_year": 2022,
    "authors": "Norah Alotaibi; John Williamson; Mohamed Khamis",
    "corresponding_authors": "",
    "abstract": "Thermal cameras can reveal heat traces on user interfaces, such as keyboards. This can be exploited maliciously to infer sensitive input, such as passwords. While previous work considered thermal attacks that rely on visual inspection of simple image processing techniques, we show that attackers can perform more effective artificial intelligence (AI)–driven attacks. We demonstrate this by presenting the development of ThermoSecure and its evaluation in two user studies (N = 21, N = 16), which reveal novel insights about thermal attacks. We detail the implementation of ThermoSecure and make a dataset of 1,500 thermal images of keyboards with heat traces resulting from input publicly available. Our first study shows that ThermoSecure successfully attacks 6-symbol, 8-symbol, 12-symbol, and 16-symbol passwords with an average accuracy of 92%, 80%, 71%, and 55% respectively, and even higher accuracy when thermal images are taken within 30 seconds. We found that typing behavior significantly impacts vulnerability to thermal attacks: hunt-and-peck typists are more vulnerable than fast typists (92% vs. 83% thermal attack success. respectively, if performed within 30 seconds). The second study showed that keycap material has a statistically significant effect on the effectiveness of thermal attacks: ABS keycaps retain the thermal trace of user presses for a longer period of time, making them more vulnerable to thermal attacks, with a 52% average attack accuracy compared with 14% for keyboards with PBT keycaps. Finally, we discuss how systems can leverage our results to protect from thermal attacks and present 7 mitigation approaches that are based on our results and previous work.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4296130367",
    "type": "article"
  },
  {
    "title": "Automated Security Assessments of Amazon Web Services Environments",
    "doi": "https://doi.org/10.1145/3570903",
    "publication_date": "2022-11-09",
    "publication_year": 2022,
    "authors": "Viktor Engström; Pontus Johnson; Robert Lagerström; Erik Ringdahl; Max Wällstedt",
    "corresponding_authors": "",
    "abstract": "Migrating enterprises and business capabilities to cloud platforms like Amazon Web Services (AWS) has become increasingly common. However, securing cloud operations, especially at large scales, can quickly become intractable. Customer-side issues such as service misconfigurations, data breaches, and insecure changes are prevalent. Furthermore, cloud-specific tactics and techniques paired with application vulnerabilities create a large and complex search space. Various solutions and modeling languages for cloud security assessments exist. However, no single one appeared sufficiently cloud-centered and holistic. Many also did not account for tactical security dimensions. This article, therefore, presents a domain-specific modeling language for AWS environments. When used to model AWS environments, manually or automatically, the language automatically constructs and traverses attack graphs to assess security. Assessments, therefore, require minimal security expertise from the user. The modeling language was primarily tested on four third-party AWS environments through securiCAD Vanguard, a commercial tool built around the AWS modeling language. The language was validated further by measuring performance on models provided by anonymous end users and a comparison with a similar open source assessment tool. As of March 2020, the modeling language could represent essential AWS structures, cloud tactics, and threats. However, the tests highlighted certain shortcomings. Data collection steps, such as planted credentials, and some missing tactics were obvious. Nevertheless, the issues covered by the DSL were already reminiscent of common issues with real-world precedents. Future additions to attacker tactics and addressing data collection should yield considerable improvements.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4308731708",
    "type": "article"
  },
  {
    "title": "Balancing Security and Privacy in Genomic Range Queries",
    "doi": "https://doi.org/10.1145/3575796",
    "publication_date": "2022-12-09",
    "publication_year": 2022,
    "authors": "Seoyeon Hwang; Ercan Ozturk; Gene Tsudik",
    "corresponding_authors": "",
    "abstract": "Exciting recent advances in genome sequencing, coupled with greatly reduced storage and computation costs, make genomic testing increasingly accessible to individuals. Already today, one’s digitized DNA can be easily obtained from a sequencing lab and later used to conduct numerous tests by engaging with a testing facility. Due to the inherent sensitivity of genetic material and the often-proprietary nature of genomic tests, privacy is a natural and crucial issue. While genomic privacy received a great deal of attention within and outside the research community, genomic security has not been sufficiently studied. This is surprising since the usage of fake or altered genomes can have grave consequences, such as erroneous drug prescriptions and genetic test outcomes. Unfortunately, in the genomic domain, privacy and security (as often happens) are at odds with each other. In this article, we attempt to reconcile security with privacy in genomic testing by designing a novel technique for a secure and private genomic range query protocol between a genomic testing facility and an individual user. The proposed technique ensures authenticity and completeness of user-supplied genomic material while maintaining its privacy by releasing only the minimum thereof. To confirm its broad usability, we show how to apply the proposed technique to a previously proposed genomic private substring matching protocol. Experiments show that the proposed technique offers good performance and is quite practical. Furthermore, we generalize the genomic range query problem to sparse integer sets and discuss potential use cases.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4310916456",
    "type": "article"
  },
  {
    "title": "<scp>B</scp> <sup>3</sup> : Backdoor Attacks against Black-box Machine Learning Models",
    "doi": "https://doi.org/10.1145/3605212",
    "publication_date": "2023-06-22",
    "publication_year": 2023,
    "authors": "Xueluan Gong; Yanjiao Chen; Wenbin Yang; Huayang Huang; Qian Wang",
    "corresponding_authors": "",
    "abstract": "Backdoor attacks aim to inject backdoors to victim machine learning models during training time, such that the backdoored model maintains the prediction power of the original model towards clean inputs and misbehaves towards backdoored inputs with the trigger. The reason for backdoor attacks is that resource-limited users usually download sophisticated models from model zoos or query the models from MLaaS rather than training a model from scratch, thus a malicious third party has a chance to provide a backdoored model. In general, the more precious the model provided (i.e., models trained on rare datasets), the more popular it is with users. In this article, from a malicious model provider perspective, we propose a black-box backdoor attack, named B 3 , where neither the rare victim model (including the model architecture, parameters, and hyperparameters) nor the training data is available to the adversary. To facilitate backdoor attacks in the black-box scenario, we design a cost-effective model extraction method that leverages a carefully constructed query dataset to steal the functionality of the victim model with a limited budget. As the trigger is key to successful backdoor attacks, we develop a novel trigger generation algorithm that intensifies the bond between the trigger and the targeted misclassification label through the neuron with the highest impact on the targeted label. Extensive experiments have been conducted on various simulated deep learning models and the commercial API of Alibaba Cloud Compute Service. We demonstrate that B 3 has a high attack success rate and maintains high prediction accuracy for benign inputs. It is also shown that B 3 is robust against state-of-the-art defense strategies against backdoor attacks, such as model pruning and NC.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4381612381",
    "type": "article"
  },
  {
    "title": "Multi-agent Deep Reinforcement Learning-based Key Generation for Graph Layer Security",
    "doi": "https://doi.org/10.1145/3711900",
    "publication_date": "2025-01-14",
    "publication_year": 2025,
    "authors": "Liang Wang; Zi‐Jie Wei; Weisi Guo",
    "corresponding_authors": "",
    "abstract": "Recently, the emergence of Internet of Things (IoT) devices has posed a challenge for securing information and avoiding attacks. Most of the cryptography solutions are based on physical layer security (PLS), whose idea is to fully exploit the properties of wireless channel state information (CSI) for generating symmetric keys between two communication nodes. However, accurate channel estimation is vulnerable for attackers and relies on powerful signal processing capability, which is not suitable for low-power IoT devices. In this paper, we expect to apply graph layer security (GLS) to exploit the common features of physical dynamics detected by IoT sensors placed in networked systems to generate keys for data encryption and decryption, which we believe is a new frontier to security for both industry and academic research. We propose a distributed key generation algorithm based on multi-agent deep reinforcement learning (MADRL) approach, which enables communication nodes to cooperatively generate symmetric keys based on their locally detected physical dynamics (e.g., water/gas/oil/electrical pressure/flow/voltage) with low computational complexity and without information exchange. In order to demonstrate the feasibility, we conduct and evaluate our key generation algorithm in both a simulated and real water distribution network. The experimental results show that the proposed algorithm has considerable performance in terms of randomness, bit agreement rate (BAR), etc.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406371438",
    "type": "article"
  },
  {
    "title": "PredicTor: A Global, Machine Learning Approach to Tor Path Selection",
    "doi": "https://doi.org/10.1145/3723356",
    "publication_date": "2025-03-13",
    "publication_year": 2025,
    "authors": "Armon Barton; Timothy Walsh; Mohsen Imani; Jiang Ming; Matthew Wright",
    "corresponding_authors": "",
    "abstract": "Tor users derive anonymity in part from the size of the Tor user base, but Tor struggles to attract and support more users due to performance limitations. Previous works have proposed modifications to Tor’s path selection algorithm to enhance both performance and security, but many proposals have unintended consequences due to incorporating information related to client location. We instead propose selecting paths using a global view of the network, independent of client location, and we propose doing so with a machine learning classifier to predict the performance of a given path before building a circuit. We show through a variety of simulated and live experimental settings, across different time periods, that this approach can significantly improve performance compared to Tor’s default path selection algorithm and two previously proposed approaches. In addition to evaluating the security of our approach with traditional metrics, we propose a novel anonymity metric that captures information leakage resulting from location-aware path selection, and we show that our path selection approach leaks no more information than the default path selection algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408413231",
    "type": "article"
  },
  {
    "title": "Beyond the Screen: Exploring Privacy Boundaries through Automated User Profiling",
    "doi": "https://doi.org/10.1145/3725813",
    "publication_date": "2025-03-22",
    "publication_year": 2025,
    "authors": "Jean Mouchotte; Maxence Delong; Layth Sliman",
    "corresponding_authors": "",
    "abstract": "Social Media Intelligence (SOCMINT) is widely used for gathering sensitive information about individuals, companies, or organizations, fueling potential attacks. This study highlights the inadequacy of current privacy protection measures and proposes an automated, sustainable approach to correlate user profiles, including homonyms and pseudonyms, solely through publicly available data. A sustainable method presents a solution to bypass API privatization and anti-scraping measures for data collection and formatting, emphasizing data correlation and the creation of cross-referenced dictionaries. Aggregated data enables indirect correlations, enhancing accuracy and relevance compared to existing methods. The purpose of this study is to create a self-learning knowledge base that addresses acronyms, homonyms, and pseudonyms while incorporating context to establish deeper connections between data. Comparisons will account for contextual relevance rather than relying solely on distances or metrics. Despite challenges posed by GDPR implementation and diminishing exploitable data, analysis of a database containing 7,600 accounts from major social platforms reveals over 90% accuracy in user-to-profile associations with 30% of homonyms and unpredictable pseudonyms or usernames. Notably, the study unveils the feasibility of retrieving information from private profiles solely through the application of dictionaries. If privacy limits on social networks, a cautionary note highlights the emphasis on the passive role of users in extensive data dissemination by governance structures and the necessity to create solutions to ensure end-to-end privacy data protection.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408723959",
    "type": "article"
  },
  {
    "title": "CBDRA-IS: Centrality-Based Defense Resource Allocation for Securing Interdependent Systems",
    "doi": "https://doi.org/10.1145/3736760",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Mohammad Ryiad Al-Eiadeh; Mustafa Abdallah",
    "corresponding_authors": "",
    "abstract": "Interdependent systems, with multiple interconnected assets, face escalating cybersecurity threats from external attackers. This paper explores security decision-making, operating on complex interdependent systems and proposes a security resource allocation methodology to enhance their proactive security. Using attack graphs, we model vulnerabilities and propose different defense mechanisms integrating different network analysis algorithms, including degree, betweenness, and harmonic centralities, TrustRank, and Katz centrality. We introduce Average Based Node Ranking (ABNR) to average ranks from these methods. The resource allocation methods leverage four different graph-theoretic methods. Each ranking algorithm is combined with these four allocation techniques. Our methods show low sensitivity to simultaneous attacks on interdependent systems. We validate our framework using eleven attack graphs representing real-world systems, measuring security improvements against four well-known allocation algorithms: behavioral decision-making, defense-in-depth, risk-based defense and min-cut. Our framework outperformed the baselines in most cases, with superior outcomes confirmed by the Friedman statistical test. We show that the main components in our framework have low-time overhead. We also evaluate our framework against multi-stage attacks and cascading failures Our framework enhances security decision-making across different scenarios, including top-1 and all attack paths for different attacks. We release the the implementation of our resource allocation methodology to the research community.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410623898",
    "type": "article"
  },
  {
    "title": "FairQuanti: Enhancing Fairness in Deep Neural Network Quantization via Neuron Role Contribution",
    "doi": "https://doi.org/10.1145/3744560",
    "publication_date": "2025-06-16",
    "publication_year": 2025,
    "authors": "Jinyin Chen; Zhiqi Cao; Xiaojuan Wang; Haibin Zheng; Zhaoyan Ming; Yayu Zheng",
    "corresponding_authors": "",
    "abstract": "The increasing complexity of deep neural networks (DNNs) poses significant resource challenges for edge devices, prompting the development of compression technologies like model quantization. However, while improving model efficiency, quantization can introduce or perpetuate the original model’s bias. Existing debiasing methods for quantized models often incur additional costs. To address this issue, we propose FairQuanti , a novel quantization approach that leverages neuron role contribution to achieve fairness. By distinguishing between biased and normal neurons, FairQuanti employs mixed precision quantization to mitigate model bias during the quantization process. FairQuanti has four key differences from previous studies: (1) Neuron Roles - It formally defines biased and normal neuron roles, establishing a framework for feasible model quantization and bias mitigation; (2) Effectiveness - It introduces a fair quantization strategy that discriminatively quantizes neuron roles, balancing model accuracy and fairness through Bayesian optimization; (3) Generality - It applies to both structured and unstructured data across various quantization bit levels; (4) Robustness - It demonstrates resilience against adaptive attacks. Extensive experiments on five datasets (three structured and two unstructured) using five different models validate FairQuanti ’s superior performance against eight baseline methods. Specifically, fairness metrics such as demographic parity (DP) improve by approximately 1.03 times, and the demographic parity ratio (DPR) improves by approximately 1.51 times compared to the baselines, with an average accuracy loss of less than 7.5% at 8-bit quantization. FairQuanti presents a promising solution for deploying fair and efficient deep models on resource-constrained devices and holds potential for application in large language models to reduce size and computational demands while minimizing bias. Our source code is available at https://github.com/Caozq2/FairQuanti.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411350623",
    "type": "article"
  },
  {
    "title": "Adaptive Network Intrusion Detection Using Reinforcement Learning with Proximal Policy Optimization",
    "doi": "https://doi.org/10.1145/3764586",
    "publication_date": "2025-08-28",
    "publication_year": 2025,
    "authors": "Akshaya Suresh; Arun Cyril Jose",
    "corresponding_authors": "",
    "abstract": "In an increasingly digital and interconnected world, the need for robust network intrusion detection systems is crucial to ensure cybersecurity. This paper presents a novel approach to network intrusion detection that integrates both traditional machine learning methods and advanced reinforcement learning techniques to enhance detection capabilities and accuracy. The proposed system uses Proximal Policy Optimization, a reinforcement learning algorithm, to dynamically adjust ensemble weights, thereby optimizing the contributions of base learners, such as Random Forest and CatBoost. Additionally, a Multi-layer Perceptron-based meta-learner is employed to refine the predictions, leading to an overall improvement in detection performance. The model was evaluated on five diverse datasets, including NSL-KDD, CICIDS, TON IoT, DDoS, and UNSW-NB15, achieving an average accuracy of 97.16%, and an average precision, recall, and F1-score of 97% across all datasets. The proposed work is compared with the existing state-of-the-art detection methods demonstrating its better performance in detecting both known and novel attack types. Furthermore, the integration of reinforcement learning allowed for dynamic and context-sensitive decision-making, enabling the system to handle complex attack patterns that traditional models struggle with. The training and validation results across all datasets showed rapid convergence and minimal overfitting, further supporting the model’s robustness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413792329",
    "type": "article"
  },
  {
    "title": "Rectifying Multi-Attack Adversarial Perturbations in Deep Neural Network based Image Classifier",
    "doi": "https://doi.org/10.1145/3765757",
    "publication_date": "2025-09-03",
    "publication_year": 2025,
    "authors": "Yulong Wang; Jiaxuan Song; Tianxiang Li; Xin Yuan; Hong Li; Ni Wei",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) for image classification remain vulnerable to adversarial perturbations—subtle input manipulations that induce catastrophic misclassifications. To address this issue, we propose the Adversarial Image Rectifier (AIR), a linguistically inspired detection and mitigation framework that enhances DNN robustness by intercepting and inverting adversarial perturbations at the feature level. Unlike existing defenses, AIR operates without prior knowledge of attack patterns: it first encodes hierarchical hidden-layer feature maps of a DNN into semantically structured sentence representations, then identifies adversarial inputs through ”sentiment” anomalies in these sentences—a linguistic metaphor for subtle adversarial traces. Crucially, we pinpoint a pivotal intermediate layer where adversarial perturbations dominantly propagate and train a lightweight rectifier network to selectively nullify adversarial features at this layer while preserving benign semantics. Extensive experiments on Tiny-ImageNet, CIFAR-10, SVHN, and MS COCO demonstrate that AIR achieves a correction rate of up to 95.02% and 94.62% when defending against known attacks and unknown attacks, respectively, significantly surpassing existing defense techniques.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413941654",
    "type": "article"
  },
  {
    "title": "VPT: Privacy Preserving Energy Trading and Block Mining Mechanism for Blockchain Based Virtual Power Plants",
    "doi": "https://doi.org/10.1145/3767163",
    "publication_date": "2025-09-11",
    "publication_year": 2025,
    "authors": "Muneeb Ul Hassan; Mubashir Husain Rehmani; Jinjun Chen",
    "corresponding_authors": "",
    "abstract": "The desire to overcome reliability issues of the distributed energy resources (DERs) led researchers to develop a novel concept named virtual power plant (VPP). VPPs are supposed to carry out intelligent and secure energy trading among prosumers, buyers, and generating stations along with providing efficient energy management. Therefore, integrating blockchain within a decentralized VPP network emerged as a novel paradigm. However, this decentralization also suffers with trust, reliability, energy management, and efficiency issues due to DERs dynamic nature. Thus, in this paper, we first work to provide an efficient energy management strategy for VPPs to enhance demand response, then we propose an energy oriented trading and block mining protocol and name it as P roof o f E nergy M arket (PoEM). To enhance it further, we integrate differential privacy in PoEM and propose a P rivate PoEM (PPoEM) model. Collectively, we propose a private decentralized VPP trading model and named it as V irtual P rivate T rading (VPT). We further carry out extensive theoretical analysis and derive step-by-step valuations for market race probability, market stability probability, energy trading expectation, winning state probability, and prospective leading-time profit values. Afterwards, we carry out simulation-based experiments of our proposed model to show the effectiveness and novelty as compared to state-of-the-art works.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414128156",
    "type": "article"
  },
  {
    "title": "GradCAM-AE: A New Shield Defense against Poisoning Attacks on Federated Learning",
    "doi": "https://doi.org/10.1145/3765743",
    "publication_date": "2025-09-12",
    "publication_year": 2025,
    "authors": "Jingjing Zheng; Kai Li; Xin Yuan; Wei Ni; Eduardo Tovar; Özgür B. Akan",
    "corresponding_authors": "",
    "abstract": "Recent poisoning attacks on federated learning (FL) generate malicious model updates that circumvent widely adopted Euclidean distance-based detection methods. This paper proposes a new defense mechanism, namely, GradCAM-AE, against model poisoning attacks on FL, which integrates Gradient-weighted Class Activation Mapping (GradCAM) and autoencoder (AE) to offer a substantially more powerful detection capability compared to existing Euclidean distance-based approaches. Particularly, GradCAM-AE generates a heat map for each uploaded local model update, transforming each local model update into a lower-dimensional, visual representation. An autoencoder further reprojects the GradCAM heat maps of all local module updates with improved distinguishability, thereby accentuating the hidden features of the heat maps and increasing the success rate of identifying anomalous heat maps and malicious local models. A comprehensive evaluation of the proposed GradCAM-AE framework is conducted using the CIFAR-10 and GTSRB datasets under both Independent and Identically Distributed (IID) and Non-IID settings. The ResNet-18 and MobileNetV3-Large models are tested. The results substantiate that GradCAM-AE offers superior detection rates and test accuracy of FL global model, juxtaposed with contemporary state-of-the-art methods. Our code is available at: https://github.com/jjzgeeks/GradCAM-AE",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414593562",
    "type": "article"
  },
  {
    "title": "Toward a Robust Detection of PowerShell Malware against Code Mixing and Obfuscation by Using Sentence Transformer and Similarity Learning",
    "doi": "https://doi.org/10.1145/3771542",
    "publication_date": "2025-10-09",
    "publication_year": 2025,
    "authors": "Zhiwei Fu; Leo Song; Steven H. H. Ding; Furkan Alaca; Sweta Acharya",
    "corresponding_authors": "",
    "abstract": "Embedded PowerShell commands or scripts are among the most popular malware payloads. For malware that prioritizes stealthiness, such as fileless malware, PowerShell’s access to Windows API functions without additional libraries makes it useful for evading detection. Detecting malicious PowerShell scripts and commands is an open challenge for proactive endpoint protection due to three major issues: 1) The malicious commands are usually hidden in a long script beyond the processing limit of typical machine learning models. 2) They are usually mixed with bulky benign scripts. 3) Script obfuscation can easily conceal their potential matching signatures. In this article, we introduce a novel model addressing these challenges. It incorporates similarity learning, sentence transformer, sliding window method, and stochastic gradient descent (SGD) classifier. Our key insight is that malicious PowerShell code, particularly when obfuscated, exhibits semantic and statistical deviations from benign administrative usage, and these deviations can be captured by contrastive sentence embeddings without the need for de-obfuscation or handcrafted features. We operate this insight through a Siamese similarity learning framework that improves robustness against Out-of-Vocabulary tokens due to unseen code obfuscation methods. The sliding window method enables the model to handle long scripts, and the SGD classifier evaluates segment-level maliciousness. Our model achieves accuracies of 99.01%, 97.59%, 98.70%, and 99.73% across multiple obfuscated and mixed script benchmarks, outperforming existing baselines by over 30% in all cases. This work demonstrates a scalable and effective strategy for robust PowerShell malware detection in real-world scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414982131",
    "type": "article"
  },
  {
    "title": "Characterizing the Security of the SMS Ecosystem with Public Gateways",
    "doi": "https://doi.org/10.1145/3268932",
    "publication_date": "2018-12-10",
    "publication_year": 2018,
    "authors": "Bradley Reaves; Luis Vargas; Nolen Scaife; Dave Tian; Logan Blue; Patrick Traynor; Kevin Butler",
    "corresponding_authors": "",
    "abstract": "Recent years have seen the Short Message Service (SMS) become a critical component of the security infrastructure, assisting with tasks including identity verification and second-factor authentication. At the same time, this messaging infrastructure has become dramatically more open and connected to public networks than ever before. However, the implications of this openness, the security practices of benign services, and the malicious misuse of this ecosystem are not well understood. In this article, we provide a comprehensive longitudinal study to answer these questions, analyzing over 900,000 text messages sent to public online SMS gateways over the course of 28 months. From this data, we uncover the geographical distribution of spam messages, study SMS as a transmission medium of malicious content, and find that changes in benign and malicious behaviors in the SMS ecosystem have been minimal during our collection period. The key takeaways of this research show many services sending sensitive security-based messages through an unencrypted medium, implementing low entropy solutions for one-use codes, and behaviors indicating that public gateways are primarily used for evading account creation policies that require verified phone numbers. This latter finding has significant implications for combating phone-verified account fraud and demonstrates that such evasion will continue to be difficult to detect and prevent.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2905568113",
    "type": "article"
  },
  {
    "title": "Alpha-Beta Privacy",
    "doi": "https://doi.org/10.1145/3289255",
    "publication_date": "2019-01-22",
    "publication_year": 2019,
    "authors": "Sebastian Mödersheim; Luca Viganò",
    "corresponding_authors": "",
    "abstract": "The formal specification of privacy goals in symbolic protocol models has proved to be not quite trivial so far. The most widely used approach in formal methods is based on the static equivalence of frames in the applied pi-calculus, basically asking whether or not the intruder is able to distinguish two given worlds. But then a subtle question emerges: How can we be sure that we have specified all pairs of worlds to properly reflect our intuitive privacy goal? To address this problem, we introduce in this article a novel and declarative way to specify privacy goals, called (α, β)-privacy. This new approach is based on specifying two formulae α and β in first-order logic with Herbrand universes, where α reflects the intentionally released information and β includes the actual cryptographic (“technical”) messages the intruder can see. Then (α, β)-privacy means that the intruder cannot derive any “nontechnical” statement from β that he cannot derive from α already. We describe by a variety of examples how this notion can be used in practice. Even though (α, β)-privacy does not directly contain a notion of distinguishing between worlds, there is a close relationship to static equivalence of frames that we investigate formally. This allows us to justify (and criticize) the specifications that are currently used in verification tools and obtain a decision procedure for a large fragment of (α, β)-privacy.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2914152958",
    "type": "article"
  },
  {
    "title": "Database Audit Workload Prioritization via Game Theory",
    "doi": "https://doi.org/10.1145/3323924",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Chao Yan; Bo Li; Yevgeniy Vorobeychik; Áron Lászka; Daniel Fabbri; Bradley Malin",
    "corresponding_authors": "",
    "abstract": "The quantity of personal data that is collected, stored, and subsequently processed continues to grow rapidly. Given its sensitivity, ensuring privacy protections has become a necessary component of database management. To enhance protection, a number of mechanisms have been developed, such as audit logging and alert triggers, which notify administrators about suspicious activities. However, this approach is limited. First, the volume of alerts is often substantially greater than the auditing capabilities of organizations. Second, strategic attackers can attempt to disguise their actions or carefully choose targets, thus hide illicit activities. In this article, we introduce an auditing approach that accounts for adversarial behavior by (1) prioritizing the order in which types of alerts are investigated and (2) providing an upper bound on how much resource to allocate for each type. Specifically, we model the interaction between a database auditor and attackers as a Stackelberg game. We show that even a highly constrained version of such problem is NP-Hard. Then, we introduce a method that combines linear programming, column generation, and heuristic searching to derive an auditing policy. On the synthetic data, we perform an extensive evaluation on the approximation degree of our solution with the optimal one. The two real datasets, (1) 1.5 months of audit logs from Vanderbilt University Medical Center and (2) a publicly available credit card application dataset, are used to test the policy-searching performance. The findings demonstrate the effectiveness of the proposed methods for searching the audit strategies, and our general approach significantly outperforms non-game-theoretic baselines.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2950266870",
    "type": "article"
  },
  {
    "title": "Skype &amp; Type",
    "doi": "https://doi.org/10.1145/3365366",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Stefano Cecconello; Alberto Compagno; Mauro Conti; Daniele Lain; Gene Tsudik",
    "corresponding_authors": "",
    "abstract": "Voice-over-IP (VoIP) software are among the most widely spread and pervasive software, counting millions of monthly users. However, we argue that people ignore the drawbacks of transmitting information along with their voice, such as keystroke sounds—as such sound can reveal what someone is typing on a keyboard. In this article, we present and assess a new keyboard acoustic eavesdropping attack that involves VoIP, called Skype &amp; Type ( S&amp;T ). Unlike previous attacks, S&amp;T assumes a weak adversary model that is very practical in many real-world settings. Indeed, S&amp;T is very feasible, as it does not require (i) the attacker to be physically close to the victim (either in person or with a recording device) and (ii) precise profiling of the victim’s typing style and keyboard; moreover, it can work with a very small amount of leaked keystrokes. We observe that leakage of keystrokes during a VoIP call is likely, as people often “multi-task” during such calls. As expected, VoIP software acquires and faithfully transmits all sounds, including emanations of pressed keystrokes, which can include passwords and other sensitive information. We show that one very popular VoIP software (Skype) conveys enough audio information to reconstruct the victim’s input—keystrokes typed on the remote keyboard. Our results demonstrate that, given some knowledge on the victim’s typing style and keyboard model, the attacker attains top-5 accuracy of 91.7% in guessing a random key pressed by the victim. This work extends previous results on S&amp;T , demonstrating that our attack is effective with many different recording devices (such as laptop microphones, headset microphones, and smartphones located in proximity of the target keyboard), diverse typing styles and speed, and is particularly threatening when the victim is typing in a known language.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2996019764",
    "type": "article"
  },
  {
    "title": "AutoProfile: Towards Automated Profile Generation for Memory Analysis",
    "doi": "https://doi.org/10.1145/3485471",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Fabio Pagani; Davide Balzarotti",
    "corresponding_authors": "",
    "abstract": "Despite a considerable number of approaches that have been proposed to protect computer systems, cyber-criminal activities are on the rise and forensic analysis of compromised machines and seized devices is becoming essential in computer security. This article focuses on memory forensics, a branch of digital forensics that extract artifacts from the volatile memory. In particular, this article looks at a key ingredient required by memory forensics frameworks: a precise model of the OS kernel under analysis, also known as profile . By using the information stored in the profile, memory forensics tools are able to bridge the semantic gap and interpret raw bytes to extract evidences from a memory dump. A big problem with profile-based solutions is that custom profiles must be created for each and every system under analysis. This is especially problematic for Linux systems, because profiles are not generic : they are strictly tied to a specific kernel version and to the configuration used to build the kernel. Failing to create a valid profile means that an analyst cannot unleash the true power of memory forensics and is limited to primitive carving strategies. For this reason, in this article we present a novel approach that combines source code and binary analysis techniques to automatically generate a profile from a memory dump, without relying on any non-public information. Our experiments show that this is a viable solution and that profiles reconstructed by our framework can be used to run many plugins, which are essential for a successful forensics investigation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3216796243",
    "type": "article"
  },
  {
    "title": "CBAs: Character-level Backdoor Attacks against Chinese Pre-trained Language Models",
    "doi": "https://doi.org/10.1145/3678007",
    "publication_date": "2024-08-16",
    "publication_year": 2024,
    "authors": "Xiquan He; Fengrui Hao; Tianlong Gu; Liang Chang",
    "corresponding_authors": "",
    "abstract": "Pre-trained language models (PLMs) aim to assist computers in various domains to provide natural and efficient language interaction and text processing capabilities. However, recent studies have shown that PLMs are highly vulnerable to malicious backdoor attacks, where triggers could be injected into the models to guide them to exhibit the expected behavior of the attackers. Unfortunately, existing research on backdoor attacks has mainly focused on English PLMs and paid less attention to Chinese PLMs. Moreover, these extant backdoor attacks do not work well against Chinese PLMs. In this article, we disclose the limitations of English backdoor attacks against Chinese PLMs, and propose the character-level backdoor attacks (CBAs) against the Chinese PLMs. Specifically, we first design three Chinese trigger generation strategies to ensure that the backdoor is effectively triggered while improving the effectiveness of the backdoor attacks. Then, based on the attacker’s capabilities of accessing the training dataset, we develop trigger injection mechanisms with either the target label similarity or the masked language model, which select the most influential position and insert the trigger to maximize the stealth of backdoor attacks. Extensive experiments on three major natural language processing tasks in various Chinese PLMs and English PLMs demonstrate the effectiveness and stealthiness of our method. In addition, CBAs have very strong resistance against three state-of-the-art backdoor defense methods. 1",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4400587428",
    "type": "article"
  },
  {
    "title": "VeriBin: A Malware Authorship Verification Approach for APT Tracking through Explainable and Functionality-Debiasing Adversarial Representation Learning",
    "doi": "https://doi.org/10.1145/3669901",
    "publication_date": "2024-08-16",
    "publication_year": 2024,
    "authors": "Weihan Ou; Steven H. H. Ding; Mohammad Zulkernine; Litao Li; Sarah Labrosse",
    "corresponding_authors": "",
    "abstract": "Malware attacks are posing a significant threat to national security, cooperate network, and public endpoint security. Identifying the Advanced Persistent Threat (APT) groups behind the attacks and grouping their activities into attack campaigns help security investigators trace their activities thus providing better security protections against future attacks. Existing Cyber Threat Intelligent (CTI) components mainly focus on malware family identification and behavior characterization, which cannot solve the APT tracking problem: while APT tracking needs one to link malware binaries of multiple families to a single threat actor, these behavior or function-based techniques are tightened up to a specific attack technique and would fail on connecting different families. Binary Authorship Attribution (AA) solutions could discriminate against threat actors based on their stylometric traits. However, AA solutions assume that the author of a binary is within a fixed candidate author set. However, real-world malware binaries may be created by a new unknown threat actor. To address this research gap, we propose VeriBin for the Binary Authorship Verification (BAV) problem. VeriBin is a novel adversarial neural network that extracts functionality-agnostic style representations from assembly code for the AV task. The extracted style representations can be visualized and are explainable with VeriBin’s multi-head attention mechanism. We benchmark VeriBin with state-of-the-art coding style representations on a standard dataset and a recent malware-APT dataset. Given two anonymous binaries of out-of-sample authors, VeriBin can accurately determine whether they belong to the same author or not. VeriBin is resilient to compiler optimizations and robust against malware family variants.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4400853529",
    "type": "article"
  },
  {
    "title": "SPArch: A Hardware-oriented Sketch-based Architecture for High-speed Network Flow Measurements",
    "doi": "https://doi.org/10.1145/3687477",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Arish Sateesan; Jo Vliegen; Simon Scherrer; Hsu‐Chun Hsiao; Adrian Perrig; Nele Mentens",
    "corresponding_authors": "",
    "abstract": "Network flow measurement is an integral part of modern high-speed applications for network security and data-stream processing. However, processing at line rate while maintaining the required data structure within the on-chip memory of the hardware platform is a challenging task for measurement algorithms, especially when accuracy is of primary importance, such as in network security applications. Most of the existing measurement algorithms are no exception to such issues when deployed in high-speed networking environments and are also not tailored for efficient hardware implementation. Sketch-based measurement algorithms minimize the memory requirement and are suitable for high-speed networks but possess a low memory-accuracy trade-off and lack the versatility of individual flow mapping. To address these challenges, we present a hardware-friendly data structure named Sketch-based Pseudo-associative array Architecture (SPArch). SPArch is highly accurate and extremely memory-efficient, making it suitable for network flow measurement and security applications. The parallelism in SPArch ensures minimal and constant memory access cycles. Unlike other sketch architectures, SPArch provides the functionality of individual flow mapping similar to associative arrays, and the optimized version of SPArch allows the organization of counters in multiple buckets based on the flow sizes. An in-depth analysis of SPArch is carried out in this article and implemented SPArch on the Alveo data center accelerator card, demonstrating its suitability for high-speed networks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401426711",
    "type": "article"
  },
  {
    "title": "Category-Based Administrative Access Control Policies",
    "doi": "https://doi.org/10.1145/3698199",
    "publication_date": "2024-09-28",
    "publication_year": 2024,
    "authors": "Clara Bertolissi; Maribel Fernández; Bhavani Thuraisingham",
    "corresponding_authors": "",
    "abstract": "As systems evolve, security administrators need to review and update access control policies. Such updates must be carefully controlled due to the risks associated with erroneous or malicious policy changes. We propose a category-based access control (CBAC) model, called Admin-CBAC , to control administrative actions. Since most of the access control models in use nowadays (including the popular RBAC and ABAC models) are instances of CBAC, from Admin-CBAC , we derive administrative models for RBAC and ABAC, too. We present a graph-based representation of Admin-CBAC policies and a formal operational semantics for administrative actions via graph rewriting. We also discuss implementations of Admin-CBAC exploiting the graph-based representation. Using the formal semantics, we show how properties (such as safety, liveness, and effectiveness of policies) and constraints (such as separation of duties) can be checked, and discuss the impact of policy changes. Although the most interesting properties of policies are generally undecidable in dynamic access control models, we identify particular cases where reachability properties are decidable and can be checked using our operational semantics, generalising previous results for RBAC and ABAC α .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4402938516",
    "type": "article"
  },
  {
    "title": "Formal Security Analysis of the OpenID FAPI 2.0 Family of Protocols: Accompanying a Standardization Process",
    "doi": "https://doi.org/10.1145/3699716",
    "publication_date": "2024-10-08",
    "publication_year": 2024,
    "authors": "Pedram Hosseyni; Ralf Küsters; Tim Würtele",
    "corresponding_authors": "",
    "abstract": "FAPI 2.0 is a suite of Web protocols developed by the OpenID Foundation’s FAPI Working Group (FAPI WG) for third-party data sharing and digital identity in high-risk environments. Even though the specifications are not completely finished, several important entities have started to adopt the FAPI 2.0 protocols, including Norway’s national HelseID, Australia’s Consumer Data Standards, as well as private companies like Authlete and Australia-based connectID; the predecessor FAPI 1.0 is in widespread use with millions of users. The FAPI WG asked us to accompany the standardization of the FAPI 2.0 protocols with a formal security analysis to proactively identify vulnerabilities before widespread deployment and to provide formal security guarantees for the standards. In this paper, we report on our analysis and findings. Our analysis is based on a detailed model of the Web infrastructure, the so-called Web Infrastructure Model (WIM), which we extend to be able to carry out our analysis of the FAPI 2.0 protocols including important extensions like FAPI-CIBA. Based on the (extended) WIM and formalizations of the security goals and attacker model laid out in the FAPI 2.0 specifications, we provide a formal model of the protocols and carry out a formal security analysis, revealing several attacks. We have worked with the FAPI WG to fix the protocols, resulting in several amendments to the specifications. With these changes in place, we have adjusted our protocol model and formally proved that the security properties hold true under the strong attacker model defined by the FAPI WG.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4403221646",
    "type": "article"
  },
  {
    "title": "Pulse-Response",
    "doi": "https://doi.org/10.1145/3064645",
    "publication_date": "2017-05-25",
    "publication_year": 2017,
    "authors": "Ivan Martinović; Kasper Rasmussen; Marc Roeschlin; Gene Tsudik",
    "corresponding_authors": "",
    "abstract": "Biometric characteristics are often used as a supplementary component in user authentication and identification schemes. Many biometric traits, both physiological and behavioral, offering a wider range of security and stability, have been explored. We propose a new physiological trait based on the human body’s electrical response to a square pulse signal, called pulse-response , and analyze how this biometric characteristic can be used to enhance security in the context of two example applications: (1) an additional authentication mechanism in PIN entry systems and (2) a means of continuous authentication on a secure terminal. The pulse-response biometric recognition is effective because each human body exhibits a unique response to a signal pulse applied at the palm of one hand and measured at the palm of the other. This identification mechanism integrates well with other established methods and could offer an additional layer of security, either on a continuous basis or at log-in time. We build a proof-of-concept prototype and perform experiments to assess the feasibility of pulse-response for biometric authentication. The results are very encouraging, achieving an equal error rate of 2% over a static dataset and 9% over a dataset with samples taken over several weeks. We also quantize resistance to attack by estimating individual worst-case probabilities for zero-effort impersonation in different experiments.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2617948203",
    "type": "article"
  },
  {
    "title": "Kernel Protection Against Just-In-Time Code Reuse",
    "doi": "https://doi.org/10.1145/3277592",
    "publication_date": "2019-01-04",
    "publication_year": 2019,
    "authors": "Marios Pomonis; Theofilos Petsios; Angelos D. Keromytis; Michalis Polychronakis; Vasileios P. Kemerlis",
    "corresponding_authors": "",
    "abstract": "The abundance of memory corruption and disclosure vulnerabilities in kernel code necessitates the deployment of hardening techniques to prevent privilege escalation attacks. As stricter memory isolation mechanisms between the kernel and user space become commonplace, attackers increasingly rely on code reuse techniques to exploit kernel vulnerabilities. Contrary to similar attacks in more restrictive settings, as in web browsers, in kernel exploitation, non-privileged local adversaries have great flexibility in abusing memory disclosure vulnerabilities to dynamically discover, or infer, the location of code snippets in order to construct code-reuse payloads. Recent studies have shown that the coupling of code diversification with the enforcement of a “read XOR execute” (R ∧ X) memory safety policy is an effective defense against the exploitation of userland software, but so far this approach has not been applied for the protection of the kernel itself. In this article, we fill this gap by presenting kR ∧ X: a kernel-hardening scheme based on execute-only memory and code diversification. We study a previously unexplored point in the design space, where a hypervisor or a super-privileged component is not required. Implemented mostly as a set of GCC plugins, kR ∧ X is readily applicable to x86 Linux kernels (both 32b and 64b) and can benefit from hardware support (segmentation on x86, MPX on x86-64) to optimize performance. In full protection mode, kR ∧ X incurs a low runtime overhead of 4.04%, which drops to 2.32% when MPX is available, and 1.32% when memory segmentation is in use.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2910663633",
    "type": "article"
  },
  {
    "title": "BLC",
    "doi": "https://doi.org/10.1145/3041760",
    "publication_date": "2017-05-25",
    "publication_year": 2017,
    "authors": "Alessandro Checco; Giuseppe Bianchi; Douglas J. Leith",
    "corresponding_authors": "",
    "abstract": "We propose a privacy-enhanced matrix factorization recommender that exploits the fact that users can often be grouped together by interest. This allows a form of “hiding in the crowd” privacy. We introduce a novel matrix factorization approach suited to making recommendations in a shared group (or “nym”) setting and the BLC algorithm for carrying out this matrix factorization in a privacy-enhanced manner. We demonstrate that the increased privacy does not come at the cost of reduced recommendation accuracy.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2962781798",
    "type": "article"
  },
  {
    "title": "“So if Mr Blue Head here clicks the link...” Risk Thinking in Cyber Security Decision Making",
    "doi": "https://doi.org/10.1145/3419101",
    "publication_date": "2020-11-08",
    "publication_year": 2020,
    "authors": "Benjamin Shreeve; Joseph Hallett; Matthew Edwards; Pauline Anthonysamy; Sylvain Frey; Awais Rashid",
    "corresponding_authors": "",
    "abstract": "Cyber security decision making is inherently complicated, with nearly every decision having knock-on consequences for an organisation’s vulnerability and exposure. This is further compounded by the fact that decision-making actors are rarely security experts and may have an incomplete understanding of the security that the organisation currently has in place. They must contend with a multitude of possible security options that they may only partially understand. This challenge is met by decision makers’ risk thinking —their strategies for identifying risks, assessing their severity, and prioritising responses. We study the risk thinking strategies employed by teams of participants in an existing dataset derived from a tabletop cyber-physical systems security game. Our analysis identifies four structural patterns of risk thinking and two reasoning strategies: risk-first and opportunity-first . Our work highlights that risk-first approaches (as prescribed by the likes of NIST-800-53 and ISO 27001) are followed neither substantially nor exclusively when it comes to decision making. Instead, our analysis finds that decision making is affected by the plasticity of teams—that is, the ability to readily switch between ideas and practising both risk-first and opportunity-first reasoning.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3088431595",
    "type": "article"
  },
  {
    "title": "Exploiting Mixed Binaries",
    "doi": "https://doi.org/10.1145/3418898",
    "publication_date": "2021-01-02",
    "publication_year": 2021,
    "authors": "Michalis Papaevripides; Ηλίας Αθανασόπουλος",
    "corresponding_authors": "",
    "abstract": "Unsafe programming systems are still very popular, despite the shortcomings due to several published memory-corruption vulnerabilities. Toward defending memory corruption, compilers have started to employ advanced software hardening such as Control-flow Integrity (CFI) and SafeStack. However, there is a broad interest for realizing compilers that impose memory safety with no heavy runtime support (e.g., garbage collection). Representative examples of this category are Rust and Go, which enforce memory safety primarily statically at compile time. Software hardening and Rust/Go are promising directions for defending memory corruption, albeit combining the two is questionable. In this article, we consider hardened mixed binaries, i.e., machine code that has been produced from different compilers and, in particular, from hardened C/C++ and Rust/Go (e.g., Mozilla Firefox, Dropbox, npm, and Docker). Our analysis is focused on Mozilla Firefox, which outsources significant code to Rust and is open source with known public vulnerabilities (with assigned CVE). Furthermore, we extend our analysis in mixed binaries that leverage Go, and we derive similar results. The attacks explored in this article do not exploit Rust or Go binaries that depend on some legacy (vulnerable) C/C++ code. In contrast, we explore how Rust/Go compiled code can stand as a vehicle for bypassing hardening in C/C++ code. In particular, we discuss CFI and SafeStack, which are available in the latest Clang. Our assessment concludes that CFI can be completely nullified through Rust or Go code by constructing much simpler attacks than state-of-the-art CFI bypasses.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3120812951",
    "type": "article"
  },
  {
    "title": "A Lightweight Privacy-Aware Continuous Authentication Protocol-PACA",
    "doi": "https://doi.org/10.1145/3464690",
    "publication_date": "2021-09-02",
    "publication_year": 2021,
    "authors": "Abbas Acar; Shoukat Ali; Koray Karabina; Cengiz Kaygusuz; Hidayet Aksu; Kemal Akkaya; Selcuk Uluagac",
    "corresponding_authors": "",
    "abstract": "As many vulnerabilities of one-time authentication systems have already been uncovered, there is a growing need and trend to adopt continuous authentication systems. Biometrics provides an excellent means for periodic verification of the authenticated users without breaking the continuity of a session. Nevertheless, as attacks to computing systems increase, biometric systems demand more user information in their operations, yielding privacy issues for users in biometric-based continuous authentication systems. However, the current state-of-the-art privacy technologies are not viable or costly for the continuous authentication systems, which require periodic real-time verification. In this article, we introduce a novel, lightweight, &lt;underline&gt;p&lt;/underline&gt;rivacy-&lt;underline&gt;a&lt;/underline&gt;ware, and secure &lt;underline&gt;c&lt;/underline&gt;ontinuous &lt;underline&gt;a&lt;/underline&gt;uthentication protocol called PACA. PACA is initiated through a password-based key exchange (PAKE) mechanism, and it continuously authenticates users based on their biometrics in a privacy-aware manner. Then, we design an actual continuous user authentication system under the proposed protocol. In this concrete system, we utilize a privacy-aware template matching technique and a wearable-assisted keystroke dynamics-based continuous authentication method. This provides privacy guarantees without relying on any trusted third party while allowing the comparison of noisy user inputs (due to biometric data) and yielding an efficient and lightweight protocol. Finally, we implement our system on an Apple smartwatch and perform experiments with real user data to evaluate the accuracy and resource consumption of our concrete system.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3198384297",
    "type": "article"
  },
  {
    "title": "A Novel Hybrid Approach for Multi-Dimensional Data Anonymization for Apache Spark",
    "doi": "https://doi.org/10.1145/3484945",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Sibghat Ullah Bazai; Julian Jang‐Jaccard; Hooman Alavizadeh",
    "corresponding_authors": "",
    "abstract": "Multi-dimensional data anonymization approaches (e.g., Mondrian) ensure more fine-grained data privacy by providing a different anonymization strategy applied for each attribute. Many variations of multi-dimensional anonymization have been implemented on different distributed processing platforms (e.g., MapReduce, Spark) to take advantage of their scalability and parallelism supports. According to our critical analysis on overheads, either existing iteration-based or recursion-based approaches do not provide effective mechanisms for creating the optimal number of and relative size of resilient distributed datasets (RDDs), thus heavily suffer from performance overheads. To solve this issue, we propose a novel hybrid approach for effectively implementing a multi-dimensional data anonymization strategy (e.g., Mondrian) that is scalable and provides high-performance. Our hybrid approach provides a mechanism to create far fewer RDDs and smaller size partitions attached to each RDD than existing approaches. This optimal RDD creation and operations approach is critical for many multi-dimensional data anonymization applications that create tremendous execution complexity. The new mechanism in our proposed hybrid approach can dramatically reduce the critical overheads involved in re-computation cost, shuffle operations, message exchange, and cache management.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3214816803",
    "type": "article"
  },
  {
    "title": "Don’t Let Google Know I’m Lonely",
    "doi": "https://doi.org/10.1145/2937754",
    "publication_date": "2016-08-05",
    "publication_year": 2016,
    "authors": "Pól Mac Aonghusa; Douglas J. Leith",
    "corresponding_authors": "",
    "abstract": "From buying books to finding the perfect partner, we share our most intimate wants and needs with our favourite online systems. But how far should we accept promises of privacy in the face of personalized profiling? In particular, we ask how we can improve detection of sensitive topic profiling by online systems. We propose a definition of privacy disclosure that we call ε-indistinguishability, from which we construct scalable, practical tools to assess the learning potential from personalized content. We demonstrate our results using openly available resources, detecting a learning rate in excess of 98% for a range of sensitive topics during our experiments.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2296759492",
    "type": "article"
  },
  {
    "title": "Toward Improved Audio CAPTCHAs Based on Auditory Perception and Language Understanding",
    "doi": "https://doi.org/10.1145/2856820",
    "publication_date": "2016-11-19",
    "publication_year": 2016,
    "authors": "Hendrik Meutzner; Santosh K. Gupta; VietHung Nguyen; Thorsten Holz; Dorothea Kolossa",
    "corresponding_authors": "",
    "abstract": "A so-called completely automated public Turing test to tell computers and humans apart (CAPTCHA) represents a challenge-response test that is widely used on the Internet to distinguish human users from fraudulent computer programs, often referred to as bots. To enable access for visually impaired users, most Web sites utilize audio CAPTCHAs in addition to a conventional image-based scheme. Recent research has shown that most currently available audio CAPTCHAs are insecure, as they can be broken by means of machine learning at relatively low costs. Moreover, most audio CAPTCHAs suffer from low human success rates that arise from severe signal distortions. This article proposes two different audio CAPTCHA schemes that systematically exploit differences between humans and computers in terms of auditory perception and language understanding, yielding a better trade-off between usability and security as compared to currently available schemes. Furthermore, we provide an elaborate analysis of Google’s prominent reCAPTCHA that serves as a baseline setting when evaluating our proposed CAPTCHA designs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2552633819",
    "type": "article"
  },
  {
    "title": "Dynamic Binary Translation for SGX Enclaves",
    "doi": "https://doi.org/10.1145/3532862",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Jinhua Cui; Shweta Shinde; Satyaki Sen; Prateek Saxena; Pinghai Yuan",
    "corresponding_authors": "",
    "abstract": "Enclaves, such as those enabled by Intel SGX, offer a hardware primitive for shielding user-level applications from the OS. While enclaves are a useful starting point, code running in the enclave requires additional checks whenever control or data is transferred to/from the untrusted OS. The enclave-OS interface on SGX, however, can be extremely large if we wish to run existing unmodified binaries inside enclaves. This article presents Ratel , a dynamic binary translation engine running inside SGX enclaves on Linux. Ratel offers complete interposition , the ability to interpose on all executed instructions in the enclave and monitor all interactions with the OS. Instruction-level interposition offers a general foundation for implementing a large variety of inline security monitors in thefuture. We take a principled approach in explaining why complete interposition on SGX is challenging. We draw attention to five design decisions in SGX that create fundamental trade-offs between performance and ensuring complete interposition, and we explain how to resolve them in the favor of complete interposition. To illustrate the utility of the Ratel framework, we present the first attempt to offer binary compatibility with existing software on SGX. We report that Ratel offers binary compatibility with over 200 programs we tested, including micro-benchmarks and real applications, such as Linux shell utilities. Runtimes for two programming languages, namely, Python and R, tested with standard benchmarks work out-of-the-box on Ratel without any specialized handling.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3148536947",
    "type": "article"
  },
  {
    "title": "HotFuzz: Discovering Temporal and Spatial Denial-of-Service Vulnerabilities Through Guided Micro-Fuzzing",
    "doi": "https://doi.org/10.1145/3532184",
    "publication_date": "2022-05-20",
    "publication_year": 2022,
    "authors": "W Blair; Andrea Mambretti; Sajjad Arshad; Michael Weissbacher; William Robertson; Engin Kirda; Manuel Egele",
    "corresponding_authors": "",
    "abstract": "Fuzz testing repeatedly assails software with random inputs in order to trigger unexpected program behaviors, such as crashes or timeouts, and has historically revealed serious security vulnerabilities. In this article, we present HotFuzz, a framework for automatically discovering Algorithmic Complexity (AC) time and space vulnerabilities in Java libraries. HotFuzz uses micro-fuzzing, a genetic algorithm that evolves arbitrary Java objects in order to trigger the worst-case performance for a method under test. We define Small Recursive Instantiation (SRI) as a technique to derive seed inputs represented as Java objects to micro-fuzzing. After micro-fuzzing, HotFuzz synthesizes test cases that triggered AC vulnerabilities into Java programs and monitors their execution in order to reproduce vulnerabilities outside the fuzzing framework. HotFuzz outputs those programs that exhibit high resource utilization as witnesses for AC vulnerabilities in a Java library. We evaluate HotFuzz over the Java Runtime Environment (JRE), the 100 most popular Java libraries on Maven, and challenges contained in the DARPA Space and Time Analysis for Cybersecurity (STAC) program. We evaluate SRI’s effectiveness by comparing the performance of micro-fuzzing with SRI, measured by the number of AC vulnerabilities detected, to simply using empty values as seed inputs. In this evaluation, we verified known AC vulnerabilities, discovered previously unknown AC vulnerabilities that we responsibly reported to vendors, and received confirmation from both IBM and Oracle. Our results demonstrate that micro-fuzzing finds AC vulnerabilities in real-world software, and that micro-fuzzing with SRI-derived seed inputs outperforms using empty values in both the temporal and spatial domains.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4280628778",
    "type": "article"
  },
  {
    "title": "InkFiltration: Using Inkjet Printers for Acoustic Data Exfiltration from Air-Gapped Networks",
    "doi": "https://doi.org/10.1145/3510583",
    "publication_date": "2022-05-04",
    "publication_year": 2022,
    "authors": "Julian de Gortari Briseno; Akash Deep Singh; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "Printers have become ubiquitous in modern office spaces, and their placement in these spaces been guided more by accessibility than security. Due to the proximity of printers to places with potentially high-stakes information, the possible misuse of these devices is concerning. We present a previously unexplored covert channel that effectively uses the sound generated by printers with inkjet technology to exfiltrate arbitrary sensitive data (unrelated to the apparent content of the document being printed) from an air-gapped network. We also discuss a series of defense techniques that can make these devices invulnerable to covert manipulation. The proposed covert channel works by malware installed on a computer with access to a printer, injecting certain imperceptible patterns into all documents that applications on the computer send to the printer. These patterns can control the printing process without visibly altering the original content of a document, and generate acoustic signals that a nearby acoustic recording device, such as a smartphone, can capture and decode. To prove and analyze the capabilities of this new covert channel, we carried out tests considering different types of document layouts and distances between the printer and recording device. We achieved a bit error ratio less than 5% and an average bit rate of approximately 0.5 bps across all tested printers at distances up to 4 m, which is sufficient to extract tiny bits of information.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4281294746",
    "type": "article"
  },
  {
    "title": "What Users Want From Cloud Deletion and the Information They Need: A Participatory Action Study",
    "doi": "https://doi.org/10.1145/3546578",
    "publication_date": "2022-08-02",
    "publication_year": 2022,
    "authors": "Kopo M. Ramokapane; José M. Such; Awais Rashid",
    "corresponding_authors": "",
    "abstract": "Current cloud deletion mechanisms fall short in meeting users’ various deletion needs. They assume all data is deleted the same way—data is temporally removed (or hidden) from users’ cloud accounts before being completely deleted. This assumption neglects users’ desire to have data completely deleted instantly or their preference to have it recoverable for a more extended period. To date, these preferences have not been explored. To address this gap, we conducted a participatory study with four groups of active cloud users (five subjects per group). We examined their deletion preferences and the information they require to aid deletion. In particular, we explored how users want to delete cloud data and identify what information about cloud deletion they consider essential, the time it should be made available to them, and the communication channel that should be used. We show that cloud deletion preferences are complex and multi-dimensional, varying between subjects and groups. Information about deletion should be within reach when needed, for instance, be part of deletion controls. Based on these findings, we discuss the implications of our study in improving the current deletion mechanism to accommodate these preferences.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4289523249",
    "type": "article"
  },
  {
    "title": "Stateful Protocol Composition in Isabelle/HOL",
    "doi": "https://doi.org/10.1145/3577020",
    "publication_date": "2023-01-25",
    "publication_year": 2023,
    "authors": "Andreas Viktor Hess; Sebastian Mödersheim; Achim D. Brucker",
    "corresponding_authors": "",
    "abstract": "Communication networks like the Internet form a large distributed system where a huge number of components run in parallel, such as security protocols and distributed web applications. For what concerns security, it is obviously infeasible to verify them all at once as one monolithic entity; rather, one has to verify individual components in isolation.\\\\While many typical components like TLS have been studied intensively, there exists much less research on analyzing and ensuring the security of the composition of security protocols. This is a problem since the composition of systems that are secure in isolation can easily be insecure. The main goal of compositionality is thus a theorem of the form: given a set of components that are already proved secure in isolation and that satisfy a number of easy-to-check conditions, then also their parallel composition is secure. Said conditions should of course also be realistic in practice, or better yet, already be satisfied for many existing components. Another benefit of compositionality is that when one would like to exchange a component with another one, all that is needed is the proof that the new component is secure in isolation and satisfies the composition conditions—without having to re-prove anything about the other components.\\\\This paper has three contributions over previous work in parallel compositionality. First, we extend the compositionality paradigm to stateful systems: while previous approaches work only for simple protocols that only have a local session state, our result supports participants who maintain long-term databases that can be shared among several protocols. This includes a paradigm for declassification of shared secrets. This result is in fact so general that it also covers many forms of sequential composition as a special case of stateful parallel composition. Second, our compositionality result is formalized and proved in Isabelle/HOL, providing a strong correctness guarantee of our proofs. This also means that one can prove, without gaps, the security of an entire system in Isabelle/HOL, namely the security of components in isolation, the composition conditions, and thus derive the security of the entire system as an Isabelle theorem. For the components one can also make use of our tool PSPSP that can perform automatic proofs for many stateful protocols. Third, for the compositionality conditions we have also implemented an automated check procedure in Isabelle.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4317935366",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Resilient Consensus for Multi-agent Systems in a General Topology Structure",
    "doi": "https://doi.org/10.1145/3587933",
    "publication_date": "2023-03-16",
    "publication_year": 2023,
    "authors": "Jian Hou; Jing Wang; Mingyue Zhang; Zhi Jin; Chunlin Wei; Zuohua Ding",
    "corresponding_authors": "",
    "abstract": "Recent advances of consensus control have made it significant in multi-agent systems such as in distributed machine learning, distributed multi-vehicle cooperative systems. However, during its application it is crucial to achieve resilience and privacy; specifically, when there are adversary/faulty nodes in a general topology structure, normal agents can also reach consensus while keeping their actual states unobserved. In this article, we modify the state-of-the-art Q-consensus algorithm by introducing predefined noise or well-designed cryptography to guarantee the privacy of each agent state. In the former case, we add specified noise on agent state before it is transmitted to the neighbors and then gradually decrease the value of noise so the exact agent state cannot be evaluated. In the latter one, the Paillier cryptosystem is applied for reconstructing reward function in two consecutive interactions between each pair of neighboring agents. Therefore, multi-agent privacy-preserving resilient consensus (MAPPRC) can be achieved in a general topology structure. Moreover, in the modified version, we reconstruct reward function and credibility function so both convergence rate and stability of the system are improved. The simulation results indicate the algorithms’ tolerance for constant and/or persistent faulty agents as well as their protection of privacy. Compared with the previous studies that consider both resilience and privacy-preserving requirements, the proposed algorithms in this article greatly relax the topological conditions. At the end of the article, to verify the effectiveness of the proposed algorithms, we conduct two sets of experiments, i.e., a smart-car hardware platform consisting of four vehicles and a distributed machine learning platform containing 10 workers and a server.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4327590953",
    "type": "article"
  },
  {
    "title": "End-to-End Security for Distributed Event-driven Enclave Applications on Heterogeneous TEEs",
    "doi": "https://doi.org/10.1145/3592607",
    "publication_date": "2023-04-13",
    "publication_year": 2023,
    "authors": "Gianluca Scopelliti; Sepideh Pouyanrad; Job Noorman; Fritz Alder; Christoph Baumann; Frank Piessens; Jan Tobias Mühlberg",
    "corresponding_authors": "",
    "abstract": "This paper presents an approach to provide strong assurance of the secure execution of distributed event-driven applications on shared infrastructures, while relying on a small Trusted Computing Base. We build upon and extend security primitives provided by Trusted Execution Environments (TEEs) to guarantee authenticity and integrity properties of applications, and to secure control of input and output devices. More specifically, we guarantee that if an output is produced by the application, it was allowed to be produced by the application's source code based on an authentic trace of inputs. We present an integrated open-source framework to develop, deploy, and use such applications across heterogeneous TEEs. Beyond authenticity and integrity, our framework optionally provides confidentiality and a notion of availability, and facilitates software development at a high level of abstraction over the platform-specific TEE layer. We support event-driven programming to develop distributed enclave applications in Rust and C for heterogeneous TEE, including Intel SGX, ARM TrustZone and Sancus. In this article we discuss the workings of our approach, the extensions we made to the Sancus processor, and the integration of our development model with commercial TEEs. Our evaluation of security and performance aspects show that TEEs, together with our programming model, form a basis for powerful security architectures for dependable systems in domains such as Industrial Control Systems and the Internet of Things, illustrating our framework's unique suitability for a broad range of use cases which combine cloud processing, mobile and edge devices, and lightweight sensing and actuation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4365451513",
    "type": "article"
  },
  {
    "title": "Fraud Detection under Siege: Practical Poisoning Attacks and Defense Strategies",
    "doi": "https://doi.org/10.1145/3613244",
    "publication_date": "2023-08-08",
    "publication_year": 2023,
    "authors": "Tommaso Paladini; Francesco Monti; Mario Polino; Michele Carminati; Stefano Zanero",
    "corresponding_authors": "",
    "abstract": "Machine learning (ML) models are vulnerable to adversarial machine learning (AML) attacks. Unlike other contexts, the fraud detection domain is characterized by inherent challenges that make conventional approaches hardly applicable. In this article, we extend the application of AML techniques to the fraud detection task by studying poisoning attacks and their possible countermeasures. First, we present a novel approach for performing poisoning attacks that overcomes the fraud detection domain-specific constraints. It generates fraudulent candidate transactions and tests them against a machine learning-based Oracle , which simulates the target fraud detection system aiming at evading it. Misclassified fraudulent candidate transactions are then integrated into the target detection system’s training set, poisoning its model and shifting its decision boundary. Second, we propose a novel approach that extends the adversarial training technique to mitigate AML attacks: During the training phase of the detection system, we generate artificial frauds by modifying random original legitimate transactions; then, we include them in the training set with the correct label. By doing so, we instruct our model to recognize evasive transactions before an attack occurs. Using two real bank datasets, we evaluate the security of several state-of-the-art fraud detection systems by deploying our poisoning attack with different degrees of attacker’s knowledge and attacking strategies. The experimental results show that our attack works even when the attacker has minimal knowledge of the target system. Then, we demonstrate that the proposed countermeasure can mitigate adversarial attacks by reducing the stolen amount of money up to 100%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4385665118",
    "type": "article"
  },
  {
    "title": "Measures of Information Leakage for Incomplete Statistical Information: Application to a Binary Privacy Mechanism",
    "doi": "https://doi.org/10.1145/3624982",
    "publication_date": "2023-09-19",
    "publication_year": 2023,
    "authors": "Shahnewaz Karim Sakib; George T. Amariucai; Yong Guan",
    "corresponding_authors": "",
    "abstract": "Information leakage is usually defined as the logarithmic increment in the adversary’s probability of correctly guessing the legitimate user’s private data or some arbitrary function of the private data when presented with the legitimate user’s publicly disclosed information. However, this definition of information leakage implicitly assumes that both the privacy mechanism and the prior probability of the original data are entirely known to the attacker. In reality, the assumption of complete knowledge of the privacy mechanism for an attacker is often impractical. The attacker can usually have access to only an approximate version of the correct privacy mechanism, computed from a limited set of the disclosed data, for which they can access the corresponding un-distorted data. In this scenario, the conventional definition of leakage no longer has an operational meaning. To address this problem, in this article, we propose novel meaningful information-theoretic metrics for information leakage when the attacker has incomplete information about the privacy mechanism—we call them average subjective leakage , average confidence boost , and average objective leakage , respectively. For the simplest, binary scenario, we demonstrate how to find an optimized privacy mechanism that minimizes the worst-case value of either of these leakages.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386864822",
    "type": "article"
  },
  {
    "title": "symbSODA: Configurable and Verifiable Orchestration Automation for Active Malware Deception",
    "doi": "https://doi.org/10.1145/3624568",
    "publication_date": "2023-09-20",
    "publication_year": 2023,
    "authors": "Md Sajidul Islam Sajid; Jinpeng Wei; Ehab Al‐Shaer; Qi Duan; Basel Abdeen; Latifur Khan",
    "corresponding_authors": "",
    "abstract": "Malware is commonly used by adversaries to compromise and infiltrate cyber systems in order to steal sensitive information or destroy critical assets. Active Cyber Deception (ACD) has emerged as an effective proactive cyber defense against malware to enable misleading adversaries by presenting fake data and engaging them to learn novel attack techniques. However, real-time malware deception is a complex and challenging task because (1) it requires a comprehensive understanding of the malware behaviors at technical and tactical levels in order to create the appropriate deception ploys and resources that can leverage this behavior and mislead malware, and (2) it requires a configurable yet provably valid deception planning to guarantee effective and safe real-time deception orchestration. This article presents symbSODA, a highly configurable and verifiable cyber deception system that analyzes real-world malware using multipath execution to discover API patterns that represent attack techniques/tactics critical for deception, enables users to create their own customized deception ploys based on the malware type and objectives, allows for constructing conflict-free Deception Playbooks , and finally automates the deception orchestration to execute the malware inside a deceptive environment. symbSODA extracts Malicious Sub-graphs (MSGs) consisting of WinAPIs from real-world malware and maps them to tactics and techniques using the ATT&amp;CK framework to facilitate the construction of meaningful user-defined deception playbooks. We conducted a comprehensive evaluation study on symbSODA using 255 recent malware samples. We demonstrated that the accuracy of the end-to-end malware deception is 95% on average, with negligible overhead using various deception goals and strategies. Furthermore, our approach successfully extracted MSGs with a 97% recall, and our MSG-to-MITRE mapping achieved a top-1 accuracy of 88.75%. Our study suggests that symbSODA can serve as a general-purpose Malware Deception Factory to automatically produce customized deception playbooks against arbitrary malware behavior.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386889927",
    "type": "article"
  },
  {
    "title": "Sphinx-in-the-Head: Group Signatures from Symmetric Primitives",
    "doi": "https://doi.org/10.1145/3638763",
    "publication_date": "2023-12-27",
    "publication_year": 2023,
    "authors": "Liqun Chen; Changyu Dong; Christopher J. P. Newton; Yalan Wang",
    "corresponding_authors": "",
    "abstract": "Group signatures and their variants have been widely used in privacy-sensitive scenarios such as anonymous authentication and attestation. In this paper, we present a new post-quantum group signature scheme from symmetric primitives. Using only symmetric primitives makes the scheme less prone to unknown attacks than basing the design on newly proposed hard problems whose security is less well-understood. However, symmetric primitives do not have rich algebraic properties, and this makes it extremely challenging to design a group signature scheme on top of them. It is even more challenging if we want a group signature scheme suitable for real-world applications, one that can support large groups and require few trust assumptions. Our scheme is based on MPC-in-the-head non-interactive zero-knowledge proofs, and we specifically design a novel hash-based group credential scheme, which is rooted in the SPHINCS+ signature scheme but with various modifications to make it MPC (multi-party computation) friendly. The security of the scheme has been proved under the fully dynamic group signature model. We provide an implementation of the scheme and demonstrate the feasibility of handling a group size as large as 2 60 . This is the first group signature scheme from symmetric primitives that supports such a large group size and meets all the security requirements.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4390263812",
    "type": "article"
  },
  {
    "title": "Large-scale and Robust Code Authorship Identification with Deep Feature Learning",
    "doi": "https://doi.org/10.1145/3461666",
    "publication_date": "2021-07-19",
    "publication_year": 2021,
    "authors": "Mohammed Abuhamad; Tamer Abuhmed; Aziz Mohaisen; DaeHun Nyang",
    "corresponding_authors": "",
    "abstract": "Successful software authorship de-anonymization has both software forensics applications and privacy implications. However, the process requires an efficient extraction of authorship attributes. The extraction of such attributes is very challenging, due to various software code formats from executable binaries with different toolchain provenance to source code with different programming languages. Moreover, the quality of attributes is bounded by the availability of software samples to a certain number of samples per author and a specific size for software samples. To this end, this work proposes a deep Learning-based approach for software authorship attribution, that facilitates large-scale, format-independent, language-oblivious, and obfuscation-resilient software authorship identification. This proposed approach incorporates the process of learning deep authorship attribution using a recurrent neural network, and ensemble random forest classifier for scalability to de-anonymize programmers. Comprehensive experiments are conducted to evaluate the proposed approach over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1,987 public repositories on GitHub. The results of our work show high accuracy despite requiring a smaller number of samples per author. Experimenting with source-code, our approach allows us to identify 8,903 GCJ authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Using the real-world dataset, we achieved an identification accuracy of 94.38% for 745 C programmers on GitHub. Moreover, the proposed approach is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g., C, C++, Java, and Python), and authors writing in mixed languages (e.g., Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g., using C Tigress) with an accuracy of 93.42% for a set of 120 authors. Experimenting with executable binaries, our approach achieves 95.74% for identifying 1,500 programmers of software binaries. Similar results were obtained when software binaries are generated with different compilation options, optimization levels, and removing of symbol information. Moreover, our approach achieves 93.86% for identifying 1,500 programmers of obfuscated binaries using all features adopted in Obfuscator-LLVM tool.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3175479455",
    "type": "article"
  },
  {
    "title": "Learning Relationship-Based Access Control Policies from Black-Box Systems",
    "doi": "https://doi.org/10.1145/3517121",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Padmavathi Iyer; Amirreza Masoumzadeh",
    "corresponding_authors": "",
    "abstract": "Access control policies are crucial in securing data in information systems. Unfortunately, often times, such policies are poorly documented, and gaps between their specification and implementation prevent the system users, and even its developers, from understanding the overall enforced policy of a system. To tackle this problem, we propose the first of its kind systematic approach for learning the enforced authorizations from a target system by interacting with and observing it as a black box. The black-box view of the target system provides the advantage of learning its overall access control policy without dealing with its internal design complexities. Furthermore, compared to the previous literature on policy mining and policy inference, we avoid exhaustive exploration of the authorization space by minimizing our observations. We focus on learning relationship-based access control (ReBAC) policy, and show how we can construct a deterministic finite automaton (DFA) to formally characterize such an enforced policy. We theoretically analyze our proposed learning approach by studying its termination, correctness, and complexity. Furthermore, we conduct extensive experimental analysis based on realistic application scenarios to establish its cost, quality of learning, and scalability in practice.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4280649132",
    "type": "article"
  },
  {
    "title": "Secure and Reliable Network Updates",
    "doi": "https://doi.org/10.1145/3556542",
    "publication_date": "2022-08-12",
    "publication_year": 2022,
    "authors": "James Lembke; Srivatsan Ravi; Pierre-Louis Roman; Patrick Eugster",
    "corresponding_authors": "",
    "abstract": "Software-defined wide area networking (SD-WAN) enables dynamic network policy control over a large distributed network via network updates . To be practical, network updates must be consistent (i.e., free of transient errors caused by updates to multiple switches), secure (i.e., only be executed when sent from valid controllers), and reliable (i.e., function despite the presence of faulty or malicious members in the control plane), while imposing only minimal overhead on controllers and switches. We present SERENE: a protocol for se cure and re liable ne twork updates for SD-WAN environments. In short: Consistency is provided through the combination of an update scheduler and a distributed transactional protocol. Security is preserved by authenticating network events and updates, the latter with an adaptive threshold cryptographic scheme. Reliability is provided by replicating the control plane and making it resilient to a dynamic adversary by using a distributed ledger as a controller failure detector. We ensure practicality by providing a mechanism for scalability through the definition of independent network domains and exploiting the parallelism of network updates both within and across domains. We formally define SERENE’s protocol and prove its safety with regards to event-linearizability. Extensive experiments show that SERENE imposes minimal switch burden and scales to large networks running multiple network applications all requiring concurrent network updates, imposing at worst a 16% overhead on short-lived flow completion and negligible overhead on anticipated normal workloads.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4291636707",
    "type": "article"
  },
  {
    "title": "Iterative Analysis to Improve Key Properties of Critical Human-Intensive Processes",
    "doi": "https://doi.org/10.1145/3041041",
    "publication_date": "2017-03-15",
    "publication_year": 2017,
    "authors": "Leon J. Osterweil; Matt Bishop; Heather M. Conboy; Huong Thu Thi Phan; Borislava I. Simidchieva; George S. Avrunin; Lori A. Clarke; Sean Peisert",
    "corresponding_authors": "",
    "abstract": "In this article, we present an approach for systematically improving complex processes, especially those involving human agents, hardware devices, and software systems. We illustrate the utility of this approach by applying it to part of an election process and show how it can improve the security and correctness of that subprocess. We use the Little-JIL process definition language to create a precise and detailed definition of the process. Given this process definition, we use two forms of automated analysis to explore whether specified key properties, such as security and safety policies, can be undermined. First, we use model checking to identify process execution sequences that fail to conform to event-sequence properties. After these are addressed, we apply fault tree analysis to identify when the misperformance of steps might allow undesirable outcomes, such as security breaches. The results of these analyses can provide assurance about the process; suggest areas for improvement; and, when applied to a modified process definition, evaluate proposed changes.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2598296510",
    "type": "article"
  },
  {
    "title": "Utilizing Performance Counters for Compromising Public Key Ciphers",
    "doi": "https://doi.org/10.1145/3156015",
    "publication_date": "2018-01-02",
    "publication_year": 2018,
    "authors": "Sarani Bhattacharya; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Hardware performance counters (HPCs) are useful artifacts for evaluating the performance of software implementations. Recently, HPCs have been made more convenient to use without requiring explicit kernel patches or superuser privileges. However, in this article, we highlight that the information revealed by HPCs can be also exploited to attack standard implementations of public key algorithms. In particular, we analyze the vulnerability due to the event branch miss leaked via the HPCs during execution of the target ciphers. We present an iterative attack that targets the key bits of 1,024-bit RSA and 256-bit ECC, whereas in the offline phase, the system’s underlying branch predictor is approximated by a theoretical predictor in the literature. Subsimulations are performed corresponding to each bit guess to classify the message space into distinct partitions based on the event branch misprediction and the target key bit value. In the online phase, branch mispredictions obtained from the hardware performance monitors on the target system reveal the secret key bits. We also theoretically prove that the probability of success of the attack is equivalent to the accurate modeling of the theoretical predictor to the underlying system predictor. In addition, we propose an improved version of the attack that requires fewer branch misprediction traces from the HPCs to recover the secret. Experimentations using both attack strategies have been provided on Intel Core 2 Duo, Core i3, and Core i5 platforms for 1,024-bit implementation of RSA and 256-bit scalar multiplication over the secp 256 r 1 curve followed by results on the effect of change of parameters on the success rate. The attack can successfully reveal the exponent bits and thus seeks attention to model secure branch predictors such that it inherently prevents information leakage.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2781692780",
    "type": "article"
  },
  {
    "title": "Using Episodic Memory for User Authentication",
    "doi": "https://doi.org/10.1145/3308992",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Simon S. Woo; Ron Artstein; Elsi Kaiser; Le Xiao; Jelena Mirković",
    "corresponding_authors": "",
    "abstract": "Passwords are widely used for user authentication, but they are often difficult for a user to recall, easily cracked by automated programs, and heavily reused. Security questions are also used for secondary authentication. They are more memorable than passwords, because the question serves as a hint to the user, but they are very easily guessed. We propose a new authentication mechanism, called “life-experience passwords (LEPs).” Sitting somewhere between passwords and security questions, an LEP consists of several facts about a user-chosen life event—such as a trip, a graduation, a wedding, and so on. At LEP creation, the system extracts these facts from the user’s input and transforms them into questions and answers. At authentication, the system prompts the user with questions and matches the answers with the stored ones. We show that question choice and design make LEPs much more secure than security questions and passwords, while the question-answer format promotes low password reuse and high recall. Specifically, we find that: (1) LEPs are 10 9 --10 14 × stronger than an ideal, randomized, eight-character password; (2) LEPs are up to 3 × more memorable than passwords and on par with security questions; and (3) LEPs are reused half as often as passwords. While both LEPs and security questions use personal experiences for authentication, LEPs use several questions that are closely tailored to each user. This increases LEP security against guessing attacks. In our evaluation, only 0.7% of LEPs were guessed by casual friends, and 9.5% by family members or close friends—roughly half of the security question guessing rate. On the downside, LEPs take around 5 × longer to input than passwords. So, these qualities make LEPs suitable for multi-factor authentication at high-value servers, such as financial or sensitive work servers, where stronger authentication strength is needed.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2926316232",
    "type": "article"
  },
  {
    "title": "Privado",
    "doi": "https://doi.org/10.1145/3386154",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Sanaz Taheri Boshrooyeh; Alptekın Küpçü; Öznur Özkasap",
    "corresponding_authors": "",
    "abstract": "Online Social Networks (OSNs) offer free storage and social networking services through which users can communicate personal information with one another. The personal information of the users collected by the OSN provider comes with privacy problems when being monetized for advertising purposes. To protect user privacy, existing studies propose utilizing data encryption that immediately prevents OSNs from monetizing users data and hence leaves secure OSNs with no convincing commercial model. To address this problem, we propose Privado as a privacy-preserving group-based advertising mechanism to be integrated into secure OSNs to re-empower monetizing ability. Privado is run by N servers, each provided by an independent provider. User privacy is protected against an active malicious adversary controlling N − 1 providers, all the advertisers, and a large fraction of the users. We base our design on the group-based advertising notion to protect user privacy, which is not possible in the personalized variant. Our design also delivers advertising transparency; the procedure of identifying target customers is operated solely by the OSN servers without getting users and advertisers involved. We carry out experiments to examine the advertising running time under various number of servers and group sizes. We also argue about the optimum number of servers with respect to user privacy and advertising running time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3032945924",
    "type": "article"
  },
  {
    "title": "Optimally Efficient Multi-party Fair Exchange and Fair Secure Multi-party Computation",
    "doi": "https://doi.org/10.1145/3477530",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Handan Kılınç Alper; Alptekın Küpçü",
    "corresponding_authors": "",
    "abstract": "Multi-party fair exchange (MFE) and fair secure multi-party computation (fair SMPC) are under-studied fields of research, with practical importance. In particular, we consider MFE scenarios where at the end of the protocol, either every participant receives every other participant’s item, or no participant receives anything. We analyze the case where a trusted third party (TTP) is optimistically available, although we emphasize that the trust put on the TTP is only regarding the fairness , and our protocols preserve the privacy of the exchanged items against the TTP. In the fair SMPC case, we prove that a malicious TTP can only harm fairness, but not security . We construct an asymptotically optimal multi-party fair exchange protocol that requires a constant number of rounds (in comparison to linear) and O(n 2 ) messages (in comparison to cubic), where n is the number of participating parties. In our protocol, we enable the parties to efficiently exchange any item that can be efficiently put into a verifiable encryption (e.g., signatures on a contract). We show how to apply this protocol on top of any SMPC protocol to achieve fairness with very little overhead (independent of the circuit size). We then generalize our protocol to efficiently handle any exchange topology (participants exchange items with arbitrary other participants). Our protocol guarantees fairness in its strongest sense: even if all n-1 other participants are malicious and colluding with each other, the fairness is still guaranteed.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3216252083",
    "type": "article"
  },
  {
    "title": "PRShare: A Framework for Privacy-preserving, Interorganizational Data Sharing",
    "doi": "https://doi.org/10.1145/3531225",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Lihi Idan; Joan Feigenbaum",
    "corresponding_authors": "",
    "abstract": "We consider the task of interorganizational data sharing, in which data owners, data clients, and data subjects have different and sometimes competing privacy concerns. One real-world scenario in which this problem arises concerns law-enforcement use of phone-call metadata: The data owner is a phone company, the data clients are law-enforcement agencies, and the data subjects are individuals who make phone calls. A key challenge in this type of scenario is that each organization uses its own set of proprietary intraorganizational attributes to describe the shared data; such attributes cannot be shared with other organizations. Moreover, data-access policies are determined by multiple parties and may be specified using attributes that are not directly comparable with the ones used by the owner to specify the data. We propose a system architecture and a suite of protocols that facilitate dynamic and efficient interorganizational data sharing, while allowing each party to use its own set of proprietary attributes to describe the shared data and preserving the confidentiality of both data records and proprietary intraorganizational attributes. We introduce the novel technique of Attribute-Based Encryption with Oblivious Attribute Translation (OTABE) , which plays a crucial role in our solution. This extension of attribute-based encryption uses semi-trusted proxies to enable dynamic and oblivious translation between proprietary attributes that belong to different organizations; it supports hidden access policies, direct revocation, and fine-grained, data-centric keys and queries. We prove that our OTABE-based framework is secure in the standard model and provide two real-world use cases.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4226285104",
    "type": "article"
  },
  {
    "title": "Assessment Framework for the Identification and Evaluation of Main Features for Distributed Usage Control Solutions",
    "doi": "https://doi.org/10.1145/3561511",
    "publication_date": "2022-09-09",
    "publication_year": 2022,
    "authors": "G Piedrola Gil; Aitor Arnáiz; Mariví Higuero; Francisco Javier Díez",
    "corresponding_authors": "",
    "abstract": "Data exchange between organizations is becoming an increasingly significant issue due to the great opportunities it presents. However, there is great reluctance to share if data sovereignty is not provided. Providing it calls for not only access control but also usage control implemented in distributed systems. Access control is a research field where there has been a great deal of work, but usage control, especially implemented in distributed systems as Distributed Usage Control (DUC), is a very new field of research that presents great challenges. Moreover, little is known about what challenges must really be faced and how they must be addressed. This is evidenced by the fact that existing research has focused non-specifically on different features of DUC, which are not formalized. Therefore, the path for the development of DUC solutions is unclear and it is difficult to analyze the scope of data sovereignty attained by the wide range of DUC solutions. In this context, this article is based on an initial in-depth analysis of DUC related work. In it, the challenges posed by DUC in terms of data sovereignty and the features that must be provided to address them are identified and analyzed for the first time. Based on these features, an initial DUC framework is proposed to assess in a practical and unified way the extent to which DUC solutions provide data sovereignty. Finally, the assessment framework is applied to compare the scopes of the most widespread DUC solutions and identify their limitations.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4295024044",
    "type": "article"
  },
  {
    "title": "Costs and Benefits of Authentication Advice",
    "doi": "https://doi.org/10.1145/3588031",
    "publication_date": "2023-03-17",
    "publication_year": 2023,
    "authors": "Hazel Murray; David Malone",
    "corresponding_authors": "",
    "abstract": "Authentication security advice is given with the goal of guiding users and organisations towards secure actions and practices. In this article, a taxonomy of 270 pieces of authentication advice is created, and a survey is conducted to gather information on the costs associated with following or enforcing the advice. Our findings indicate that security advice can be ambiguous and contradictory, with 41% of the advice collected being contradicted by another source. Additionally, users reported high levels of frustration with the advice and identified high usability costs. The study also found that end-users disagreed with each other 71% of the time about whether a piece of advice was valuable or not. We define a formal approach to identifying security benefits of advice. Our research suggests that cost-benefit analysis is essential in understanding the value of enforcing security policies. Furthermore, we find that organisation investment in security seems to have better payoffs than mechanisms with high costs to users.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3048404072",
    "type": "article"
  },
  {
    "title": "Resilience-by-design in Adaptive Multi-agent Traffic Control Systems",
    "doi": "https://doi.org/10.1145/3592799",
    "publication_date": "2023-04-17",
    "publication_year": 2023,
    "authors": "Ranwa Al Mallah; Talal Halabi; Bilal Farooq",
    "corresponding_authors": "",
    "abstract": "Connected and Autonomous Vehicles (CAVs) with their evolving data gathering capabilities will play a significant role in road safety and efficiency applications supported by Intelligent Transport Systems (ITSs), such as Traffic Signal Control (TSC) for urban traffic congestion management. However, their involvement will expand the space of security vulnerabilities and create larger threat vectors. In this article, we perform the first detailed security analysis and implementation of a new cyber-physical attack category carried out by the network of CAVs against Adaptive Multi-Agent Traffic Signal Control (AMATSC), namely, coordinated Sybil attacks, where vehicles with forged or fake identities try to alter the data collected by the AMATSC algorithms to sabotage their decisions. Consequently, a novel, game-theoretic mitigation approach at the application layer is proposed to minimize the impact of such sophisticated data corruption attacks. The devised minimax game model enables the AMATSC algorithm to generate optimal decisions under a suspected attack, improving its resilience. Extensive experimentation is performed on a traffic dataset provided by the city of Montréal under real-world intersection settings to evaluate the attack impact. Our results improved time loss on attacked intersections by approximately 48.9%. Substantial benefits can be gained from the mitigation, yielding more robust adaptive control of traffic across networked intersections.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3195793810",
    "type": "article"
  },
  {
    "title": "SAM: Query-efficient Adversarial Attacks against Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3611307",
    "publication_date": "2023-07-28",
    "publication_year": 2023,
    "authors": "Chenhan Zhang; Shiyao Zhang; James J. Q. Yu; Shui Yu",
    "corresponding_authors": "",
    "abstract": "Recent studies indicate that Graph Neural Networks (GNNs) are vulnerable to adversarial attacks. Particularly, adversarially perturbing the graph structure, e.g., flipping edges, can lead to salient degeneration of GNNs’ accuracy. In general, efficiency and stealthiness are two significant metrics to evaluate an attack method in practical use. However, most prevailing graph structure-based attack methods are query intensive, which impacts their practical use. Furthermore, while the stealthiness of perturbations has been discussed in previous studies, the majority of them focus on the attack scenario targeting a single node. To fill the research gap, we present a global attack method against GNNs, Saturation adversarial Attack with Meta-gradient, in this article. We first propose an enhanced meta-learning-based optimization method to obtain useful gradient information concerning graph structural perturbations. Then, leveraging the notion of saturation attack, we devise an effective algorithm to determine the perturbations based on the derived meta-gradients. Meanwhile, to ensure stealthiness, we introduce a similarity constraint to suppress the number of perturbed edges. Thorough experiments demonstrate that our method can effectively depreciate the accuracy of GNNs with a small number of queries. While achieving a higher misclassification rate, we also show that the perturbations developed by our method are not noticeable.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4385342974",
    "type": "article"
  },
  {
    "title": "Efficient History-Driven Adversarial Perturbation Distribution Learning in Low Frequency Domain",
    "doi": "https://doi.org/10.1145/3632293",
    "publication_date": "2023-11-08",
    "publication_year": 2023,
    "authors": "Han Cao; Qindong Sun; Yaqi Li; Rong Geng; Xiaoxiong Wang",
    "corresponding_authors": "",
    "abstract": "The existence of adversarial image makes us have to doubt the credibility of artificial intelligence system. Attackers can use carefully processed adversarial images to carry out a variety of attacks. Inspired by the theory of image compressed sensing, this paper proposes a new black-box attack, \\(\\mathcal {N}\\text{-HSA}_{LF}\\) . It uses covariance matrix adaptive evolution strategy (CMA-ES) to learn the distribution of adversarial perturbation in low frequency domain, reducing the dimensionality of solution space. And sep-CMA-ES is used to set the covariance matrix as a diagonal matrix, which further reduces the dimensions that need to be updated for the covariance matrix of multivariate Gaussian distribution learned in attacks, thereby reducing the computational cost of attack. And on this basis, we propose history-driven mean update and current optimal solution-guided improvement strategies to avoid the evolution of distribution to a worse direction. The experimental results show that the proposed \\(\\mathcal {N}\\text{-HSA}_{LF}\\) can achieve a higher attack success rate with fewer queries on attacking both CNN-based and transformer-based target models under \\(L_2\\) -norm and \\(L_\\infty\\) -norm constraints of perturbation. We also conduct an ablation study and the results show that the proposed improved strategies can effectively reduce the number of visits to the target model when making adversarial examples for hard examples. In addition, our attack is able to make the integrated defense strategy of GRIP-GAN and noise-embedded training ineffective to a certain extent.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4388491638",
    "type": "article"
  },
  {
    "title": "Safe and Efficient Implementation of a Security System on ARM using Intra-level Privilege Separation",
    "doi": "https://doi.org/10.1145/3309698",
    "publication_date": "2019-02-26",
    "publication_year": 2019,
    "authors": "Donghyun Kwon; Hayoon Yi; Yeongpil Cho; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "Security monitoring has long been considered as a fundamental mechanism to mitigate the damage of a security attack. Recently, intra-level security systems have been proposed that can efficiently and securely monitor system software without any involvement of more privileged entity. Unfortunately, there exists no full intra-level security system that can universally operate at any privilege level on ARM. However, as malware and attacks increase against virtually every level of privileged software including an OS, a hypervisor, and even the highest privileged software armored by TrustZone, we have been motivated to develop an intra-level security system, named Hilps . Hilps realizes true intra-level scheme in all these levels of privileged software on ARM by elaborately exploiting a new hardware feature of ARM’s latest 64-bit architecture, called TxSZ, that enables elastic adjustment of the accessible virtual address range. Furthermore, Hilps newly supports the sandbox mechanism that provides security tools with individually isolated execution environments, thereby minimizing security threats from untrusted security tools. We have implemented a prototype of Hilps on a real machine. The experimental results demonstrate that Hilps is quite promising for practical use in real deployments.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2917234824",
    "type": "article"
  },
  {
    "title": "Implementing Support for Pointers to Private Data in a General-Purpose Secure Multi-Party Compiler",
    "doi": "https://doi.org/10.1145/3154600",
    "publication_date": "2017-12-19",
    "publication_year": 2017,
    "authors": "Yihua Zhang; Marina Blanton; Ghada Almashaqbeh",
    "corresponding_authors": "",
    "abstract": "Recent compilers allow a general-purpose program (written in a conventional programming language) that handles private data to be translated into a secure distributed implementation of the corresponding functionality. The resulting program is then guaranteed to provably protect private data using secure multi-party computation techniques. The goals of such compilers are generality, usability, and efficiency, but the complete set of features of a modern programming language has not been supported to date by the existing compilers. In particular, recent compilers PICCO and the two-party ANSI C compiler strive to translate any C program into its secure multi-party implementation, but they currently lack support for pointers and dynamic memory allocation, which are important components of many C programs. In this work, we mitigate the limitation and add support for pointers to private data and consequently dynamic memory allocation to the PICCO compiler, enabling it to handle a more diverse set of programs over private data. Because doing so opens up a new design space, we investigate the use of pointers to private data (with known as well as private locations stored in them) in programs and report our findings. Aside from dynamic memory allocation, we examine other important topics associated with common pointer use such as reference by pointer/address, casting, and building various data structures in the context of secure multi-party computation. This results in enabling the compiler to automatically translate a user program that uses pointers to private data into its distributed implementation that provably protects private data throughout the computation. We empirically evaluate the constructions and report on the performance of representative programs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2964266265",
    "type": "article"
  },
  {
    "title": "GPLADD",
    "doi": "https://doi.org/10.1145/3326283",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Alexander V. Outkin; Brandon Eames; Meghan Galiardi; Sarah Walsh; Eric D. Vugrin; Byron Heersink; Jacob Aaron Hobbs; Gregory Dane Wyss",
    "corresponding_authors": "",
    "abstract": "Trust in a microelectronics-based system can be characterized as the level of confidence that a system is free of subversive alterations made during system development, or that the development process of a system has not been manipulated by a malicious adversary. Trust in systems has become an increasing concern over the past decade. This article presents a novel game-theoretic framework, called GPLADD (Graph-based Probabilistic Learning Attacker and Dynamic Defender), for analyzing and quantifying system trustworthiness at the end of the development process, through the analysis of risk of development-time system manipulation. GPLADD represents attacks and attacker-defender contests over time. It treats time as an explicit constraint and allows incorporating the informational asymmetries between the attacker and defender into analysis. GPLADD includes an explicit representation of attack steps via multi-step attack graphs, attacker and defender strategies, and player actions at different times. GPLADD allows quantifying the attack success probability over time and the attacker and defender costs based on their capabilities and strategies. This ability to quantify different attacks provides an input for evaluation of trust in the development process. We demonstrate GPLADD on an example attack and its variants. We develop a method for representing success probability for arbitrary attacks and derive an explicit analytic characterization of success probability for a specific attack. We present a numeric Monte Carlo study of a small set of attacks, quantify attack success probabilities, attacker and defender costs, and illustrate the options the defender has for limiting the attack success and improving trust in the development process.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2951816324",
    "type": "article"
  },
  {
    "title": "Malicious Overtones",
    "doi": "https://doi.org/10.1145/3360469",
    "publication_date": "2019-11-03",
    "publication_year": 2019,
    "authors": "Brian A. Powell",
    "corresponding_authors": "Brian A. Powell",
    "abstract": "A method for detecting electronic data theft from computer networks is described, capable of recognizing patterns of remote exfiltration occurring over days to weeks. Normal traffic flow data, in the form of a host’s ingress and egress bytes over time, is used to train an ensemble of one-class learners. The detection ensemble is modular, with individual classifiers trained on different traffic features thought to characterize malicious data transfers. We select features that model the egress to ingress byte balance over time, periodicity, short timescale irregularity, and density of the traffic. The features are most efficiently modeled in the frequency domain, which has the added benefit that variable duration flows are transformed to a fixed-size feature vector, and by sampling the frequency space appropriately, long-duration flows can be tested. When trained on days or weeks worth of traffic from individual hosts, our ensemble achieves a low false-positive rate (&lt;2%) on a range of different system types. Simulated exfiltration samples with a variety of different timing and data characteristics were generated and used to test ensemble performance on different kinds of systems: When trained on a client workstation’s external traffic, the ensemble was generally successful at detecting exfiltration that is not simultaneously ingress-heavy, connection-sparse, and of short duration—a combination that is not optimal for attackers seeking to transfer large amounts of data. Remote exfiltration is more difficult to detect from egress-heavy systems, like web servers, with normal traffic exhibiting timing characteristics similar to a wide range of exfiltration types.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4288085976",
    "type": "article"
  },
  {
    "title": "Improving Unlinkability of Attribute-based Authentication through Game Theory",
    "doi": "https://doi.org/10.1145/3501260",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Yevhen Zolotavkin; Jongkil Jay Jeong; Veronika Kuchta; Maksym Slavnenko; Robin Doss",
    "corresponding_authors": "",
    "abstract": "This article first formalizes the problem of unlinkable attribute-based authentication in the system where each user possesses multiple assertions and uses them interchangeably. Currently, there are no recommendations for optimal usage of assertions in such authentication systems. To mitigate this issue, we use conditional entropy to measure the uncertainty for a Relying Party who attempts to link observed assertions with user labels. Conditional entropy is the function of usage statistics for all assertions in the system. Personal decisions made by the users about the usage of assertions contribute to these statistics. This collective effect from all the users impacts the unlinkability of authentication and must be studied using game theory. We specify several instances of the game where context information that is provided to the users differs. Through game theory and based on conditional entropy, we demonstrate how each user optimizes usage for the personal set of assertions. In the experiment, we substantiate the advantage of the proposed rational decision-making approaches: Unlinkability that we obtain under Nash equilibrium is higher than in the system where users authenticate using their assertions at random. We finally propose an algorithm that calculates equilibrium and assists users with the selection of assertions. This manifests that described techniques can be executed in realistic settings. This does not require modification of existing authentication protocols and can be implemented in platform-independent identity agents. As a use case, we describe how our technique can be used in Digital Credential Wallets: We suggest that unlinkability of authentication can be improved for Verifiable Credentials.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4214892635",
    "type": "article"
  },
  {
    "title": "In the Land of MMUs: Multiarchitecture OS-Agnostic Virtual Memory Forensics",
    "doi": "https://doi.org/10.1145/3528102",
    "publication_date": "2022-03-30",
    "publication_year": 2022,
    "authors": "Andrea Oliveri; Davide Balzarotti",
    "corresponding_authors": "",
    "abstract": "The first step required to perform any analysis of a physical memory image is the reconstruction of the virtual address spaces, which allows translating virtual addresses to their corresponding physical offsets. However, this phase is often overlooked, and the challenges related to it are rarely discussed in the literature. Practical tools solve the problem by using a set of custom heuristics tailored on a very small number of well-known operating systems (OSs) running on few architectures. In this article, we look for the first time at all the different ways the virtual to physical translation can be operated in 10 different CPU architectures. In each case, we study the inviolable constraints imposed by the memory management unit that can be used to build signatures to recover the required data structures from memory without any knowledge about the running OS. We build a proof-of-concept tool to experiment with the extraction of virtual address spaces showing the challenges of performing an OS-agnostic virtual to physical address translation in real-world scenarios. We conduct experiments on a large set of 26 different OSs and a use case on a real hardware device. Finally, we show a possible usage of our technique to retrieve information about user space processes running on an unknown OS without any knowledge of its internals.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4221070120",
    "type": "article"
  },
  {
    "title": "What is Beautiful is Secure",
    "doi": "https://doi.org/10.1145/3533047",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Milica Stojmenović; Eric Spero; Miloš Stojmenović; Robert Biddle",
    "corresponding_authors": "",
    "abstract": "Visual appeal has been shown to influence perceptions of usability and credibility, and we hypothesize that something similar is happening with user judgments of website security: What is beautiful is secure . Web certificates provide reliable information about a website’s level of security, presented in browser interfaces. Users should use this to inform their trust decisions online, but evidence from laboratory studies and real-world usage suggests that they do not. We conducted two studies—one in lab, and one online—in which participants view and interact with websites with high and low visual appeal, and various security levels, and then make security-related judgments. In both studies, participants consistently rated visually appealing websites as more secure, and indicated they would be more likely to enter sensitive information into visually appealing websites—even when they were less secure. Our results provide evidence that users rely on visual appeal when making security and trust decisions on websites. We discuss how these results may be used to help users.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4225275488",
    "type": "article"
  },
  {
    "title": "So Near and Yet So Far – Symbolic Verification of Distance-Bounding Protocols",
    "doi": "https://doi.org/10.1145/3501402",
    "publication_date": "2022-05-31",
    "publication_year": 2022,
    "authors": "Alexandre Debant; Stéphanie Delaune; Cyrille Wiedling",
    "corresponding_authors": "",
    "abstract": "The continuous adoption of Near Field Communication (NFC) tags offers many new applications whose security is essential (e.g., contactless payments). In order to prevent flaws and attacks, we develop in this article a framework allowing us to analyse the underlying security protocols, taking into account the location of the agents and the transmission delay when exchanging messages. We propose two reduction results to render automatic verification possible relying on the existing verification tool ProVerif . Our first result allows one to consider a unique topology to catch all possible attacks. The second result simplifies the security analysis when considering Terrorist fraud. Then, based on these results, we perform a comprehensive case study analysis (27 protocols), in which we obtain new proofs of security for some protocols and detect attacks on some others.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4283770409",
    "type": "article"
  },
  {
    "title": "Differentially Private <i>k</i> -Nearest Neighbor Missing Data Imputation",
    "doi": "https://doi.org/10.1145/3507952",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Chris Clifton; Eric J. Hanson; Keith Merrill; Shawn Merrill",
    "corresponding_authors": "",
    "abstract": "Using techniques employing smooth sensitivity , we develop a method for \\( k \\) -nearest neighbor missing data imputation with differential privacy. This requires bounding the number of data incomplete tuples that can have their data complete “donor” changed by making a single addition or deletion to the dataset. The multiplicity of a single individual’s impact on an imputed dataset necessarily means our mechanisms require the addition of more noise than mechanisms that ignore missing data, but we show empirically that this is significantly outweighed by the bias reduction from imputing missing data.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4297790104",
    "type": "article"
  },
  {
    "title": "X-squatter: AI Multilingual Generation of Cross-Language Sound-squatting",
    "doi": "https://doi.org/10.1145/3663569",
    "publication_date": "2024-05-06",
    "publication_year": 2024,
    "authors": "Rodolfo Valentim; Idílio Drago; Marco Mellia; Federico Cerutti",
    "corresponding_authors": "",
    "abstract": "Sound-squatting is a squatting technique that exploits similarities in word pronunciation to trick users into accessing malicious resources. It is an understudied threat that has gained traction with the popularity of smart speakers and audio-only content, such as podcasts. The picture gets even more complex when multiple languages are involved. We here introduce X-squatter, a multi- and cross-language AI-based system that relies on a Transformer Neural Network for generating high-quality sound-squatting candidates. We illustrate the use of X-squatter by searching for domain name squatting abuse across hundreds of millions of issued TLS certificates, alongside other squatting types. Key findings unveil that approximately 15% of generated sound-squatting candidates have associated TLS certificates, well above the prevalence of other squatting types (7%). Furthermore, we employ X-squatter to assess the potential for abuse in PyPI packages, revealing the existence of hundreds of candidates within a 3-year package history. Notably, our results suggest that the current platform checks cannot handle sound-squatting attacks, calling for better countermeasures. We believe X-squatter uncovers the usage of multilingual sound-squatting phenomena on the Internet and it is a crucial asset for proactive protection against the threat.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4396671104",
    "type": "article"
  },
  {
    "title": "Flexichain: Flexible Payment Channel Network to Defend Against Channel Exhaustion Attack",
    "doi": "https://doi.org/10.1145/3687476",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Susil Kumar Mohanty; Somanath Tripathy",
    "corresponding_authors": "",
    "abstract": "The payment channel network (PCN) is an effective off-chain scaling solution widely recognized for reducing operational costs on permissionless blockchains. However, it still faces challenges such as lack of flexibility, channel exhaustion, and poor sustainability. Currently, a separate deposit is required for each payment channel, which locks a significant amount of coins for a longer period. This restricts the ability to move locked coins across their channels off-chain. Additionally, unbalanced (unidirectional) transfers can lead to channel exhaustion, rendering the channel unsustainable. To address these issues, we propose a novel off-chain flexible PCN protocol called Flexichain . Unlike existing approaches, Flexichain allows users to deposit coins per user rather than per channel. This provides flexibility to move coins freely between channels without relying on the blockchain or disrupting the off-chain cycle. Flexichain is proven to be secure under the Universal Composability framework and resistant against channel exhaustion attacks. To assess the performance of Flexichain, we conduct experiments on both on-chain and off-chain operations using snapshots of the Lightning Network. We evaluate the on-chain gas costs, success ratio and success amount of off-chain payments under uniform and skewed payment demands, as well as the computational and communication overheads of the off-chain contracts.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401427000",
    "type": "article"
  },
  {
    "title": "Bi-objective Optimization in Role Mining",
    "doi": "https://doi.org/10.1145/3697833",
    "publication_date": "2024-10-14",
    "publication_year": 2024,
    "authors": "Jason Crampton; Eduard Eiben; Gregory Gutin; Daniel Karapetyan; Diptapriyo Majumdar",
    "corresponding_authors": "",
    "abstract": "Role mining is a technique that is used to derive a role-based authorization policy from an existing policy. Given a set of users U , a set of permissions P , and a user–permission authorization relation \\(\\mathit {UPA} \\subseteq U \\times P\\) , a role mining algorithm seeks to compute a set of roles R , a user–role authorization relation \\(\\mathit {UA} \\subseteq U \\times R\\) , and a permission–role authorization relation \\(\\mathit {PA} \\subseteq R \\times P\\) , such that the composition of UA and PA is close (in some appropriate sense) to UPA . Role mining is therefore a core problem in the specification of role-based authorization policies. Role mining is known to be hard in general and exact solutions are often impossible to obtain, so there exists an extensive literature on variants of the role mining problem that seek to find approximate solutions and algorithms that use heuristics to find reasonable solutions efficiently. In this article, we first introduce the Generalized Noise Role Mining problem (GNRM)—a generalization of the MinNoise Role Mining problem—which we believe has considerable practical relevance. In particular, GNRM can produce “security-aware” or “availability-aware” solutions. Extending the work of Fomin et al., we show that GNRM is fixed parameter tractable, with parameter \\(r + k\\) , where \\(r\\) is the number of roles in the solution and \\(k\\) is the number of discrepancies between \\(\\mathit {UPA}\\) and the relation defined by the composition of \\(\\mathit {UA}\\) and \\(\\mathit {PA}\\) . We further introduce a bi-objective optimization variant of GNRM, where we wish to minimize both \\(r\\) and \\(k\\) subject to upper bounds \\(r \\le \\bar{r}\\) and \\(k\\le \\bar{k}\\) , where \\(\\bar{r}\\) and \\(\\bar{k}\\) are constants. We show that the Pareto front of this bi-objective optimization problem (BO-GNRM) can be computed in fixed-parameter tractable time with parameter \\(\\bar{r} +\\bar{k}\\) . From a practical perspective, a solution to BO-GNRM gives security managers the opportunity to identify a mined policy offering the best tradeoff between the number of policy discrepancies and the number of roles. We then report the results of our experimental work using the integer programming solver Gurobi to solve instances of BO-GNRM. Our key findings are that (a) we obtained strong support that Gurobi’s performance is fixed-parameter tractable, and (b) our results suggest that our techniques may be useful for role mining in practice, based on our experiments in the context of three well-known real-world authorization policies. We observed that, in many cases, our solver is capable of obtaining optimal solutions when the values of either k or r are small.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403398628",
    "type": "article"
  },
  {
    "title": "Cyber Threat Intelligence meets the Analytic Tradecraft",
    "doi": "https://doi.org/10.1145/3701299",
    "publication_date": "2024-10-24",
    "publication_year": 2024,
    "authors": "Björn Bjurling; Shahid Raza",
    "corresponding_authors": "",
    "abstract": "The volumes and sophistication of cyber threats in today’s cyber threat landscape have risen to levels where automated quantitative tools for Cyber Threat Intelligence (CTI) have become an indispensable part in the cyber defense arsenals. The AI and cyber security research communities are producing novel automated tools for CTI that quickly find their ways into commercial products. However, the quality of such automated intelligence products is being questioned by the intelligence community. Cyber security operators are forced to complement the automated tools with costly and time-consuming human intelligence analysis in order to improve the quality of the end product. For improving the quality, it has been suggested that researchers should incorporate methods from traditional intelligence analysis into the quantitative algorithms. This article presents a novel approach to cyber intelligence analysis called AMBARGO, which takes the inherent ambiguity of evidence into account in the analysis, using the Choquet integral, in formalizing the re-evaluation of evidence and hypotheses made by human analysts. The development of AMBARGO revolves around a cyber attribution use case, one of the hardest problems in CTI. The results of our evaluating experiments show that the robustness of AMBARGO outperforms state-of-the-art quantitative approaches to CTI in the presence of ambiguous evidence and potentially deceptive threat actor tactics. AMBARGO has thus the potential to fill a gap in the CTI state-of-the-art, which currently handles ambiguity poorly. The findings are also confirmed in a large-scale realistic experimental setting based on data from an APT campaign obtained from the MITRE ATT&amp;CK Framework.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403735097",
    "type": "article"
  },
  {
    "title": "DP-Poison: Poisoning Federated Learning under the Cover of Differential Privacy",
    "doi": "https://doi.org/10.1145/3702325",
    "publication_date": "2024-11-02",
    "publication_year": 2024,
    "authors": "Haibin Zheng; Jinyin Chen; Tao Liu; Yao Cheng; Zhao Wang; Yun Wang; Lan Gao; Shouling Ji; Xuhong Zhang",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) enables resource-constrained node devices to learn a shared model while keeping the training data local. Since recent research has demonstrated multiple privacy leakage attacks in FL, e.g., gradient inference attacks and membership inference attacks, differential privacy (DP) is applied to serve as one of the most effective privacy protection mechanisms. Despite the benefit DP brings, we observe that the introduction of DP also brings random changes to client updates, which will affect the robust aggregation algorithms. We reveal a novel poisoning attack under the cover of DP, named the DP-Poison attack in FL. Specifically, the DP-Poison attack is designed to achieve four goals: 1) maintaining the main task performance; 2) launching a successful attack; 3) escaping the robust aggregation algorithms in FL; and 4) keeping the effectiveness of DP privacy protection. To achieve these goals, we design multiple optimization goals to generate DP noise through a genetic algorithm. The optimization ensures that while the benign updates change randomly, the malicious updates can change towards the global model after adding the DP noise, so that it is easier to be accepted by the robust aggregation algorithms. Extensive experiments show that DP-Poison achieves a nearly 100% attack success rate while maintaining the proposed four goals.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404006835",
    "type": "article"
  },
  {
    "title": "Adversarial Attack and Defense for Commercial Black-box Chinese-English Speech Recognition Systems",
    "doi": "https://doi.org/10.1145/3701725",
    "publication_date": "2024-11-07",
    "publication_year": 2024,
    "authors": "Xuejing Yuan; Jiangshan Zhang; Kai Chen; Cheng'an Wei; Ruiyuan Li; Zhenkun Ma; Xinqi Ling",
    "corresponding_authors": "",
    "abstract": "The attacker can generate adversarial examples (AEs) to stealthily mislead automatic speech recognition (ASR) models, raising significant concerns about the security of intelligent voice control (IVC) devices. Existing adversarial attacks mainly generate AEs to mislead ASR models to output specific target English commands (e.g., open the door). However, it remains unknown whether AEs can be used to issue commands in other languages to attack commercial black-box ASR models. In this paper, taking Chinese phrases (e.g., 支付宝付款) and “Chinese-English code-switching” phrases (e.g., 关闭GPS) as the target commands, we propose adversarial attacks for commercial multilingual ASR models. In particular, if a multilingual speech recognition model can recognize Chinese and English, we call it a Chinese-English speech recognition model. In English, the meaning of “支付宝付款” and “关闭GPS” are “Alipay payment” and “turn off GPS”, respectively. In detail, we generate transferable AEs based on the open-sourced conventional DataTang Mandarin ASR model. Given 55 target commands, the success rate for generating AEs of them is up to 96% and 80% for Aliyun ASR API and Tencentyun ASR API, respectively. Our AEs can trigger actual attack actions on voice assistants (e.g., Apple Siri, Xiaomi Xiaoaitongxue) or spread malicious messages through ASR API services, while the target commands in the AEs are inaudible to human beings. Finally, by analyzing the spectrum differences between benign audio clips and AEs, we propose a general defense against adversarial audio attacks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404122108",
    "type": "article"
  },
  {
    "title": "AutoFR: Automated Filter Rule Generation for Adblocking",
    "doi": "https://doi.org/10.1145/3703836",
    "publication_date": "2024-11-14",
    "publication_year": 2024,
    "authors": "Hieu X. Le; Salma Elmalaki; Athina Markopoulou; Zubair Shafiq",
    "corresponding_authors": "",
    "abstract": "Adblocking relies on filter lists, which are manually curated and maintained by a community of filter list authors. Filter list curation is a laborious process that does not scale well to a large number of sites or over time. In this paper, we introduce AutoFR, a reinforcement learning framework to fully automate the process of filter rule creation and evaluation for sites of interest. We design an algorithm based on multi-arm bandits to generate filter rules that block ads while controlling the trade-off between blocking ads and avoiding visual breakage. We test AutoFR on thousands of sites and we show that it is efficient: it takes only a few minutes to generate filter rules for a site of interest. AutoFR is effective: it optimizes filter rules for a particular site that can block 86% of the ads, as compared to 87% by EasyList, while achieving comparable visual breakage. Using AutoFR as a building block, we devise three methodologies that generate filter rules across sites based on: (1) a modified version of AutoFR, (2) rule popularity, and (3) site similarity. We conduct an in-depth comparative analysis of these approaches by considering their effectiveness, efficiency, and maintainability. We demonstrate that some of them can generalize well to new sites in both controlled and live settings. We envision that AutoFR can assist the adblocking community in automatically generating and updating filter rules at scale.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404357929",
    "type": "article"
  },
  {
    "title": "End-to-Same-End Encryption: Modularly Augmenting an App with an Efficient, Portable, and Blind Cloud Storage",
    "doi": "https://doi.org/10.1145/3707460",
    "publication_date": "2024-12-06",
    "publication_year": 2024,
    "authors": "Long Chen; Ya‐Nan Li; Qiang Tang; Moti Yung",
    "corresponding_authors": "",
    "abstract": "The cloud has become pervasive, and we ask: how can we protect cloud data against the cloud itself? For secure user-to-user communication via a cloud server, End-to-End encryption has been formally studied, building on existing TLS channels without requiring new primitives. However, enabling user-to-same-user secure outsourced data storage–solving the analogous problem of “privacy from the server” while (1) relying on existing infrastructure and (2) supporting user mobility, remains open. Existing proposals, like password-protected secret sharing, target the same goal but are incompatible with existing cloud storage services. Specifically, they lack the simplicity needed to directly utilize existing cloud storage without requiring changes on the cloud side. Here, we propose a novel system for securely storing private data in existing cloud storage with the help of a key server (necessary, given the requirements). In our system, user data is secure against threats from the cloud server, the key server, and illegitimate users. Only the legitimate user can access the data on any device using a correct passphrase. Most importantly, our system does not require the storage server to support any newly programmable operations. Moreover, leveraging the existing App login, our system requires only one passphrase, which never leaves the user’s device and remains hidden from both servers. The security is proved under formal models, and its efficiency is demonstrated by experiments conducted on Amazon S3. Notably, a preliminary variant, based on our principles, was deployed by Snapchat in their My Eyes Only module, serving hundreds of millions of users!",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405114684",
    "type": "article"
  },
  {
    "title": "A Metric Differential Privacy Mechanism for Sentence Embeddings",
    "doi": "https://doi.org/10.1145/3708321",
    "publication_date": "2024-12-18",
    "publication_year": 2024,
    "authors": "Danushka Bollegala; Shuichi Otake; Tomoya Machide; Ken‐ichi Kawarabayashi",
    "corresponding_authors": "",
    "abstract": "Sentence embeddings represent the meaning of a given sentence using a fixed dimensional vector. Different approaches have been proposed in the Natural Language Processing (NLP) community for learning encoders that can produce accurate sentence embeddings that perform well for diverse downstream tasks requiring sentence representations. Despite prior work focusing mainly on creating accurate sentence embeddings, how to keep private the sensitive information contained in the sentences remains an unexplored research problem. In this article, we propose Covering Metric Analytic Gaussian (CMAG), a covering metric Differential Privacy (DP) mechanism for sentence embeddings such that minimal random noise is added to a set of sentence embeddings produced by an encoder to protect the private information expressed in those sentences. Given a sentence embedding s , CMAG considers the Mahalanobis distance between s and the other sentence embeddings s ’ in the local neighbourhood of s to determine the minimal amount of random noise that must be added to s to obtain provable metric DP guarantees. Experimental results show that the proposed DP mechanism protects private information better than previously proposed DP mechanisms while reporting good performance in a broad range of downstream NLP tasks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405547542",
    "type": "article"
  },
  {
    "title": "A Multi-view Approach to Preserve Privacy and Utility in Network Trace Anonymization",
    "doi": "https://doi.org/10.1145/3439732",
    "publication_date": "2021-02-09",
    "publication_year": 2021,
    "authors": "Meisam Mohammady; Momen Oqaily; Lingyu Wang; Yuan Hong; Habib Louafi; Makan Pourzandi; Mourad Debbabi",
    "corresponding_authors": "",
    "abstract": "As network security monitoring grows more sophisticated, there is an increasing need for outsourcing such tasks to third-party analysts. However, organizations are usually reluctant to share their network traces due to privacy concerns over sensitive information, e.g., network and system configuration, which may potentially be exploited for attacks. In cases where data owners are convinced to share their network traces, the data are typically subjected to certain anonymization techniques, e.g., CryptoPAn, which replaces real IP addresses with prefix-preserving pseudonyms. However, most such techniques either are vulnerable to adversaries with prior knowledge about some network flows in the traces or require heavy data sanitization or perturbation, which may result in a significant loss of data utility. In this article, we aim to preserve both privacy and utility through shifting the trade-off from between privacy and utility to between privacy and computational cost. The key idea is for the analysts to generate and analyze multiple anonymized views of the original network traces: Those views are designed to be sufficiently indistinguishable even to adversaries armed with prior knowledge, which preserves the privacy, whereas one of the views will yield true analysis results privately retrieved by the data owner, which preserves the utility. We formally analyze the privacy of our solution and experimentally evaluate it using real network traces provided by a major ISP. The experimental results show that our approach can significantly reduce the level of information leakage (e.g., less than 1% of the information leaked by CryptoPAn) with comparable utility.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3126333114",
    "type": "article"
  },
  {
    "title": "Inhibiting and Detecting Offline Password Cracking Using ErsatzPasswords",
    "doi": "https://doi.org/10.1145/2996457",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "Christopher Gutierrez; Mohammed H. Almeshekah; Eugene H. Spafford; Mikhail J. Atallah; Jeff Avery",
    "corresponding_authors": "",
    "abstract": "In this work, we present a simple, yet effective and practical scheme to improve the security of stored password hashes, increasing the difficulty to crack passwords and exposing cracking attempts. We utilize a hardware-dependent function (HDF), such as a physically unclonable function (PUF) or a hardware security module (HSM), at the authentication server to inhibit offline password discovery. Additionally, a deception mechanism is incorporated to alert administrators of cracking attempts. Using an HDF to generate password hashes hinders attackers from recovering the true passwords without constant access to the HDF. Our scheme can integrate with legacy systems without needing additional servers, changing the structure of the hashed password file, nor modifying client machines. When using our scheme, the structure of the hashed passwords file, e.g., etc/shadow or etc/master.passwd , will appear no different than traditional hashed password files. 1 However, when attackers exfiltrate the hashed password file and attempt to crack it, the passwords they will receive are ErsatzPasswords—“fake passwords.” The ErsatzPasswords scheme is flexible by design, enabling it to be integrated into existing authentication systems without changes to user experience. The proposed scheme is integrated into the pam_unix module as well as two client/server authentication schemes: Lightweight Directory Access Protocol (LDAP) authentication and the Pythia pseudorandom function (PRF) Service [Everspaugh et al. 2015]. The core library to support ErsatzPasswords written in C and Python consists of 255 and 103 lines of code, respectively. The integration of ErsatzPasswords into each explored authentication system required less than 100 lines of additional code. Experimental evaluation of ErsatzPasswords shows an increase in authentication latency on the order of 100ms, which maybe acceptable for real world systems. We also describe a framework for implementing ErsatzPasswords using a Trusted Platform Module (TPM).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2561122436",
    "type": "article"
  },
  {
    "title": "Mechanized Proofs of Adversarial Complexity and Application to Universal Composability",
    "doi": "https://doi.org/10.1145/3589962",
    "publication_date": "2023-03-31",
    "publication_year": 2023,
    "authors": "Manuel Barbosa; Gilles Barthe; Benjamin Grégoire; Adrien Koutsos; Pierre-Yves Strub",
    "corresponding_authors": "",
    "abstract": "In this work, we enhance the EasyCrypt proof assistant to reason about the computational complexity of adversaries. The key technical tool is a Hoare logic for reasoning about computational complexity (execution time and oracle calls) of adversarial computations. Our Hoare logic is built on top of the module system used by EasyCrypt for modeling adversaries. We prove that our logic is sound w.r.t. the semantics of EasyCrypt programs—we also provide full semantics for the EasyCrypt module system, which was lacking previously. We showcase (for the first time in EasyCrypt and in other computer-aided cryptographic tools) how our approach can express precise relationships between the probability of adversarial success and their execution time. In particular, we can quantify existentially over adversaries in a complexity class and express general composition statements in simulation-based frameworks. Moreover, such statements can be composed to derive standard concrete security bounds for cryptographic constructions whose security is proved in a modular way. As a main benefit of our approach, we revisit security proofs of some well-known cryptographic constructions and present a new formalization of universal composability.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3152271084",
    "type": "article"
  },
  {
    "title": "The Multi-User Constrained Pseudorandom Function Security of Generalized GGM Trees for MPC and Hierarchical Wallets",
    "doi": "https://doi.org/10.1145/3592608",
    "publication_date": "2023-04-14",
    "publication_year": 2023,
    "authors": "Chun Guo; Xiao Wang; Xiang Xie; Yu Yu",
    "corresponding_authors": "",
    "abstract": "Multi-user (mu) security considers large-scale attackers that, given access to a number of cryptosystem instances, attempt to compromise at least one of them. We initiate the study of mu security of the so-called GGM tree that stems from the pseudorandom generator to pseudorandom function transformation of Goldreich, Goldwasser, and Micali, with a goal to provide references for its recently popularized use in applied cryptography. We propose a generalized model for GGM trees and analyze its mu prefix-constrained pseudorandom function security in the random oracle model. Our model allows to derive concrete bounds and improvements for various protocols, and we showcase on the Bitcoin-Improvement-Proposal standard Bip32 hierarchical wallets and function secret sharing protocols. In both scenarios, we propose improvements with better performance and concrete security bounds at the same time. Compared with the state-of-the-art designs, our SHACAL3 - and Keccak -p-based Bip32 variants reduce the communication cost of MPC-based implementations by 73.3% to 93.8%, whereas our AES -based function secret sharing substantially improves mu security while reducing computations by 50%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4365509744",
    "type": "article"
  },
  {
    "title": "System Auditing for Real-Time Systems",
    "doi": "https://doi.org/10.1145/3625229",
    "publication_date": "2023-09-23",
    "publication_year": 2023,
    "authors": "Ayoosh Bansal; Anant Kandikuppa; Monowar Hasan; Chien-Ying Chen; Adam Bates; Sibin Mohan",
    "corresponding_authors": "",
    "abstract": "System auditing is an essential tool for detecting malicious events and conducting forensic analysis. Although used extensively on general-purpose systems, auditing frameworks have not been designed with consideration for the unique constraints and properties of Real-Time Systems (RTS). System auditing could provide tremendous benefits for security-critical RTS. However, a naive deployment of auditing on RTS could violate the temporal requirements of the system while also rendering auditing incomplete and ineffectual. To ensure effective auditing that meets the computational needs of recording complete audit information while adhering to the temporal requirements of the RTS, it is essential to carefully integrate auditing into the real-time (RT) schedule. This work adapts the Linux Audit framework for use in RT Linux by leveraging the common properties of such systems, such as special purpose and predictability. Ellipsis , an efficient system for auditing RTS, is devised that learns the expected benign behaviors of the system and generates succinct descriptions of the expected activity. Evaluations using varied RT applications show that Ellipsis reduces the volume of audit records generated during benign activity by up to 97.55% while recording detailed logs for suspicious activities. Empirical analyses establish that the auditing infrastructure adheres to the properties of predictability and isolation that are important to RTS. Furthermore, the schedulability of RT tasksets under audit is comprehensively analyzed to enable the safe integration of auditing in RT task schedules.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386982018",
    "type": "article"
  },
  {
    "title": "Eyes See Hazy while Algorithms Recognize Who You Are",
    "doi": "https://doi.org/10.1145/3632292",
    "publication_date": "2023-11-10",
    "publication_year": 2023,
    "authors": "Yong Zeng; Jiale Liu; Dong Tong; Qingqi Pei; Jianfeng Ma; Yao Liu",
    "corresponding_authors": "",
    "abstract": "Facial recognition technology has been developed and widely used for decades. However, it has also made privacy concerns and researchers’ expectations for facial recognition privacy-preserving technologies. To provide privacy, detailed or semantic contents in face images should be obfuscated. However, face recognition algorithms have to be tailor-designed according to current obfuscation methods, as a result the face recognition service provider has to update its commercial off-the-shelf(COTS) products for each obfuscation method. Meanwhile, current obfuscation methods have no clearly quantified explanation. This paper presents a universal face obfuscation method for a family of face recognition algorithms using global or local structure of eigenvector space. By specific mathematical explanations, we show that the upper bound of the distance between the original and obfuscated face images is smaller than the given recognition threshold. Experiments show that the recognition degradation is 0% for global structure based and 0.3%-5.3% for local structure based, respectively. Meanwhile, we show that even if an attacker knows the whole obfuscation method, he/she has to enumerate all the possible roots of a polynomial with an obfuscation coefficient, which is computationally infeasible to reconstruct original faces. So our method shows a good performance in both privacy and recognition accuracy without modifying recognition algorithms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388574677",
    "type": "article"
  },
  {
    "title": "Sound-based Two-Factor Authentication: Vulnerabilities and Redesign",
    "doi": "https://doi.org/10.1145/3632175",
    "publication_date": "2023-11-11",
    "publication_year": 2023,
    "authors": "Prakash Shrestha; Ahmed Tanvir Mahdad; Nitesh Saxena",
    "corresponding_authors": "",
    "abstract": "Reducing the level of user effort involved in traditional two-factor authentication (TFA) constitutes an important research topic. An interesting representative approach, Sound-Proof , leverages ambient sounds to detect the proximity between the second-factor device (phone) and the login terminal (browser), and eliminates the need for the user to transfer PIN codes. In this paper, we identify a weakness of the Sound-Proof system that makes it completely vulnerable to passive “environment guessing” and active “environment manipulating” remote attackers and proximity attackers. Addressing these security issues, we propose Listening-Watch , a new TFA mechanism based on a wearable device (watch/bracelet) and active browser-generated random speech sounds. As the user attempts to log in, the browser populates a short random code encoded into speech, and the login succeeds if the watch’s audio recording contains this code (decoded using speech recognition ), and is similar enough to the browser’s audio recording. The remote attacker, who has guessed/manipulated the user’s environment, will be defeated since authentication success relies upon the presence of the random code in watch’s recordings. The proximity attacker will also be defeated unless it is extremely close (&lt; 50 cm) to the watch since the wearable microphones are usually designed to capture only nearby sounds (e.g., voice commands).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388594071",
    "type": "article"
  },
  {
    "title": "Non-Intrusive Balance Tomography Using Reinforcement Learning in the Lightning Network",
    "doi": "https://doi.org/10.1145/3639366",
    "publication_date": "2023-12-29",
    "publication_year": 2023,
    "authors": "Yan Qiao; Kui Wu; Majid Khabbazian",
    "corresponding_authors": "",
    "abstract": "The Lightning Network (LN) is a second layer system for solving the scalability problem of Bitcoin transactions. In the current implementation of LN, channel capacity (i.e., the sum of individual balances held in the channel) is public information, while individual balances are kept secret for privacy concerns. Attackers may discover a particular balance of a channel by sending multiple fake payments through the channel. Such an attack, however, can hardly threaten the security of the LN system due to its high cost and noticeable intrusions. In this work, we present a novel non-intrusive balance tomography attack, which infers channel balances silently by performing legal transactions between two pre-created LN nodes. To minimize the cost of the attack, we propose an algorithm to compute the optimal payment amount for each transaction and design a path construction method using reinforcement learning to explore the most informative path to conduct the transactions. Finally, we propose two approaches (NIBT-RL and NIBT-RL- β ) to accurately and efficiently infer all individual balances using the results of these transactions. Experiments using simulated account balances over actual LN topology show that our method can accurately infer \\(90\\%\\sim 94\\% \\) of all balances in LN with around 12 USD.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390399721",
    "type": "article"
  },
  {
    "title": "A Multi-server ORAM Framework with Constant Client Bandwidth Blowup",
    "doi": "https://doi.org/10.1145/3369108",
    "publication_date": "2020-02-05",
    "publication_year": 2020,
    "authors": "Thang Hoang; Attila A. Yavuz; Jorge Guajardo",
    "corresponding_authors": "",
    "abstract": "Oblivious Random Access Machine (ORAM) allows a client to hide the access pattern when accessing sensitive data on a remote server. It is known that there exists a logarithmic communication lower bound on any passive ORAM construction, where the server only acts as the storage service. This overhead, however, was shown costly for some applications. Several active ORAM schemes with server computation have been proposed to overcome this limitation. However, they mostly rely on costly homomorphic encryptions, whose performance is worse than passive ORAM. In this article, we propose S 3 ORAM, a new multi-server ORAM framework, which features O (1) client bandwidth blowup and low client storage without relying on costly cryptographic primitives. Our key idea is to harness Shamir Secret Sharing and a multi-party multiplication protocol on applicable binary tree-ORAM paradigms. This strategy allows the client to instruct the server(s) to perform secure and efficient computation on his/her behalf with a low intervention thereby, achieving a constant client bandwidth blowup and low server computational overhead. Our framework can also work atop a general k -ary tree ORAM structure ( k ≥ 2). We fully implemented our framework, and strictly evaluated its performance on a commodity cloud platform (Amazon EC2). Our comprehensive experiments confirmed the efficiency of S 3 ORAM framework, where it is approximately 10× faster than the most efficient passive ORAM (i.e., Path-ORAM) for a moderate network bandwidth while being three orders of magnitude faster than active ORAM with O (1) bandwidth blowup (i.e., Onion-ORAM). We have open-sourced the implementation of our framework for public testing and adaptation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3010963761",
    "type": "article"
  },
  {
    "title": "A Study on the Use of Checksums for Integrity Verification of Web Downloads",
    "doi": "https://doi.org/10.1145/3410154",
    "publication_date": "2020-09-28",
    "publication_year": 2020,
    "authors": "Alexandre Meylan; Mauro Cherubini; Bertil Chapuis; Mathias Humbert; Igor Bilogrevic; Kévin Huguenin",
    "corresponding_authors": "",
    "abstract": "App stores provide access to millions of different programs that users can download on their computers. Developers can also make their programs available for download on their websites and host the program files either directly on their website or on third-party platforms, such as mirrors. In the latter case, as users download the software without any vetting from the developers, they should take the necessary precautions to ensure that it is authentic. One way to accomplish this is to check that the published file’s integrity verification code—the checksum—matches that (if provided) of the downloaded file. To date, however, there is little evidence to suggest that such a process is effective. Even worse, very few usability studies about it exist. In this article, we provide the first comprehensive study that assesses the usability and effectiveness of the manual checksum verification process. First, by means of an in-situ experiment with 40 participants and eye-tracking technology, we show that the process is cumbersome and error-prone. Second, after a 4-month-long in-the-wild experiment with 134 participants, we demonstrate how our proposed solution—a Chrome extension that verifies checksums automatically—significantly reduces human errors, improves coverage, and has only limited impact on usability. It also confirms that, sadly, only a tiny minority of websites that link to executable files in our sample provide checksums (0.01%), which is a strong call to action for web standards bodies, service providers, and content creators to increase the use of file integrity verification on their properties.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3089880085",
    "type": "article"
  },
  {
    "title": "Designing Strong Privacy Metrics Suites Using Evolutionary Optimization",
    "doi": "https://doi.org/10.1145/3439405",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Isabel Wagner; Iryna Yevseyeva",
    "corresponding_authors": "",
    "abstract": "The ability to measure privacy accurately and consistently is key in the development of new privacy protections. However, recent studies have uncovered weaknesses in existing privacy metrics, as well as weaknesses caused by the use of only a single privacy metric. Metrics suites, or combinations of privacy metrics, are a promising mechanism to alleviate these weaknesses, if we can solve two open problems: which metrics should be combined and how. In this article, we tackle the first problem, i.e., the selection of metrics for strong metrics suites, by formulating it as a knapsack optimization problem with both single and multiple objectives. Because solving this problem exactly is difficult due to the large number of combinations and many qualities/objectives that need to be evaluated for each metrics suite, we apply 16 existing evolutionary and metaheuristic optimization algorithms. We solve the optimization problem for three privacy application domains: genomic privacy, graph privacy, and vehicular communications privacy. We find that the resulting metrics suites have better properties, i.e., higher monotonicity, diversity, evenness, and shared value range, than previously proposed metrics suites.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3120673763",
    "type": "article"
  },
  {
    "title": "#PrettyFlyForAWiFi",
    "doi": "https://doi.org/10.1145/3473672",
    "publication_date": "2021-09-30",
    "publication_year": 2021,
    "authors": "Simon Birnbach; Richard Baker; Simon Eberz; Ivan Martinović",
    "corresponding_authors": "",
    "abstract": "Drones are becoming increasingly popular for hobbyists and recreational use. But with this surge in popularity comes increased risk to privacy as the technology makes it easy to spy on people in otherwise-private environments, such as an individual’s home. An attacker can fly a drone over fences and walls to observe the inside of a house, without having physical access. Existing drone detection systems require specialist hardware and expensive deployment efforts, making them inaccessible to the general public. In this work, we present a drone detection system that requires minimal prior configuration and uses inexpensive commercial off-the-shelf hardware to detect drones that are carrying out privacy invasion attacks. We use a model of the attack structure to derive statistical metrics for movement and proximity that are then applied to received communications between a drone and its controller. We test our system in real-world experiments with two popular consumer drone models mounting privacy invasion attacks using a range of flight patterns. We are able both to detect the presence of a drone and to identify which phase of the privacy attack was in progress while being resistant to false positives from other mobile transmitters. For line-of-sight approaches using our kurtosis-based method, we are able to detect all drones at a distance of 6 m, with the majority of approaches detected at 25 m or farther from the target window without suffering false positives for stationary or mobile non-drone transmitters.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3201736149",
    "type": "article"
  },
  {
    "title": "Contact Discovery in Mobile Messengers: Low-cost Attacks, Quantitative Analyses, and Efficient Mitigations",
    "doi": "https://doi.org/10.1145/3546191",
    "publication_date": "2022-06-30",
    "publication_year": 2022,
    "authors": "Christoph Hagen; Christian Weinert; Christoph Sendner; Alexandra Dmitrienko; Thomas Schneider",
    "corresponding_authors": "",
    "abstract": "Contact discovery allows users of mobile messengers to conveniently connect with people in their address book. In this work, we demonstrate that severe privacy issues exist in currently deployed contact discovery methods and propose suitable mitigations. Our study of three popular messengers (WhatsApp, Signal, and Telegram) shows that large-scale crawling attacks are (still) possible. Using an accurate database of mobile phone number prefixes and very few resources, we queried 10 % of US mobile phone numbers for WhatsApp and 100 % for Signal. For Telegram, we find that its API exposes a wide range of sensitive information, even about numbers not registered with the service. We present interesting (cross-messenger) usage statistics, which also reveal that very few users change the default privacy settings. Furthermore, we demonstrate that currently deployed hashing-based contact discovery protocols are severely broken by comparing three methods for efficient hash reversal. Most notably, we show that with the password cracking tool “JTR,” we can iterate through the entire worldwide mobile phone number space in &lt; 150 s on a consumer-grade GPU. We also propose a significantly improved rainbow table construction for non-uniformly distributed input domains that is of independent interest. Regarding mitigations, we most notably propose two novel rate-limiting schemes: our incremental contact discovery for services without server-side contact storage strictly improves over Signal’s current approach while being compatible with private set intersection, whereas our differential scheme allows even stricter rate limits at the overhead for service providers to store a small constant-size state that does not reveal any contact information.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4283747505",
    "type": "article"
  },
  {
    "title": "Accountable Private Set Cardinality for Distributed Measurement",
    "doi": "https://doi.org/10.1145/3477531",
    "publication_date": "2022-04-27",
    "publication_year": 2022,
    "authors": "Ellis Fenske; Akshaya Mani; Aaron Johnson; Micah Sherr",
    "corresponding_authors": "",
    "abstract": "We introduce cryptographic protocols for securely and efficiently computing the cardinality of set union and set intersection. Our private set-cardinality protocols ( PSC ) are designed for the setting in which a large set of parties in a distributed system makes observations, and a small set of parties with more resources and higher reliability aggregates the observations. PSC allows for secure and useful statistics gathering in privacy-preserving distributed systems. For example, it allows operators of anonymity networks such as Tor to securely answer the questions: How many unique users are using the network? and How many hidden services are being accessed? We prove the correctness and security of PSC in the Universal Composability framework against an active adversary that compromises all but one of the aggregating parties. Although successful output cannot be guaranteed in this setting, PSC either succeeds or terminates with an abort, and we furthermore make the adversary accountable for causing an abort by blaming at least one malicious party. We also show that PSC prevents adaptive corruption of the data parties from revealing past observations, which prevents them from being victims of targeted compromise, and we ensure safe measurements by making outputs differentially private. We present a proof-of-concept implementation of PSC and use it to demonstrate that PSC operates with low computational overhead and reasonable bandwidth. It can count tens of thousands of unique observations from tens to hundreds of data-collecting parties while completing within hours. PSC is thus suitable for daily measurements in a distributed system.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4283775510",
    "type": "article"
  },
  {
    "title": "Time-Aware Anonymization of Knowledge Graphs",
    "doi": "https://doi.org/10.1145/3563694",
    "publication_date": "2022-09-23",
    "publication_year": 2022,
    "authors": "Anh-Tu Hoang; Barbara Carminati; Elena Ferrari",
    "corresponding_authors": "",
    "abstract": "Knowledge graphs (KGs) play an essential role in data sharing because they can model both users’ attributes and their relationships. KGs can tailor many data analyses, such as classification where a sensitive attribute is selected and the analyst analyzes the associations between users and the sensitive attribute’s values (aka sensitive values). Data providers anonymize their KGs and share the anonymized versions to protect users’ privacy. Unfortunately, an adversary can exploit these attributes and relationships to infer sensitive information by monitoring either one or many snapshots of a KG. To cope with this issue, in this paper, we introduce ( k , l )-Sequential Attribute Degree (( k , l )-sad), an extension of the k w -tad principle[10], to ensure that sensitive values of re-identified users are diverse enough to prevent them from being inferred with a confidence higher than \\(\\frac{1}{l} \\) even though adversaries monitor all published KGs. In addition, we develop the Time-Aware Knowledge Graph Anonymization Algorithm to anonymize KGs such that all published anonymized versions of a KG satisfy the ( k , l )-sad principle, by, at the same time, preserving the utility of the anonymized data. We conduct experiments on four real-life datasets to show the effectiveness of our proposal and compare it with k w -tad.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4297009420",
    "type": "article"
  },
  {
    "title": "Pareto-optimal Defenses for the Web Infrastructure: Theory and Practice",
    "doi": "https://doi.org/10.1145/3567595",
    "publication_date": "2022-10-13",
    "publication_year": 2022,
    "authors": "Giorgio Di Tizio; Patrick Speicher; Milivoj Simeonovski; Michael Backes; Ben Stock; Robert Künnemann",
    "corresponding_authors": "",
    "abstract": "The integrity of the content a user is exposed to when browsing the web relies on a plethora of non-web technologies and an infrastructure of interdependent hosts, communication technologies, and trust relations. Incidents like the Chinese Great Cannon or the MyEtherWallet attack make it painfully clear: the security of end users hinges on the security of the surrounding infrastructure: routing, DNS, content delivery, and the PKI. There are many competing, but isolated proposals to increase security, from the network up to the application layer. So far, researchers have focused on analyzing attacks and defenses on specific layers. We still lack an evaluation of how, given the status quo of the web, these proposals can be combined, how effective they are, and at what cost the increase of security comes. In this work, we propose a graph-based analysis based on Stackelberg planning that considers a rich attacker model and a multitude of proposals from IPsec to DNSSEC and SRI. Our threat model considers the security of billions of users against attackers ranging from small hacker groups to nation-state actors. Analyzing the infrastructure of the Top 5k Alexa domains, we discover that the security mechanisms currently deployed are ineffective and that some infrastructure providers have a comparable threat potential to nations. We find a considerable increase of security (up to 13% protected web visits) is possible at a relatively modest cost, due to the effectiveness of mitigations at the application and transport layer, which dominate expensive infrastructure enhancements such as DNSSEC and IPsec.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4304944577",
    "type": "article"
  },
  {
    "title": "Revisiting the Security of Biometric Authentication Systems Against Statistical Attacks",
    "doi": "https://doi.org/10.1145/3571743",
    "publication_date": "2022-11-19",
    "publication_year": 2022,
    "authors": "Sohail Habib; Hassan Khan; Andrew Hamilton-Wright; Urs Hengartner",
    "corresponding_authors": "",
    "abstract": "The uniqueness of behavioral biometrics (e.g., voice or keystroke patterns) has been challenged by recent works. Statistical attacks have been proposed that infer general population statistics and target behavioral biometrics against a particular victim. We show that despite their success, these approaches require several attempts for successful attacks against different biometrics due to the different nature of overlap in users’ behavior for these biometrics. Furthermore, no mechanism has been proposed to date that detects statistical attacks. In this work, we propose a new hypervolumes-based statistical attack and show that unlike existing methods, it (1) is successful against a variety of biometrics, (2) is successful against more users, and (3) requires fewest attempts for successful attacks. More specifically, across five diverse biometrics, for the first attempt, on average our attack is 18 percentage points more successful than the second best (37% vs. 19%). Similarly, for the fifth attack attempt, on average our attack is 18 percentage points more successful than the second best (67% vs. 49%). We propose and evaluate a mechanism that can detect the more devastating statistical attacks. False rejects in biometric systems are common, and by distinguishing statistical attacks from false rejects, our defense improves usability and security. The evaluation of the proposed detection mechanism shows its ability to detect on average 94% of the tested statistical attacks with an average probability of 3% to detect false rejects as a statistical attack. Given the serious threat posed by statistical attacks to biometrics that are used today (e.g., voice), our work highlights the need for defending against these attacks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4309562180",
    "type": "article"
  },
  {
    "title": "Verifiable Graph Processing",
    "doi": "https://doi.org/10.1145/3233181",
    "publication_date": "2018-10-01",
    "publication_year": 2018,
    "authors": "Yupeng Zhang; Charalampos Papamanthou; Jonathan Katz",
    "corresponding_authors": "",
    "abstract": "We consider a scenario in which a data owner outsources storage of a large graph to an untrusted server; the server performs computations on this graph in response to queries from a client (whether the data owner or others), and the goal is to ensure verifiability of the returned results. Applying generic verifiable computation (VC) would involve compiling each graph computation to a circuit or a RAM program and would incur large overhead, especially in the proof-computation time. In this work, we address the above by designing, building, and evaluating A litheia , a VC system tailored for graph queries such as computing shortest paths, longest paths, and maximum flows. The underlying principle of A litheia is to minimize the use of generic VC techniques by leveraging various algorithmic approaches specific for graphs. This leads to both theoretical and practical improvements. Asymptotically, it improves the complexity of proof computation by at least a logarithmic factor. On the practical side, our system achieves significant performance improvements over current state-of-the-art VC systems (up to a 10-orders-of-magnitude improvement in proof-computation time, and a 99.9% reduction in server storage), while scaling to 200,000-node graphs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2895062505",
    "type": "article"
  },
  {
    "title": "Code Renewability for Native Software Protection",
    "doi": "https://doi.org/10.1145/3404891",
    "publication_date": "2020-08-25",
    "publication_year": 2020,
    "authors": "Bert Abrath; Bart Coppens; Jens Van den Broeck; Brecht Wyseur; Alessandro Cabutto; Paolo Falcarin; Bjorn De Sutter",
    "corresponding_authors": "",
    "abstract": "Software protection aims at safeguarding assets embedded in software by preventing and delaying reverse engineering and tampering attacks. This paper presents an architecture and supporting tool flow to renew parts of native applications dynamically. Renewed and diversified code and data belonging to either the original application or to linked-in protections are delivered from a secure server to a client on demand. This results in frequent changes to the software components when they are under attack, thus making attacks harder. By supporting various forms of diversification and renewability, novel protection combinations become available, and existing combinations become stronger. The prototype implementation is evaluated on a number of industrial use cases.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3010113207",
    "type": "article"
  },
  {
    "title": "Systematic Mutation-Based Evaluation of the Soundness of Security-Focused Android Static Analysis Techniques",
    "doi": "https://doi.org/10.1145/3439802",
    "publication_date": "2021-02-09",
    "publication_year": 2021,
    "authors": "Amit Seal Ami; Kaushal Kafle; Kevin Moran; Adwait Nadkarni; Denys Poshyvanyk",
    "corresponding_authors": "",
    "abstract": "Mobile application security has been a major area of focus for security research over the course of the last decade. Numerous application analysis tools have been proposed in response to malicious, curious, or vulnerable apps. However, existing tools, and specifically, static analysis tools, trade soundness of the analysis for precision and performance and are hence soundy. Unfortunately, the specific unsound choices or flaws in the design of these tools is often not known or well-documented, leading to misplaced confidence among researchers, developers, and users. This paper describes the Mutation-based Soundness Evaluation ($\\mu$SE) framework, which systematically evaluates Android static analysis tools to discover, document, and fix flaws, by leveraging the well-founded practice of mutation analysis. We implemented $\\mu$SE and applied it to a set of prominent Android static analysis tools that detect private data leaks in apps. In a study conducted previously, we used $\\mu$SE to discover $13$ previously undocumented flaws in FlowDroid, one of the most prominent data leak detectors for Android apps. Moreover, we discovered that flaws also propagated to other tools that build upon the design or implementation of FlowDroid or its components. This paper substantially extends our $\\mu$SE framework and offers an new in-depth analysis of two more major tools in our 2020 study, we find $12$ new, undocumented flaws and demonstrate that all $25$ flaws are found in more than one tool, regardless of any inheritance-relation among the tools. Our results motivate the need for systematic discovery and documentation of unsound choices in soundy tools and demonstrate the opportunities in leveraging mutation testing in achieving this goal.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3133003395",
    "type": "article"
  },
  {
    "title": "Computation on Encrypted Data Using Dataflow Authentication",
    "doi": "https://doi.org/10.1145/3513005",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Andreas Fischer; Benny Fuhry; Jörn Kußmaul; Jonas Janneck; Florian Kerschbaum; Eric Bodden",
    "corresponding_authors": "",
    "abstract": "Encrypting data before sending it to the cloud ensures data confidentiality but requires the cloud to compute on encrypted data. Trusted execution environments, such as Intel SGX enclaves, promise to provide a secure environment in which data can be decrypted and then processed. However, vulnerabilities in the executed program give attackers ample opportunities to execute arbitrary code inside the enclave. This code can modify the dataflow of the program and leak secrets via SGX side channels. Fully homomorphic encryption would be an alternative to compute on encrypted data without data leaks. However, due to its high computational complexity, its applicability to general-purpose computing remains limited. Researchers have made several proposals for transforming programs to perform encrypted computations on less powerful encryption schemes. Yet current approaches do not support programs making control-flow decisions based on encrypted data. We introduce the concept of dataflow authentication (DFAuth) to enable such programs. DFAuth prevents an adversary from arbitrarily deviating from the dataflow of a program. Our technique hence offers protections against the side-channel attacks described previously. We implemented two flavors of DFAuth, a Java bytecode-to-bytecode compiler, and an SGX enclave running a small and program-independent trusted code base. We applied DFAuth to a neural network performing machine learning on sensitive medical data and a smart charging scheduler for electric vehicles. Our transformation yields a neural network with encrypted weights, which can be evaluated on encrypted inputs in \\( 12.55 \\,\\mathrm{m}\\mathrm{s} \\) . Our protected scheduler is capable of updating the encrypted charging plan in approximately 1.06 seconds.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2762867759",
    "type": "article"
  },
  {
    "title": "A Case for Feedforward Control with Feedback Trim to Mitigate Time Transfer Attacks",
    "doi": "https://doi.org/10.1145/3382503",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Fatima M. Anwar; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "We propose a new clock synchronization architecture for systems under time transfer attacks. Facilitated by a feedforward control with feedback trim --based clock adjustment, coupled with packet filtering and frequency shaping techniques, our proposed architecture bounds the clock errors in the presence of a powerful network attacker capable of attacking packets between a master and a client. A key advantage is consistent measurements, timely coordination, and synchronized actuation in distributed systems. In contrast, current time synchronization architectures behave poorly under attacks due to assumptions that the network is benign and delays are symmetric. The usage of feedback controllers aggravates poor performance. We provide an architecture that is indifferent to delays and eases the integration to traditional protocols. We implement a delay attack--resistant precision time protocol and validate the results on a hardware-supported testbed.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3031323474",
    "type": "article"
  },
  {
    "title": "The Tip of the Iceberg",
    "doi": "https://doi.org/10.1145/3406112",
    "publication_date": "2020-09-28",
    "publication_year": 2020,
    "authors": "Nikolaos Alexopoulos; Sheikh Mahbub Habib; Steffen Schulz; Max Mühlhäuser",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate a fundamental question regarding software security: Is the security of SW releases increasing over time? We approach this question with a detailed analysis of the large body of open-source software packaged in the popular Debian GNU/Linux distribution. Contrary to common intuition, we find no clear evidence that the vulnerability rate of widely used software decreases over time: Even in popular and “stable” releases, the fixing of bugs does not seem to reduce the rate of newly identified vulnerabilities. The intuitive conclusion is worrisome: Commonly employed development and validation procedures do not seem to scale with the increase of features and complexity—they are only chopping pieces off the top of an iceberg of vulnerabilities. To the best of our knowledge, this is the first investigation into the problem that studies a complete distribution of software, spanning multiple versions. Although we can not give a definitive answer, we show that several popular beliefs also cannot be confirmed given our dataset. We publish our Debian Vulnerability Analysis Framework (DVAF) , an automated dataset creation and analysis process, to enable reproduction and further analysis of our results. Overall, we hope our contributions provide important insights into the vulnerability discovery process and help in identifying effective techniques for vulnerability analysis and prevention.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3093633035",
    "type": "article"
  },
  {
    "title": "Valued Authorization Policy Existence Problem: Theory and Experiments",
    "doi": "https://doi.org/10.1145/3528101",
    "publication_date": "2022-04-21",
    "publication_year": 2022,
    "authors": "Jason Crampton; Eduard Eiben; Gregory Gutin; Daniel Karapetyan; Diptapriyo Majumdar",
    "corresponding_authors": "",
    "abstract": "Recent work has shown that many problems of satisfiability and resiliency in workflows may be viewed as special cases of the authorization policy existence problem (APEP), which returns an authorization policy if one exists and “No” otherwise. However, in many practical settings it would be more useful to obtain a “least bad” policy than just a “No,” where “least bad” is characterized by some numerical value indicating the extent to which the policy violates the base authorization relation and constraints. Accordingly, we introduce the Valued APEP, which returns an authorization policy of minimum weight, where the (non-negative) weight is determined by the constraints violated by the returned solution. We then establish a number of results concerning the parameterized complexity of Valued APEP. We prove that the problem is fixed-parameter tractable (FPT) if the set of constraints satisfies two restrictions, but is intractable if only one of these restrictions holds. (Most constraints known to be of practical use satisfy both restrictions.) Our analysis is based on the novel concept of a user profile. We also introduce a new type of resiliency problem in the context of workflow satisfiability, show how it can be addressed using Valued APEP, and use this to build a set of benchmark instances for Valued APEP. We describe two different formulations of this problem using mixed integer programming and report the results of computational experiments which solve the problem using these formulations as input to a general-purpose solver. Our results show that the formulation which employs the user profile concept, has FPT-like running time and usually significantly outperforms our naive formulation of the problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3181338812",
    "type": "article"
  },
  {
    "title": "<scp>Terminator</scp> : A Secure Coprocessor to Accelerate Real-Time AntiViruses Using Inspection Breakpoints",
    "doi": "https://doi.org/10.1145/3494535",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Marcus Botacin; Francis B. Moreira; Philippe O. A. Navaux; André Grégio; Marco A. Z. Alves",
    "corresponding_authors": "",
    "abstract": "AntiViruses (AVs) are essential to face the myriad of malware threatening Internet users. AVs operate in two modes: on-demand checks and real-time verification. Software-based real-time AVs intercept system and function calls to execute AV’s inspection routines, resulting in significant performance penalties as the monitoring code runs among the suspicious code. Simultaneously, dark silicon problems push the industry to add more specialized accelerators inside the processor to mitigate these integration problems. In this article, we propose Terminator , an AV-specific coprocessor to assist software AVs by outsourcing their matching procedures to the hardware, thus saving CPU cycles and mitigating performance degradation. We designed Terminator to be flexible and compatible with existing AVs by using YARA and ClamAV rules. Our experiments show that our approach can save up to 70 million CPU cycles per rule when outsourcing on-demand checks for matching typical, unmodified YARA rules against a dataset of 30 thousand in-the-wild malware samples. Our proposal eliminates the AV’s need for blocking the CPU to perform full system checks, which can now occur in parallel. We also designed a new inspection breakpoint mechanism that signals to the coprocessor the beginning of a monitored region, allowing it to scan the regions in parallel with their execution. Overall, our mechanism mitigated up to 44% of the overhead imposed to execute and monitor the SPEC benchmark applications in the most challenging scenario.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4214824370",
    "type": "article"
  },
  {
    "title": "A Comparison of Systemic and Systematic Risks of Malware Encounters in Consumer and Enterprise Environments",
    "doi": "https://doi.org/10.1145/3565362",
    "publication_date": "2022-10-03",
    "publication_year": 2022,
    "authors": "Savino Dambra; Leyla Bilge; Davide Balzarotti",
    "corresponding_authors": "",
    "abstract": "Malware is still a widespread problem, and it is used by malicious actors to routinely compromise the security of computer systems. Consumers typically rely on a single AV product to detect and block possible malware infections, while corporations often install multiple security products, activate several layers of defenses, and establish security policies among employees. However, if a better security posture should lower the risk of malware infections, then the actual extent to which this happens is still under debate by risk analysis experts. Moreover, the difference in risks encountered by consumers and enterprises has never been empirically studied by using real-world data. In fact, the mere use of third-party software, network services, and the interconnected nature of our society necessarily exposes both classes of users to undiversifiable risks: Independently from how careful users are and how well they manage their cyber hygiene, a portion of that risk would simply exist because of the fact of using a computer, sharing the same networks, and running the same software. In this work, we shed light on both systemic (i.e., diversifiable and dependent on the security posture) and systematic (i.e., undiversifiable and independent of the cyber hygiene) risk classes. Leveraging the telemetry data of a popular security company, we compare, in the first part of our study, the effects that different security measures have on malware encounter risks in consumer and enterprise environments. In the second part, we conduct exploratory research on systematic risk, investigate the quality of nine different indicators we were able to extract from our telemetry, and provide, for the first time, quantitative indicators of their predictive power. Our results show that even if consumers have a slightly lower encounter rate than enterprises (9.8% vs. 12.0%), the latter do considerably better when selecting machines with an increasingly higher uptime (89% vs. 53%). The two segments also diverge when we separately consider the presence of Adware and Potentially Unwanted Applications (PUA) and the generic samples detected through behavioral signatures: While consumers have an encounter rate for Adware and PUA that is 6 times higher than enterprise machines, those on average match behavioral signatures 2 times more frequently than the counterpart. We find, instead, similar trends when analyzing the age of encountered signatures, and the prevalence of different classes of traditional malware (such as Ransomware and Cryptominers). Finally, our findings show that the amount of time a host is active, the volume of files generated on the machine, the number and reputation of vendors of the installed applications, the host geographical location, and its recurrent infected state carry useful information as indicators of systematic risk of malware encounters. Activity days and hours have a higher influence in the risk of consumers, increasing the odds of encountering malware of 4.51 and 2.65 times. In addition, we measure that the volume of files generated on the host represents a reliable indicator, especially when considering Adware. We further report that the likelihood of encountering Worms and Adware is much higher (on average 8 times in consumers and enterprises) for those machines that already reported this kind of signature in the past.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4300865450",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2997655",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Many applications today rely on storage and management of semi-structured information, for example, XML databases and document-oriented databases. These data often have to be shared with untrusted third parties, which makes individuals’ privacy a ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4240036279",
    "type": "paratext"
  },
  {
    "title": "Energy Efficient and Secure Neural Network–based Disease Detection Framework for Mobile Healthcare Network",
    "doi": "https://doi.org/10.1145/3585536",
    "publication_date": "2023-02-27",
    "publication_year": 2023,
    "authors": "Sona Alex; K.J. Dhanaraj; P. P. Deepthi",
    "corresponding_authors": "",
    "abstract": "Adopting mobile healthcare network (MHN) services such as disease detection is fraught with concerns about the security and privacy of the entities involved and the resource restrictions at the Internet of Things (IoT) nodes. Hence, the essential requirements for disease detection services are to (i) produce accurate and fast disease detection without jeopardizing the privacy of health clouds and medical users and (ii) reduce the computational and transmission overhead (energy consumption) of the IoT devices while maintaining the privacy. For privacy preservation of widely used neural network– (NN) based disease detection, existing literature suggests either computationally heavy public key fully homomorphic encryption (FHE), or secure multiparty computation, with a large number of interactions. Hence, the existing privacy-preserving NN schemes are energy consuming and not suitable for resource-constrained IoT nodes in MHN. This work proposes a lightweight, fully homomorphic, symmetric key FHE scheme (SkFhe) to address the issues involved in implementing privacy-preserving NN. Based on SkFhe, widely used non-linear activation functions ReLU and Leaky ReLU are implemented over the encrypted domain. Furthermore, based on the proposed privacy-preserving linear transformation and non-linear activation functions, an energy-efficient, accurate, and privacy-preserving NN is proposed. The proposed scheme guarantees privacy preservation of the health cloud’s NN model and medical user’s data. The experimental analysis demonstrates that the proposed solution dramatically reduces the overhead in communication and computation at the user side compared to the existing schemes. Moreover, the improved energy efficiency at the user is accomplished with reduced diagnosis time without sacrificing classification accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4322397542",
    "type": "article"
  },
  {
    "title": "PrivExtractor: Toward Redressing the Imbalance of Understanding between Virtual Assistant Users and Vendors",
    "doi": "https://doi.org/10.1145/3588770",
    "publication_date": "2023-03-23",
    "publication_year": 2023,
    "authors": "Tom Bolton; Tooska Dargahi; Sana Belguith; Carsten Maple",
    "corresponding_authors": "",
    "abstract": "The use of voice-controlled virtual assistants (VAs) is significant, and user numbers increase every year. Extensive use of VAs has provided the large, cash-rich technology companies who sell them with another way of consuming users’ data, providing a lucrative revenue stream. Whilst these companies are legally obliged to treat users’ information “fairly and responsibly,” artificial intelligence techniques used to process data have become incredibly sophisticated, leading to users’ concerns that a lack of clarity is making it hard to understand the nature and scope of data collection and use. There has been little work undertaken on a self-contained user awareness tool targeting VAs. PrivExtractor, a novel web-based awareness dashboard for VA users, intends to redress this imbalance of understanding between the data “processors” and the user. It aims to achieve this using the four largest VA vendors as a case study and providing a comparison function that examines the four companies’ privacy practices and their compliance with data protection law. As a result of this research, we conclude that the companies studied are largely compliant with the law, as expected. However, the user remains disadvantaged due to the ineffectiveness of current data regulation that does not oblige the companies to fully and transparently disclose how and when they use, share, or profit from the data. Furthermore, the software tool developed during the research is, we believe, the first that is capable of a comparative analysis of VA privacy with a visual demonstration to increase ease of understanding for the user.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4360612289",
    "type": "article"
  },
  {
    "title": "Spoofing Against Spoofing: Toward Caller ID Verification in Heterogeneous Telecommunication Systems",
    "doi": "https://doi.org/10.1145/3625546",
    "publication_date": "2023-09-27",
    "publication_year": 2023,
    "authors": "Shen Wang; Mahshid Delavar; Muhammad Ajmal Azad; Farshad Nabizadeh; Steve Smith; Feng Hao",
    "corresponding_authors": "",
    "abstract": "Caller ID spoofing is a global industry problem and often acts as a critical enabler for telephone fraud. To address this problem, the Federal Communications Commission has mandated telecom providers in the U.S. to implement STIR/SHAKEN, an industry-driven solution based on digital signatures. STIR/SHAKEN relies on a public key infrastructure (PKI) to manage digital certificates, but scaling up this PKI for the global telecom industry is extremely difficult, if not impossible. Furthermore, it only works with IP-based systems (e.g., SIP), leaving the traditional non-IP systems (e.g., SS7) unprotected. So far the alternatives to the STIR/SHAKEN have not been sufficiently studied. In this article, we propose a PKI-free solution, called Caller ID Verification (CIV). CIV authenticates the caller ID based on a challenge-response process instead of digital signatures, hence requiring no PKI. It supports both IP and non-IP systems. Perhaps counter-intuitively, we show that number spoofing can be leveraged, in conjunction with Dual-tone Multi-frequency, to efficiently implement the challenge-response process, i.e., using spoofing to fight against spoofing. We implement CIV for Voice over Internet Protocol, cellular, and landline phones across heterogeneous networks (SS7/SIP) by only updating the software on the user’s phone. This is the first caller ID authentication solution with working prototypes for all three types of telephone systems in the current telecom architecture. Finally, we show how the implementation of CIV can be optimized by integrating it into telecom clouds as a service, which users may subscribe to.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387105401",
    "type": "article"
  },
  {
    "title": "On Detecting and Measuring Exploitable JavaScript Functions in Real-World Applications",
    "doi": "https://doi.org/10.1145/3630253",
    "publication_date": "2023-10-26",
    "publication_year": 2023,
    "authors": "Maryna Kluban; Mohammad Mannan; Amr Youssef",
    "corresponding_authors": "",
    "abstract": "JavaScript is often rated as the most popular programming language for the development of both client-side and server-side applications. Because of its popularity, JavaScript has become a frequent target for attackers who exploit vulnerabilities in the source code to take control over the application. To address these JavaScript security issues, such vulnerabilities must be identified first. Existing studies in vulnerable code detection in JavaScript mostly consider package-level vulnerability tracking and measurements. However, such package-level analysis is largely imprecise as real-world services that include a vulnerable package may not use the vulnerable functions in the package. Moreover, even the inclusion of a vulnerable function may not lead to a security problem, if the function cannot be triggered with exploitable inputs. In this paper, we develop a vulnerability detection framework that uses vulnerable pattern recognition and textual similarity methods to detect vulnerable functions in real-world JavaScript projects, combined with a static multi-file taint analysis mechanism to further assess the impact of the vulnerabilities on the whole project (i.e., whether the vulnerability can be exploited in a given project). We compose a comprehensive dataset of 1,360 verified vulnerable JavaScript functions using the Snyk vulnerability database and the VulnCode-DB project. From this ground-truth dataset, we build our vulnerable patterns for two common vulnerability types: prototype pollution and Regular Expression Denial of Service (ReDoS). With our framework, we analyze 9,205,654 functions (from 3,000 NPM packages, 1892 websites and 557 Chrome Web extensions), and detect 117,601 prototype pollution and 7,333 ReDoS vulnerabilities. By further processing all 5,839 findings from NPM packages with our taint analyzer, we verify the exploitability of 290 zero-day cases across 134 NPM packages. In addition, we conduct an in-depth contextual analysis of the findings in 17 popular/critical projects and study the practical security exposure of 20 functions. With our semi-automated vulnerability reporting functionality, we disclosed all verified findings to project owners. We also obtained 25 published CVEs for our findings, 19 of them rated as “Critical” severity, and six rated as “High” severity. Additionally, we obtained 169 CVEs that are currently “Reserved” (as of Apr. 2023). As evident from the results, our approach can shift JavaScript vulnerability detection from the coarse package/library level to the function level, and thus improve the accuracy of detection and aid timely patching.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388197345",
    "type": "article"
  },
  {
    "title": "Forward Security with Crash Recovery for Secure Logs",
    "doi": "https://doi.org/10.1145/3631524",
    "publication_date": "2023-11-03",
    "publication_year": 2023,
    "authors": "Erik-Oliver Blaß; Guevara Noubir",
    "corresponding_authors": "",
    "abstract": "Logging is a key mechanism in the security of computer systems. Beyond supporting important forward security properties, it is critical that logging withstands both failures and intentional tampering to prevent subtle attacks leaving the system in an inconsistent state with inconclusive evidence. We propose new techniques combining forward security with crash recovery for secure log data storage. As the support of specifically forward integrity and the online nature of logging prevent the use of conventional coding, we propose and analyze a coding scheme resolving these unique design constraints. Specifically, our coding enables forward integrity, online encoding, and most importantly a constant number of operations per encoding. It adds a new log item by 𝖷𝖮𝖱 ing it to k cells of a table. If up to a certain threshold of cells is modified by the adversary, or lost due to a crash, we still guarantee recovery of all stored log items. The main advantage of the coding scheme is its efficiency and compatibility with forward integrity. The key contribution of the paper is the use of spectral graph theory techniques to prove that k is constant in the number n of all log items ever stored and small in practice, e.g., k = 5. Moreover, we prove that to cope with up to \\(\\sqrt {n}\\) modified or lost log items, storage expansion is constant in n and small in practice. For k = 5, the size of the table is only 12% more than the simple concatenation of all n items. We propose and evaluate original techniques to scale the computation cost of recovery to several GBytes of security logs. We instantiate our scheme into an abstract data structure which allows to either detect adversarial modifications to log items or treat modifications like data loss in a system crash. The data structure can recover lost log items, thereby effectively reverting adversarial modifications.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388282444",
    "type": "article"
  },
  {
    "title": "FIMCE",
    "doi": "https://doi.org/10.1145/3195181",
    "publication_date": "2018-05-21",
    "publication_year": 2018,
    "authors": "Siqi Zhao; Xuhua Ding",
    "corresponding_authors": "",
    "abstract": "Virtualization-based memory isolation has been widely used as a security primitive in various security systems to counter kernel-level attacks. In this article, our in-depth analysis on this primitive shows that its security is significantly undermined in the multicore setting when other hardware resources for computing are not enclosed within the isolation boundary. We thus propose to construct a fully isolated micro-computing environment (FIMCE) as a new primitive. By virtue of its architectural niche, FIMCE not only offers stronger security assurance than its predecessor, but also features a flexible and composable environment with support for peripheral device isolation, thus greatly expanding the scope of applications. In addition, FIMCE can be integrated with recent technologies such as Intel Software Guard Extensions (SGX) to attain even stronger security guarantees. We have built a prototype of FIMCE with a bare-metal hypervisor. To show the benefits of using FIMCE as a building block, we have also implemented four applications which are difficult to construct using the existing memory isolation method. Experiments with these applications demonstrate that FIMCE imposes less than 1% overhead on single-threaded applications, while the maximum performance loss on multithreaded applications is bounded by the degree of parallelism at the processor level.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2803135478",
    "type": "article"
  },
  {
    "title": "Analytical Models for the Scalability of Dynamic Group-key Agreement Protocols and Secure File Sharing Systems",
    "doi": "https://doi.org/10.1145/3342998",
    "publication_date": "2019-09-25",
    "publication_year": 2019,
    "authors": "Gokcan Cantali; Orhan Ermiş; M.U. Çağlayan; Cem Ersoy",
    "corresponding_authors": "",
    "abstract": "research-article Share on Analytical Models for the Scalability of Dynamic Group-key Agreement Protocols and Secure File Sharing Systems Authors: Gokcan Cantali Dept. of Computer Engineering, Bogazici University, Istanbul, Turkey Dept. of Computer Engineering, Bogazici University, Istanbul, TurkeyView Profile , Orhan Ermis Dept. of Computer Engineering, Bogazici University and EURECOM, Sophia-Antipolis, France, Dept. of Computer Engineering, Bogazici University and EURECOM, Sophia-Antipolis, France,View Profile , Mehmet Ufuk Çağlayan Dept. of Computer Engineering, Yasar University, Izmir, Turkey Dept. of Computer Engineering, Yasar University, Izmir, TurkeyView Profile , Cem Ersoy Dept. of Computer Engineering, Bogazici University, Istanbul, Turkey Dept. of Computer Engineering, Bogazici University, Istanbul, TurkeyView Profile Authors Info & Claims ACM Transactions on Privacy and SecurityVolume 22Issue 4November 2019 Article No.: 20pp 1–36https://doi.org/10.1145/3342998Published:25 September 2019Publication History 0citation349DownloadsMetricsTotal Citations0Total Downloads349Last 12 Months22Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2975457494",
    "type": "article"
  },
  {
    "title": "MRAAC: A Multi-stage Risk-aware Adaptive Authentication and Access Control Framework for Android",
    "doi": "https://doi.org/10.1145/3648372",
    "publication_date": "2024-02-15",
    "publication_year": 2024,
    "authors": "Jiayi Chen; Urs Hengartner; Hassan Khan",
    "corresponding_authors": "",
    "abstract": "Adaptive authentication enables smartphones and enterprise apps to decide when and how to authenticate users based on contextual and behavioral factors. In practice, a system may employ multiple policies to adapt its authentication mechanisms and access controls to various scenarios. However, existing approaches suffer from contradictory or insecure adaptations, which may enable attackers to bypass the authentication system. Besides, most existing approaches are inflexible and do not provide desirable access controls. We design and build a multi-stage risk-aware adaptive authentication and access control framework (MRAAC), which provides the following novel contributions: Multi-stage: MRAAC organizes adaptation policies in multiple stages to handle different risk types and progressively adapts authentication mechanisms based on context, resource sensitivity, and user authenticity. Appropriate access control: MRAAC provides libraries to enable sensitive apps to manage the availability of their in-app resources based on MRAAC’s risk awareness. Extensible: While existing proposals are tailored to cater to a single use case, MRAAC supports a variety of use cases with custom risk models. We exemplify these advantages of MRAAC by deploying it for three use cases: an enhanced version of Android Smart Lock, guest-aware continuous authentication, and corporate app for BYOD. We conduct experiments to quantify the CPU, memory, latency, and battery performance of MRAAC. Our evaluation shows that MRAAC enables various stakeholders (device manufacturers, enterprise and secure app developers) to provide complex adaptive authentication workflows on COTS Android with low processing and battery overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391842999",
    "type": "article"
  },
  {
    "title": "Toward Robust ASR System against Audio Adversarial Examples using Agitated Logit",
    "doi": "https://doi.org/10.1145/3661822",
    "publication_date": "2024-04-26",
    "publication_year": 2024,
    "authors": "Namgyu Park; Jong Kim",
    "corresponding_authors": "",
    "abstract": "Automatic speech recognition (ASR) systems are vulnerable to audio adversarial examples, which aim at deceiving ASR systems by adding perturbations to benign speech signals. These audio adversarial examples appear indistinguishable from benign audio waves, but the ASR system decodes them as intentional malicious commands. Previous studies have demonstrated the feasibility of such attacks in simulated environments (over-line) and have further showcased the creation of robust physical audio adversarial examples (over-air). Various defense techniques have been proposed to counter these attacks. However, most of them have either failed to handle various types of attacks effectively or have resulted in significant time overhead. In this article, we propose a novel method for detecting audio adversarial examples. Our approach involves feeding both smoothed audio and original audio inputs into the ASR system. Subsequently, we introduce noise to the logits before providing them to the decoder of the ASR. We demonstrate that carefully selected noise can considerably influence the transcription results of audio adversarial examples while having minimal impact on the transcription of benign audio waves. Leveraging this characteristic, we detect audio adversarial examples by comparing the altered transcription, resulting from logit noising, with the original transcription. The proposed method can be easily applied to ASR systems without requiring any structural modifications or additional training. Experimental results indicate that the proposed method exhibits robustness against both over-line and over-air audio adversarial examples, outperforming state-of-the-art detection methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4395667911",
    "type": "article"
  },
  {
    "title": "ZPredict: ML-Based IPID Side-channel Measurements",
    "doi": "https://doi.org/10.1145/3672560",
    "publication_date": "2024-06-20",
    "publication_year": 2024,
    "authors": "Haya Schulmann; Shujie Zhao",
    "corresponding_authors": "",
    "abstract": "Network reconnaissance and measurements play a central role in improving Internet security and are important for understanding the current deployments and trends. Such measurements often require coordination with the measured target. This limits the scalability and the coverage of the existing proposals. IP Identification (IPID) provides a side channel for remote measurements without requiring the targets to install agents or visit the measurement infrastructure. However, current IPID-based techniques have technical limitations due to their reliance on the idealistic assumption of stable IPID changes or prior knowledge, making them challenging to adopt for practical measurements. In this work, we aim to tackle the limitations of existing techniques by introducing a novel approach: predictive analysis of IPID counter behavior. This involves utilizing a machine learning (ML) model to understand the historical patterns of IPID counter changes and predict future IPID values. To validate our approach, we implement six ML models and evaluate them on realistic IPID data collected from 4,698 Internet sources. Our evaluations demonstrate that among the six models, the Gaussian Process (GP) model has superior accuracy in tracking and predicting IPID values. Using the GP-based predictive analysis, we implement a tool, called ZPredict, to infer various favorable information about target networks or servers. Our evaluation on a large dataset of public servers demonstrates its effectiveness in idle port scanning, measuring Russian censorship, and inferring Source Address Validation. Our study methodology is ethical and was developed to mitigate any potential harm, taking into account the concerns associated with measurements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399859716",
    "type": "article"
  },
  {
    "title": "PEBASI: A Privacy preserving, Efficient Biometric Authentication Scheme based on Irises",
    "doi": "https://doi.org/10.1145/3677017",
    "publication_date": "2024-08-20",
    "publication_year": 2024,
    "authors": "Hasini Gunasinghe; Mikhail Atallah; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "We introduce a novel privacy-preserving biometric authentication scheme based on irises that allows a user to enroll once at a trusted biometric certification authority (BCA) and authenticate to online service providers (SPs) multiple times without involving the BCA during the authentication. Our scheme preserves the user’s biometric privacy from the SPs and transactional privacy from the BCA, while providing security against a malicious user. During the enrollment, the BCA issues a signed token that encrypts the user’s biometrics. We introduce techniques enabling the SP and the user to perform secure computation of biometric matching between such encrypted biometrics and the user’s biometrics captured at the authentication time. We provide a prototype implementation, a performance evaluation, and a security analysis of the protocol.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400550374",
    "type": "article"
  },
  {
    "title": "ArmSpy++: Enhanced PIN Inference through Video-based Fine-grained Arm Posture Analysis",
    "doi": "https://doi.org/10.1145/3696418",
    "publication_date": "2024-09-23",
    "publication_year": 2024,
    "authors": "Huan Dai; Yuefeng Chen; Yicong Du; Luping Wang; Ziyu Shao; Hongbo Liu; Yanzhi Ren; Jiadi Yu; Bo Liu",
    "corresponding_authors": "",
    "abstract": "As one of the most common ways for user authentication, Personal Identification Number (PIN), due to its simplicity and convenience, has suffered from plenty of side-channel attacks, which pose a severe threat to people’s privacy and property. The success of existing attacks is usually built upon the premise of no occlusion between the attacker and the victim’s hand gesture, but it increases the difficulty of launching the attack and the possibility of exposure. To overcome such limitation, we propose ArmSpy++, an improved video-assisted PIN inference attack built upon our previous research, ArmSpy. Specifically, ArmSpy++ employs new modules to leverage more features like the keystroke-induced elbow bending, wrist speed variation, and the spatial relationship between different arm joints, to correctly detect Keystrokes. ArmSpy++ delves into the perspective relationship and natural typing habits to ensure a high success rate of PIN inference. We also re-designed the inferred PIN pattern coordination mechanism to accurately deduce the PINs. By using a pre-trained HigherHRNet model for posture estimation ArmSpy++ eliminates the necessity of additional training. The extensive experiments demonstrate that ArmSpy++ can achieve over 83.1% average accuracy with 3 attempts and even 92.5% for some victims, indicating the severity of the threat posed by ArmSpy++.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402728080",
    "type": "article"
  },
  {
    "title": "The Effect of Domain Terms on Password Security",
    "doi": "https://doi.org/10.1145/3703350",
    "publication_date": "2024-11-04",
    "publication_year": 2024,
    "authors": "Yubing Bao; Jianping Zeng; Jirui Yang; Ruining Yang; Zhihui Lu",
    "corresponding_authors": "",
    "abstract": "The predominant authentication method still relies on usernames and passwords. To enhance memorability, domain terms may have been opted to include as part of passwords. However, there is little analysis of the extent to which such practice affects password security, so there is a lack of guidance on how users use domain terms on websites with different domain characteristics. To address the problem, we propose a novel approach to analyze the security effect of using domain terms in passwords. The methodology primarily consists of three stages. Firstly, we utilize Web crawlers to harvest domain vocabularies, subsequently leveraging the TextRank algorithm to rank their importance. Afterward, we propose an algorithm for constructing a simulated domain-specific password dataset by replacing password elements with domain terms. Finally, password guessing experiments are done on the dataset using PCFG and Markov model to evaluate the impact of domain terms on password security. The experimental results indicate that, for systems without clear domain, 20% domain terms replacement in the test set can reduce the cracking rate by up to 5.45%. In contrast, for domain-specific systems, 20% domain terms replacement in the training set can increase the cracking rate by 6.45%. These findings provide practical guidance on the application of domain knowledge in password creation for different types of systems. In summary, this study offers a novel perspective for exploring the security implications of passwords influenced by specific domains.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404047809",
    "type": "article"
  },
  {
    "title": "Understanding Information Disclosure from Secure Computation Output: A Comprehensive Study of Average Salary Computation",
    "doi": "https://doi.org/10.1145/3705004",
    "publication_date": "2024-11-23",
    "publication_year": 2024,
    "authors": "Alessandro Baccarini; Marina Blanton; Shaofeng Zou",
    "corresponding_authors": "",
    "abstract": "Secure multi-party computation has seen substantial performance improvements in recent years and is being increasingly used in commercial products. While a significant amount of work was dedicated to improving its efficiency under standard security models, the threat models do not account for information leakage from the output of secure function evaluation. Quantifying information disclosure about private inputs from observing the function outcome is the subject of this work. Motivated by the City of Boston gender pay gap studies, in this work we focus on the computation of the average of salaries and quantify information disclosure about private inputs of one or more participants (the target) to an adversary via information-theoretic techniques. We study a number of distributions including log-normal, which is typically used for modeling salaries. We consequently evaluate information disclosure after repeated evaluation of the average function on overlapping inputs, as was done in the Boston gender pay study that ran multiple times, and provide recommendations for using the sum and average functions in secure computation applications. Our goal is to develop mechanisms that lower information disclosure about participants’ inputs to a desired level and provide guidelines for setting up real-world secure evaluation of this function.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404650510",
    "type": "article"
  },
  {
    "title": "Safe Driving Adversarial Trajectory Can Mislead: Towards More Stealthy Adversarial Attack Against Autonomous Driving Prediction Module",
    "doi": "https://doi.org/10.1145/3705611",
    "publication_date": "2024-11-25",
    "publication_year": 2024,
    "authors": "Yingkai Dong; Li Wang; Zheng Li; Hao Li; Peng Tang; Chengyu Hu; Shanqing Guo",
    "corresponding_authors": "",
    "abstract": "The prediction module, powered by deep learning models, constitutes a fundamental component of high-level Autonomous Vehicles (AVs). Given the direct influence of the module’s prediction accuracy on AV driving behavior, ensuring its security is paramount. However, limited studies have explored the adversarial robustness of the prediction modules. Furthermore, existing methods still generate adversarial trajectories that deviate significantly from human driving behavior. These deviations can be easily identified as hazardous by AVs’ anomaly detection models and thus cannot effectively evaluate and reflect the robustness of the prediction modules. To bridge this gap, we propose a stealthy and more effective optimization-based attack method. Specifically, we reformulate the optimization problem using Lagrangian relaxation and design a Frenet-based objective function along with a distinct constraint space. We conduct extensive evaluations on 2 popular prediction models and 2 benchmark datasets. Our results show that our attack is highly effective, with over 87% attack success rates, outperforming all baseline attacks. Moreover, our attack method significantly improves the stealthiness of adversarial trajectories while guaranteeing adherence to physical constraints. Our attack is also found robust to noise from upstream modules, transferable across trajectory prediction models, and high realizability. Lastly, to verify its effectiveness in real-world applications, we conduct further simulation evaluations using a production-grade simulator. These simulations reveal that the adversarial trajectory we created could convincingly induce autonomous vehicles (AVs) to initiate hard braking.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404700041",
    "type": "article"
  },
  {
    "title": "A Trustworthy and Untraceable Centralised Payment Protocol for Mobile Payment",
    "doi": "https://doi.org/10.1145/3706421",
    "publication_date": "2024-11-30",
    "publication_year": 2024,
    "authors": "Jeyamohan Neera; Xiaomin Chen; Nauman Aslam; Biju Issac",
    "corresponding_authors": "",
    "abstract": "Current mobile payment schemes gather detailed information about purchases customers make. This data can then be used to infer a customer’s spending behaviour, potentially violating their privacy. To tackle this problem, we propose an untraceable mobile payment scheme that strikes a better balance, preserving user privacy while allowing the Third-Party Service Provider (TPSP) to collect necessary information such as card details and transaction amount for regulatory compliance. Our scheme offers untraceability for legitimate users from malicious adversaries and curious TPSPs using cryptographic primitives such as partially blind signatures, zero-knowledge proofs, and identity-based signatures. It also guarantees that only authorised TPSPs can issue valid payment tokens, and even with limited data, the TPSP can still prevent dishonest customers/merchants from double-spending a payment token. We also propose a comprehensive evaluation framework to assess the untraceable payment schemes against seven key criteria such as untraceability, exculpability—merchant double-spending, exculpability—customer double-spending, unforgeability, confidentiality, message authenticity, efficiency, and regulatory compliance. We rigorously benchmark the security and privacy of our proposed payment scheme against this framework and other established schemes. Furthermore, we formally verify these properties using complexity-based analysis and Proverif modelling.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404883607",
    "type": "article"
  },
  {
    "title": "The Security of Lazy Users in Out-of-Band Authentication",
    "doi": "https://doi.org/10.1145/3377849",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Moni Naor; Lior Rotem; Gil Segev",
    "corresponding_authors": "",
    "abstract": "Faced with the threats posed by man-in-the-middle attacks, messaging platforms rely on “out-of-band” authentication, assuming that users have access to an external channel for authenticating one short value. For example, assuming that users recognizing each other’s voice can authenticate a short value, Telegram and WhatApp ask their users to compare 288-bit and 200-bit values, respectively. The existing protocols, however, do not take into account the plausible behavior of users who may be “lazy” and only compare parts of these values (rather than their entirety). Motivated by such a security-critical user behavior, we study the security of lazy users in out-of-band authentication. We start by showing that both the protocol implemented by WhatsApp and the statistically optimal protocol of Naor, Segev, and Smith (CRYPTO’06) are completely vulnerable to man-in-the-middle attacks when the users consider only a half of the out-of-band authenticated value. In this light, we put forward a framework that captures the behavior and security of lazy users. Our notions of security consider both statistical security and computational security, and for each flavor we derive a lower bound on the tradeoff between the number of positions that are considered by the lazy users and the adversary’s forgery probability. Within our framework, we then provide two authentication protocols. First, in the statistical setting, we present a transformation that converts any out-of-band authentication protocol into one that is secure even when executed by lazy users. Instantiating our transformation with a new refinement of the protocol of Naor et al. results in a protocol whose tradeoff essentially matches our lower bound in the statistical setting. Then, in the computational setting, we show that the computationally optimal protocol of Vaudenay (CRYPTO’05) is secure even when executed by lazy users—and its tradeoff matches our lower bound in the computational setting.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3016937771",
    "type": "article"
  },
  {
    "title": "Constrained Proximity Attacks on Mobile Targets",
    "doi": "https://doi.org/10.1145/3498543",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Xueou Wang; Xiaolu Hou; Rubén Rı́os; Nils Ole Tippenhauer; Martín Ochoa",
    "corresponding_authors": "",
    "abstract": "Proximity attacks allow an adversary to uncover the location of a victim by repeatedly issuing queries with fake location data. These attacks have been mostly studied in scenarios where victims remain static and there are no constraints that limit the actions of the attacker. In such a setting, it is not difficult for the attacker to locate a particular victim and quantifying the effort for doing so is straightforward. However, it is far more realistic to consider scenarios where potential victims present a particular mobility pattern. In this article, we consider abstract (constrained and unconstrained) attacks on services that provide location information on other users in the proximity. We derive strategies for constrained and unconstrained attackers, and show that when unconstrained they can practically achieve success with theoretically optimal effort. We then propose a simple yet effective constraint that may be employed by a proximity service (for example, running in the cloud or using a suitable two-party protocol) as a countermeasure to increase the effort for the attacker several orders of magnitude both in simulated and real-world cases.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4214893614",
    "type": "article"
  },
  {
    "title": "DeviceWatch: A Data-Driven Network Analysis Approach to Identifying Compromised Mobile Devices with Graph-Inference",
    "doi": "https://doi.org/10.1145/3558767",
    "publication_date": "2022-08-25",
    "publication_year": 2022,
    "authors": "Euijin Choo; Mohamed Nabeel; Mashael AlSabah; Issa Khalil; Ting Yu; Wei Wang",
    "corresponding_authors": "",
    "abstract": "We propose to identify compromised mobile devices from a network administrator’s point of view. Intuitively, inadvertent users (and thus their devices) who download apps through untrustworthy markets are often lured to install malicious apps through in-app advertisements or phishing. We thus hypothesize that devices sharing similar apps would have a similar likelihood of being compromised, resulting in an association between a compromised device and its apps. We propose to leverage such associations to identify unknown compromised devices using the guilt-by-association principle. Admittedly, such associations could be relatively weak as it is hard, if not impossible, for an app to automatically download and install other apps without explicit user initiation. We describe how we can magnify such associations by carefully choosing parameters when applying graph-based inferences. We empirically evaluate the effectiveness of our approach on real datasets provided by a major mobile service provider. Specifically, we show that our approach achieves nearly 98% AUC (area under the ROC curve) and further detects as many as 6 ~ 7 times of new compromised devices not covered by the ground truth by expanding the limited knowledge on known devices. We show that the newly detected devices indeed present undesirable behavior in terms of leaking private information and accessing risky IPs and domains. We further conduct in-depth analysis of the effectiveness of graph inferences to understand the unique structure of the associations between mobile devices and their apps, and its impact on graph inferences, based on which we propose how to choose key parameters.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4293088673",
    "type": "article"
  },
  {
    "title": "Boost Your Immunity: VACCINE for Preventing a Novel Stealthy Slice Selection Attack in 5G and Beyond",
    "doi": "https://doi.org/10.1145/3686152",
    "publication_date": "2024-08-03",
    "publication_year": 2024,
    "authors": "Vipin N. Sathi; C. Siva Ram Murthy",
    "corresponding_authors": "",
    "abstract": "G networks can offer network slices customized according to the demands of the services to enhance the quality of their users’ experience. The time for selecting an appropriate network slice to facilitate traffic flow between users and services by the core network functions in 5G networks is crucial for services such as emergency service and ultra-reliable low latency services. Therefore, we propose a distributed slice selection architecture for 5G and beyond networks to reduce the waiting time for starting services for users. The proposed architecture distributes slice selection function (SSF) to the edge of the network. The networks have to ensure stealthy slice selection attack (S3 attack) free operation, as moving the SSF to the edge increases attack surface. Attackers can launch S3 attack by manipulating the slice selection decisions of SSFs distributed in the network edge. The S3 attacker intentionally maps service requests from users to inappropriate network slices to damage cloud radio access network utilization and the quality of experience of users. In this article, we also present a countermeasure to tackle the S3 attack using a novel protocol called VACCINE ( v erifi a ble priva c y-preserving proto c ol for sl i ce selectio n in 5G and beyond n e tworks). VACCINE also ensures privacy-preserving slice selection by the SSFs to prevent traffic analysis attacks. We prove the chosen-ciphertext attack security strength of VACCINE and also compare the computational cost of VACCINE with other related protocols.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401288698",
    "type": "article"
  },
  {
    "title": "Specifying and Verifying Information Flow Control in SELinux Configurations",
    "doi": "https://doi.org/10.1145/3690636",
    "publication_date": "2024-08-29",
    "publication_year": 2024,
    "authors": "Lorenzo Ceragioli; Letterio Galletta; Pierpaolo Degano; David Basin",
    "corresponding_authors": "",
    "abstract": "Security Enhanced Linux (SELinux) is a security architecture for Linux implementing Mandatory Access Control. It has been used in numerous security-critical contexts ranging from servers to mobile devices. However, its application is challenging as SELinux security policies are difficult to write, understand, and maintain. Recently, the intermediate language CIL was introduced to foster the development of high-level policy languages and to write structured configurations. Despite CIL’s high level features, CIL configurations are hard to understand as different constructs interact in non-trivial ways. Moreover, there is no mechanism to ensure that a given configuration obeys desired information flow policies. To remedy this, we enrich CIL with a formal semantics, and we propose IFCIL, a backward compatible extension of CIL for specifying fine-grained information flow requirements. Using IFCIL, administrators can express confidentiality, integrity, and non-interference properties. We also provide a tool to statically verify these requirements and we experimentally assess it on ten real-world policies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402005606",
    "type": "article"
  },
  {
    "title": "Defending Against Deep Learning-Based Traffic Fingerprinting Attacks With Adversarial Examples",
    "doi": "https://doi.org/10.1145/3698591",
    "publication_date": "2024-10-03",
    "publication_year": 2024,
    "authors": "Blake Hayden; Timothy Walsh; Armon Barton",
    "corresponding_authors": "",
    "abstract": "In an increasingly digital and interconnected world, online anonymity and privacy are paramount issues for Internet users. To address this, tools like The Onion Router (Tor) offer anonymous and private communication by routing traffic through multiple relays with multiple layers of encryption. However, traffic fingerprinting attacks have threatened anonymity and privacy. In response, the community has proposed additional defenses for Tor, but fingerprinting techniques that utilize deep neural networkss (DNNs) have undermined many of these defenses. The latest defenses that are both lightweight and robust against DNNs use adversarial examples, but these defenses require either the full traffic trace beforehand or a database of pre-computed adversarial examples. We propose Prism , a defense against fingerprinting attacks that utilizes adversarial examples with neither prior access to the full traffic trace nor a database. We describe a novel method of adversarial example generation as input is learned over time. Prism injects these adversarial examples into the Tor traffic stream to prevent DNNs from accurately classifying both websites and videos that a user is viewing, even if the DNN is hardened by adversarial training. We also show that the Tor network could implement Prism entirely on relays under certain conditions, extending the defense to users who may run Tor on devices without graphics processing units.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403103413",
    "type": "article"
  },
  {
    "title": "MAC Precomputation with Applications to Secure Memory",
    "doi": "https://doi.org/10.1145/2943780",
    "publication_date": "2016-09-17",
    "publication_year": 2016,
    "authors": "Juan A. Garay; Vladimir Kolesnikov; Rae McLellan",
    "corresponding_authors": "",
    "abstract": "We present Shallow MAC (ShMAC), a fixed-input-length message authentication code that performs most of the computation prior to the availability of the message. Specifically, ShMAC’s message-dependent computation is much faster and smaller in hardware than the evaluation of a pseudorandom permutation (PRP) and can be implemented by a small shallow circuit, while its precomputation consists of one PRP evaluation. A main building block for ShMAC is the notion of strong differential uniformity (SDU), which we introduce and which may be of independent interest. We show an efficient SDU construction built from previously considered differentially uniform functions. Our main motivating application is a system architecture where a hardware-secured processor uses memory controlled by an adversary. We also present in technical detail a novel, efficient approach to encrypting and authenticating memory and discuss the associated tradeoffs, while paying special attention to minimizing hardware costs and the reduction of Dynamic Random Access Memory latency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2522440407",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2957761",
    "publication_date": "2016-08-05",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We introduce a novel biometric based on distinctive eye movement patterns. The biometric consists of 20 features that allow us to reliably distinguish users based on differences in these patterns. We leverage this distinguishing power along with the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236812865",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2988517",
    "publication_date": "2016-09-17",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we propose Segugio, a novel defense system that allows for efficiently tracking the occurrence of new malware-control domain names in very large ISP networks. Segugio passively monitors the DNS traffic to build a machine-domain ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253881475",
    "type": "paratext"
  },
  {
    "title": "C3PO: <u>C</u> loud-based <u>C</u> onfidentiality-preserving <u>C</u> ontinuous Query <u>P</u> r <u>o</u> cessing",
    "doi": "https://doi.org/10.1145/3472717",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Savvas Savvides; Seema Kumar; Julian James Stephen; Patrick Eugster",
    "corresponding_authors": "",
    "abstract": "With the advent of the Internet of things (IoT), billions of devices are expected to continuously collect and process sensitive data (e.g., location, personal health factors). Due to the limited computational capacity available on IoT devices, the current de facto model for building IoT applications is to send the gathered data to the cloud for computation. While building private cloud infrastructures for handling large amounts of data streams can be expensive, using low-cost public (untrusted) cloud infrastructures for processing continuous queries including sensitive data leads to strong concerns over data confidentiality. This article presents C3PO, a confidentiality-preserving, continuous query processing engine, that leverages the public cloud. The key idea is to intelligently utilize partially homomorphic and property-preserving encryption to perform as many computationally intensive operations as possible—without revealing plaintext—in the untrusted cloud. C3PO provides simple abstractions to the developer to hide the complexities of applying complex cryptographic primitives, reasoning about the performance of such primitives, deciding which computations can be executed in an untrusted tier, and optimizing cloud resource usage. An empirical evaluation with several benchmarks and case studies shows the feasibility of our approach. We consider different classes of IoT devices that differ in their computational and memory resources (from a Raspberry Pi 3 to a very small device with a Cortex-M3 microprocessor) and through the use of optimizations, we demonstrate the feasibility of using partially homomorphic and property-preserving encryption on IoT devices.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3215791279",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3143524",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Intertwined developments between program attacks and defenses witness the evolution of program anomaly detection methods. Emerging categories of program attacks, e.g., non-control data attacks and data-oriented programming, are able to comply with ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233582269",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3129335",
    "publication_date": "2017-08-11",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The Sancus security architecture for networked embedded devices was proposed in 2013 at the USENIX Security conference. It supports remote (even third-party) software installation on devices while maintaining strong security guarantees. More ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237287125",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3018656",
    "publication_date": "2017-02-03",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A so-called completely automated public Turing test to tell computers and humans apart (CAPTCHA) represents a challenge-response test that is widely used on the Internet to distinguish human users from fraudulent computer programs, often referred to as ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242097475",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3064808",
    "publication_date": "2017-05-28",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We propose a privacy-enhanced matrix factorization recommender that exploits the fact that users can often be grouped together by interest. This allows a form of “hiding in the crowd” privacy. We introduce a novel matrix factorization approach suited to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250477963",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3038258",
    "publication_date": "2017-02-06",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we address the problem of scaling authentication for naming, routing, and end-entity (EE) certification to a global environment in which authentication policies and users’ sets of trust roots vary widely. The current mechanisms for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256486158",
    "type": "paratext"
  },
  {
    "title": "Lightbox: Sensor Attack Detection for Photoelectric Sensors via Spectrum Fingerprinting",
    "doi": "https://doi.org/10.1145/3615867",
    "publication_date": "2023-08-17",
    "publication_year": 2023,
    "authors": "Dohyun Kim; Mangi Cho; Hocheol Shin; Jae-Hoon Kim; Juhwan Noh; Yongdae Kim",
    "corresponding_authors": "",
    "abstract": "Photoelectric sensors are utilized in a range of safety-critical applications, such as medical devices and autonomous vehicles. However, the public exposure of the input channel of a photoelectric sensor makes it vulnerable to malicious inputs. Several studies have suggested possible attacks on photoelectric sensors by injecting malicious signals. While a few defense techniques have been proposed against such attacks, they could be either bypassed or used for limited purposes. In this study, we propose Lightbox, a novel defense system to detect sensor attacks on photoelectric sensors based on signal fingerprinting. Lightbox uses the spectrum of the received light as a feature to distinguish the attacker’s malicious signals from the authentic signal, which is a signal from the sensor’s light source. We evaluated Lightbox against (1) a saturation attacker, (2) a simple spoofing attacker, and (3) a sophisticated attacker who is aware of Lightbox and can combine multiple light sources to mimic the authentic light source. Lightbox achieved the overall accuracy over 99% for the saturation attacker and simple spoofing attacker, and robustness against a sophisticated attacker. We also evaluated Lightbox considering various environments such as transmission medium, background noise, and input waveform. Finally, we demonstrate the practicality of Lightbox with experiments using a single-board computer after further reducing the training time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385954365",
    "type": "article"
  },
  {
    "title": "<i>OptiClass</i> : An Optimized Classifier for Application Layer Protocols Using Bit Level Signatures",
    "doi": "https://doi.org/10.1145/3633777",
    "publication_date": "2023-11-22",
    "publication_year": 2023,
    "authors": "Mayank Swarnkar; Neha Sharma",
    "corresponding_authors": "",
    "abstract": "Network traffic classification has many applications, such as security monitoring, quality of service, traffic engineering, and so on. For the aforementioned applications, Deep Packet Inspection (DPI) is a popularly used technique for traffic classification because it scrutinizes the payload and provides comprehensive information for accurate analysis of network traffic. However, DPI-based methods reduce network performance because they are computationally expensive and hinder end-user privacy as they analyze the payload. To overcome these challenges, bit-level signatures are significantly used to perform network traffic classification. However, most of these methods still need to improve performance as they perform one-by-one signature matching of unknown payloads with application signatures for classification. Moreover, these methods become stagnant with the increase in application signatures. Therefore, to fill this gap, we propose OptiClass , an optimized classifier for application protocols using bit-level signatures. OptiClass performs parallel application signature matching with unknown flows, which results in faster, more accurate, and more efficient network traffic classification. OptiClass achieves twofold performance gains compared to the state-of-the-art methods. First, OptiClass generates bit-level signatures of just 32 bits for all the applications. This keeps OptiClass swift and privacy-preserving. Second, OptiClass uses a novel data structure called BiTSPLITTER for signature matching for fast and accurate classification. We evaluated the performance of OptiClass on three datasets consisting of twenty application protocols. Experimental results report that OptiClass has an average recall, precision, and F1-score of 97.36%, 97.38%, and 97.37%, respectively, and an average classification speed of 9.08 times faster than five closely related state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388912804",
    "type": "article"
  },
  {
    "title": "Security analysis of VMs on the cloud",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "D Rolles; Lucas McDaniel",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2945497969",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3316298",
    "publication_date": "2019-04-10",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Software-defined networking (SDN) decouples the control and data planes of traditional networks, logically centralizing the functional properties of the network in the SDN controller. While this centralization brought advantages such as a faster pace of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238205690",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3232648",
    "publication_date": "2018-10-13",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Vulnerability remediation is a critical task in operational software and network security management. In this article, an effective vulnerability management strategy, called VULCON (VULnerability CONtrol), is developed and evaluated. The strategy is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240719445",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3175499",
    "publication_date": "2018-02-24",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Recent compilers allow a general-purpose program (written in a conventional programming language) that handles private data to be translated into a secure distributed implementation of the corresponding functionality. The resulting program is then ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244414553",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3171591",
    "publication_date": "2018-01-06",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We introduce the first known mechanism providing realtime server location verification. Its uses include enhancing server authentication by enabling browsers to automatically interpret server location information. We describe the design of this new ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247232347",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3328797",
    "publication_date": "2019-07-19",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Private record linkage protocols allow multiple parties to exchange matching records, which refer to the same entities or have similar values, while keeping the non-matching ones secret. Conventional protocols are based on computationally expensive ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250653609",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3287762",
    "publication_date": "2019-01-23",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Multi-tenancy in the cloud is a double-edged sword. While it enables cost-effective resource sharing, it increases security risks for the hosted applications. Indeed, multiplexing virtual resources belonging to different tenants on the same physical ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252649469",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3364835",
    "publication_date": "2019-12-17",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Location-Based Services (LBSs) provide valuable services, with convenient features for mobile users. However, the location and other information disclosed through each query to the LBS erodes user privacy. This is a concern especially because LBS ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254594120",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3208360",
    "publication_date": "2018-06-02",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The significant growth of banking fraud, fueled by the underground economy of malware, has raised the need for effective detection systems. Therefore, in the last few years, banks have upgraded their security to protect transactions from fraud. State-of-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255152641",
    "type": "paratext"
  },
  {
    "title": "Measuring and Analysing the Chain of Implicit Trust",
    "doi": "https://doi.org/10.1145/3380466",
    "publication_date": "2020-04-28",
    "publication_year": 2020,
    "authors": "Muhammad Ikram; Rahat Masood; Gareth Tyson; Mohamed Ali Kâafar; Noha Loizon; Roya Ensafi",
    "corresponding_authors": "",
    "abstract": "The web is a tangled mass of interconnected services, whereby websites import a range of external resources from various third-party domains. The latter can also load further resources hosted on other domains. For each website, this creates a dependency chain underpinned by a form of implicit trust between the first-party and transitively connected third parties. The chain can only be loosely controlled as first-party websites often have little, if any, visibility on where these resources are loaded from. This article performs a large-scale study of dependency chains in the web to find that around 50% of first-party websites render content that they do not directly load. Although the majority (84.91%) of websites have short dependency chains (below three levels), we find websites with dependency chains exceeding 30. Using VirusTotal, we show that 1.2% of these third parties are classified as suspicious—although seemingly small, this limited set of suspicious third parties have remarkable reach into the wider ecosystem. We find that 73% of websites under-study load resources from suspicious third parties, and 24.8% of first-party webpages contain at least three third parties classified as suspicious in their dependency chain. By running sandboxed experiments, we observe a range of activities with the majority of suspicious JavaScript codes downloading malware.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3023348505",
    "type": "article"
  },
  {
    "title": "Exploiting Behavioral Side Channels in Observation Resilient Cognitive Authentication Schemes",
    "doi": "https://doi.org/10.1145/3414844",
    "publication_date": "2020-09-28",
    "publication_year": 2020,
    "authors": "Benjamin Zi Hao Zhao; Hassan Jameel Asghar; Mohamed Ali Kâafar; Francesca Trevisan; Haiyue Yuan",
    "corresponding_authors": "",
    "abstract": "Observation Resilient Authentication Schemes (ORAS) are a class of shared secret challenge–response identification schemes where a user mentally computes the response via a cognitive function to authenticate herself such that eavesdroppers cannot readily extract the secret. Security evaluation of ORAS generally involves quantifying information leaked via observed challenge–response pairs. However, little work has evaluated information leaked via human behavior while interacting with these schemes. A common way to achieve observation resilience is by including a modulus operation in the cognitive function. This minimizes the information leaked about the secret due to the many-to-one map from the set of possible secrets to a given response. In this work, we show that user behavior can be used as a side channel to obtain the secret in such ORAS. Specifically, the user’s eye-movement patterns and associated timing information can deduce whether a modulus operation was performed (a fundamental design element) to leak information about the secret. We further show that the secret can still be retrieved if the deduction is erroneous, a more likely case in practice. We treat the vulnerability analytically and propose a generic attack algorithm that iteratively obtains the secret despite the “faulty” modulus information. We demonstrate the attack on five ORAS and show that the secret can be retrieved with considerably less challenge–response pairs than non-side-channel attacks (e.g., algebraic/statistical attacks). In particular, our attack is applicable on Mod10, a one-time-pad-based scheme, for which no non-side-channel attack exists. We field test our attack with a small-scale eye-tracking user study.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3089170408",
    "type": "article"
  },
  {
    "title": "Privacy Analysis of Query-Set-Size Control",
    "doi": "https://doi.org/10.1145/3532774",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Eyal Nussbaum; Michael Segal",
    "corresponding_authors": "",
    "abstract": "The publication of user data for statistical analysis and research can be extremely beneficial for both academic and commercial uses, such as statistical research and recommendation systems. To maintain user privacy when such a publication occurs many databases employ anonymization techniques, either on the query results or the data itself. In this article, we examine and analyze the privacy offered when using the query-set-size control method for aggregate queries over a data structures representing various topologies. We focus on the mathematical queries of minimum, maximum, median, and average and show some query types that may be used to extract hidden information. We prove some combinations of these queries will maintain a measurable level of privacy even when using multiple queries. We offer a privacy probability measure, indicating the probability of an attacker to obtain information defined as sensitive by utilizing legitimate queries over such a system. Our results are mathematically proven and backed by simulations using vehicular network data based on the TAPASCologne project.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4225275060",
    "type": "article"
  },
  {
    "title": "Log-related Coding Patterns to Conduct Postmortems of Attacks in Supervised Learning-based Projects",
    "doi": "https://doi.org/10.1145/3568020",
    "publication_date": "2022-12-14",
    "publication_year": 2022,
    "authors": "Farzana Ahamed Bhuiyan; Akond Rahman",
    "corresponding_authors": "",
    "abstract": "Adversarial attacks against supervised learning a algorithms, which necessitates the application of logging while using supervised learning algorithms in software projects. Logging enables practitioners to conduct postmortem analysis, which can be helpful to diagnose any conducted attacks. We conduct an empirical study to identify and characterize log-related coding patterns, i.e., recurring coding patterns that can be leveraged to conduct adversarial attacks and needs to be logged. A list of log-related coding patterns can guide practitioners on what to log while using supervised learning algorithms in software projects. We apply qualitative analysis on 3,004 Python files used to implement 103 supervised learning-based software projects. We identify a list of 54 log-related coding patterns that map to six attacks related to supervised learning algorithms. Using Lo g Assistant to conduct P ostmortems for Su pervised L earning ( LOPSUL ) , we quantify the frequency of the identified log-related coding patterns with 278 open-source software projects that use supervised learning. We observe log-related coding patterns to appear for 22% of the analyzed files, where training data forensics is the most frequently occurring category.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4311491592",
    "type": "article"
  },
  {
    "title": "Towards Better Understanding of User Authorization Query Problem via Multi-variable Complexity Analysis",
    "doi": "https://doi.org/10.1145/3450768",
    "publication_date": "2021-08-19",
    "publication_year": 2021,
    "authors": "Jason Crampton; Gregory Gutin; Diptapriyo Majumdar",
    "corresponding_authors": "",
    "abstract": "User authorization queries in the context of role-based access control have attracted considerable interest in the past 15 years. Such queries are used to determine whether it is possible to allocate a set of roles to a user that enables the user to complete a task, in the sense that all the permissions required to complete the task are assigned to the roles in that set. Answering such a query, in general, must take into account a number of factors, including, but not limited to, the roles to which the user is assigned and constraints on the sets of roles that can be activated. Answering such a query is known to be NP-hard. The presence of multiple parameters and the need to find efficient and exact solutions to the problem suggest that a multi-variate approach will enable us to better understand the complexity of the user authorization query problem (UAQ). In this article, we establish a number of complexity results for UAQ. Specifically, we show the problem remains hard even when quite restrictive conditions are imposed on the structure of the problem. Our fixed-parameter tractable (FPT) results show that we have to use either a parameter with potentially quite large values or quite a restricted version of UAQ. Moreover, our second FPT algorithm is complex and requires sophisticated, state-of-the-art techniques. In short, our results show that it is unlikely that all variants of UAQ that arise in practice can be solved reasonably quickly in general.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3193733816",
    "type": "article"
  },
  {
    "title": "Secure Selections on Encrypted Multi-writer Streams",
    "doi": "https://doi.org/10.1145/3485470",
    "publication_date": "2021-11-23",
    "publication_year": 2021,
    "authors": "Angelo Massimo Perillo; Giuseppe Persiano; Alberto Trombetta",
    "corresponding_authors": "",
    "abstract": "Performing searches over encrypted data is a very current and active area. Several efficient solutions have been provided for the single-writer scenario in which all sensitive data originate with one party (the Data Owner ) that encrypts and uploads the data to a public repository. Subsequently, the Data Owner accesses the encrypted data through a Query Processor , which has direct access to the public encrypted repository. Motivated by the recent trend in pervasive data collection, we depart from this model and consider a multi-writer scenario in which the data originate with several and mutually untrusted parties, the Data Sources . In this new scenario, the Data Owner provides public parameters so that each Data Source can add encrypted items to the public encrypted stream; moreover, the Data Owner keeps some related secret information needed to generate tokens so that different Query Sources can decrypt different subsets of the encrypted stream, as specified by corresponding access policies. We propose security model for this problem that we call Secure Selective Stream ( SSS ) and give a secure construction for it based on hard problems in Pairing-Based Cryptography. The cryptographic core of our construction is a new primitive, Amortized Orthogonality Encryption , that is crucial for the efficiency of the proposed implementation for SSS .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3215956322",
    "type": "article"
  }
]